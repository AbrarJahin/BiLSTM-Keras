phrase,sentances
nearly constant time per retrieval,Hash functions and their associated hash tables are used in data storage and retrieval applications to access data in a small and nearly constant time per retrieval.
intolerably bad,"Use of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision)."
often confused,"Hash functions are related to (and often confused with) checksums, check digits, fingerprints, lossy compression, randomization functions, error-correcting codes, and ciphers."
may improve,"In artificial intelligence, an intelligent agent (IA) is anything which perceives its environment, takes actions autonomously in order to achieve goals, and may improve its performance with learning or may use knowledge."
may use knowledge,"In artificial intelligence, an intelligent agent (IA) is anything which perceives its environment, takes actions autonomously in order to achieve goals, and may improve its performance with learning or may use knowledge."
achieve goals,"In artificial intelligence, an intelligent agent (IA) is anything which perceives its environment, takes actions autonomously in order to achieve goals, and may improve its performance with learning or may use knowledge."
many interdisciplinary socio,"Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations."
closely related,"Automata theory is closely related to formal language theory. !! In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called ""Bayesian probability"". !! Type theory is closely related to, and in some cases overlaps with, type systems, which are a programming language feature used to reduce bugs and facilitate certain compiler optimizations. !! Human-centered computing is closely related to human-computer interaction and information science. !! Parallel programming models are closely related to models of computation. !! Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains. !! The generalized Shanks transformation is closely related to Pad approximants and Pad tables. !! Mathematical induction in this extended sense is closely related to recursion. !! Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network. !! The longest increasing subsequence problem is closely related to the longest common subsequence problem, which has a quadratic time dynamic programming solution: the longest increasing subsequence of a sequence S is the longest common subsequence of S and T, where T is the result of sorting S. However, for the special case in which the input is a permutation of the integers 1, 2, . !! Similarity learning is closely related to distance metric learning. !! Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations."
practical reason,"The concept of rational agents can be found in various disciplines such as artificial intelligence, cognitive science, decision theory, economics, ethics, game theory, and the study of practical reason. !! Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations."
often described schematically,Intelligent agents are often described schematically as an abstract functional system similar to a computer program.
used widely,"In a wide sense, a scientific programming language is a programming language that is used widely for computational science and computational mathematics."
wide sense,"In a wide sense, a scientific programming language is a programming language that is used widely for computational science and computational mathematics."
stronger sense,"In a stronger sense, a scientific programming language is one that is designed and optimized for the use of mathematical formula and matrices."
higher standards,"Scientific programming languages in the stronger sense include ALGOL, APL, Fortran, J, Julia, Maple, MATLAB and R. Scientific programming languages should not be confused with scientific language in general, which refers loosely to the higher standards in precision, correctness and concision expected from practitioners of the scientific method."
refers loosely,"Scientific programming languages in the stronger sense include ALGOL, APL, Fortran, J, Julia, Maple, MATLAB and R. Scientific programming languages should not be confused with scientific language in general, which refers loosely to the higher standards in precision, correctness and concision expected from practitioners of the scientific method."
specified explicitly,"Vertex normals can also be computed for polygonal approximations to surfaces such as NURBS, or specified explicitly for artistic purposes."
artistic purposes,"Vertex normals can also be computed for polygonal approximations to surfaces such as NURBS, or specified explicitly for artistic purposes."
phong shading,"Vertex normals are used in Gouraud shading, Phong shading and other lighting models."
cannot produce,"Using vertex normals, much smoother shading than flat shading can be achieved; however, without some modifications, it cannot produce a sharp edge."
much smoother shading,"Using vertex normals, much smoother shading than flat shading can be achieved; however, without some modifications, it cannot produce a sharp edge."
sharp edge,"Using vertex normals, much smoother shading than flat shading can be achieved; however, without some modifications, it cannot produce a sharp edge."
proteins online,Users can calculate solvent accessible surface area of the proteins online at http://curie.
calculate solvent accessible surface area,Users can calculate solvent accessible surface area of the proteins online at http://curie.
transfer free energy required,Accessible surface area is often used when calculating the transfer free energy required to move a biomolecule from aqueous solvent to a non-polar solvent such as a lipid environment.
often used,"Social affordance is most often used in the context of a social technology such as Wiki, Chat and Facebook applications and refers to sociotechnical affordances. !! Digital identity is now often used in ways that require data about persons stored in computer systems to be linked to their civil, or national, identities. !! A database dump is most often used for backing up a database so that its contents can be restored in the event of data loss. !! In linear algebra, a QR decomposition, also known as a QR factorization or QU factorization, is a decomposition of a matrix A into a product A = QR of an orthogonal matrix Q and an upper triangular matrix R. QR decomposition is often used to solve the linear least squares problem and is the basis for a particular eigenvalue algorithm, the QR algorithm. !! These prerequisites are known as (computer) system requirements and are often used as a guideline as opposed to an absolute rule. !! In numerical analysis, finite differences are widely used for approximating derivatives, and the term ""finite difference"" is often used as an abbreviation of ""finite difference approximation of derivatives"". !! An incomplete Cholesky factorization is often used as a preconditioner for algorithms like the conjugate gradient method. !! For example, kinetic data structures are often used with a set of points. !! Computational thinking can be used to algorithmically solve complicated problems of scale, and is often used to realize large improvements in efficiency. !! Amdahl's law is often used in parallel computing to predict the theoretical speedup when using multiple processors. !! Minimum degree algorithms are often used in the finite element method where the reordering of nodes can be carried out depending only on the topology of the mesh, rather than the coefficients in the partial differential equation, resulting in efficiency savings when the same mesh is used for a variety of coefficient values. !! Accessible surface area is often used when calculating the transfer free energy required to move a biomolecule from aqueous solvent to a non-polar solvent such as a lipid environment. !! In the theory of computation, abstract machines are often used in thought experiments regarding computability or to analyze the complexity of algorithms. !! Finite automata are often used in the frontend of programming language compilers. !! Hybrid algorithms are often used for efficiency, to reduce the overhead of recursion in small cases, and arm's-length recursion is a special case of this. !! Error detection and correction codes are often used to improve the reliability of data storage media. !! DLL injection is often used by external programs to influence the behavior of another program in a way its authors did not anticipate or intend. !! In analytic number theory, big O notation is often used to express a bound on the difference between an arithmetical function and a better understood approximation; a famous example of such a difference is the remainder term in the prime number theorem. !! Queueing theory is generally considered a branch of operations research because the results are often used when making business decisions about the resources needed to provide a service."
protein secondary structure,It is recently suggested that (predicted) accessible surface area can be used to improve prediction of protein secondary structure.
improve prediction,It is recently suggested that (predicted) accessible surface area can be used to improve prediction of protein secondary structure.
recently suggested,It is recently suggested that (predicted) accessible surface area can be used to improve prediction of protein secondary structure.
solvent accessible surface area,solvent accessible surface area and excluded volume in proteins.
excluded volume,solvent accessible surface area and excluded volume in proteins.
certain point,"In computing, a stack trace (also called stack backtrace or stack traceback) is a report of the active stack frames at a certain point in time during the execution of a program."
users may see,"End-users may see a stack trace displayed as part of an error message, which the user can then report to a programmer."
necessary condition,Necessary condition: a Hurwitz stable polynomial (with real coefficients) has coefficients of the same sign (either all positive or all negative).
various definitions,"Solution architecture, term used in information technology with various definitions such as; ""A description of a discrete and focused business operation or activity and how IS/IT supports that operation""."
term used,"Polymorphic association is a term used in discussions of Object-Relational Mapping with respect to the problem of representing in the relational database domain, a relationship from one class to multiple classes. !! Solution architecture, term used in information technology with various definitions such as; ""A description of a discrete and focused business operation or activity and how IS/IT supports that operation"". !! In natural language processing (NLP), word embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning. !! Neural dust is a term used to refer to millimeter-sized devices operated as wirelessly powered nerve sensors; it is a type of braincomputer interface."
following three,"The Open Group's definition of Solution Architecture, as provided above, is accompanied by the following three from Scaled Agile, Gartner and Greefhorst/Proper."
open group,"The Open Group's definition of Solution Architecture, as provided above, is accompanied by the following three from Scaled Agile, Gartner and Greefhorst/Proper. !! Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures."
specific solution,Gartner (2013) A solution architecture (SA) is an architectural description of a specific solution.
solution within,"As such, it concerns those properties of a solution that are necessary and sufficient to meet its essential requirementsA typical property of Solution Architecture, in contrast to other flavours of Enterprise Architecture, is that it often seeks to define a solution within the context of a project or initiative."
often seeks,"As such, it concerns those properties of a solution that are necessary and sufficient to meet its essential requirementsA typical property of Solution Architecture, in contrast to other flavours of Enterprise Architecture, is that it often seeks to define a solution within the context of a project or initiative."
essential requirementsa typical property,"As such, it concerns those properties of a solution that are necessary and sufficient to meet its essential requirementsA typical property of Solution Architecture, in contrast to other flavours of Enterprise Architecture, is that it often seeks to define a solution within the context of a project or initiative."
observed values,"In machine learning, sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values."
common example,"A common example of a sequence labeling task is part of speech tagging, which seeks to assign a part of speech to each word in an input sentence or document."
one per member,"Sequence labeling can be treated as a set of independent classification tasks, one per member of the sequence."
independent classification tasks,"Sequence labeling can be treated as a set of independent classification tasks, one per member of the sequence."
particular word,"The most common statistical models in use for sequence labeling make a Markov assumption, i. e. that the choice of label for a particular word is directly dependent only on the immediately adjacent labels; hence the set of labels forms a Markov chain."
finds use among,There are many different matrix decompositions; each finds use among a particular class of problems.
state diagrams require,"State diagrams require that the system described is composed of a finite number of states; sometimes, this is indeed the case, while at other times this is a reasonable abstraction."
finite number,"A digital signal is a signal that represents data as a sequence of discrete values; at any given time it can only take on, at most, one of a finite number of values. !! State diagrams require that the system described is composed of a finite number of states; sometimes, this is indeed the case, while at other times this is a reasonable abstraction. !! In optimization theory, semi-infinite programming (SIP) is an optimization problem with a finite number of variables and an infinite number of constraints, or an infinite number of variables and a finite number of constraints."
differ slightly,"Many forms of state diagrams exist, which differ slightly and have different semantics."
many forms,"Many forms of state diagrams exist, which differ slightly and have different semantics."
final stage,"The block Lanczos algorithm is amongst the most efficient methods known for finding nullspaces, which is the final stage in integer factorization algorithms such as the quadratic sieve and number field sieve, and its development has been entirely driven by this application."
entirely driven,"The block Lanczos algorithm is amongst the most efficient methods known for finding nullspaces, which is the final stage in integer factorization algorithms such as the quadratic sieve and number field sieve, and its development has been entirely driven by this application."
efficient methods known,"The block Lanczos algorithm is amongst the most efficient methods known for finding nullspaces, which is the final stage in integer factorization algorithms such as the quadratic sieve and number field sieve, and its development has been entirely driven by this application."
also support,"In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis."
relatively new area,Posthoc interpretation of support-vector machine models in order to identify features used by the model to make predictions is a relatively new area of research with special significance in the biological sciences.
two different versions,"The fact that the shape context is a rich and discriminative descriptor can be seen in the figure below, in which the shape contexts of two different versions of the letter ""A"" are shown."
representing solutions,"In computer programming, genetic representation is a way of representing solutions/individuals in evolutionary computation methods."
hard problem,Designing a good genetic representation that is expressive and evolvable is a hard problem in evolutionary computation.
main property,The main property that makes these genetic representations convenient is that their parts are easily aligned due to their fixed size.
mental weaknesses,Video game rehabilitation is a process of using common video game consoles and methodology to target and improve physical and mental weaknesses through therapeutic processes.
improve physical,Video game rehabilitation is a process of using common video game consoles and methodology to target and improve physical and mental weaknesses through therapeutic processes.
therapeutic processes,Video game rehabilitation is a process of using common video game consoles and methodology to target and improve physical and mental weaknesses through therapeutic processes.
alternative leisure actives,"Also,Wii Sports in Video Game Rehabilitation benefit the patient's recovery and provide motivation for alternative leisure actives."
video game rehabilitation benefit,"Also,Wii Sports in Video Game Rehabilitation benefit the patient's recovery and provide motivation for alternative leisure actives."
wii sports,"Also,Wii Sports in Video Game Rehabilitation benefit the patient's recovery and provide motivation for alternative leisure actives."
provide motivation,"Also,Wii Sports in Video Game Rehabilitation benefit the patient's recovery and provide motivation for alternative leisure actives."
using video game rehabilitation,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
based conclusions,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
cerebral palsy,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
compare outcomes,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
reach evidence,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
great interest,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
expanding outside,"Expanding outside of virtual reality and gaming systems, a newer segment of video game rehabilitation focuses on games that can be played on mobile phones or tablet computers - mobile apps."
video game rehabilitation focuses,"Expanding outside of virtual reality and gaming systems, a newer segment of video game rehabilitation focuses on games that can be played on mobile phones or tablet computers - mobile apps."
newer segment,"Expanding outside of virtual reality and gaming systems, a newer segment of video game rehabilitation focuses on games that can be played on mobile phones or tablet computers - mobile apps."
another challenge,"Another challenge in video game rehabilitation, can result to lack of computer skills on the part of therapists, lack of support infrastructure, expensive equipment, inadequate communication infrastructure, and patient safety concerns."
support infrastructure,"Another challenge in video game rehabilitation, can result to lack of computer skills on the part of therapists, lack of support infrastructure, expensive equipment, inadequate communication infrastructure, and patient safety concerns."
expensive equipment,"Another challenge in video game rehabilitation, can result to lack of computer skills on the part of therapists, lack of support infrastructure, expensive equipment, inadequate communication infrastructure, and patient safety concerns."
inadequate communication infrastructure,"Another challenge in video game rehabilitation, can result to lack of computer skills on the part of therapists, lack of support infrastructure, expensive equipment, inadequate communication infrastructure, and patient safety concerns."
richard snodgrass proposed,Richard Snodgrass proposed in 1992 that temporal extensions to SQL be developed by the temporal database community.
typically refers,"The term ""deterministic global optimization"" typically refers to complete or rigorous (see below) optimization methods."
user desires,"Deterministic global optimization methods are typically used when locating the global solution is a necessity (i. e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user desires to locate the best possible solution to a problem."
feasible solution,"Deterministic global optimization methods are typically used when locating the global solution is a necessity (i. e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user desires to locate the best possible solution to a problem."
typically used,"Deterministic global optimization methods are typically used when locating the global solution is a necessity (i. e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user desires to locate the best possible solution to a problem. !! Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system. !! Therefore, brute-force search is typically used when the problem size is limited, or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size. !! Link spectral efficiency is typically used to analyse the efficiency of a digital modulation method or line code, sometimes in combination with a forward error correction (FEC) code and other physical layer overhead. !! The counter machine is typically used in the process of designing parallel algorithms in relation to the mutual exclusion principle. !! Median cut is typically used for color quantization. !! Random-access memory (RAM; ) is a form of computer memory that can be read and changed in any order, typically used to store working data and machine code. !! Code words are typically used for reasons of reliability, clarity, brevity, or secrecy. !! Block diagrams are typically used for higher level, less detailed descriptions that are intended to clarify overall concepts without concern for the details of implementation."
extremely difficult,"Computational archaeology may include the use of geographical information systems (GIS), especially when applied to spatial analyses such as viewshed analysis and least-cost path analysis as these approaches are sufficiently computationally complex that they are extremely difficult if not impossible to implement without the processing power of a computer. !! Deterministic global optimization methods are typically used when locating the global solution is a necessity (i. e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user desires to locate the best possible solution to a problem."
naturally occurring state described,"Deterministic global optimization methods are typically used when locating the global solution is a necessity (i. e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user desires to locate the best possible solution to a problem."
best possible solution,"Deterministic global optimization methods are typically used when locating the global solution is a necessity (i. e. when the only naturally occurring state described by a mathematical model is the global minimum of an optimization problem), when it is extremely difficult to find a feasible solution, or simply when the user desires to locate the best possible solution to a problem."
last two categories,Deterministic global optimization methods typically belong to the last two categories.
remarkably good properties,Lexicographic codes or lexicodes are greedily generated error-correcting codes with remarkably good properties.
closely connected,The theory of lexicographic codes is closely connected to combinatorial game theory.
winning positions,"In particular, the codewords in a binary lexicographic code of distance d encode the winning positions in a variant of Grundy's game, played on a collection of heaps of stones, in which each move consists of replacing any one heap by at most d 1 smaller heaps, and the goal is to take the last stone."
move consists,"In particular, the codewords in a binary lexicographic code of distance d encode the winning positions in a variant of Grundy's game, played on a collection of heaps of stones, in which each move consists of replacing any one heap by at most d 1 smaller heaps, and the goal is to take the last stone."
edges whose removal would partition,"In mathematics, the minimum k-cut, is a combinatorial optimization problem that requires finding a set of edges whose removal would partition the graph to at least k connected components."
requires finding,"In mathematics, the minimum k-cut, is a combinatorial optimization problem that requires finding a set of edges whose removal would partition the graph to at least k connected components."
concept extends,"Most manifold alignment techniques consider only two data sets, but the concept extends to arbitrarily many initial data sets."
indicates whether,"A fuzzy classification corresponds to a membership function that indicates whether an individual is a member of a class, given its fuzzy classification predicate ~."
fuzzy set defined,"The fuzzy classification predicate ~ corresponds to a fuzzy restriction ""i is R"" of U, where R is a fuzzy set defined by a truth function."
also visually,"An immersive virtual musical instrument, or immersive virtual environment for music and sound, represents sound processes and their parameters as 3D entities of a virtual reality so that they can be perceived not only through auditory feedback but also visually in 3D and possibly through tactile as well as haptic feedback, using 3D interface metaphors consisting of interaction techniques such as navigation, selection and manipulation (NSM)."
practices surrounding,"Human-centered computing is usually concerned with systems and practices of technology use while human-computer interaction is more focused on ergonomics and the usability of computing artifacts and information science is focused on practices surrounding the collection, manipulation, and use of information."
usually concerned,"Human-centered computing is usually concerned with systems and practices of technology use while human-computer interaction is more focused on ergonomics and the usability of computing artifacts and information science is focused on practices surrounding the collection, manipulation, and use of information."
practitioners usually come,"Human-centered computing researchers and practitioners usually come from one or more of disciplines such as computer science, human factors, sociology, psychology, cognitive science, anthropology, communication studies, graphic design and industrial design."
specific types,"Specific types of parsimonious reductions may be defined by the computational complexity or other properties of the transformation algorithm. !! The network architecture of the Internet is predominantly expressed by its use of the Internet protocol suite, rather than a specific model for interconnecting networks or nodes in the network, or the usage of specific types of hardware links."
specific model,"The network architecture of the Internet is predominantly expressed by its use of the Internet protocol suite, rather than a specific model for interconnecting networks or nodes in the network, or the usage of specific types of hardware links."
predominantly expressed,"The network architecture of the Internet is predominantly expressed by its use of the Internet protocol suite, rather than a specific model for interconnecting networks or nodes in the network, or the usage of specific types of hardware links."
often referred,"The same problem may have multiple distinct neighborhoods defined on it; local optimization with neighborhoods that involve changing up to k components of the solution is often referred to as k-opt. !! The contents of the database are encrypted using a symmetric key that is often referred to as a ""database encryption key"". !! In distributed computing, the network architecture often describes the structure and classification of a distributed application architecture, as the participating nodes in a distributed application are often referred to as a network. !! The boundaries of the polytopes, the data dependencies, and the transformations are often described using systems of constraints, and this approach is often referred to as a constraint-based approach to loop optimization."
required distinguishing spaces,"Geometric topology as an area distinct from algebraic topology may be said to have originated in the 1935 classification of lens spaces by Reidemeister torsion, which required distinguishing spaces that are homotopy equivalent but not homeomorphic."
area distinct,"Geometric topology as an area distinct from algebraic topology may be said to have originated in the 1935 classification of lens spaces by Reidemeister torsion, which required distinguishing spaces that are homotopy equivalent but not homeomorphic."
reidemeister torsion,"Geometric topology as an area distinct from algebraic topology may be said to have originated in the 1935 classification of lens spaces by Reidemeister torsion, which required distinguishing spaces that are homotopy equivalent but not homeomorphic."
perfectly reconstructed,Lossless compression is a class of data compression that allows the original data to be perfectly reconstructed from the compressed data.
two things,"Most lossless compression programs do two things in sequence: the first step generates a statistical model for the input data, and the second step uses this model to map input data to bit sequences in such a way that ""probable"" (e. g. frequently encountered) data will produce shorter output than ""improbable"" data."
second step uses,"Most lossless compression programs do two things in sequence: the first step generates a statistical model for the input data, and the second step uses this model to map input data to bit sequences in such a way that ""probable"" (e. g. frequently encountered) data will produce shorter output than ""improbable"" data."
formally speaking,"Finite-state machine-based programming is generally the same, but, formally speaking, does not cover all possible variants, as FSM stands for finite-state machine, and automata-based programming does not necessarily employ FSMs in the strict sense."
possible variants,"Finite-state machine-based programming is generally the same, but, formally speaking, does not cover all possible variants, as FSM stands for finite-state machine, and automata-based programming does not necessarily employ FSMs in the strict sense."
thinking used,"Another reason for using the notion of automata-based programming is that the programmer's style of thinking about the program in this technique is very similar to the style of thinking used to solve mathematical tasks using Turing machines, Markov algorithms, etc."
another reason,"Another reason for using the notion of automata-based programming is that the programmer's style of thinking about the program in this technique is very similar to the style of thinking used to solve mathematical tasks using Turing machines, Markov algorithms, etc."
widely used,"Different syntaxes for writing regular expressions have existed since the 1980s, one being the POSIX standard and another, widely used, being the Perl syntax. !! Householder transformations are widely used in numerical linear algebra, for example, to annihilate the entries below the main diagonal of a matrix, to perform QR decompositions and in the first step of the QR algorithm. !! Evidence shows that software metrics are being widely used by government agencies, the US military, NASA, IT consultants, academic institutions, and commercial and academic development estimation software. !! Nonlinear optimization methods are widely used in conformational analysis. !! In numerical analysis, finite differences are widely used for approximating derivatives, and the term ""finite difference"" is often used as an abbreviation of ""finite difference approximation of derivatives"". !! Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known. !! A well-known example implicitly using additive state decomposition is the Superposition Principle, widely used in physics and engineering. !! However, typical research in quantum neural networks involves combining classical artificial neural network models (which are widely used in machine learning for the important task of pattern recognition) with the advantages of quantum information in order to develop more efficient algorithms. !! Automata-based programming is widely used in lexical and syntactic analyses. !! Computer algebra is widely used to experiment in mathematics and to design the formulas that are used in numerical programs. !! A probabilistic neural network (PNN) is a feedforward neural network, which is widely used in classification and pattern recognition problems. !! Because the spectral centroid is a good predictor of the ""brightness"" of a sound, it is widely used in digital audio and music processing as an automatic measure of musical timbre. !! Therefore, a subobject classifier is also known as a ""truth value object"" and the concept is widely used in the categorical description of logic."
person perceives,"User experience evaluation (UXE) or user experience assessment (UXA) refers to a collection of methods, skills and tools utilized to uncover how a person perceives a system (product, service, non-commercial item, or a combination of them) before, during and after interacting with it."
centered design practices,"User experience evaluation has become common practice in web design, especially within organizations implementing user-centered design practices."
become common practice,"User experience evaluation has become common practice in web design, especially within organizations implementing user-centered design practices."
major problem,Data sparsity is a major problem in building language models.
beyond compare,"Some widely used file comparison programs are diff, cmp, FileMerge, WinMerge, Beyond Compare, and File Compare."
also known,"Similarly, an external node (also known as an outer node, leaf node, or terminal node) is any node that does not have child nodes. !! In statistics, originally in geostatistics, kriging or Kriging, also known as Gaussian process regression, is a method of interpolation based on Gaussian process governed by prior covariances. !! In computing, the Red Hat Virtual Machine Manager, also known as virt-manager, is a desktop virtual machine monitor. !! In numerical analysis, inverse iteration (also known as the inverse power method) is an iterative eigenvalue algorithm. !! Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scaling. !! In cryptography, a Caesar cipher, also known as Caesar's cipher, the shift cipher, Caesar's code or Caesar shift, is one of the simplest and most widely known encryption techniques. !! Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes. !! Interface-based programming, also known as interface-based architecture, is an architectural pattern for implementing modular programming at the component level in an object-oriented programming language which does not have a module system. !! In software engineering, version control (also known as revision control, source control, or source code management) is a class of systems responsible for managing changes to computer programs, documents, large web sites, or other collections of information. !! Computational science, also known as scientific computing or scientific computation (SC), is a rapidly growing field that uses advanced computing capabilities to understand and solve complex problems. !! Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning. !! Synchronization Models, also known as Configuration Management Models (Feiler, 1991), describe methods to enable revision control through allowing simultaneous, concurrent changes to individual files. !! Computational lithography (also known as computational scaling) is the set of mathematical and algorithmic approaches designed to improve the resolution attainable through photolithography. !! A digital image is an image composed of picture elements, also known as pixels, each with finite, discrete quantities of numeric representation for its intensity or gray level that is an output from its two-dimensional functions fed as input by its spatial coordinates denoted with x, y on the x-axis and y-axis, respectively. !! The greedy randomized adaptive search procedure (also known as GRASP) is a metaheuristic algorithm commonly applied to combinatorial optimization problems. !! The instruction cycle (also known as the fetchdecodeexecute cycle, or simply the fetch-execute cycle) is the cycle that the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions. !! Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information. !! In mathematics, a submodular set function (also known as a submodular function) is a set function whose value, informally, has the property that the difference in the incremental value of the function that a single element makes when added to an input set decreases as the size of the input set increases. !! Computability theory, also known as recursion theory, is a branch of mathematical logic, computer science, and the theory of computation that originated in the 1930s with the study of computable functions and Turing degrees. !! Code stylometry (also known as program authorship attribution or source code authorship analysis) is the application of stylometry to computer code to attribute authorship to anonymous binary or source code. !! The parameters of a hidden Markov model are of two types, transition probabilities and emission probabilities (also known as output probabilities). !! Shortest remaining time, also known as shortest remaining time first (SRTF), is a scheduling method that is a preemptive version of shortest job next scheduling. !! Computational archaeology is also known as ""archaeological informatics"" (Burenhult 2002, Huggett and Ross 2004) or ""archaeoinformatics"" (sometimes abbreviated as ""AI"", but not to be confused with artificial intelligence). !! In computer science, graph traversal (also known as graph search) refers to the process of visiting (checking and/or updating) each vertex in a graph. !! In computer science, Prim's algorithm (also known as Jarnk's algorithm) is a greedy algorithm that finds a minimum spanning tree for a weighted undirected graph. !! In computer science, model checking or property checking is a method for checking whether a finite-state model of a system meets a given specification (also known as correctness). !! Legacy modernization, also known as software modernization or platform modernization, refers to the conversion, rewriting or porting of a legacy system to modern computer programming languages, architectures (e. g. microservices), software libraries, protocols or hardware platforms. !! In linear algebra, a QR decomposition, also known as a QR factorization or QU factorization, is a decomposition of a matrix A into a product A = QR of an orthogonal matrix Q and an upper triangular matrix R. QR decomposition is often used to solve the linear least squares problem and is the basis for a particular eigenvalue algorithm, the QR algorithm. !! A wearable computer, also known as a wearable or body-borne computer, is a computing device worn on the body. !! Data Stream Mining (also known as stream learning) is the process of extracting knowledge structures from continuous, rapid data records. !! Such methods may be achieved by rewriting systems (also known as rewrite systems, rewrite engines, or reduction systems). !! The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden. !! In mathematics and computer science, a string metric (also known as a string similarity metric or string distance function) is a metric that measures distance (""inverse similarity"") between two text strings for approximate string matching or comparison and in fuzzy string searching. !! Raw data, also known as primary data, are data (e. g. , numbers, instrument readings, figures, etc. ) !! Stack search (also known as Stack decoding algorithm) is a search algorithm similar to beam search. !! Defining sets by properties is also known as set comprehension, set abstraction or as defining a set's intension. !! In linear algebra, a Householder transformation (also known as a Householder reflection or elementary reflector) is a linear transformation that describes a reflection about a plane or hyperplane containing the origin. !! A Bayesian network (also known as a Bayes network, Bayes net, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG). !! Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously. !! In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array. !! Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. !! Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length. !! While neural dust does fall under the category of BCI, it also could be used in the field of neuroprosthetics (also known as neural prosthetics). !! In numerical linear algebra, the tridiagonal matrix algorithm, also known as the Thomas algorithm (named after Llewellyn Thomas), is a simplified form of Gaussian elimination that can be used to solve tridiagonal systems of equations. !! Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. !! The idea of a rational agent is important to the philosophy of utilitarianism, as detailed by philosopher Jeremy Bentham's theory of the felicific calculus, also known as the hedonistic calculus. !! In statistics, linear regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables). !! In algorithmic information theory, algorithmic probability, also known as Solomonoff probability, is a mathematical method of assigning a prior probability to a given observation. !! A scripting language can be viewed as a domain-specific language for a particular environment; in the case of scripting an application, it is also known as an extension language. !! Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism. !! It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). !! Weighted correlation network analysis, also known as weighted gene co-expression network analysis (WGCNA), is a widely used data mining method especially for studying biological networks based on pairwise correlations between variables. !! Proof by contradiction is also known as indirect proof, proof by assuming the opposite, and reductio ad impossibile. !! In physics, topological order is a kind of order in the zero-temperature phase of matter (also known as quantum matter). !! The most widely known string metric is a rudimentary one called the Levenshtein distance (also known as edit distance). !! Linear programming is a special case of mathematical programming (also known as mathematical optimization). !! Connectivity-based clustering, also known as hierarchical clustering, is based on the core idea of objects being more related to nearby objects than to objects farther away. !! In mathematics, ancient Egyptian multiplication (also known as Egyptian multiplication, Ethiopian multiplication, Russian multiplication, or peasant multiplication), one of two multiplication methods used by scribes, is a systematic method for multiplying two numbers that does not require the multiplication table, only the ability to multiply and divide by 2, and to add. !! are also known as truncated binary encoding. !! In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! In object-oriented programming, sequential coupling (also known as temporal coupling) is a form of coupling where a class requires its methods to be called in a particular sequence. !! Short-circuiting the base case, also known as arm's-length recursion, consists of checking the base case before making a recursive call i. e. , checking if the next call will be the base case, instead of calling and then checking for the base case. !! Cross-site request forgery, also known as one-click attack or session riding and abbreviated as CSRF (sometimes pronounced sea-surf) or XSRF, is a type of malicious exploit of a website where unauthorized commands are submitted from a user that the web application trusts. !! The shoelace formula, shoelace algorithm, or shoelace method (also known as Gauss's area formula and the surveyor's formula) is a mathematical algorithm to determine the area of a simple polygon whose vertices are described by their Cartesian coordinates in the plane. !! Lazy loading (also known as asynchronous loading) is a design pattern commonly used in computer programming and mostly in web design and development to defer initialization of an object until the point at which it is needed. !! Algorithmic art, also known as computer-generated art, is a subset of generative art (generated by an autonomous system) and is related to systems art (influenced by systems theory). !! Callback verification, also known as callout verification or Sender Address Verification, is a technique used by SMTP software in order to validate e-mail addresses. !! Therefore, a subobject classifier is also known as a ""truth value object"" and the concept is widely used in the categorical description of logic. !! The Distributed Tree Search Algorithm (also known as KorfFerguson algorithm) was created to solve the following problem: ""Given a tree with non-uniform branching factor and depth, search it in parallel with an arbitrary number of processors as fast as possible. """
methods may,"Such methods may be achieved by rewriting systems (also known as rewrite systems, rewrite engines, or reduction systems)."
changing one term,"Rewriting systems then do not provide an algorithm for changing one term to another, but a set of possible rule applications."
includes supporting planning,"Requirements management further includes supporting planning for requirements, integrating requirements and the organization for working with them (attributes for requirements), as well as relationships with other information delivering against requirements, and changes for these."
key role,"The ambiguity function plays a key role in the field of timefrequency signal processing, as it is related to the WignerVille distribution by a 2-dimensional Fourier transform. !! An accessibility relation is a relation which plays a key role in assigning truth values to sentences in the relational semantics for modal logic."
alternative scenarios,"Accessibility relations are motivated conceptually by the fact that natural language modal statements depend on some, but not all alternative scenarios."
suggest different restrictions,"Different applications of modal logic can suggest different restrictions on admissible accessibility relations, which can in turn lead to different validities."
create low,One such example is using mobile virtualization to create low-cost Android smartphones without a separate baseband processor by running the applications and the baseband processor code in separate virtual machines on a single processor.
another use case,Another use case for mobile virtualization is in the enterprise market.
important example,"In numerical linear algebra, the Arnoldi iteration is an eigenvalue algorithm and an important example of an iterative method."
important role,"""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks. !! Tree decompositions are also called junction trees, clique trees, or join trees; they play an important role in problems like probabilistic inference, constraint satisfaction, query optimization, and matrix decomposition. !! Reasoning systems play an important role in the implementation of artificial intelligence and knowledge-based systems. !! Graph theory plays an important role in electrical modeling of electrical networks, here, weights are associated with resistance of the wire segments to obtain electrical properties of network structures."
originally introduced,The concept of tree decompositions was originally introduced by Rudolf Halin (1976).
sometimes also known,"An object code optimizer, sometimes also known as a post pass optimizer or, for small sections of code, peephole optimizer, takes the output from a source language compile step - the object code or binary file - and tries to replace identifiable sections of the code with replacement code that is more algorithmically efficient (usually improved speed)."
small sections,"An object code optimizer, sometimes also known as a post pass optimizer or, for small sections of code, peephole optimizer, takes the output from a source language compile step - the object code or binary file - and tries to replace identifiable sections of the code with replacement code that is more algorithmically efficient (usually improved speed)."
authors use,"In linguistics, some authors use the term phrase structure grammar to refer to context-free grammars, whereby phrase-structure grammars are distinct from dependency grammars. !! More recently, authors use the term abstract rewriting system as well."
stanford university,"The uniform binary search was developed by A. K. Chandra of Stanford University in 1971. !! Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
support creating,"SQL-92 does not support creating or using table-valued columns, which means that using only the ""traditional relational database features"" (excluding extensions even if they were later standardized) most relational databases will be in first normal form by necessity."
valued columns,"SQL-92 does not support creating or using table-valued columns, which means that using only the ""traditional relational database features"" (excluding extensions even if they were later standardized) most relational databases will be in first normal form by necessity."
often called,"For this reason, the LDL decomposition is often called the square-root-free Cholesky decomposition. !! In the philosophy of decision theory, Bayesian inference is closely related to subjective probability, often called ""Bayesian probability"". !! Database systems which do not require first normal form are often called no sql systems."
constitute animal brains,"Artificial neural networks (ANNs), usually simply called neural networks (NNs), are computing systems inspired by the biological neural networks that constitute animal brains."
psychologist frank rosenblatt invented,"In 1958, psychologist Frank Rosenblatt invented the perceptron, the first artificial neural network, funded by the United States Office of Naval Research."
united states office,"In 1958, psychologist Frank Rosenblatt invented the perceptron, the first artificial neural network, funded by the United States Office of Naval Research."
naval research,"In 1958, psychologist Frank Rosenblatt invented the perceptron, the first artificial neural network, funded by the United States Office of Naval Research."
largely based,Logic programming is a programming paradigm which is largely based on formal logic.
formal logic,"The autoepistemic logic is a formal logic for the representation and reasoning of knowledge about knowledge. !! A counter machine is an abstract machine used in a formal logic and theoretical computer science to model computation. !! The term 'formal ontology' itself was coined by Edmund Husserl in the second edition of his Logical Investigations (190001), where it refers to an ontological counterpart of formal logic. !! Logic programming is a programming paradigm which is largely based on formal logic."
expressing facts,"Any program written in a logic programming language is a set of sentences in logical form, expressing facts and rules about some problem domain."
solving behaviour,"In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs."
also use,"In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs."
many applications especially,Topological sorting has many applications especially in ranking problems such as feedback arc set.
possible even,Topological sorting is possible even when the DAG has disconnected components.
disconnected components,Topological sorting is possible even when the DAG has disconnected components.
tasks based,The canonical application of topological sorting is in scheduling a sequence of jobs or tasks based on their dependencies.
closely related application,A closely related application of topological sorting algorithms was first studied in the early 1960s in the context of the PERT technique for scheduling in project management.
first studied,A closely related application of topological sorting algorithms was first studied in the early 1960s in the context of the PERT technique for scheduling in project management.
critical path,"Topological sorting forms the basis of linear-time algorithms for finding the critical path of the project, a sequence of milestones and tasks that controls the length of the overall project schedule."
overall project schedule,"Topological sorting forms the basis of linear-time algorithms for finding the critical path of the project, a sequence of milestones and tasks that controls the length of the overall project schedule."
one side,The classifier will classify all the points on one side of the decision boundary as belonging to one class and all those on the other side as belonging to the other class.
considered feasible,"computational learning theory, a computation is considered feasible if it can be done in polynomial time."
primary goal,"While its primary goal is to understand learning abstractly, computational learning theory has led to the development of practical algorithms."
selected bibliography,Computational learning theory: Survey and selected bibliography.
external factors,"The objective of the system context diagram is to focus attention on external factors and events that should be considered in developing a complete set of systems requirements and constraints. !! System context diagrams show a system, as a whole and its inputs and outputs from/to external factors."
used early,System context diagrams are used early in a project to get agreement on the scope under investigation.
get agreement,System context diagrams are used early in a project to get agreement on the scope under investigation.
easily deduced,"Many properties of matrices may be easily deduced from their row echelon form, such as the rank and the kernel."
many properties,"Because many properties of matrices and vectors also apply to functions and operators, numerical linear algebra can also be viewed as a type of functional analysis which has a particular emphasis on practical algorithms. !! Many properties of matrices may be easily deduced from their row echelon form, such as the rank and the kernel. !! Many properties of the real logarithm also apply to the logarithmic derivative, even when the function does not take values in the positive reals."
designs tasks,"Cognitive ergonomics is a scientific discipline that studies, evaluates, and designs tasks, jobs, products, environments and systems and how they interact with humans and their cognitive abilities."
persons understanding,"Cognitive ergonomics is responsible for how work is done in the mind, meaning, the quality of work is dependent on the persons understanding of situations."
optimize human well,"Cognitive ergonomics studies cognition in work and operational settings, in order to optimize human well-being and system performance."
sometimes known,"Backward compatibility (sometimes known as backwards compatibility) is a property of an operating system, product, or technology that allows for interoperability with an older legacy system, or with input designed for such a system, especially in telecommunications and computing. !! The opposite of lazy evaluation is eager evaluation, sometimes known as strict evaluation. !! With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others. !! Cognitive ergonomics (sometimes known as cognitive engineering though this was an earlier field) is an emerging branch of ergonomics."
emerging branch,Cognitive ergonomics (sometimes known as cognitive engineering though this was an earlier field) is an emerging branch of ergonomics.
earlier field,Cognitive ergonomics (sometimes known as cognitive engineering though this was an earlier field) is an emerging branch of ergonomics.
situation awareness,"Some cognitive ergonomics aims are: diagnosis, workload, situation awareness, decision making, and planning."
desired positive impacts,"Improving user experience is important to most companies, designers, and creators when creating and refining products because negative user experience can diminish the use of the product and, therefore, any desired positive impacts; conversely, designing toward profitability often conflicts with ethical user experience objectives and even causes harm."
ethical user experience objectives,"Improving user experience is important to most companies, designers, and creators when creating and refining products because negative user experience can diminish the use of the product and, therefore, any desired positive impacts; conversely, designing toward profitability often conflicts with ethical user experience objectives and even causes harm."
refining products,"Improving user experience is important to most companies, designers, and creators when creating and refining products because negative user experience can diminish the use of the product and, therefore, any desired positive impacts; conversely, designing toward profitability often conflicts with ethical user experience objectives and even causes harm."
even causes harm,"Improving user experience is important to most companies, designers, and creators when creating and refining products because negative user experience can diminish the use of the product and, therefore, any desired positive impacts; conversely, designing toward profitability often conflicts with ethical user experience objectives and even causes harm."
1  became important,"With the advent of computer graphics, Bernstein polynomials, restricted to the interval [0, 1], became important in the form of Bzier curves."
simplest case,"In the simplest case only products of the unit interval [0,1] are considered; but, using affine transformations of the line, Bernstein polynomials can also be defined for products [a1, b1] [a2, b2] ."
practical uses,"Practical uses of acoustic fingerprinting include identifying songs, melodies, tunes, or advertisements; sound effect library management; and video file identification."
particularly useful,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma. !! Deterministic context-free grammars were particularly useful because they could be parsed sequentially by a deterministic pushdown automaton, which was a requirement due to computer memory constraints."
requirement due,"Deterministic context-free grammars were particularly useful because they could be parsed sequentially by a deterministic pushdown automaton, which was a requirement due to computer memory constraints."
relation holds,"Universal quantification is distinct from existential quantification (""there exists""), which only asserts that the property or relation holds for at least one member of the domain."
least one member,"Universal quantification is distinct from existential quantification (""there exists""), which only asserts that the property or relation holds for at least one member of the domain."
mentioned explicitly,"In the universal quantification, on the other hand, the natural numbers are mentioned explicitly."
single counterexample,"It is immaterial that ""2n > 2 + n"" is true for most natural numbers n: even the existence of a single counterexample is enough to prove the universal quantification false."
much weaker,"Skolem arithmetic is much weaker than Peano arithmetic, which includes both addition and multiplication operations."
effectively determine,"This means it is possible to effectively determine, for any sentence in the language of Skolem arithmetic, whether that sentence is provable from the axioms of Skolem arithmetic."
unlike first,"Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers."
special case,"Sequential pattern mining is a special case of structured data mining. !! The derivation of the tridiagonal matrix algorithm is a special case of Gaussian elimination. !! SSP is a special case of the knapsack problem and of the multiple subset sum problem. !! Automatic vectorization, in parallel computing, is a special case of automatic parallelization, where a computer program is converted from a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once. !! The chi-squared distribution is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing and in construction of confidence intervals. !! The general rate of the Gower-Richtarik algorithm precisely recovers the rate of the randomized Kaczmarz method in the special case when it reduced to it. !! Tensor product of Hilbert spaces the Frobenius inner product is the special case where the vector spaces are finite-dimensional real or complex vector spaces with the usual Euclidean inner product !! This is a special case of the smoothness assumption and gives rise to feature learning with clustering algorithms. !! A multi-objective optimization problem is a special case of a vector optimization problem: The objective space is the finite dimensional Euclidean space partially ordered by the component-wise ""less than or equal to"" ordering. !! This can be regarded as the special case of mathematical optimization where the objective value is the same for every solution, and thus any solution is optimal. !! The signals are usually processed in a digital representation, so speech processing can be regarded as a special case of digital signal processing, applied to speech signals. !! This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution. !! The observed variables are modelled as linear combinations of the potential factors plus ""error"" terms, hence factor analysis can be thought of as a special case of errors-in-variables models. !! The asymptotic gain model is a special case of the extra element theorem. !! The modifications can themselves depend on spike timing patterns (temporal coding), i. e. , can be a special case of spike-timing-dependent plasticity. !! The longest increasing subsequence problem is closely related to the longest common subsequence problem, which has a quadratic time dynamic programming solution: the longest increasing subsequence of a sequence S is the longest common subsequence of S and T, where T is the result of sorting S. However, for the special case in which the input is a permutation of the integers 1, 2, . !! It has been shown that cuckoo search is a special case of the well-known ( + )-evolution strategy. !! Tree traversal is a special case of graph traversal. !! Linear programming is a special case of mathematical programming (also known as mathematical optimization). !! In the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. !! Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates law of diminishing returns. !! The logistic distribution is a special case of the Tukey lambda distribution. !! The discrete Fourier transform can be viewed as a special case of the z-transform, evaluated on the unit circle in the complex plane; more general z-transforms correspond to complex shifts a and b above. !! Hybrid algorithms are often used for efficiency, to reduce the overhead of recursion in small cases, and arm's-length recursion is a special case of this. !! Loop peeling is a special case of loop splitting which splits any problematic first (or last) few iterations from the loop and performs them outside of the loop body."
original method,Convergence of Cuckoo Search algorithm can be substantially improved by genetically replacing abandoned nests (instead of using the random replacements from the original method).
substantially improved,Convergence of Cuckoo Search algorithm can be substantially improved by genetically replacing abandoned nests (instead of using the random replacements from the original method).
result replaces one,Most bitwise operations are presented as two-operand instructions where the result replaces one of the input operands.
simple low,"On simple low-cost processors, typically, bitwise operations are substantially faster than division, several times faster than multiplication, and sometimes significantly faster than addition."
reduced use,"While modern processors usually perform addition and multiplication just as fast as bitwise operations due to their longer instruction pipelines and other architectural design choices, bitwise operations do commonly use less power because of the reduced use of resources."
first suggested,"Gradient descent is generally attributed to Cauchy, who first suggested it in 1847. !! According to Huntington, the term ""Boolean algebra"" was first suggested by Sheffer in 1913, although Charles Sanders Peirce gave the title ""A Boolean Algebra with One Constant"" to the first chapter of his ""The Simplest Mathematics"" in 1880. !! Time-symmetric interpretations of quantum mechanics were first suggested by Walter Schottky in 1921."
generally attributed,"Gradient descent is generally attributed to Cauchy, who first suggested it in 1847."
hypothetical scenario,The basic intuition behind gradient descent can be illustrated by a hypothetical scenario.
involves looking,"They can use the method of gradient descent, which involves looking at the steepness of the hill at their current position, then proceeding in the direction with the steepest descent (i. e. , downhill)."
highly likely,They are highly likely to confound the concept of probability with the concept of degree of truth.
altered product,"In systems engineering and software engineering, requirements analysis focuses on the tasks that determine the needs or conditions to meet the new or altered product or project, taking account of the possibly conflicting requirements of the various stakeholders, analyzing, documenting, validating and managing software or system requirements."
approximate inference methods make,"Approximate inference methods make it possible to learn realistic models from big data by trading off computation time for accuracy, when exact learning and inference are computationally intractable."
video lecture,"""Machine Learning Summer School (MLSS), Cambridge 2009, Approximate Inference"" (video lecture)."
applications including,"Deep reinforcement learning has been used for a diverse set of applications including but not limited to robotics, video games, natural language processing, computer vision, education, transportation, finance and healthcare."
rising interest,"Along with rising interest in neural networks beginning in the mid 1980s, interest grew in deep reinforcement learning, where a neural network is used in reinforcement learning to represent policies or value functions."
interest grew,"Along with rising interest in neural networks beginning in the mid 1980s, interest grew in deep reinforcement learning, where a neural network is used in reinforcement learning to represent policies or value functions."
sized 1919 board,"Deep reinforcement learning reached another milestone in 2015 when AlphaGo, a computer program trained with deep RL to play Go, became the first computer Go program to beat a human professional Go player without handicap on a full-sized 1919 board."
sometimes thought,"Most free-form languages are also structured programming languages, which is sometimes thought to go along with the free-form syntax: Earlier imperative programming languages such as Fortran 77 used particular columns for line numbers, which many structured languages do not use or need."
two methods,Semiotic engineering has two methods to evaluate the quality of metacommunication in HCI: the semiotic inspection method (SIM) and the communicability evaluation method (CEM). !! There are two methods to define and categorize consistency models; issue and view.
standard problems solved,"Standard problems solved by distributed algorithms include leader election, consensus, distributed search, spanning tree generation, mutual exclusion, and resource allocation."
limited information,"Distributed algorithms are a sub-type of parallel algorithm, typically executed concurrently, with separate parts of the algorithm being run simultaneously on independent processors, and having limited information about what the other parts of the algorithm are doing."
separate parts,"Distributed algorithms are a sub-type of parallel algorithm, typically executed concurrently, with separate parts of the algorithm being run simultaneously on independent processors, and having limited information about what the other parts of the algorithm are doing."
major challenges,One of the major challenges in developing and implementing distributed algorithms is successfully coordinating the behavior of the independent parts of the algorithm in the face of processor failures and unreliable communications links.
mit open courseware,MIT Open Courseware - Distributed Algorithms
typically defined,"As typically defined or implemented, syntactic predicates implicitly order the productions so that predicated productions specified earlier have higher precedence than predicated productions specified later within the same decision."
also discussed,Message authentication codes and data origin authentication have been also discussed in the framework of quantum cryptography. !! The term syntactic predicate was coined by Parr & Quong and differentiates this form of predicate from semantic predicates (also discussed).
resource used,"In computational complexity theory, a computational resource is a resource used by some computational models in the solution of computational problems."
computational resources needed,"As the inputs get bigger, the amount of computational resources needed to solve a problem will increase."
inputs get bigger,"As the inputs get bigger, the amount of computational resources needed to solve a problem will increase."
certain amount,"The set of all of the computational problems that can be solved using a certain amount of a certain computational resource is a complexity class, and relationships between different complexity classes are one of the most important topics in complexity theory. !! Computational resources are useful because we can study which problems can be computed in a certain amount of each computational resource."
certain computational resource,"The set of all of the computational problems that can be solved using a certain amount of a certain computational resource is a complexity class, and relationships between different complexity classes are one of the most important topics in complexity theory."
solved using,"Automata theory is the study of abstract machines and automata, as well as the computational problems that can be solved using them. !! The set of all of the computational problems that can be solved using a certain amount of a certain computational resource is a complexity class, and relationships between different complexity classes are one of the most important topics in complexity theory."
different complexity classes,"The set of all of the computational problems that can be solved using a certain amount of a certain computational resource is a complexity class, and relationships between different complexity classes are one of the most important topics in complexity theory."
important topics,"The set of all of the computational problems that can be solved using a certain amount of a certain computational resource is a complexity class, and relationships between different complexity classes are one of the most important topics in complexity theory."
additionally requires,"Within the latter notion, partial correctness, requiring that if an answer is returned it will be correct, is distinguished from total correctness, which additionally requires that an answer is eventually returned, i. e. the algorithm terminates."
latter notion,"Within the latter notion, partial correctness, requiring that if an answer is returned it will be correct, is distinguished from total correctness, which additionally requires that an answer is eventually returned, i. e. the algorithm terminates."
partial correctness,"Correspondingly, to prove a program's total correctness, it is sufficient to prove its partial correctness, and its termination. !! Within the latter notion, partial correctness, requiring that if an answer is returned it will be correct, is distinguished from total correctness, which additionally requires that an answer is eventually returned, i. e. the algorithm terminates."
total correctness,"Correspondingly, to prove a program's total correctness, it is sufficient to prove its partial correctness, and its termination. !! Within the latter notion, partial correctness, requiring that if an answer is returned it will be correct, is distinguished from total correctness, which additionally requires that an answer is eventually returned, i. e. the algorithm terminates."
eventually returned,"Within the latter notion, partial correctness, requiring that if an answer is returned it will be correct, is distinguished from total correctness, which additionally requires that an answer is eventually returned, i. e. the algorithm terminates."
two iteration variables used,"In compiler theory, loop interchange is the process of exchanging the order of two iteration variables used by a nested loop."
take advantage,"When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix. !! The major purpose of loop interchange is to take advantage of the CPU cache when accessing array elements. !! Anchor modeling was created in order to take advantage of the benefits from a high degree of normalization while avoiding its drawbacks."
major purpose,The major purpose of loop interchange is to take advantage of the CPU cache when accessing array elements.
accessing array elements,The major purpose of loop interchange is to take advantage of the CPU cache when accessing array elements.
cache misses occur,"Cache misses occur if the contiguously accessed array elements within the loop come from a different cache block, and loop interchange can help prevent this."
loop come,"Cache misses occur if the contiguously accessed array elements within the loop come from a different cache block, and loop interchange can help prevent this."
help prevent,"Cache misses occur if the contiguously accessed array elements within the loop come from a different cache block, and loop interchange can help prevent this."
contiguously accessed array elements within,"Cache misses occur if the contiguously accessed array elements within the loop come from a different cache block, and loop interchange can help prevent this."
different cache block,"Cache misses occur if the contiguously accessed array elements within the loop come from a different cache block, and loop interchange can help prevent this."
array model used,The effectiveness of loop interchange depends on and must be considered in light of the cache model used by the underlying hardware and the array model used by the compiler.
cache model used,The effectiveness of loop interchange depends on and must be considered in light of the cache model used by the underlying hardware and the array model used by the compiler.
loop interchange depends,The effectiveness of loop interchange depends on and must be considered in light of the cache model used by the underlying hardware and the array model used by the compiler.
underlying hardware,The effectiveness of loop interchange depends on and must be considered in light of the cache model used by the underlying hardware and the array model used by the compiler.
loop interchange may lead,"Like any compiler optimization, loop interchange may lead to worse performance because cache performance is only part of the story."
worse performance,"Like any compiler optimization, loop interchange may lead to worse performance because cache performance is only part of the story."
dimensional vector space model implementations,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
new terminology,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
chosen appropriately,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
models need,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
new items,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
also verified,It can be also verified that random indexing is a random projection technique for the construction of Euclidean spacesi.
topsig technique extends,The TopSig technique extends the random indexing model to produce bit vectors for comparison with the Hamming distance similarity function.
unreliable communication channels,"In information theory and coding theory with applications in computer science and telecommunication, error detection and correction or error control are techniques that enable reliable delivery of digital data over unreliable communication channels."
purpose commercial telegraph code known,Acme Commodity and Phrase Code is a codebook providing the general-purpose commercial telegraph code known as the Acme Code.
potentially heterogeneous implementations depending,"In programming languages, ad hoc polymorphism is a kind of polymorphism in which polymorphic functions can be applied to arguments of different types, because a polymorphic function can denote a number of distinct and potentially heterogeneous implementations depending on the type of argument(s) to which it is applied."
different types,"A simple agglomerative clustering algorithm is described in the single-linkage clustering page; it can easily be adapted to different types of linkage (see below). !! In programming languages, ad hoc polymorphism is a kind of polymorphism in which polymorphic functions can be applied to arguments of different types, because a polymorphic function can denote a number of distinct and potentially heterogeneous implementations depending on the type of argument(s) to which it is applied. !! Different types of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks. !! BoostSRL: A system specialized on gradient-based boosting approach learning for different types of Statistical Relational Learning models, including Relational Dependency Networks. !! There are different types of non-negative matrix factorizations. !! In computer science, imperialist competitive algorithms are a type of computational method used to solve optimization problems of different types."
dispatch mechanism,Ad hoc polymorphism is a dispatch mechanism: control moving through one named function is dispatched to various other functions without having to specify the exact function being called.
one named function,Ad hoc polymorphism is a dispatch mechanism: control moving through one named function is dispatched to various other functions without having to specify the exact function being called.
exact function,Ad hoc polymorphism is a dispatch mechanism: control moving through one named function is dispatched to various other functions without having to specify the exact function being called.
control moving,Ad hoc polymorphism is a dispatch mechanism: control moving through one named function is dispatched to various other functions without having to specify the exact function being called.
functions without,Ad hoc polymorphism is a dispatch mechanism: control moving through one named function is dispatched to various other functions without having to specify the exact function being called.
previous section notwithstanding,"The previous section notwithstanding, there are other ways in which ad hoc polymorphism can work out."
also extended,"Therefore, polymorphism is given by subtyping polymorphism as in other languages, and it is also extended in functionality by ad hoc polymorphism at run time."
also reveal,A closer look will also reveal that Smalltalk provides a slightly different variety of ad hoc polymorphism.
smalltalk provides,A closer look will also reveal that Smalltalk provides a slightly different variety of ad hoc polymorphism.
slightly different variety,A closer look will also reveal that Smalltalk provides a slightly different variety of ad hoc polymorphism.
closer look,"A closer look will also reveal that Smalltalk provides a slightly different variety of ad hoc polymorphism. !! This article will present an overview of the skill of navigation and try to identify the basic blocks of a robot navigation system, types of navigation systems, and closer look at its related building components."
identify regions,"In bioinformatics, a sequence alignment is a way of arranging the sequences of DNA, RNA, or protein to identify regions of similarity that may be a consequence of functional, structural, or evolutionary relationships between the sequences."
also used,"The term artificial imagination is also used to describe a property of machines or programs. !! The carry flag is affected by the result of most arithmetic (and typically several bit wise) instructions and is also used as an input to many of them. !! The term quantum information theory is also used, but it fails to encompass experimental research, and can be confused with a subfield of quantum information science that addresses the processing of quantum information. !! Weighted round robin (WRR) is a network scheduler for data flows, but also used to schedule processes. !! Because parsimonious reductions preserve the property of having a unique solution, they are also used in game complexity, to show the hardness of puzzles such as sudoku where the uniqueness of the solution is an important part of the definition of the puzzle. !! Big O notation is also used in many other fields to provide similar estimates. !! The von Neumann entropy is also used in different forms (conditional entropies, relative entropies, etc. ) !! Bit slicing, although not called that at the time, was also used in computers before large-scale integrated circuits (LSI, the predecessor to today's VLSI, or very-large-scale integration circuits). !! Structured prediction is also used in a wide variety of application domains including bioinformatics, natural language processing, speech recognition, and computer vision. !! A focus group is also used by sociologists, psychologists, and researchers in communication studies, education, political science, and public health. !! Sequence alignments are also used for non-biological sequences, such as calculating the distance cost between strings in a natural language or in financial data. !! In information theory, units of information are also used to measure information contained in messages and the entropy of random variables. !! Graph theory is also used to study molecules in chemistry and physics. !! Abstract syntax trees are also used in program analysis and program transformation systems."
rough measure,"In sequence alignments of proteins, the degree of similarity between amino acids occupying a particular position in the sequence can be interpreted as a rough measure of how conserved a particular region or sequence motif is among lineages."
amino acids occupying,"In sequence alignments of proteins, the degree of similarity between amino acids occupying a particular position in the sequence can be interpreted as a rough measure of how conserved a particular region or sequence motif is among lineages."
particular position,"In sequence alignments of proteins, the degree of similarity between amino acids occupying a particular position in the sequence can be interpreted as a rough measure of how conserved a particular region or sequence motif is among lineages."
particular region,"In sequence alignments of proteins, the degree of similarity between amino acids occupying a particular position in the sequence can be interpreted as a rough measure of how conserved a particular region or sequence motif is among lineages."
produce high,"Instead, human knowledge is applied in constructing algorithms to produce high-quality sequence alignments, and occasionally in adjusting the final results to reflect patterns that are difficult to represent algorithmically (especially in the case of nucleotide sequences)."
constructing algorithms,"Instead, human knowledge is applied in constructing algorithms to produce high-quality sequence alignments, and occasionally in adjusting the final results to reflect patterns that are difficult to represent algorithmically (especially in the case of nucleotide sequences)."
final results,"Instead, human knowledge is applied in constructing algorithms to produce high-quality sequence alignments, and occasionally in adjusting the final results to reflect patterns that are difficult to represent algorithmically (especially in the case of nucleotide sequences)."
sequence alignment generally fall,Computational approaches to sequence alignment generally fall into two categories: global alignments and local alignments.
two categories,Computational approaches to sequence alignment generally fall into two categories: global alignments and local alignments.
two principal types,Two principal types of audio normalization exist.
audio normalization exist,Two principal types of audio normalization exist.
final product,A software blueprint is the final product of a software blueprinting process.
key properties,"Therefore, alternative terms that reflect the main foci of the field include statistical relational learning and reasoning (emphasizing the importance of reasoning) and first-order probabilistic languages (emphasizing the key properties of the languages with which models are represented). !! Therefore, a true software blueprint should share a number of key properties with its building-blueprint counterpart."
logically orthogonal aspects,Software blueprinting relies on achieving a clean separation between logically orthogonal aspects of the software.
clean separation,Software blueprinting relies on achieving a clean separation between logically orthogonal aspects of the software.
one application aspect,"Software blueprints focus on one application aspect, for clarity of presentation and to ensure that all of the relevant logic is localized."
relevant logic,"Software blueprints focus on one application aspect, for clarity of presentation and to ensure that all of the relevant logic is localized."
software blueprint means,The single-aspect focus of a software blueprint means that an optimal description medium can be selected.
aspect focus,The single-aspect focus of a software blueprint means that an optimal description medium can be selected.
studies sets,"Set theory is the branch of mathematical logic that studies sets, which can be informally described as collections of objects."
mostly concerned,"Although objects of any kind can be collected into a set, set theory, as a branch of mathematics, is mostly concerned with those that are relevant to mathematics as a whole."
although objects,"Although objects of any kind can be collected into a set, set theory, as a branch of mathematics, is mostly concerned with those that are relevant to mathematics as a whole."
german mathematicians richard dedekind,The modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s.
georg cantor,"The modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s. !! In particular, Georg Cantor is commonly considered the founder of set theory."
modern study,"These developments have led to the modern study of logic and computability, and indeed the field of theoretical computer science as a whole. !! The modern study of set theory was initiated by the German mathematicians Richard Dedekind and Georg Cantor in the 1870s."
commonly considered,"Even though it is commonly considered a synonym of soft computing, there is still no commonly accepted definition of computational intelligence. !! Computational science is now commonly considered a third mode of science, complementing and adding to experimentation/observation and theory (see image on the right). !! In particular, Georg Cantor is commonly considered the founder of set theory."
formalized systems investigated,The non-formalized systems investigated during this early stage go under the name of naive set theory.
early stage go,The non-formalized systems investigated during this early stage go under the name of naive set theory.
efficient even,The Classifier Chains method is based on the BR method and it is efficient even on a big number of labels.
big number,The Classifier Chains method is based on the BR method and it is efficient even on a big number of labels.
recursive definition using,"A recursive definition using just set theory notions is that a (non-empty) binary tree is a tuple (L, S, R), where L and R are binary trees or the empty set and S is a singleton set containing the root."
analogous example,"The everyday division of documents into chapters, sections, paragraphs, and so on is an analogous example with n-ary rather than binary trees."
everyday division,"The everyday division of documents into chapters, sections, paragraphs, and so on is an analogous example with n-ary rather than binary trees."
adding edges,"if T1 and T2 are extended binary trees, then denote by T1 T2 the extended binary tree obtained by adding a root r connected to the left to T1 and to the right to T2 by adding edges when these sub-trees are non-empty."
extended binary tree obtained,"if T1 and T2 are extended binary trees, then denote by T1 T2 the extended binary tree obtained by adding a root r connected to the left to T1 and to the right to T2 by adding edges when these sub-trees are non-empty."
root r connected,"if T1 and T2 are extended binary trees, then denote by T1 T2 the extended binary tree obtained by adding a root r connected to the left to T1 and to the right to T2 by adding edges when these sub-trees are non-empty."
extended binary trees,"if T1 and T2 are extended binary trees, then denote by T1 T2 the extended binary tree obtained by adding a root r connected to the left to T1 and to the right to T2 by adding edges when these sub-trees are non-empty."
left child,"A more informal way of making the distinction is to say, quoting the Encyclopedia of Mathematics, that ""every node has a left child, a right child, neither, or both"" and to specify that these ""are all different"" binary trees."
informal way,"A more informal way of making the distinction is to say, quoting the Encyclopedia of Mathematics, that ""every node has a left child, a right child, neither, or both"" and to specify that these ""are all different"" binary trees."
lacks specialized features,"A general-purpose language is a computer language that is broadly applicable across application domains, and lacks specialized features for a particular domain."
purpose language,"A general-purpose language is a computer language that is broadly applicable across application domains, and lacks specialized features for a particular domain."
broadly applicable across application domains,"A general-purpose language is a computer language that is broadly applicable across application domains, and lacks specialized features for a particular domain."
particular domain,"A general-purpose language is a computer language that is broadly applicable across application domains, and lacks specialized features for a particular domain."
original work,"Boson sampling is a restricted model of non-universal quantum computation introduced by Scott Aaronson and Alex Arkhipov after the original work of L. Troyansky and Naftali Tishby, that explored possible usage of boson scattering to evaluate expectation values of permanents of matrices."
explored possible usage,"Boson sampling is a restricted model of non-universal quantum computation introduced by Scott Aaronson and Alex Arkhipov after the original work of L. Troyansky and Naftali Tishby, that explored possible usage of boson scattering to evaluate expectation values of permanents of matrices."
evaluate expectation values,"Boson sampling is a restricted model of non-universal quantum computation introduced by Scott Aaronson and Alex Arkhipov after the original work of L. Troyansky and Naftali Tishby, that explored possible usage of boson scattering to evaluate expectation values of permanents of matrices."
currently considered,"Although the problem is well defined for any bosonic particles, its photonic version is currently considered as the most promising platform for a scalable implementation of a boson sampling device, which makes it a non-universal approach to linear optical quantum computing."
promising platform,"Although the problem is well defined for any bosonic particles, its photonic version is currently considered as the most promising platform for a scalable implementation of a boson sampling device, which makes it a non-universal approach to linear optical quantum computing."
scalable implementation,"Although the problem is well defined for any bosonic particles, its photonic version is currently considered as the most promising platform for a scalable implementation of a boson sampling device, which makes it a non-universal approach to linear optical quantum computing."
well defined,"Unicode, a well defined and extensible encoding system, has supplanted most earlier character encodings, but the path of code development to the present is fairly well known. !! Although the problem is well defined for any bosonic particles, its photonic version is currently considered as the most promising platform for a scalable implementation of a boson sampling device, which makes it a non-universal approach to linear optical quantum computing."
universal approach,"Although the problem is well defined for any bosonic particles, its photonic version is currently considered as the most promising platform for a scalable implementation of a boson sampling device, which makes it a non-universal approach to linear optical quantum computing."
using far fewer physical resources,"Moreover, while not universal, the boson sampling scheme is strongly believed to implement computing tasks which are hard to implement with classical computers by using far fewer physical resources than a full linear-optical quantum computing setup."
implement computing tasks,"Moreover, while not universal, the boson sampling scheme is strongly believed to implement computing tasks which are hard to implement with classical computers by using far fewer physical resources than a full linear-optical quantum computing setup."
strongly believed,"Moreover, while not universal, the boson sampling scheme is strongly believed to implement computing tasks which are hard to implement with classical computers by using far fewer physical resources than a full linear-optical quantum computing setup."
boson sampling task consists,"Then, the photonic implementation of the boson sampling task consists of generating a sample from the probability distribution of single-photon measurements at the output of the circuit."
three ingredients,"Therefore, based on these three ingredients, the boson sampling setup does not require any ancillas, adaptive measurements or entangling operations, as does e. g. the universal optical scheme by Knill, Laflamme and Milburn (the KLM scheme)."
entangling operations,"Therefore, based on these three ingredients, the boson sampling setup does not require any ancillas, adaptive measurements or entangling operations, as does e. g. the universal optical scheme by Knill, Laflamme and Milburn (the KLM scheme)."
structure used depends,"The semi-structured model is a database model where there is no separation between the data and the schema, and the amount of structure used depends on the purpose."
mathematical tool designed,"In numerical analysis, a numerical method is a mathematical tool designed to solve numerical problems."
solve numerical problems,"In numerical analysis, a numerical method is a mathematical tool designed to solve numerical problems."
appropriate convergence check,The implementation of a numerical method with an appropriate convergence check in a programming language is called a numerical algorithm.
weakly chained diagonally dominant matrix,Any strictly diagonally dominant matrix is trivially a weakly chained diagonally dominant matrix.
strictly diagonally dominant matrix,Any strictly diagonally dominant matrix is trivially a weakly chained diagonally dominant matrix. !! A strictly diagonally dominant matrix (or an irreducibly diagonally dominant matrix) is non-singular.
strictly column diagonally dominant matrix,No (partial) pivoting is necessary for a strictly column diagonally dominant matrix when performing Gaussian elimination (LU factorization).
performing gaussian elimination,No (partial) pivoting is necessary for a strictly column diagonally dominant matrix when performing Gaussian elimination (LU factorization).
analyzing relationships,"Latent semantic analysis (LSA) is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms."
concepts related,"Latent semantic analysis (LSA) is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms."
particular distributional semantics,"Latent semantic analysis (LSA) is a technique in natural language processing, in particular distributional semantics, of analyzing relationships between a set of documents and the terms they contain by producing a set of concepts related to the documents and terms."
give better results,"Thus, a newer alternative is probabilistic latent semantic analysis, based on a multinomial model, which is reported to give better results than standard LSA."
newer alternative,"Thus, a newer alternative is probabilistic latent semantic analysis, based on a multinomial model, which is reported to give better results than standard LSA."
also called latent semantic analysis,"The method, also called latent semantic analysis (LSA), uncovers the underlying latent semantic structure in the usage of words in a body of text and how it can be used to extract the meaning of the text in response to user queries, commonly referred to as concept searches."
commonly referred,"In the adaptive control literature, the learning rate is commonly referred to as gain. !! The method, also called latent semantic analysis (LSA), uncovers the underlying latent semantic structure in the usage of words in a body of text and how it can be used to extract the meaning of the text in response to user queries, commonly referred to as concept searches."
partitioning design pattern,"In software engineering, the composite pattern is a partitioning design pattern."
composite pattern describes,The composite pattern describes a group of objects that are treated the same way as a single instance of the same type of object.
single instance,The composite pattern describes a group of objects that are treated the same way as a single instance of the same type of object.
compositions uniformly,Implementing the composite pattern lets clients treat individual objects and compositions uniformly.
used instead,"Syntactic pattern recognition can be used instead of statistical pattern recognition if there is clear structure in the patterns. !! When degrees of freedom is used instead of dimension, this usually means that the manifold or variety that models the system is only implicitly defined."
clear structure,Syntactic pattern recognition can be used instead of statistical pattern recognition if there is clear structure in the patterns.
different code points,Multiple coded character sets may share the same repertoire; for example ISO/IEC 8859-1 and IBM code pages 037 and 500 all cover the same repertoire but map them to different code points.
ibm code pages 037,Multiple coded character sets may share the same repertoire; for example ISO/IEC 8859-1 and IBM code pages 037 and 500 all cover the same repertoire but map them to different code points.
coded character sets,"Coded Character Sets, History and Development."
positively must know,"The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)"
related supervised learning methods,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
squares support,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
recognize patterns,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
joseph hodges,"In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover."
later expanded,"In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover."
thomas cover,"In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover."
common among,"An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small)."
typically small,"An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). !! In computing, a Monte Carlo algorithm is a randomized algorithm whose output may be incorrect with a certain (typically small) probability."
plurality vote,"An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small)."
simply assigned,"If k = 1, then the object is simply assigned to the class of that single nearest neighbor."
many factors,"Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders."
many people,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character. !! Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders."
affected differently,"Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders."
including brain damage,"Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders."
mcgurk effect based,"Many people are affected differently by the McGurk effect based on many factors, including brain damage and other disorders."
visual information happens early,The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception.
mcgurk effect arises,The McGurk effect arises during phonetic processing because the integration of audio and visual information happens early in speech perception.
little effect,"The McGurk effect is very robust; that is, knowledge about it seems to have little effect on one's perception of it."
protection state,"In computer science, an access control matrix or access matrix is an abstract, formal security model of protection state in computer systems, that characterizes the rights of each subject with respect to every object in the system."
every object,"In computer science, an access control matrix or access matrix is an abstract, formal security model of protection state in computer systems, that characterizes the rights of each subject with respect to every object in the system. !! A rewriting system has the weak normalization property or is (weakly) normalizing (WN) if every object is weakly normalizing."
protection mechanisms,"Because it does not define the granularity of protection mechanisms, the Access Control Matrix can be used as a model of the static access permissions in any type of access control system."
static access permissions,"Because it does not define the granularity of protection mechanisms, the Access Control Matrix can be used as a model of the static access permissions in any type of access control system."
access control system,"Because it does not define the granularity of protection mechanisms, the Access Control Matrix can be used as a model of the static access permissions in any type of access control system."
literal implementation,An Access Control Matrix should be thought of only as an abstract model of permissions at a given point in time; a literal implementation of it as a two-dimensional array would have excessive memory requirements.
excessive memory requirements,An Access Control Matrix should be thought of only as an abstract model of permissions at a given point in time; a literal implementation of it as a two-dimensional array would have excessive memory requirements.
given point,An Access Control Matrix should be thought of only as an abstract model of permissions at a given point in time; a literal implementation of it as a two-dimensional array would have excessive memory requirements.
dimensional array would,An Access Control Matrix should be thought of only as an abstract model of permissions at a given point in time; a literal implementation of it as a two-dimensional array would have excessive memory requirements.
account dynamic behaviour,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
protection paper,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
simply row,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
butler lampson,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
two mechanisms,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
misleading equivalence,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
based implementations,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
nouns first,Object Oriented Programming puts the Nouns first and foremost.
two different ways,"Sixth normal form (6NF) is a term in relational database theory, used in two different ways."
sixth normal form,"Sixth normal form is intended to decompose relation variables to irreducible components. !! Relvar R is in sixth normal form (6NF) if and only if every JD [Join Dependency] of R is trivial where a JD is trivial if and only if one of its components is equal to the pertinent heading in its entirety. !! Date and others have defined sixth normal form as a normal form, based on an extension of the relational algebra. !! Sixth normal form (6NF) is a term in relational database theory, used in two different ways. !! A relvar R [table] is in sixth normal form (abbreviated 6NF) if and only if it satisfies no nontrivial join dependencies at all where, as before, a join dependency is trivial if and only if at least one of the projections (possibly U_projections) involved is taken over the set of all attributes of the relvar [table] concerned."
defined sixth normal form,"Date and others have defined sixth normal form as a normal form, based on an extension of the relational algebra."
least one,"A relvar R [table] is in sixth normal form (abbreviated 6NF) if and only if it satisfies no nontrivial join dependencies at all where, as before, a join dependency is trivial if and only if at least one of the projections (possibly U_projections) involved is taken over the set of all attributes of the relvar [table] concerned."
abbreviated 6nf,"A relvar R [table] is in sixth normal form (abbreviated 6NF) if and only if it satisfies no nontrivial join dependencies at all where, as before, a join dependency is trivial if and only if at least one of the projections (possibly U_projections) involved is taken over the set of all attributes of the relvar [table] concerned."
every jd,Relvar R is in sixth normal form (6NF) if and only if every JD [Join Dependency] of R is trivial where a JD is trivial if and only if one of its components is equal to the pertinent heading in its entirety.
search algorithm similar,Stack search (also known as Stack decoding algorithm) is a search algorithm similar to beam search.
intuitively understood,"String kernels can be intuitively understood as functions measuring the similarity of pairs of strings: the more similar two strings a and b are, the higher the value of a string kernel K(a, b) will be."
functions measuring,"String kernels can be intuitively understood as functions measuring the similarity of pairs of strings: the more similar two strings a and b are, the higher the value of a string kernel K(a, b) will be."
similar two strings,"String kernels can be intuitively understood as functions measuring the similarity of pairs of strings: the more similar two strings a and b are, the higher the value of a string kernel K(a, b) will be."
support vector machines allow,"Using string kernels with kernelized learning algorithms such as support vector machines allow such algorithms to work with strings, without having to translate these to fixed-length, real-valued feature vectors."
using string kernels,"Using string kernels with kernelized learning algorithms such as support vector machines allow such algorithms to work with strings, without having to translate these to fixed-length, real-valued feature vectors."
valued feature vectors,"Using string kernels with kernelized learning algorithms such as support vector machines allow such algorithms to work with strings, without having to translate these to fixed-length, real-valued feature vectors."
string kernel allows,"(i. e. data are elements of a vector space), using a string kernel allows the extension of these methods to handle sequence data."
vector space  using,"(i. e. data are elements of a vector space), using a string kernel allows the extension of these methods to handle sequence data."
handle sequence data,"(i. e. data are elements of a vector space), using a string kernel allows the extension of these methods to handle sequence data."
small region,Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.
single form,"Since no single form of classification is appropriate for all data sets, a large toolkit of classification algorithms have been developed."
tree used,A semantic resolution tree is a tree used for the definition of the semantics of a programming language.
following paragraphs,A requirement diagram is a diagram specially used in SysML in which requirements and the relations between them and their relationship to other model elements are shown as discussed in the following paragraphs.
requirement diagram,A requirement diagram is a diagram specially used in SysML in which requirements and the relations between them and their relationship to other model elements are shown as discussed in the following paragraphs.
least surprise,"The principle of least astonishment (POLA), aka principle of least surprise (alternatively a law or rule), applies to user interface and software design."
principle of least astonishment,"Principle of Least Astonishment at Portland Pattern Repository !! The principle of least astonishment (POLA), aka principle of least surprise (alternatively a law or rule), applies to user interface and software design."
least astonishment,"Principle of Least Astonishment at Portland Pattern Repository !! The principle of least astonishment (POLA), aka principle of least surprise (alternatively a law or rule), applies to user interface and software design."
pola  aka principle,"The principle of least astonishment (POLA), aka principle of least surprise (alternatively a law or rule), applies to user interface and software design."
rule  applies,"The principle of least astonishment (POLA), aka principle of least surprise (alternatively a law or rule), applies to user interface and software design."
file name,"""Bad command or file name"" is a common and ambiguous error message in MS-DOS and some other operating systems."
maximum amount,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink. !! Since an algorithm's running time may vary among different inputs of the same size, one commonly considers the worst-case time complexity, which is the maximum amount of time required for inputs of a given size."
cut theorem refers,The other half of the max-flow min-cut theorem refers to a different aspect of a network: the collection of cuts.
different aspect,The other half of the max-flow min-cut theorem refers to a different aspect of a network: the collection of cuts.
dual program also,"The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
two solutions,"The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
cut theorem follows,"The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
optimal values formed,"The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
maximum value,", the binary entropy function attains its maximum value. !! In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense. !! Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value."
new definition,"In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
minimum capacity,"In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
new sense,"In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
generalized max,"In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
every graph property definable,"In the study of graph algorithms, Courcelle's theorem is the statement that every graph property definable in the monadic second-order logic of graphs can be decided in linear time on graphs of bounded treewidth."
bounded treewidth may,"Thus, by Courcelle's theorem, 3-colorability of graphs of bounded treewidth may be tested in linear time."
stronger variation,Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2.
theorem may also,Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2.
order logic known,Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2.
theorem concerns logical formulas,Another direction for extending Courcelle's theorem concerns logical formulas that include predicates for counting the size of the test.
extending courcelle,Another direction for extending Courcelle's theorem concerns logical formulas that include predicates for counting the size of the test.
another direction,Another direction for extending Courcelle's theorem concerns logical formulas that include predicates for counting the size of the test.
include predicates,Another direction for extending Courcelle's theorem concerns logical formulas that include predicates for counting the size of the test.
tests whether,which tests whether the cardinality of set S is congruent to r modulo q. Courcelle's theorem can be extended to these logics.
signaling protocol based,The Bearer-Independent Call Control (BICC) is a signaling protocol based on N-ISUP that is used for supporting narrowband Integrated Services Digital Network (ISDN) service over a broadband backbone network.
independent call control,The Bearer-Independent Call Control (BICC) is a signaling protocol based on N-ISUP that is used for supporting narrowband Integrated Services Digital Network (ISDN) service over a broadband backbone network.
broadband backbone network,The Bearer-Independent Call Control (BICC) is a signaling protocol based on N-ISUP that is used for supporting narrowband Integrated Services Digital Network (ISDN) service over a broadband backbone network.
bearer-independent call control,The Bearer-Independent Call Control (BICC) is a signaling protocol based on N-ISUP that is used for supporting narrowband Integrated Services Digital Network (ISDN) service over a broadband backbone network.
possible set,Data-flow analysis is a technique for gathering information about the possible set of values calculated at various points in a computer program.
values calculated,Data-flow analysis is a technique for gathering information about the possible set of values calculated at various points in a computer program.
gathering information,Data-flow analysis is a technique for gathering information about the possible set of values calculated at various points in a computer program.
flow analysis,"Data-flow analysis is the process of collecting information about the way the variables are used, defined in the program. !! Data-flow analysis is a technique for gathering information about the possible set of values calculated at various points in a computer program. !! In computer science, control-flow analysis (CFA) is a static-code-analysis technique for determining the control flow of a program. !! A canonical example of a data-flow analysis is reaching definitions. !! Techniques such as abstract interpretation, constraint solving, and type systems may be used for control-flow analysis. !! A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint. !! Each particular type of data-flow analysis has its own specific transfer function and join operation."
various points,Data-flow analysis is a technique for gathering information about the possible set of values calculated at various points in a computer program.
reaching definitions,A canonical example of a data-flow analysis is reaching definitions.
simple way,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
repeatedly calculating,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
whole system stabilizes,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
collecting information,"Data-flow analysis is the process of collecting information about the way the variables are used, defined in the program."
join operation,Each particular type of data-flow analysis has its own specific transfer function and join operation.
specific transfer function,Each particular type of data-flow analysis has its own specific transfer function and join operation.
particular type,"In computer science, a tagged architecture is a particular type of computer architecture where every word of memory constitutes a tagged union, being divided into a number of bits of data, and a tag section that describes the type of the data: how it is to be interpreted, and, if it is a reference, the type of the object that it points to. !! In computational complexity theory, a gap reduction is a reduction to a particular type of decision problem, known as a c-gap problem. !! Each particular type of data-flow analysis has its own specific transfer function and join operation."
mathematical optimization problems involving,"Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously."
optimized simultaneously,"Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously."
one objective function,"Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously."
optimal decisions need,"Multi-objective optimization has been applied in many fields of science, including engineering, economics and logistics where optimal decisions need to be taken in the presence of trade-offs between two or more conflicting objectives."
many fields,"Artificial imagination research uses tools and insights from many fields, including computer science, rhetoric, psychology, creative arts, philosophy, neuroscience, affective computing, Artificial Intelligence, cognitive science, linguistics, operations research, creative writing, probability and logic. !! Fuzzy logic has been applied to many fields, from control theory to artificial intelligence. !! Voronoi diagrams have practical and theoretical applications in many fields, mainly in science and technology, but also in visual art. !! Multi-objective optimization has been applied in many fields of science, including engineering, economics and logistics where optimal decisions need to be taken in the presence of trade-offs between two or more conflicting objectives."
conflicting objectives,"Multi-objective optimization has been applied in many fields of science, including engineering, economics and logistics where optimal decisions need to be taken in the presence of trade-offs between two or more conflicting objectives."
including engineering,"Multi-objective optimization has been applied in many fields of science, including engineering, economics and logistics where optimal decisions need to be taken in the presence of trade-offs between two or more conflicting objectives."
objective optimization problems involving two,"Minimizing cost while maximizing comfort while buying a car, and maximizing performance whilst minimizing fuel consumption and emission of pollutants of a vehicle are examples of multi-objective optimization problems involving two and three objectives, respectively."
maximizing comfort,"Minimizing cost while maximizing comfort while buying a car, and maximizing performance whilst minimizing fuel consumption and emission of pollutants of a vehicle are examples of multi-objective optimization problems involving two and three objectives, respectively."
three objectives,"Minimizing cost while maximizing comfort while buying a car, and maximizing performance whilst minimizing fuel consumption and emission of pollutants of a vehicle are examples of multi-objective optimization problems involving two and three objectives, respectively."
objective optimization problem,"A multi-objective optimization problem is a special case of a vector optimization problem: The objective space is the finite dimensional Euclidean space partially ordered by the component-wise ""less than or equal to"" ordering. !! For a nontrivial multi-objective optimization problem, no single solution exists that simultaneously optimizes each objective."
simultaneously optimizes,"For a nontrivial multi-objective optimization problem, no single solution exists that simultaneously optimizes each objective."
nontrivial multi,"For a nontrivial multi-objective optimization problem, no single solution exists that simultaneously optimizes each objective."
single solution exists,"For a nontrivial multi-objective optimization problem, no single solution exists that simultaneously optimizes each objective."
exist different solution philosophies,"Researchers study multi-objective optimization problems from different viewpoints and, thus, there exist different solution philosophies and goals when setting and solving them."
different viewpoints,"Researchers study multi-objective optimization problems from different viewpoints and, thus, there exist different solution philosophies and goals when setting and solving them."
objective optimization problems,"Researchers study multi-objective optimization problems from different viewpoints and, thus, there exist different solution philosophies and goals when setting and solving them."
researchers study multi,"Researchers study multi-objective optimization problems from different viewpoints and, thus, there exist different solution philosophies and goals when setting and solving them."
agile database modeling technique suited,Anchor modeling is an agile database modeling technique suited for information that changes over time both in structure and content.
anchor modeling,"Anchor modeling is an agile database modeling technique suited for information that changes over time both in structure and content. !! Since then research concerning anchor modeling is being done in a collaboration between the creators Olle Regardt and Lars Rnnbck and a team at the Department of Computer and Systems Sciences, Stockholm University. !! The earliest installations using anchor modeling were made in Sweden with the first dating back to 2004, when a data warehouse for an insurance company was built using the technique. !! Anchor modeling was created in order to take advantage of the benefits from a high degree of normalization while avoiding its drawbacks. !! In order to handle changes in the information content anchor modeling emulates aspects of a temporal database in the resulting relational database schema."
high degree,Effective music visualization aims to attain a high degree of visual correlation between a musical track's spectral characteristics such as frequency and amplitude and the objects or components of the visual image being rendered and displayed. !! Anchor modeling was created in order to take advantage of the benefits from a high degree of normalization while avoiding its drawbacks.
handle changes,In order to handle changes in the information content anchor modeling emulates aspects of a temporal database in the resulting relational database schema.
resulting relational database schema,In order to handle changes in the information content anchor modeling emulates aspects of a temporal database in the resulting relational database schema.
earliest installations using anchor modeling,"The earliest installations using anchor modeling were made in Sweden with the first dating back to 2004, when a data warehouse for an insurance company was built using the technique."
first dating back,"The earliest installations using anchor modeling were made in Sweden with the first dating back to 2004, when a data warehouse for an insurance company was built using the technique."
insurance company,"The earliest installations using anchor modeling were made in Sweden with the first dating back to 2004, when a data warehouse for an insurance company was built using the technique."
built using,"The earliest installations using anchor modeling were made in Sweden with the first dating back to 2004, when a data warehouse for an insurance company was built using the technique."
lars rnnbck,"Since then research concerning anchor modeling is being done in a collaboration between the creators Olle Regardt and Lars Rnnbck and a team at the Department of Computer and Systems Sciences, Stockholm University."
creators olle regardt,"Since then research concerning anchor modeling is being done in a collaboration between the creators Olle Regardt and Lars Rnnbck and a team at the Department of Computer and Systems Sciences, Stockholm University."
stockholm university,"The Mobile Life Centre at Stockholm University in Kista, Sweden, conducts research in mobile services and ubiquitous computing. !! Since then research concerning anchor modeling is being done in a collaboration between the creators Olle Regardt and Lars Rnnbck and a team at the Department of Computer and Systems Sciences, Stockholm University."
research concerning anchor modeling,"Since then research concerning anchor modeling is being done in a collaboration between the creators Olle Regardt and Lars Rnnbck and a team at the Department of Computer and Systems Sciences, Stockholm University."
matrix containing,The cross-correlation matrix of two random vectors is a matrix containing as elements the cross-correlations of all pairs of elements of the random vectors.
two random vectors,The cross-correlation matrix of two random vectors is a matrix containing as elements the cross-correlations of all pairs of elements of the random vectors.
various digital signal processing algorithms,The cross-correlation matrix is used in various digital signal processing algorithms.
many types,"While any signal can be used in analog signal processing, there are many types of signals that are used very frequently. !! In mathematics, binary splitting is a technique for speeding up numerical evaluation of many types of series with rational terms. !! Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require."
rational terms,"In mathematics, binary splitting is a technique for speeding up numerical evaluation of many types of series with rational terms."
direct term,"Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
conveniently eliminates rounding errors,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors."
rational series uses,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors."
one final division,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors."
binary splitting may render,"To take full advantage of the scheme, fast multiplication algorithms such as ToomCook and SchnhageStrassen must be used; with ordinary O(n2) multiplication, binary splitting may render no speedup at all or be slower."
fast multiplication algorithms,"To take full advantage of the scheme, fast multiplication algorithms such as ToomCook and SchnhageStrassen must be used; with ordinary O(n2) multiplication, binary splitting may render no speedup at all or be slower."
take full advantage,"To take full advantage of the scheme, fast multiplication algorithms such as ToomCook and SchnhageStrassen must be used; with ordinary O(n2) multiplication, binary splitting may render no speedup at all or be slower."
binary splitting lends well,"Since all subdivisions of the series can be computed independently of each other, binary splitting lends well to parallelization and checkpointing."
computed independently,"Since all subdivisions of the series can be computed independently of each other, binary splitting lends well to parallelization and checkpointing."
designs stakeholders,"A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
software design description,"IEEE 1016-2009, titled IEEE Standard for Information TechnologySystems DesignSoftware Design Descriptions, is an IEEE standard that specifies ""the required information content and organization"" for an SDD. !! A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
also software design specification,"A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
addressing various design concerns,"A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
required information content,"IEEE 1016-2009, titled IEEE Standard for Information TechnologySystems DesignSoftware Design Descriptions, is an IEEE standard that specifies ""the required information content and organization"" for an SDD."
information technologysystems designsoftware design descriptions,"IEEE 1016-2009, titled IEEE Standard for Information TechnologySystems DesignSoftware Design Descriptions, is an IEEE standard that specifies ""the required information content and organization"" for an SDD."
benefit analysis,"In network science, the optimization mechanism is a network growth algorithm, which randomly places new nodes in the system, and connects them to the existing nodes based on a cost-benefit analysis."
existing nodes based,"In network science, the optimization mechanism is a network growth algorithm, which randomly places new nodes in the system, and connects them to the existing nodes based on a cost-benefit analysis."
randomly places new nodes,"In network science, the optimization mechanism is a network growth algorithm, which randomly places new nodes in the system, and connects them to the existing nodes based on a cost-benefit analysis."
build three types,"Depending on the parameters used in the optimization mechanism, the algorithm can build three types of networks: a star network, a random network, and a scale-free network."
parameters used,"Depending on the parameters used in the optimization mechanism, the algorithm can build three types of networks: a star network, a random network, and a scale-free network."
underlying mechanism,"Optimization mechanism is thought to be the underlying mechanism in several real networks, such as transportation networks, power grid, router networks, the network of highways, etc."
several real networks,"Optimization mechanism is thought to be the underlying mechanism in several real networks, such as transportation networks, power grid, router networks, the network of highways, etc."
preferential attachment,"The optimization mechanism is a model with growth, in which preferential attachment is valid under certain assumptions."
certain assumptions,"The optimization mechanism is a model with growth, in which preferential attachment is valid under certain assumptions."
network built,determines the type of the network built by the optimization mechanism.
generally give prime factors,"Unlike integer factorization, primality tests do not generally give prime factors, only stating whether the input number is prime or not."
unlike integer factorization,"Unlike integer factorization, primality tests do not generally give prime factors, only stating whether the input number is prime or not."
primality tests,"Unlike integer factorization, primality tests do not generally give prime factors, only stating whether the input number is prime or not. !! Therefore, the latter might more accurately be called compositeness tests instead of primality tests. !! These tests use, apart from the tested number n, some other numbers a which are chosen at random from some sample space; the usual randomized primality tests never report a prime number as composite, but it is possible for a composite number to be reported as prime. !! Some primality tests prove that a number is prime, while others like MillerRabin prove that a number is composite. !! Many popular primality tests are probabilistic tests."
input number,"Unlike integer factorization, primality tests do not generally give prime factors, only stating whether the input number is prime or not."
stating whether,"Unlike integer factorization, primality tests do not generally give prime factors, only stating whether the input number is prime or not."
primality tests prove,"Some primality tests prove that a number is prime, while others like MillerRabin prove that a number is composite."
others like millerrabin prove,"Some primality tests prove that a number is prime, while others like MillerRabin prove that a number is composite."
called compositeness tests instead,"Therefore, the latter might more accurately be called compositeness tests instead of primality tests."
latter might,"Therefore, the latter might more accurately be called compositeness tests instead of primality tests."
many popular primality tests,Many popular primality tests are probabilistic tests.
tested number n,"These tests use, apart from the tested number n, some other numbers a which are chosen at random from some sample space; the usual randomized primality tests never report a prime number as composite, but it is possible for a composite number to be reported as prime."
tests use,"These tests use, apart from the tested number n, some other numbers a which are chosen at random from some sample space; the usual randomized primality tests never report a prime number as composite, but it is possible for a composite number to be reported as prime."
also cluster objects,"For example, object recognition favors supervised learning but unsupervised learning can also cluster objects into groups."
object recognition favors supervised learning,"For example, object recognition favors supervised learning but unsupervised learning can also cluster objects into groups."
methods including,"In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods including: Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations."
dominant use,"In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods including: Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations."
wake sleep,"In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods including: Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations."
variational inference,"Florian Wenzel developed two different versions, a variational inference (VI) scheme for the Bayesian kernel support vector machine (SVM) and a stochastic version (SVI) for the linear Bayesian SVM. !! In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods including: Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations."
unsupervised learning also employ,"In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods including: Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations."
hidden state reparameterizations,"In contrast to Supervised method's dominant use of Backpropagation, Unsupervised Learning also employ other methods including: Hopfield learning rule, Boltzmann learning rule, Contrastive Divergence, Wake Sleep, Variational Inference, Maximum Likelihood, Maximum A Posteriori, Gibbs Sampling, and backpropagating reconstruction errors or hidden state reparameterizations."
classical example,"The classical example of unsupervised learning in the study of neural networks is Donald Hebb's principle, that is, neurons that fire together wire together."
fire together wire together,"The classical example of unsupervised learning in the study of neural networks is Donald Hebb's principle, that is, neurons that fire together wire together."
mathematics focused,Chaos theory is an interdisciplinary scientific theory and branch of mathematics focused on underlying patterns and deterministic laws highly sensitive to initial conditions in dynamical systems that were thought to have completely random states of disorder and irregularities.
completely random states,Chaos theory is an interdisciplinary scientific theory and branch of mathematics focused on underlying patterns and deterministic laws highly sensitive to initial conditions in dynamical systems that were thought to have completely random states of disorder and irregularities.
deterministic laws highly sensitive,Chaos theory is an interdisciplinary scientific theory and branch of mathematics focused on underlying patterns and deterministic laws highly sensitive to initial conditions in dynamical systems that were thought to have completely random states of disorder and irregularities.
initial conditions,"In continuous time, the problem of finding a closed form solution for the state variables as a function of time and of the initial conditions is called the initial value problem. !! Chaos theory is an interdisciplinary scientific theory and branch of mathematics focused on underlying patterns and deterministic laws highly sensitive to initial conditions in dynamical systems that were thought to have completely random states of disorder and irregularities. !! is called the vector of initial conditions or simply the initial condition, and contains nk pieces of information, n being the dimension of the vector X and k = 1 being the number of time lags in the system."
underlying patterns,"Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnectedness, constant feedback loops, repetition, self-similarity, fractals, and self-organization. !! Chaos theory is an interdisciplinary scientific theory and branch of mathematics focused on underlying patterns and deterministic laws highly sensitive to initial conditions in dynamical systems that were thought to have completely random states of disorder and irregularities."
constant feedback loops,"Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnectedness, constant feedback loops, repetition, self-similarity, fractals, and self-organization."
apparent randomness,"Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnectedness, constant feedback loops, repetition, self-similarity, fractals, and self-organization."
including meteorology,"Chaos theory has applications in a variety of disciplines, including meteorology, anthropology, sociology, environmental science, computer science, engineering, economics, ecology, pandemic crisis management."
pandemic crisis management,"Chaos theory has applications in a variety of disciplines, including meteorology, anthropology, sociology, environmental science, computer science, engineering, economics, ecology, pandemic crisis management."
environmental science,"Chaos theory has applications in a variety of disciplines, including meteorology, anthropology, sociology, environmental science, computer science, engineering, economics, ecology, pandemic crisis management."
theory formed,"The theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory, and self-assembly processes."
264 decoders always support quarter,H. 264 decoders always support quarter-pixel motion.
much like half,"Quarter-pixel motion compensation, much like half-pixel, is achieved through interpolation."
using statistical methods,"Statistical relational learning (SRL) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure."
field include statistical relational learning,"Therefore, alternative terms that reflect the main foci of the field include statistical relational learning and reasoning (emphasizing the importance of reasoning) and first-order probabilistic languages (emphasizing the key properties of the languages with which models are represented)."
alternative terms,"Therefore, alternative terms that reflect the main foci of the field include statistical relational learning and reasoning (emphasizing the importance of reasoning) and first-order probabilistic languages (emphasizing the key properties of the languages with which models are represented)."
main foci,"Therefore, alternative terms that reflect the main foci of the field include statistical relational learning and reasoning (emphasizing the importance of reasoning) and first-order probabilistic languages (emphasizing the key properties of the languages with which models are represented)."
common ones,"A number of canonical tasks are associated with statistical relational learning, the most common ones being."
canonical tasks,"A number of canonical tasks are associated with statistical relational learning, the most common ones being."
human body,"Human presence detection is a range of technologies and methods for detecting the presence of a human body in an area of interest (AOI), or verification that computer, smartphone (or other device controlled by software) is operated by human. !! Unlike human sensing, that is dealing with human body only, human presence detection technologies are used to verify for safety, security or other reasons that human person, but not any other object is identified. !! A peripheral nerve interface is the bridge between the peripheral nervous system and a computer interface which serves as a bidirectional information transducer recording and sending signals between the human body and a machine processor."
device controlled,"Human presence detection is a range of technologies and methods for detecting the presence of a human body in an area of interest (AOI), or verification that computer, smartphone (or other device controlled by software) is operated by human."
human presence detection,"Human presence detection is a range of technologies and methods for detecting the presence of a human body in an area of interest (AOI), or verification that computer, smartphone (or other device controlled by software) is operated by human. !! Unlike human sensing, that is dealing with human body only, human presence detection technologies are used to verify for safety, security or other reasons that human person, but not any other object is identified. !! Software and hardware technologies are used for human presence detection."
unlike human sensing,"Unlike human sensing, that is dealing with human body only, human presence detection technologies are used to verify for safety, security or other reasons that human person, but not any other object is identified."
human presence detection technologies,"Unlike human sensing, that is dealing with human body only, human presence detection technologies are used to verify for safety, security or other reasons that human person, but not any other object is identified."
human person,"Unlike human sensing, that is dealing with human body only, human presence detection technologies are used to verify for safety, security or other reasons that human person, but not any other object is identified."
world bank,"Furthermore, the international organizations such as the I. M. F. and the World Bank have independent evaluation functions."
establish un norms,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
various funds,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
works together,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
united nations,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
wide un evaluation group,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
evaluation functions,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
resource usage,"Computational complexity theory focuses on classifying computational problems according to their resource usage, and relating these classes to each other."
classifying computational problems according,"In computer science, parameterized complexity is a branch of computational complexity theory that focuses on classifying computational problems according to their inherent difficulty with respect to multiple parameters of the input or output. !! Computational complexity theory focuses on classifying computational problems according to their resource usage, and relating these classes to each other."
computational complexity theory focuses,"Computational complexity theory focuses on classifying computational problems according to their resource usage, and relating these classes to each other."
practical limits,One of the roles of computational complexity theory is to determine the practical limits on what computers can and cannot do.
particular algorithm,"A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem."
latter asks,"A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem."
possible algorithms,"A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem."
key distinction,"A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem."
resources needed,"Algorithm analysis is an important part of a broader computational complexity theory, which provides theoretical estimates for the resources needed by any algorithm which solves a given computational problem. !! In computer science, the analysis of algorithms is the process of finding the computational complexity of algorithmsthe amount of time, storage, or other resources needed to execute them. !! A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem. !! Queueing theory is generally considered a branch of operations research because the results are often used when making business decisions about the resources needed to provide a service."
general question,"A key distinction between analysis of algorithms and computational complexity theory is that the former is devoted to analyzing the amount of resources needed by a particular algorithm to solve a problem, whereas the latter asks a more general question about all possible algorithms that could be used to solve the same problem."
appropriately restricted resources,"More precisely, computational complexity theory tries to classify problems that can or cannot be solved with appropriately restricted resources."
computational complexity theory tries,"More precisely, computational complexity theory tries to classify problems that can or cannot be solved with appropriately restricted resources."
classify problems,"More precisely, computational complexity theory tries to classify problems that can or cannot be solved with appropriately restricted resources."
problem refers,"In computational complexity theory, a problem refers to the abstract question to be solved."
abstract question,"In computational complexity theory, a problem refers to the abstract question to be solved."
free content projects,"Database dumps are often published by free content projects, to allow reuse or forking, as well as local searching of the database using tools such as grep."
often published,"Database dumps are often published by free content projects, to allow reuse or forking, as well as local searching of the database using tools such as grep."
local searching,"Database dumps are often published by free content projects, to allow reuse or forking, as well as local searching of the database using tools such as grep."
allow reuse,"Database dumps are often published by free content projects, to allow reuse or forking, as well as local searching of the database using tools such as grep."
exceedingly rare,"In computer science, the ostrich algorithm is a strategy of ignoring potential problems on the basis that they may be exceedingly rare."
ignoring potential problems,"In computer science, the ostrich algorithm is a strategy of ignoring potential problems on the basis that they may be exceedingly rare."
prevention would,The ostrich algorithm pretends there is no problem and is reasonable to use if deadlocks occur very rarely and the cost of their prevention would be high.
deadlocks occur,The ostrich algorithm pretends there is no problem and is reasonable to use if deadlocks occur very rarely and the cost of their prevention would be high.
ostrich algorithm pretends,The ostrich algorithm pretends there is no problem and is reasonable to use if deadlocks occur very rarely and the cost of their prevention would be high.
dynamic avoidance,"Although using the ostrich algorithm is one of the methods of dealing with deadlocks, other effective methods exist such as dynamic avoidance, banker's algorithm, detection and recovery, and prevention."
effective methods exist,"Although using the ostrich algorithm is one of the methods of dealing with deadlocks, other effective methods exist such as dynamic avoidance, banker's algorithm, detection and recovery, and prevention."
although using,"Although using the ostrich algorithm is one of the methods of dealing with deadlocks, other effective methods exist such as dynamic avoidance, banker's algorithm, detection and recovery, and prevention."
although efficient,"Although efficient, using the Ostrich algorithm trades correctness for convenience."
ostrich algorithm trades correctness,"Although efficient, using the Ostrich algorithm trades correctness for convenience."
returned solution,"In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one. !! However, there are also many approximation algorithms that provide an additive guarantee on the quality of the returned solution."
operations research,"Constraint programming (CP) is a paradigm for solving combinatorial problems that draws on a wide range of techniques from artificial intelligence, computer science, and operations research. !! In computer science and operations research, the artificial bee colony algorithm (ABC) is an optimization algorithm based on the intelligent foraging behaviour of honey bee swarm, proposed by Dervi Karaboa (Erciyes University) in 2005. !! Factor analysis is commonly used in psychometrics, personality psychology, biology, marketing, product management, operations research, finance, and machine learning. !! Description of semi-infinite programming from INFORMS (Institute for Operations Research and Management Science). !! In operations research, the area in which online algorithms are developed is called online optimization. !! Online optimization is a field of optimization theory, more popular in computer science and operations research, that deals with optimization problems having no or incomplete knowledge of the future (online). !! Combinatorial optimization is related to operations research, algorithm theory, and computational complexity theory. !! In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one. !! Artificial imagination research uses tools and insights from many fields, including computer science, rhetoric, psychology, creative arts, philosophy, neuroscience, affective computing, Artificial Intelligence, cognitive science, linguistics, operations research, creative writing, probability and logic. !! In computer science and operations research, the bees algorithm is a population-based search algorithm which was developed by Pham, Ghanbarzadeh et al. !! The set cover problem is a classical question in combinatorics, computer science, operations research, and complexity theory. !! In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). !! Queueing theory is generally considered a branch of operations research because the results are often used when making business decisions about the resources needed to provide a service."
find approximate solutions,"In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one."
hard problems,"In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one."
efficient algorithms,"Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software. !! Efficient algorithms can perform inference and learning in Bayesian networks. !! The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems. !! Fast and Efficient Algorithms in Computational Electromagnetics. !! In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one. !! However, typical research in quantum neural networks involves combining classical artificial neural network models (which are widely used in machine learning for the important task of pattern recognition) with the advantages of quantum information in order to develop more efficient algorithms."
particular np,"In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one."
provable guarantees,"In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one."
widely believed p np conjecture,Approximation algorithms naturally arise in the field of theoretical computer science as a consequence of the widely believed P NP conjecture.
approximation algorithms naturally arise,Approximation algorithms naturally arise in the field of theoretical computer science as a consequence of the widely believed P NP conjecture.
approximate optimal solutions,"The field of approximation algorithms, therefore, tries to understand how closely it is possible to approximate optimal solutions to such problems in polynomial time."
additive guarantee,"However, there are also many approximation algorithms that provide an additive guarantee on the quality of the returned solution."
also many approximation algorithms,"However, there are also many approximation algorithms that provide an additive guarantee on the quality of the returned solution."
worst case,"Merge-insertion sort also performs fewer comparisons than the sorting numbers, which count the comparisons made by binary insertion sort or merge sort in the worst case. !! The design and analysis of approximation algorithms crucially involves a mathematical proof certifying the quality of the returned solutions in the worst case."
approximation algorithms crucially involves,The design and analysis of approximation algorithms crucially involves a mathematical proof certifying the quality of the returned solutions in the worst case.
mathematical proof certifying,The design and analysis of approximation algorithms crucially involves a mathematical proof certifying the quality of the returned solutions in the worst case.
returned solutions,The design and analysis of approximation algorithms crucially involves a mathematical proof certifying the quality of the returned solutions in the worst case.
universal communication format,Universal communication format is a communication protocol developed by the IEEE for multimedia communication.
communication protocol developed,Universal communication format is a communication protocol developed by the IEEE for multimedia communication.
popular modelviewcontroller architecture,"To support React's concept of unidirectional data flow (which might be contrasted with AngularJS's bidirectional flow), the Flux architecture was developed as an alternative to the popular modelviewcontroller architecture."
physical movements,Molecular dynamics (MD) is a computer simulation method for analyzing the physical movements of atoms and molecules.
time averages,"For systems that obey the ergodic hypothesis, the evolution of one molecular dynamics simulation may be used to determine macroscopic thermodynamic properties of the system: the time averages of an ergodic system correspond to microcanonical ensemble averages."
determine macroscopic thermodynamic properties,"For systems that obey the ergodic hypothesis, the evolution of one molecular dynamics simulation may be used to determine macroscopic thermodynamic properties of the system: the time averages of an ergodic system correspond to microcanonical ensemble averages."
one molecular dynamics simulation may,"For systems that obey the ergodic hypothesis, the evolution of one molecular dynamics simulation may be used to determine macroscopic thermodynamic properties of the system: the time averages of an ergodic system correspond to microcanonical ensemble averages."
popular method,"The results of MD simulations can be tested through comparison to experiments that measure molecular dynamics, of which a popular method is NMR spectroscopy."
md simulations,"The results of MD simulations can be tested through comparison to experiments that measure molecular dynamics, of which a popular method is NMR spectroscopy."
measure molecular dynamics,"The results of MD simulations can be tested through comparison to experiments that measure molecular dynamics, of which a popular method is NMR spectroscopy."
molecular mechanics,"a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure. """
molecular dynamics generally leads,"a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure. """
less like,"a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure. """
energy minimization,"The conjugate gradient method can also be used to solve unconstrained optimization problems such as energy minimization. !! a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure. """
central embarrassment,"a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure. """
identify compounds,implemented molecular dynamics simulation to identify compounds that complement the receptor while causing minimal disruption of the conformation and flexibility of the active site.
several object,"Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
programming idiom used,"Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
resource acquisition,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct. !! Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
technique leads,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
finally construct used,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
nodes compete,"Competitive learning is a form of unsupervised learning in artificial neural networks, in which nodes compete for the right to respond to a subset of the input data."
algorithms based,Models and algorithms based on the principle of competitive learning include vector quantization and self-organizing maps (Kohonen maps).
competitive learning include vector quantization,Models and algorithms based on the principle of competitive learning include vector quantization and self-organizing maps (Kohonen maps).
commonly known,Competitive Learning is usually implemented with Neural Networks that contain a hidden layer which is commonly known as competitive layer.
usually implemented,"An AND gate can be designed using only N-channel (pictured) or P-channel MOSFETs, but is usually implemented with both (CMOS). !! Competitive Learning is usually implemented with Neural Networks that contain a hidden layer which is commonly known as competitive layer."
find three clusters within,Here is a simple competitive learning algorithm to find three clusters within some input data.
simple competitive learning algorithm,Here is a simple competitive learning algorithm to find three clusters within some input data.
ensure referential integrity,"Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management."
third normal form,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table). !! Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management. !! A database relation (e. g. a database table) is said to meet third normal form standards if all the attributes (e. g. database columns) are functionally dependent on solely the primary key. !! The third normal form (3NF) is a normal form used in database normalization. !! A hypothetical example of a failure to meet third normal form would be a hospital database having a table of patients which included a column for the telephone number of their doctor."
uses normalizing principles,"Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management."
database schema design approach,"Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management."
avoid data anomalies,"Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management."
meet third normal form standards,A database relation (e. g. a database table) is said to meet third normal form standards if all the attributes (e. g. database columns) are functionally dependent on solely the primary key.
meet third normal form would,A hypothetical example of a failure to meet third normal form would be a hospital database having a table of patients which included a column for the telephone number of their doctor.
telephone number,A hypothetical example of a failure to meet third normal form would be a hospital database having a table of patients which included a column for the telephone number of their doctor.
doctor table,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
negative outcome,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
thus increasing,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
multiple patients,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
normal form used,The third normal form (3NF) is a normal form used in database normalization.
nathan dautenhahn,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
cryptographic hash function designed,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
michael collins,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
tim draelos,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
hilarie orman,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
mark torgerson,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
richard schroeppel,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
sandstorm hash,"The SANDstorm hash was accepted into the first round of the NIST hash function competition, but was not accepted into the second round. !! The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
andrea walker,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
first round,"The SANDstorm hash was accepted into the first round of the NIST hash function competition, but was not accepted into the second round."
second round,"The SANDstorm hash was accepted into the first round of the NIST hash function competition, but was not accepted into the second round."
real large,"For this reason, ranking-based similarity learning is easier to apply in real large-scale applications."
bellet et al,"For further information on this topic, see the surveys on metric and similarity learning by Bellet et al."
nnmf  also non,"Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements."
three matrices,"Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements."
two matrices w,"Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements."
long history,"From the technology perspective, speech recognition has a long history with several waves of major innovations. !! In chemometrics non-negative matrix factorization has a long history under the name ""self modeling curve resolution""."
name positive matrix factorization,Also early work on non-negative matrix factorizations was performed by a Finnish group of researchers in the 1990s under the name positive matrix factorization.
also early work,Also early work on non-negative matrix factorizations was performed by a Finnish group of researchers in the 1990s under the name positive matrix factorization.
finnish group,Also early work on non-negative matrix factorizations was performed by a Finnish group of researchers in the 1990s under the name positive matrix factorization.
negative matrix factorization lee,In Learning the parts of objects by non-negative matrix factorization Lee and Seung proposed NMF mainly for parts-based decomposition of images.
seung proposed nmf mainly,In Learning the parts of objects by non-negative matrix factorization Lee and Seung proposed NMF mainly for parts-based decomposition of images.
inverse iteration algorithm requires solving,The inverse iteration algorithm requires solving a linear system or calculation of the inverse matrix.
previous step,"Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration."
finds approximate eigenvalues,"Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration."
vector obtained,"Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration."
standard example,"Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration."
another example,"Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration. !! Another example is a hardware description language such as Verilog, where reactive programming enables changes to be modeled as they propagate through circuits. !! Another example of a physical neural network is taught by U. S. Patent No. !! Consequently, exploratory search covers a broader class of activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined conceptual area; exploratory data analysis is another example of an information exploration activity. !! Care-Centered Value Sensitive Design (CCVSD) proposed by Aimee van Wynsberghe is another example of how the VSD approach is modified to account for the values central to care for the design and development of care robots."
chemically connected,A biological neural network is composed of a groups of chemically connected or functionally associated neurons.
information processing paradigms inspired,"Artificial intelligence, cognitive modeling, and neural networks are information processing paradigms inspired by the way biological neural systems process data."
sometimes trying thousands,"In cryptanalysis and computer security, a dictionary attack is an attack using a restricted subset of a keyspace to defeat a cipher or authentication mechanism by trying to determine its decryption key or passphrase, sometimes trying thousands or millions of likely possibilities often obtained from lists of past security breaches."
dictionary attack,"In cryptanalysis and computer security, a dictionary attack is an attack using a restricted subset of a keyspace to defeat a cipher or authentication mechanism by trying to determine its decryption key or passphrase, sometimes trying thousands or millions of likely possibilities often obtained from lists of past security breaches. !! Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character. !! A dictionary attack tries only those possibilities which are deemed most likely to succeed. !! Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches. !! A dictionary attack is based on trying all the strings in a pre-arranged listing."
attack using,"In cryptanalysis and computer security, a dictionary attack is an attack using a restricted subset of a keyspace to defeat a cipher or authentication mechanism by trying to determine its decryption key or passphrase, sometimes trying thousands or millions of likely possibilities often obtained from lists of past security breaches."
likely possibilities often obtained,"In cryptanalysis and computer security, a dictionary attack is an attack using a restricted subset of a keyspace to defeat a cipher or authentication mechanism by trying to determine its decryption key or passphrase, sometimes trying thousands or millions of likely possibilities often obtained from lists of past security breaches."
restricted subset,"In cryptanalysis and computer security, a dictionary attack is an attack using a restricted subset of a keyspace to defeat a cipher or authentication mechanism by trying to determine its decryption key or passphrase, sometimes trying thousands or millions of likely possibilities often obtained from lists of past security breaches."
arranged listing,A dictionary attack is based on trying all the strings in a pre-arranged listing.
much larger lists available,"Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches."
open internet containing hundreds,"Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches."
reducing access time,"Hash functions rely on generating favourable probability distributions for their effectiveness, reducing access time to nearly constant."
hm that finds the position of a target value within a sorted array. !! in computer science, program analysis is the process of automatically analyzing the behavior of computer programs regarding a property such as correctness
takes actions autonomously,"In artificial intelligence, an intelligent agent (IA) is anything which perceives its environment, takes actions autonomously in order to achieve goals, and may improve its performance with learning or may use knowledge."
leading ai textbooks define,"Leading AI textbooks define ""artificial intelligence"" as the ""study and design of intelligent agents"", a definition that considers goal-directed behavior to be the essence of intelligence."
many programming languages,"String interpolation is common in many programming languages which make heavy use of string representations of data, such as Apache Groovy, Julia, Kotlin, Perl, PHP, Python, Ruby, Scala, Swift, Tcl and most Unix shells. !! Many programming languages, such as C, never perform automatic bounds checking to raise speed. !! Many programming languages, including Java and C#, have built-in support for retrieving the current stack trace via system calls."
many different matrix decompositions,There are many different matrix decompositions; each finds use among a particular class of problems.
tasks like outliers detection,"More formally, a support-vector machine constructs a hyperplane or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks like outliers detection."
interpret svm models,Support-vector machine weights have also been used to interpret SVM models in the past.
algorithm still performs well,"It is noteworthy that working in a higher-dimensional feature space increases the generalization error of support-vector machines, although given enough samples the algorithm still performs well."
attacks originally used words found,"Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches."
past data breaches,"Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches."
phrase dictionary attack  however,"Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches."
dictionary attack tries,A dictionary attack tries only those possibilities which are deemed most likely to succeed.
ordinary words,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character."
variants obtained,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character."
punctuation character,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character."
common passwords,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character."
choose short passwords,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character."
dictionary attacks often succeed,"Dictionary attacks often succeed because many people have a tendency to choose short passwords that are ordinary words or common passwords; or variants obtained, for example, by appending a digit or punctuation character."
takes two matrices,"In mathematics, the Frobenius inner product is a binary operation that takes two matrices and returns a number."
code reuse,Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class.
desired functionality,Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class.
achieve polymorphic behavior,Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class.
various interfaces representing,An implementation of composition over inheritance typically begins with the creation of various interfaces representing the behaviors that the system must exhibit.
inheritance typically begins,An implementation of composition over inheritance typically begins with the creation of various interfaces representing the behaviors that the system must exhibit.
system must exhibit,An implementation of composition over inheritance typically begins with the creation of various interfaces representing the behaviors that the system must exhibit.
favor composition,To favor composition over inheritance is a design principle that gives the design higher flexibility.
design higher flexibility,To favor composition over inheritance is a design principle that gives the design higher flexibility.
design principle,"Service abstraction is a design principle that is applied within the service-orientation design paradigm so that the information published in a service contract is limited to what is required to effectively utilize the service The service contract should not contain any superfluous information that is not required for its invocation. !! The service reusability principle is a design principle, applied within the service-orientation design paradigm, to create services that can be reused across a business. !! To favor composition over inheritance is a design principle that gives the design higher flexibility."
intermediate representation,"In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used. !! Loop optimization can be viewed as the application of a sequence of specific loop transformations (listed below or in Compiler transformations for high-performance computing) to the source code or intermediate representation, with each transformation having an associated test for legality."
often abbreviated,"In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used. !! Interaction design, often abbreviated as IxD, is ""the practice of designing interactive digital products, environments, systems, and services. !! The Rich Representation Language, often abbreviated as RRL, is a computer animation language specifically designed to facilitate the interaction of two or more animated characters. !! In numerical linear algebra, the biconjugate gradient stabilized method, often abbreviated as BiCGSTAB, is an iterative method developed by H. A. van der Vorst for the numerical solution of nonsymmetric linear systems."
static single assignment,"0 to ""internally use an intermediate representation based on Static Single Assignment (SSA). "" !! ""The Development of Static Single Assignment Form"", December 2007 talk on the origins of SSA. !! In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used. !! Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol. !! A Correspondence between Continuation Passing Style and Static Single Assignment Form."
simply ssa,"In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used."
every variable,"In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used."
assigned exactly,"In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used."
internally use,"0 to ""internally use an intermediate representation based on Static Single Assignment (SSA). """
christoph mallon,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
matthias braun,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
roland leia,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
sebastian hack,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
andreas zwinkau,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
efficient construction,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
lecture notes,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol. !! Craig Gentry, Certificate-Based Encryption and the Certificate Revocation Problem, Lecture Notes in Computer Science, pp. !! VanDrunen, T. , and Hosking, A. L. Value-Based Partial Redundancy Elimination, Lecture Notes in Computer Science Vol. !! Lecture notes on the asymptotic gain model"
conquer recurrences provides,"In the analysis of algorithms, the master theorem for divide-and-conquer recurrences provides an asymptotic analysis (using Big O notation) for recurrence relations of types that occur in the analysis of many divide and conquer algorithms."
using big,"In the analysis of algorithms, the master theorem for divide-and-conquer recurrences provides an asymptotic analysis (using Big O notation) for recurrence relations of types that occur in the analysis of many divide and conquer algorithms."
many divide,"In the analysis of algorithms, the master theorem for divide-and-conquer recurrences provides an asymptotic analysis (using Big O notation) for recurrence relations of types that occur in the analysis of many divide and conquer algorithms."
asymptotic analysis,"In the analysis of algorithms, the master theorem for divide-and-conquer recurrences provides an asymptotic analysis (using Big O notation) for recurrence relations of types that occur in the analysis of many divide and conquer algorithms."
widely used algorithms textbook introduction,"The name ""master theorem"" was popularized by the widely used algorithms textbook Introduction to Algorithms by Cormen, Leiserson, Rivest, and Stein."
notation directly,"The master theorem allows many recurrence relations of this form to be converted to -notation directly, without doing an expansion of the recursive relation."
smaller subproblems,"The master theorem always yields asymptotically tight bounds to recurrences from divide and conquer algorithms that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem."
equal sizes,"The master theorem always yields asymptotically tight bounds to recurrences from divide and conquer algorithms that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem."
original problem,"The master theorem always yields asymptotically tight bounds to recurrences from divide and conquer algorithms that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem."
subproblem solutions,"The master theorem always yields asymptotically tight bounds to recurrences from divide and conquer algorithms that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem."
subproblems recursively,"The master theorem always yields asymptotically tight bounds to recurrences from divide and conquer algorithms that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem."
basic form,"The stable model semantics, in its basic form, can be viewed as a reformulation of this idea that avoids explicit references to autoepistemic logic. !! These algorithms find the minimum spanning forest in a possibly disconnected graph; in contrast, the most basic form of Prim's algorithm only finds minimum spanning trees in connected graphs. !! Therefore, the difference is not polynomial and the basic form of the Master Theorem does not apply."
national centers,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
climate timescales,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
coupled forecast system,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
environmental prediction,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
climate model run,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
bridge weather,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
long range numerical weather prediction,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
expression results,"In compiler optimization, register allocation is the process of assigning local automatic variables and expression results to a limited number of processor registers."
limited number,"To achieve better performance, many language runtimes employ some form of non-inline caching where the results of a limited number of method lookups are stored in an associative data structure. !! If the function is only used once, or a limited number of times, an anonymous function may be syntactically lighter than using a named function. !! In compiler optimization, register allocation is the process of assigning local automatic variables and expression results to a limited number of processor registers."
assigning local automatic variables,"In compiler optimization, register allocation is the process of assigning local automatic variables and expression results to a limited number of processor registers."
specific categories,Many register allocation approaches optimize for one or more specific categories of actions.
many register allocation approaches optimize,Many register allocation approaches optimize for one or more specific categories of actions.
different register allocation approaches,Register allocation raises several problems that can be tackled (or avoided) by different register allocation approaches.
register allocation raises several problems,Register allocation raises several problems that can be tackled (or avoided) by different register allocation approaches.
also implement boolean logic,SKI combinator calculus can also implement Boolean logic in the form of an if-then-else structure.
supporting different sets,"There are general, spatial, temporal, spatiotemporal, and fuzzy description logics, and each description logic features a different balance between expressive power and reasoning complexity by supporting different sets of mathematical constructors."
many varieties,"There are many varieties of description logics and there is an informal naming convention, roughly describing the operators allowed."
roughly describing,"There are many varieties of description logics and there is an informal naming convention, roughly describing the operators allowed."
often applied,"Model checking is most often applied to hardware designs. !! Techniques for series acceleration are often applied in numerical analysis, where they are used to improve the speed of numerical integration."
two classical techniques,Two classical techniques for series acceleration are Euler's transformation of series and Kummer's transformation of series.
sequitur algorithm constructs,The sequitur algorithm constructs a grammar by substituting repeating phrases in the given sequence with new rules and therefore produces a concise representation of the sequence.
new rules,The sequitur algorithm constructs a grammar by substituting repeating phrases in the given sequence with new rules and therefore produces a concise representation of the sequence.
therefore produces,The sequitur algorithm constructs a grammar by substituting repeating phrases in the given sequence with new rules and therefore produces a concise representation of the sequence.
given sequence,"The sequitur algorithm constructs a grammar by substituting repeating phrases in the given sequence with new rules and therefore produces a concise representation of the sequence. !! In computer science, pattern matching is the act of checking a given sequence of tokens for the presence of the constituents of some pattern. !! In computer science, an optimal binary search tree (Optimal BST), sometimes called a weight-balanced binary tree, is a binary search tree which provides the smallest possible search time (or expected search time) for a given sequence of accesses (or access probabilities). !! In computer science, the longest increasing subsequence problem is to find a subsequence of a given sequence in which the subsequence's elements are in sorted order, lowest to highest, and in which the subsequence is as long as possible. !! In combinatorial mathematics, probability, and computer science, in the longest alternating subsequence problem, one wants to find a subsequence of a given sequence in which the elements are in alternating order, and in which the sequence is as long as possible."
reference sequitur algorithm implementation,"info the reference Sequitur algorithm implementation in C++, Java, and other languages"
two specific sets,"In computer science, a randomization function or randomizing function is an algorithm or procedure that implements a randomly chosen function between two specific sets, suitable for use in a randomized algorithm."
unpredictably different function every time,"In theory, randomization functions are assumed to be truly random, and yield an unpredictably different function every time the algorithm is executed."
mapping entirely determined,"The randomization technique would not work if, at every execution of the algorithm, the randomization function always performed the same mapping, or a mapping entirely determined by some externally observable parameter (such as the program's startup time)."
randomization function always performed,"The randomization technique would not work if, at every execution of the algorithm, the randomization function always performed the same mapping, or a mapping entirely determined by some externally observable parameter (such as the program's startup time)."
randomization technique would,"The randomization technique would not work if, at every execution of the algorithm, the randomization function always performed the same mapping, or a mapping entirely determined by some externally observable parameter (such as the program's startup time)."
preferably seeded,"So, in practice one often uses randomization functions that are derived from pseudo-random number generators, preferably seeded with external ""random"" data such as the program's startup time."
basic form uses,"Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist."
complex extensions exist,"Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist."
although many,"Logistic regression is a statistical model that in its basic form uses a logistic function to model a binary dependent variable, although many more complex extensions exist. !! The shapes studied in geometric modeling are mostly two- or three-dimensional, although many of its tools and principles can be applied to sets of any finite dimension."
given outcome,"Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio."
defining characteristic,"Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio."
different sigmoid function instead,"Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio."
increasing one,"Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio."
machine learning algorithm studied since 1970s,A learning automaton is one type of machine learning algorithm studied since 1970s.
one type,"A learning automaton is one type of machine learning algorithm studied since 1970s. !! One type of data occurring simultaneously in different cache memory is called cache coherence, or in some systems, global memory."
survey paper,"However, the term learning automaton was not used until Narendra and Thathachar introduced it in a survey paper in 1974."
thathachar introduced,"However, the term learning automaton was not used until Narendra and Thathachar introduced it in a survey paper in 1974."
making unit situated,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
repeated interactions,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
random environment,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
art work,A visualised demo / Art Work of a single Learning Automaton had been developed by Systems (microSystems) Research Group at Newcastle University.
newcastle university,A visualised demo / Art Work of a single Learning Automaton had been developed by Systems (microSystems) Research Group at Newcastle University.
research group,A visualised demo / Art Work of a single Learning Automaton had been developed by Systems (microSystems) Research Group at Newcastle University.
proof assistants,The proof checking feature makes dependently typed languages closely related to proof assistants.
fundamental principles,"A fundamental concept of Control theory, the closed control loop, is among the fundamental principles of autonomic networking."
fundamental concept,"A fundamental concept of Control theory, the closed control loop, is among the fundamental principles of autonomic networking."
closed control loop,"A fundamental concept of Control theory, the closed control loop, is among the fundamental principles of autonomic networking."
efipsans project http  www,Generic Autonomic Networking Architecture (GANA) EFIPSANS Project http://www.
enterprise wan governance blog,Autonomic networking at the core of enterprise Wan governance blog
generalizes well,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
membership inference attacks,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
poor machine learning practices,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
membership inference,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
every word,"In computer science, a tagged architecture is a particular type of computer architecture where every word of memory constitutes a tagged union, being divided into a number of bits of data, and a tag section that describes the type of the data: how it is to be interpreted, and, if it is a reference, the type of the object that it points to."
solving partial differential equations,Large sparse matrices often appear in scientific or engineering applications when solving partial differential equations.
often necessary,"When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix."
operations using standard dense,Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros.
manipulate using standard dense,Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.
independent software entities interact,"In computer science, a public interface is the logical point at which independent software entities interact."
logical point,"In computer science, a public interface is the logical point at which independent software entities interact."
optimizing internal,"Value network analysis (VNA) is a methodology for understanding, using, visualizing, optimizing internal and external value networks and complex economic ecosystems."
value network analysis offers,"Value network analysis offers a taxonomy for non-financial business reporting, which is becoming increasingly important in SEC Filings."
becoming increasingly important,"Value network analysis offers a taxonomy for non-financial business reporting, which is becoming increasingly important in SEC Filings. !! The capability of cross-domain interoperability is becoming increasingly important as business and government operations become more global and interdependent."
financial business reporting,"Value network analysis offers a taxonomy for non-financial business reporting, which is becoming increasingly important in SEC Filings."
future capability,"In contrast, value network analysis is one approach to assessing current and future capability for value creation and to describe and analyze a business model."
value creation,"In contrast, value network analysis is one approach to assessing current and future capability for value creation and to describe and analyze a business model."
one approach,"One approach to knowledge acquisition investigated was to use natural language parsing and generation to facilitate knowledge acquisition. !! In contrast, value network analysis is one approach to assessing current and future capability for value creation and to describe and analyze a business model."
assessing current,"In contrast, value network analysis is one approach to assessing current and future capability for value creation and to describe and analyze a business model."
financial value,Value network analysis addresses both financial and non-financial value.
traditional business practices ignore,"Traditional business practices ignore these important intangible exchanges, but they are made visible with a value network analysis."
important intangible exchanges,"Traditional business practices ignore these important intangible exchanges, but they are made visible with a value network analysis."
made visible,"Traditional business practices ignore these important intangible exchanges, but they are made visible with a value network analysis."
many optimization methods use,"More generally, if the objective function is not a quadratic function, then many optimization methods use other methods to ensure that some subsequence of iterations converges to an optimal solution."
iterations converges,"More generally, if the objective function is not a quadratic function, then many optimization methods use other methods to ensure that some subsequence of iterations converges to an optimal solution."
operations research uses stochastic programming,"Increasingly, operations research uses stochastic programming to model dynamic decisions that adapt to events; such problems can be solved with large-scale optimization and stochastic optimization methods."
receiving messages,"Message-oriented middleware (MOM) is software or hardware infrastructure supporting sending and receiving messages between distributed systems. !! The Messaging Open Service Interface Definition (OSID) is an O. K. I. specification which provided a means of sending, subscribing and receiving messages."
messaging open service interface definition,"The Messaging Open Service Interface Definition (OSID) is an O. K. I. specification which provided a means of sending, subscribing and receiving messages."
output based,Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.
example input,Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.
awe regions could therefore,"An article published in Dr. Dobb's Journal in 2004 noted that memory allocated using Address Windowing Extensions will not be written to the pagefile, and suggested that AWE regions could therefore be used as a way of protecting sensitive application data such as encryption keys."
article published,"An article published in Dr. Dobb's Journal in 2004 noted that memory allocated using Address Windowing Extensions will not be written to the pagefile, and suggested that AWE regions could therefore be used as a way of protecting sensitive application data such as encryption keys."
address windowing extensions coding example,Address Windowing Extensions Coding Example
open standard developed,Multimodal Architecture and Interfaces is an open standard developed by the World Wide Web Consortium since 2005.
world wide web consortium since 2005,Multimodal Architecture and Interfaces is an open standard developed by the World Wide Web Consortium since 2005.
interfaces recommendation introduces,The Multimodal Architecture and Interfaces recommendation introduces a generic structure and a communication protocol to allow the modules in a multimodal system to communicate with each other.
specified description,Multimodal Architecture and Interfaces is the specified description of a larger services infrastructure called The Runtime Framework which provides the main functions that a multimodal system can need.
larger services infrastructure called,Multimodal Architecture and Interfaces is the specified description of a larger services infrastructure called The Runtime Framework which provides the main functions that a multimodal system can need.
three parts,"The Multimodal Architecture and Interfaces specification is based on the MVC design pattern, that proposes to organize the user interface structure in three parts: the Model, the View and the Controller."
interfaces workshop,"Papers presented to W3C's Multimodal Architecture and Interfaces Workshop, 1920 July 2004."
papers presented,"Papers presented to W3C's Multimodal Architecture and Interfaces Workshop, 1920 July 2004."
usually abbreviated,ACS Combinatorial Science (usually abbreviated as ACS Comb.
acs combinatorial science,"ACS Combinatorial Science publishes articles, reviews, perspectives, accounts and reports in the field of Combinatorial Chemistry. !! ACS Combinatorial Science (usually abbreviated as ACS Comb."
acs comb,ACS Combinatorial Science (usually abbreviated as ACS Comb.
combinatorial chemistry,"ACS Combinatorial Science publishes articles, reviews, perspectives, accounts and reports in the field of Combinatorial Chemistry."
acs combinatorial science publishes articles,"ACS Combinatorial Science publishes articles, reviews, perspectives, accounts and reports in the field of Combinatorial Chemistry."
computer intensive simulations,The proper orthogonal decomposition is a numerical method that enables a reduction in the complexity of computer intensive simulations such as computational fluid dynamics and structural analysis (like crash simulations).
proper orthogonal decomposition,"The proper orthogonal decomposition is a numerical method that enables a reduction in the complexity of computer intensive simulations such as computational fluid dynamics and structural analysis (like crash simulations). !! Weiss, Julien: A Tutorial on the Proper Orthogonal Decomposition. !! Applications of the Proper Orthogonal Decomposition Method http://www."
like crash simulations,The proper orthogonal decomposition is a numerical method that enables a reduction in the complexity of computer intensive simulations such as computational fluid dynamics and structural analysis (like crash simulations).
principal components,"Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest. !! As its name hints, it's operating an Orthogonal Decomposition along with the Principal Components of the field."
orthogonal decomposition along,"As its name hints, it's operating an Orthogonal Decomposition along with the Principal Components of the field."
name hints,"As its name hints, it's operating an Orthogonal Decomposition along with the Principal Components of the field."
one data item,Scalar processors are a class of computer processors that process only one data item at a time.
single instruction,"A scalar processor is classified as a single instruction, single data (SISD) processor in Flynn's taxonomy."
single data,"A scalar processor is classified as a single instruction, single data (SISD) processor in Flynn's taxonomy."
one instruction,A superscalar processor (such as the Intel P5) may execute more than one instruction during a clock cycle by simultaneously dispatching multiple instructions to redundant functional units on the processor. !! A single cycle processor is a processor that carries out one instruction in a single clock cycle.
simultaneously dispatching multiple instructions,A superscalar processor (such as the Intel P5) may execute more than one instruction during a clock cycle by simultaneously dispatching multiple instructions to redundant functional units on the processor.
may execute,A superscalar processor (such as the Intel P5) may execute more than one instruction during a clock cycle by simultaneously dispatching multiple instructions to redundant functional units on the processor.
redundant functional units,A superscalar processor (such as the Intel P5) may execute more than one instruction during a clock cycle by simultaneously dispatching multiple instructions to redundant functional units on the processor.
like many consumer cpus today,"The Cortex-M7, like many consumer CPUs today, is a superscalar processor."
deceptively simple singleton pattern,How to navigate the deceptively simple Singleton pattern.
predicted according,Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals.
dynamically modify,Active networking is a communication pattern that allows packets flowing through a telecommunications network to dynamically modify the operation of the network.
one means,Network processors are one means of implementing active networking concepts.
implementing active networking concepts,Network processors are one means of implementing active networking concepts.
active networking allows,"Active networking allows the possibility of highly tailored and rapid ""real-time"" changes to the underlying network operation."
underlying network operation,"Active networking allows the possibility of highly tailored and rapid ""real-time"" changes to the underlying network operation."
highly tailored,"Active networking allows the possibility of highly tailored and rapid ""real-time"" changes to the underlying network operation."
also enabled,The use of real-time genetic algorithms within the network to compose network services is also enabled by active networking.
compose network services,The use of real-time genetic algorithms within the network to compose network services is also enabled by active networking.
time genetic algorithms within,The use of real-time genetic algorithms within the network to compose network services is also enabled by active networking.
active networking relates,Active networking relates to other networking paradigms primarily based upon how computing and communication are partitioned in the architecture.
networking paradigms primarily based upon,Active networking relates to other networking paradigms primarily based upon how computing and communication are partitioned in the architecture.
denormal numbers,"In IEEE 754-2008, denormal numbers are renamed subnormal numbers and are supported in both binary and decimal formats."
reveal internal structures hidden,"Medical imaging seeks to reveal internal structures hidden by the skin and bones, as well as to diagnose and treat disease."
normal anatomy,Medical imaging also establishes a database of normal anatomy and physiology to make it possible to identify abnormalities.
medical imaging also establishes,Medical imaging also establishes a database of normal anatomy and physiology to make it possible to identify abnormalities.
identify abnormalities,Medical imaging also establishes a database of normal anatomy and physiology to make it possible to identify abnormalities.
pathology instead,"Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging."
although imaging,"Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging."
removed organs,"Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging."
usually considered part,"Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging."
medical reasons,"Although imaging of removed organs and tissues can be performed for medical reasons, such procedures are usually considered part of pathology instead of medical imaging."
considered forms,"In a limited comparison, these technologies can be considered forms of medical imaging in another discipline."
another discipline,"In a limited comparison, these technologies can be considered forms of medical imaging in another discipline."
limited comparison,"In a limited comparison, these technologies can be considered forms of medical imaging in another discipline."
columns consisting,"In numerical analysis, interpolative decomposition (ID) factors a matrix as the product of two matrices, one of which contains selected columns from the original matrix, and the other of which has a subset of columns consisting of the identity matrix and all its values are no greater than 2 in absolute value."
contains selected columns,"In numerical analysis, interpolative decomposition (ID) factors a matrix as the product of two matrices, one of which contains selected columns from the original matrix, and the other of which has a subset of columns consisting of the identity matrix and all its values are no greater than 2 in absolute value."
financial transactions etc,"In computer science, data stream clustering is defined as the clustering of data that arrive continuously such as telephone records, multimedia data, financial transactions etc."
arrive continuously,"In computer science, data stream clustering is defined as the clustering of data that arrive continuously such as telephone records, multimedia data, financial transactions etc."
telephone records,"In computer science, data stream clustering is defined as the clustering of data that arrive continuously such as telephone records, multimedia data, financial transactions etc."
usually studied,"Data stream clustering is usually studied as a streaming algorithm and the objective is, given a sequence of points, to construct a good clustering of the stream, using a small amount of memory and time."
small amount,"Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. !! Moreover, many popular memory allocators will keep a small amount of metadata for each node allocated, increasing the effective overhead v. Both of these make unrolled linked lists more attractive. !! Data stream clustering is usually studied as a streaming algorithm and the objective is, given a sequence of points, to construct a good clustering of the stream, using a small amount of memory and time."
good clustering,"Data stream clustering is usually studied as a streaming algorithm and the objective is, given a sequence of points, to construct a good clustering of the stream, using a small amount of memory and time."
emerging applications,Data stream clustering has recently attracted attention for emerging applications that involve large amounts of streaming data.
involve large amounts,Data stream clustering has recently attracted attention for emerging applications that involve large amounts of streaming data.
recently attracted attention,Data stream clustering has recently attracted attention for emerging applications that involve large amounts of streaming data.
may also include accounting software,"Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources."
sharing operating systems schedule tasks,"Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources."
efficient use,"Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources."
many devices,Operating systems are found on many devices that contain a computer from cellular phones and video game consoles to web servers and supercomputers. !! The behavior of state machines can be observed in many devices in modern society that perform a predetermined sequence of actions depending on a sequence of events with which they are presented.
operating systems amount,"2 percent, while other operating systems amount to just 0."
many applications,"A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities. !! The term one-class classification (OCC) was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection. !! Markov chains have many applications as statistical models of real-world processes, such as studying cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, currency exchange rates and animal population dynamics. !! Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications. !! Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known. !! This operation and its O(1) performance is crucial to many applications of priority queues."
time systems,"Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications."
specialized classes,"Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications."
purpose operating systems,"Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications."
focused operating systems also exist,Security-focused operating systems also exist.
applying certain formal techniques,Data modeling in software engineering is the process of creating a data model for an information system by applying certain formal techniques.
analyze data requirements needed,Data modeling is a process used to define and analyze data requirements needed to support the business processes within the scope of corresponding information systems in organizations.
corresponding information systems,Data modeling is a process used to define and analyze data requirements needed to support the business processes within the scope of corresponding information systems in organizations.
process used,"Knowledge acquisition is the process used to define the rules and ontologies required for a knowledge-based system. !! Data modeling is a process used to define and analyze data requirements needed to support the business processes within the scope of corresponding information systems in organizations. !! State space search is a process used in the field of computer science, including artificial intelligence (AI), in which successive configurations or states of an instance are considered, with the intention of finding a goal state with the desired property."
business processes within,Data modeling is a process used to define and analyze data requirements needed to support the business processes within the scope of corresponding information systems in organizations.
business stakeholders,"Therefore, the process of data modeling involves professional data modelers working closely with business stakeholders, as well as potential users of the information system."
potential users,"Therefore, the process of data modeling involves professional data modelers working closely with business stakeholders, as well as potential users of the information system."
last step,"The last step in data modeling is transforming the logical data model to a physical data model that organizes the data into tables, and accounts for access, performance and storage details."
physical data model,"The last step in data modeling is transforming the logical data model to a physical data model that organizes the data into tables, and accounts for access, performance and storage details."
storage details,"The last step in data modeling is transforming the logical data model to a physical data model that organizes the data into tables, and accounts for access, performance and storage details."
data modeling defines,"Data modeling defines not just data elements, but also their structures and the relationships between them."
weaker version,"Some authors define a weaker version of the definition of ""graph embedding"" by omitting the non-intersection condition for edges."
intersection condition,"Some authors define a weaker version of the definition of ""graph embedding"" by omitting the non-intersection condition for edges."
authors define,"Some authors define a weaker version of the definition of ""graph embedding"" by omitting the non-intersection condition for edges."
stricter definition,"In such contexts the stricter definition is described as ""non-crossing graph embedding""."
strict definition,This article deals only with the strict definition of graph embedding.
article deals,This article deals only with the strict definition of graph embedding.
different components,"Software frameworks may include support programs, compilers, code libraries, toolsets, and application programming interfaces (APIs) that bring together all the different components to enable development of a project or system."
enable development,"Software frameworks may include support programs, compilers, code libraries, toolsets, and application programming interfaces (APIs) that bring together all the different components to enable development of a project or system."
bring together,"Software frameworks may include support programs, compilers, code libraries, toolsets, and application programming interfaces (APIs) that bring together all the different components to enable development of a project or system."
meeting software requirements rather,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
thereby reducing overall development time,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
allowing designers,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
level details,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
standard low,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
software frameworks aim,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
best frameworks,The elegance issue is why relatively few software frameworks have stood the test of time: the best frameworks have been able to evolve gracefully as the underlying technology on which they were built advanced.
elegance issue,The elegance issue is why relatively few software frameworks have stood the test of time: the best frameworks have been able to evolve gracefully as the underlying technology on which they were built advanced.
built advanced,The elegance issue is why relatively few software frameworks have stood the test of time: the best frameworks have been able to evolve gracefully as the underlying technology on which they were built advanced.
underlying technology,The elegance issue is why relatively few software frameworks have stood the test of time: the best frameworks have been able to evolve gracefully as the underlying technology on which they were built advanced.
evolve gracefully,The elegance issue is why relatively few software frameworks have stood the test of time: the best frameworks have been able to evolve gracefully as the underlying technology on which they were built advanced.
software frameworks consist,"According to Pree, software frameworks consist of frozen spots and hot spots."
hot spots,"According to Pree, software frameworks consist of frozen spots and hot spots."
frozen spots,"According to Pree, software frameworks consist of frozen spots and hot spots."
hollywood principle,"Software frameworks rely on the Hollywood Principle: ""Don't call us, we'll call you. """
software frameworks rely,"Software frameworks rely on the Hollywood Principle: ""Don't call us, we'll call you. """
call us,"Software frameworks rely on the Hollywood Principle: ""Don't call us, we'll call you. """
allows elements,"In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed."
growable array,"In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed."
dynamic arrays overcome,"Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation."
fixed capacity,"Dynamic arrays overcome a limit of static arrays, which have a fixed capacity that needs to be specified at allocation."
array whose size,"A dynamic array is not the same thing as a dynamically allocated array, which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end."
dynamic array may use,"A dynamic array is not the same thing as a dynamically allocated array, which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end."
size array,"A dynamic array is not the same thing as a dynamically allocated array, which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end."
elements immediately required,"A simple dynamic array can be constructed by allocating an array of fixed-size, typically larger than the number of elements immediately required."
typically larger,"A simple dynamic array can be constructed by allocating an array of fixed-size, typically larger than the number of elements immediately required."
stored contiguously,"The elements of the dynamic array are stored contiguously at the start of the underlying array, and the remaining positions towards the end of the underlying array are reserved, or unused."
remaining positions towards,"The elements of the dynamic array are stored contiguously at the start of the underlying array, and the remaining positions towards the end of the underlying array are reserved, or unused."
underlying array,"The elements of the dynamic array are stored contiguously at the start of the underlying array, and the remaining positions towards the end of the underlying array are reserved, or unused. !! In computer science, a Range Query Tree, or RQT, is a term for referring to a data structure that is used for performing range queries and updates on an underlying array, which is treated as the leaves of the tree."
swarm intelligence,"Except those main principles, currently popular approaches include biologically inspired algorithms such as swarm intelligence and artificial immune systems, which can be seen as a part of evolutionary computation, image processing, data mining, natural language processing, and artificial intelligence, which tends to be confused with Computational Intelligence. !! First published in 1989 Stochastic diffusion search (SDS) was the first Swarm Intelligence metaheuristic. !! Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence. !! Swarm intelligence (SI) is the collective behavior of decentralized, self-organized systems, natural or artificial. !! The application of swarm principles to robots is called swarm robotics while swarm intelligence refers to the more general set of algorithms. !! Recent work has involved merging the global search properties of SDS with other swarm intelligence algorithms."
organized systems,"Swarm intelligence (SI) is the collective behavior of decentralized, self-organized systems, natural or artificial."
collective behavior,"Agent-based modeling is related to, but distinct from, the concept of multi-agent systems or multi-agent simulation in that the goal of ABM is to search for explanatory insight into the collective behavior of agents obeying simple rules, typically in natural systems, rather than in designing agents or solving specific practical or engineering problems. !! Fish School Search (FSS), proposed by Bastos Filho and Lima Neto in 2008 is, in its basic version, an unimodal optimization algorithm inspired on the collective behavior of fish schools. !! Swarm intelligence (SI) is the collective behavior of decentralized, self-organized systems, natural or artificial."
bird flocking,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
fish schooling,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
bee colonies,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
bacterial growth,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
natural systems include ant colonies,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
microbial intelligence,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
swarm intelligence refers,The application of swarm principles to robots is called swarm robotics while swarm intelligence refers to the more general set of algorithms.
swarm principles,The application of swarm principles to robots is called swarm robotics while swarm intelligence refers to the more general set of algorithms.
called swarm robotics,The application of swarm principles to robots is called swarm robotics while swarm intelligence refers to the more general set of algorithms.
general set,The application of swarm principles to robots is called swarm robotics while swarm intelligence refers to the more general set of algorithms.
first published,A natural interface for musical expression operating on scratch input principles was first published and presented in June 2007. !! First published in 1989 Stochastic diffusion search (SDS) was the first Swarm Intelligence metaheuristic.
first swarm intelligence metaheuristic,First published in 1989 Stochastic diffusion search (SDS) was the first Swarm Intelligence metaheuristic.
1989 stochastic diffusion search,First published in 1989 Stochastic diffusion search (SDS) was the first Swarm Intelligence metaheuristic.
global search properties,Recent work has involved merging the global search properties of SDS with other swarm intelligence algorithms.
recent work,Recent work has involved merging the global search properties of SDS with other swarm intelligence algorithms.
involved merging,Recent work has involved merging the global search properties of SDS with other swarm intelligence algorithms.
security protocol used,Temporal Key Integrity Protocol (TKIP ) is a security protocol used in the IEEE 802.
another function,Indirect recursion occurs when a function is called not by itself but by another function that it called (either directly or indirectly).
indirect recursion occurs,Indirect recursion occurs when a function is called not by itself but by another function that it called (either directly or indirectly).
either directly,"In software engineering, a circular dependency is a relation between two or more modules which either directly or indirectly depend on each other to function properly. !! Indirect recursion occurs when a function is called not by itself but by another function that it called (either directly or indirectly)."
function 1 calls function 2,"For example, if f calls f, that is direct recursion, but if f calls g which calls f, then that is indirect recursion of f. Chains of three or more functions are possible; for example, function 1 calls function 2, function 2 calls function 3, and function 3 calls function 1 again."
function 2 calls function 3,"For example, if f calls f, that is direct recursion, but if f calls g which calls f, then that is indirect recursion of f. Chains of three or more functions are possible; for example, function 1 calls function 2, function 2 calls function 3, and function 3 calls function 1 again."
function 3 calls function 1,"For example, if f calls f, that is direct recursion, but if f calls g which calls f, then that is indirect recursion of f. Chains of three or more functions are possible; for example, function 1 calls function 2, function 2 calls function 3, and function 3 calls function 1 again."
different notion,"Indirect recursion is also called mutual recursion, which is a more symmetric term, though this is simply a difference of emphasis, not a different notion."
symmetric term,"Indirect recursion is also called mutual recursion, which is a more symmetric term, though this is simply a difference of emphasis, not a different notion."
also called mutual recursion,"Indirect recursion is also called mutual recursion, which is a more symmetric term, though this is simply a difference of emphasis, not a different notion."
combinatorial optimization problem studied,"In graph theory, the metric k-center or metric facility location problem is a combinatorial optimization problem studied in theoretical computer science."
metric facility location problem,"In graph theory, the metric k-center or metric facility location problem is a combinatorial optimization problem studied in theoretical computer science."
metric k-center,"In graph theory, the metric k-center or metric facility location problem is a combinatorial optimization problem studied in theoretical computer science."
error correcting codes defined,The BCJR algorithm is an algorithm for maximum a posteriori decoding of error correcting codes defined on trellises (principally convolutional codes).
susa framework implements bcjr algorithm,Susa framework implements BCJR algorithm for forward error correction codes and channel equalization in C++.
channel equalization,Susa framework implements BCJR algorithm for forward error correction codes and channel equalization in C++.
online textbook,"The online textbook: Information Theory, Inference, and Learning Algorithms, by David J. C. MacKay, discusses the BCJR algorithm in chapter 25."
various kinds,"In numerical mathematics, the gradient discretisation method (GDM) is a framework which contains classical and recent numerical schemes for diffusion problems of various kinds: linear or non-linear, steady-state or time-dependent. !! The various kinds of data structures referred to as trees in computer science have underlying graphs that are trees in graph theory, although such data structures are generally rooted trees. !! A programming language is any set of rules that converts strings, or graphical program elements in the case of visual programming languages, to various kinds of machine code output. !! Some publicly available implementations of ESNs are: (i) aureservoir: an efficient C++ library for various kinds of echo state networks with python/numpy bindings; and (ii) Matlab code: an efficient matlab for an echo state network, (iii) ReservoirComputing."
publicly available implementations,"Some publicly available implementations of ESNs are: (i) aureservoir: an efficient C++ library for various kinds of echo state networks with python/numpy bindings; and (ii) Matlab code: an efficient matlab for an echo state network, (iii) ReservoirComputing."
efficient matlab,"Some publicly available implementations of ESNs are: (i) aureservoir: an efficient C++ library for various kinds of echo state networks with python/numpy bindings; and (ii) Matlab code: an efficient matlab for an echo state network, (iii) ReservoirComputing."
various types,"Version control systems are most commonly run as stand-alone applications, but revision control is also embedded in various types of software, such as word processors and spreadsheets, collaborative web docs, and content management systems, e. g. , Wikipedia's page history. !! jl: an efficient Julia-based implementation of various types of echo state networks, and (iv) pyESN: simple echo state networks in Python."
simple echo state networks,"jl: an efficient Julia-based implementation of various types of echo state networks, and (iv) pyESN: simple echo state networks in Python."
efficient julia,"jl: an efficient Julia-based implementation of various types of echo state networks, and (iv) pyESN: simple echo state networks in Python."
previous output,"Another feature of the ESN is the autonomous operation in prediction: if the Echo State Network is trained with an input that is a backshifted version of the output, then it can be used for signal generation/prediction by using the previous output as input."
another feature,"Another feature of the ESN is the autonomous operation in prediction: if the Echo State Network is trained with an input that is a backshifted version of the output, then it can be used for signal generation/prediction by using the previous output as input."
theoretically turing complete,Recurrent neural networks are theoretically Turing complete and can run arbitrary programs to process arbitrary sequences of inputs.
run arbitrary programs,Recurrent neural networks are theoretically Turing complete and can run arbitrary programs to process arbitrary sequences of inputs.
david rumelhart,Recurrent neural networks were based on David Rumelhart's work in 1986.
recurrent neural networks introduced,Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks introduced in 2014.
time recurrent neural networks,"Note that, by the Shannon sampling theorem, discrete time recurrent neural networks can be viewed as continuous-time recurrent neural networks where the differential equations have transformed into equivalent difference equations."
first search,"This specific type of search is called greedy best-first search or pure heuristic search. !! ""Some authors have used ""best-first search"" to refer specifically to a search with a heuristic that attempts to predict how close the end of a path is to a solution (or, goal), so that paths which are judged to be closer to a solution (or, goal) are extended first. !! The output of lexicographic breadth-first search differs from a standard breadth-first search in having a consistent rule for breaking such ties. !! Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last). !! The lexicographic breadth-first search algorithm replaces the queue of vertices of a standard breadth-first search with an ordered sequence of sets of vertices. !! The result of a depth-first search of a graph can be conveniently described in terms of a spanning tree of the vertices reached during the search. !! A version of depth-first search was investigated in the 19th century by French mathematician Charles Pierre Trmaux as a strategy for solving mazes. !! Breadth-first search can be generalized to graphs, when the start node (sometimes referred to as a 'search key') is explicitly given, and precautions are taken against following a vertex twice. !! Depth-first search (DFS) is an algorithm for traversing or searching tree or graph data structures. !! In computer science, lexicographic breadth-first search or Lex-BFS is a linear time algorithm for ordering the vertices of a graph. !! Neither A* nor B* is a greedy best-first search, as they incorporate the distance from the start in addition to estimated distances to the goal. !! For example, in a chess endgame a chess engine may build the game tree from the current position by applying all possible moves, and use breadth-first search to find a win position for white. !! Implicit trees (such as game trees or other problem-solving trees) may be of infinite size; breadth-first search is guaranteed to find a solution node if one exists. !! Best-first search is a class of search algorithms, which explore a graph by expanding the most promising node chosen according to a specified rule. !! Breadth-first search (BFS) is an algorithm for searching a tree data structure for a node that satisfies a given property. !! Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search."
first access,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
first visit leaf nodes,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
latter case form,of the latter case form the relation (L) (<H) which is a partial map that assigns each non-leaf node its first child node.
partial map,of the latter case form the relation (L) (<H) which is a partial map that assigns each non-leaf node its first child node.
first child node,of the latter case form the relation (L) (<H) which is a partial map that assigns each non-leaf node its first child node.
last child node,"Similarly, (L+) (>H) assigns each non-leaf node with finitely many children its last child node."
finitely many children,"Similarly, (L+) (>H) assigns each non-leaf node with finitely many children its last child node."
human mind,"To create artificial intuition supposes the possibility of the re-creation of a higher functioning of the human mind, with capabilities such as what might be found in semantic memory and learning. !! A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence (AI) and computational cognitive science. !! Some popular accounts use the term ""artificial intelligence"" to describe machines that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"", however, this definition is rejected by major AI researchers. !! In philosophy of mind, the computational theory of mind (CTM), also known as computationalism, is a family of views that hold that the human mind is an information processing system and that cognition and consciousness together are a form of computation."
cognitive architecture refers,A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence (AI) and computational cognitive science.
computational cognitive science,A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence (AI) and computational cognitive science.
theory used,A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence (AI) and computational cognitive science.
successful cognitive architectures include act,Successful cognitive architectures include ACT-R (Adaptive Control of Thought - Rational) and SOAR.
adaptive control,Successful cognitive architectures include ACT-R (Adaptive Control of Thought - Rational) and SOAR.
allen newell,"The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959. !! Human processor model or MHP (Model Human Processor) is a cognitive modeling method developed by Stuart K. Card, Thomas P. Moran, & Allen Newell (1983) used to calculate how long it takes to perform a certain task. !! The research on cognitive architectures as software instantiation of cognitive theories was initiated by Allen Newell in 1990. !! Crucial to the understanding of knowledge level modeling are Allen Newell's notions of the knowledge level, operators, and an agent's goal state."
work together,"The Institute for Creative Technologies defines cognitive architecture as: ""hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together in conjunction with knowledge and skills embodied within the architecture to yield intelligent behavior in a diversity of complex environments. "" !! Software agents may be autonomous or work together with other agents or people."
creative technologies defines cognitive architecture,"The Institute for Creative Technologies defines cognitive architecture as: ""hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together in conjunction with knowledge and skills embodied within the architecture to yield intelligent behavior in a diversity of complex environments. """
fixed structures,"The Institute for Creative Technologies defines cognitive architecture as: ""hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together in conjunction with knowledge and skills embodied within the architecture to yield intelligent behavior in a diversity of complex environments. """
skills embodied within,"The Institute for Creative Technologies defines cognitive architecture as: ""hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together in conjunction with knowledge and skills embodied within the architecture to yield intelligent behavior in a diversity of complex environments. """
yield intelligent behavior,"The Institute for Creative Technologies defines cognitive architecture as: ""hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together in conjunction with knowledge and skills embodied within the architecture to yield intelligent behavior in a diversity of complex environments. """
term memory,"Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. !! ""Long Short-Term Memory in Recurrent Neural Networks"" (PDF). !! He included more aspects of his research on long-term memory and thinking processes into this research and eventually designed a cognitive architecture he eventually called ACT."
eventually called act,He included more aspects of his research on long-term memory and thinking processes into this research and eventually designed a cognitive architecture he eventually called ACT.
thinking processes,He included more aspects of his research on long-term memory and thinking processes into this research and eventually designed a cognitive architecture he eventually called ACT.
eventually designed,He included more aspects of his research on long-term memory and thinking processes into this research and eventually designed a cognitive architecture he eventually called ACT.
obtain increasingly accurate eigenvalue estimates,Rayleigh quotient iteration is an eigenvalue algorithm which extends the idea of the inverse iteration by using the Rayleigh quotient to obtain increasingly accurate eigenvalue estimates.
sufficiently close,"The Rayleigh quotient iteration algorithm converges cubically for Hermitian or symmetric matrices, given an initial vector that is sufficiently close to an eigenvector of the matrix that is being analyzed."
automobile adapted,An adapted automobile is an automobile adapted for ease of use by disabled people.
disabled people,An adapted automobile is an automobile adapted for ease of use by disabled people.
operate independently,An autonomous decentralized system (or ADS) is a decentralized system composed of modules or components that are designed to operate independently but are capable of interacting with each other to meet the overall goal of the system.
decentralized system composed,An autonomous decentralized system (or ADS) is a decentralized system composed of modules or components that are designed to operate independently but are capable of interacting with each other to meet the overall goal of the system.
overall goal,An autonomous decentralized system (or ADS) is a decentralized system composed of modules or components that are designed to operate independently but are capable of interacting with each other to meet the overall goal of the system.
railway signalling,"Autonomous decentralized systems have a number of applications including industrial production lines, railway signalling and robotics."
applications including industrial production lines,"Autonomous decentralized systems have a number of applications including industrial production lines, railway signalling and robotics."
first proposed,"Autonomous decentralized systems were first proposed in 1977. !! Linear predictive coding (LPC), a speech processing algorithm, was first proposed by Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966. !! Augmented tree-based routing (ATR) protocol, first proposed in 2007, is a multi-path DHT-based routing protocol for scalable networks. !! The design for neural dust was first proposed in a 2011 paper from the University of California, Berkeley Wireless Research Center, that described both the challenges and outstanding benefits of creating a long lasting wireless brain computer interface (BCI)."
ieee international symposium,IEEE International Symposium on Autonomous Decentralized Systems (ISADS) is the major conference on this topic.
major conference,IEEE International Symposium on Autonomous Decentralized Systems (ISADS) is the major conference on this topic.
important task,"However, typical research in quantum neural networks involves combining classical artificial neural network models (which are widely used in machine learning for the important task of pattern recognition) with the advantages of quantum information in order to develop more efficient algorithms."
typical research,"However, typical research in quantum neural networks involves combining classical artificial neural network models (which are widely used in machine learning for the important task of pattern recognition) with the advantages of quantum information in order to develop more efficient algorithms."
three different categories,"Quantum neural networks refer to three different categories: Quantum computer with classical data, classical computer with quantum data, and quantum computer with quantum data."
quantum neural networks refer,"Quantum neural networks refer to three different categories: Quantum computer with classical data, classical computer with quantum data, and quantum computer with quantum data."
desired input,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
output relations,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
learn interactions following,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
tunable mutual interactions,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
given qubits,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
desired output algorithm,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
available alternatives,"Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element, with regard to some criterion, from some set of available alternatives."
best element,"Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element, with regard to some criterion, from some set of available alternatives."
alternatively spelled optimisation,"Mathematical optimization (alternatively spelled optimisation) or mathematical programming is the selection of a best element, with regard to some criterion, from some set of available alternatives."
every solution,"This can be regarded as the special case of mathematical optimization where the objective value is the same for every solution, and thus any solution is optimal."
much modern controller design,Mathematical optimization is used in much modern controller design.
employ mathematical optimization,High-level controllers such as model predictive control (MPC) or real-time optimization (RTO) employ mathematical optimization.
repeatedly determine values,"These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled."
algorithms run online,"These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled."
iteratively solving,"These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled."
process plant,"These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled."
mathematical optimization problem including constraints,"These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled."
choke openings,"These algorithms run online and repeatedly determine values for decision variables, such as choke openings in a process plant, by iteratively solving a mathematical optimization problem including constraints and a model of the system to be controlled."
power set p,"This fact as well as the reason of the notation 2S denoting the power set P(S) are demonstrated in the below. !! Each subset A of S is identified by or equivalent to the indicator function IA, and {0,1}S as the set of all the functions from S to {0,1} consists of all the indicator functions of all the subsets of S. In other words, {0,1}S is equivalent or bijective to the power set P(S)."
indicator function ia,"Each subset A of S is identified by or equivalent to the indicator function IA, and {0,1}S as the set of all the functions from S to {0,1} consists of all the indicator functions of all the subsets of S. In other words, {0,1}S is equivalent or bijective to the power set P(S)."
indicator functions,"Each subset A of S is identified by or equivalent to the indicator function IA, and {0,1}S as the set of all the functions from S to {0,1} consists of all the indicator functions of all the subsets of S. In other words, {0,1}S is equivalent or bijective to the power set P(S)."
whether infinite,"Cantor's diagonal argument shows that the power set of a set (whether infinite or not) always has strictly higher cardinality than the set itself (or informally, the power set must be larger than the original set)."
diagonal argument shows,"Cantor's diagonal argument shows that the power set of a set (whether infinite or not) always has strictly higher cardinality than the set itself (or informally, the power set must be larger than the original set)."
strictly higher cardinality,"Cantor's diagonal argument shows that the power set of a set (whether infinite or not) always has strictly higher cardinality than the set itself (or informally, the power set must be larger than the original set)."
power set must,"Cantor's diagonal argument shows that the power set of a set (whether infinite or not) always has strictly higher cardinality than the set itself (or informally, the power set must be larger than the original set)."
solving combinatorial problems,"Constraint programming (CP) is a paradigm for solving combinatorial problems that draws on a wide range of techniques from artificial intelligence, computer science, and operations research."
wide range,"Constraint programming (CP) is a paradigm for solving combinatorial problems that draws on a wide range of techniques from artificial intelligence, computer science, and operations research. !! Random forests are frequently used as ""blackbox"" models in businesses, as they generate reasonable predictions across a wide range of data while requiring little configuration. !! For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions. !! There are a wide range of alternatives for the term active learning, such as: learning through play, technology-based learning, activity-based learning, group work, project method, etc. !! Evolutionary computation techniques can produce highly optimized solutions in a wide range of problem settings, making them popular in computer science. !! The generation and development of digital image processing are mainly affected by three factors: first, the development of computers; second, the development of mathematics (especially the creation and improvement of discrete mathematics theory); third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased. !! Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law. !! Topology optimization has a wide range of applications in aerospace, mechanical, bio-chemical and civil engineering. !! A wide range of supervised learning algorithms are available, each with its strengths and weaknesses. !! Spatiotemporal patterns are patterns that occur in a wide range of natural phenoma and are characterized by a spatial and a temporal patterning."
users declaratively state,"In constraint programming, users declaratively state the constraints on the feasible solutions for a set of decision variables."
feasible solutions,"In constraint programming, users declaratively state the constraints on the feasible solutions for a set of decision variables. !! Combinatorial optimization is a subfield of mathematical optimization that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set."
constraint programming takes,"Constraint programming takes its root from and can be expressed in the form of constraint logic programming, which embeds constraints into a logic program."
constraint programming approach,The constraint programming approach is to search for a state of the world in which a large number of constraints are satisfied at the same time.
large number,"A generalization of the Viterbi algorithm, termed the max-sum algorithm (or max-product algorithm) can be used to find the most likely assignment of all or some subset of latent variables in a large number of graphical models, e. g. Bayesian networks, Markov random fields and conditional random fields. !! Alignments of random points in a plane can be demonstrated by statistics to be counter-intuitively easy to find when a large number of random points are marked on a bounded flat surface. !! The constraint programming approach is to search for a state of the world in which a large number of constraints are satisfied at the same time. !! In computer science, parallel tree contraction is a broadly applicable technique for the parallel solution of a large number of tree problems, and is used as an algorithm design technique for the design of a large number of parallel graph algorithms."
sub field,Stochastic control or stochastic optimal control is a sub field of control theory that deals with the existence of uncertainty either in observations or in the noise that drives the evolution of the system.
uncertainty either,Stochastic control or stochastic optimal control is a sub field of control theory that deals with the existence of uncertainty either in observations or in the noise that drives the evolution of the system.
somehow defined,"Stochastic control aims to design the time path of the controlled variables that performs the desired control task with minimum cost, somehow defined, despite the presence of this noise."
desired control task,"Stochastic control aims to design the time path of the controlled variables that performs the desired control task with minimum cost, somehow defined, despite the presence of this noise."
stochastic control aims,"Stochastic control aims to design the time path of the controlled variables that performs the desired control task with minimum cost, somehow defined, despite the presence of this noise."
time path,"Stochastic control aims to design the time path of the controlled variables that performs the desired control task with minimum cost, somehow defined, despite the presence of this noise."
extremely well,An extremely well-studied formulation in stochastic control is that of linear quadratic Gaussian control.
studied formulation,An extremely well-studied formulation in stochastic control is that of linear quadratic Gaussian control.
developed greatly since,"The field of stochastic control has developed greatly since the 1970s, particularly in its applications to finance."
risky assets,Robert Merton used stochastic control to study optimal portfolios of safe and risky assets.
robert merton used stochastic control,Robert Merton used stochastic control to study optimal portfolios of safe and risky assets.
study optimal portfolios,Robert Merton used stochastic control to study optimal portfolios of safe and risky assets.
min item allocation,"The goal is to construct subsets that satisfy a given criterion of fairness, such as max-min item allocation."
construct subsets,"The goal is to construct subsets that satisfy a given criterion of fairness, such as max-min item allocation."
given criterion,"The goal is to construct subsets that satisfy a given criterion of fairness, such as max-min item allocation."
usually cities,"The Economic Complexity Index (ECI) is a holistic measure of the productive capabilities of large economic systems, usually cities, regions, or countries."
productive capabilities,"The Economic Complexity Index (ECI) is a holistic measure of the productive capabilities of large economic systems, usually cities, regions, or countries."
holistic measure,"The Economic Complexity Index (ECI) is a holistic measure of the productive capabilities of large economic systems, usually cities, regions, or countries."
product equivalent,The product equivalent of the Economic Complexity Index is the Product Complexity Index or PCI.
original formulation,The original formulation of the Economic Complexity Index was published in PNAS in 2009.
like topology,"Furthermore, convolutional neural networks are ideal for data with a grid-like topology (such as images) as spatial relations between separate features are taken into account during convolution and/or pooling."
automatically analyzing time,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
neural information processing workshop,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
replacing learned multiplication,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
hermann von helmholtz,The Helmholtz machine (named after Hermann von Helmholtz and his concept of Helmholtz free energy) is a type of artificial neural network that can account for the hidden structure of a set of data by being trained to create a generative model of the original set of data.
helmholtz machine contains two networks,"A Helmholtz machine contains two networks, a bottom-up recognition network that takes the data as input and produces a distribution over hidden variables, and a top-down ""generative"" network that generates values of the hidden variables and the data itself."
generates values,"A Helmholtz machine contains two networks, a bottom-up recognition network that takes the data as input and produces a distribution over hidden variables, and a top-down ""generative"" network that generates values of the hidden variables and the data itself."
used feedback,"At the time, Helmholtz machines were one of a handful of learning architectures that used feedback as well as feedforward to ensure quality of learned models."
ensure quality,"At the time, Helmholtz machines were one of a handful of learning architectures that used feedback as well as feedforward to ensure quality of learned models."
usually trained using,"Helmholtz machines are usually trained using an unsupervised learning algorithm, such as the wake-sleep algorithm."
sleep algorithm,"Helmholtz machines are usually trained using an unsupervised learning algorithm, such as the wake-sleep algorithm."
object within,"Helmholtz machines may also be used in applications requiring a supervised learning algorithm (e. g. character recognition, or position-invariant recognition of an object within a field)."
helmholtz machines may also,"Helmholtz machines may also be used in applications requiring a supervised learning algorithm (e. g. character recognition, or position-invariant recognition of an object within a field)."
applications requiring,"Helmholtz machines may also be used in applications requiring a supervised learning algorithm (e. g. character recognition, or position-invariant recognition of an object within a field)."
associated data,"An electronic signature, or e-signature, is data that is logically associated with other data and which is used by the signatory to sign the associated data."
logically associated,"An electronic signature, or e-signature, is data that is logically associated with other data and which is used by the signatory to sign the associated data."
cryptographic mechanism often used,"Electronic signatures are a legal concept distinct from digital signatures, a cryptographic mechanism often used to implement electronic signatures."
legal concept distinct,"Electronic signatures are a legal concept distinct from digital signatures, a cryptographic mechanism often used to implement electronic signatures."
name entered,"While an electronic signature can be as simple as a name entered in an electronic document, digital signatures are increasingly used in e-commerce and in regulatory filings to implement electronic signatures in a cryptographically protected way."
regulatory filings,"While an electronic signature can be as simple as a name entered in an electronic document, digital signatures are increasingly used in e-commerce and in regulatory filings to implement electronic signatures in a cryptographically protected way."
cryptographically protected way,"While an electronic signature can be as simple as a name entered in an electronic document, digital signatures are increasingly used in e-commerce and in regulatory filings to implement electronic signatures in a cryptographically protected way."
increasingly used,"While an electronic signature can be as simple as a name entered in an electronic document, digital signatures are increasingly used in e-commerce and in regulatory filings to implement electronic signatures in a cryptographically protected way."
accurate identification method,An electronic signature is intended to provide a secure and accurate identification method for the signatory to provide a seamless transaction.
seamless transaction,An electronic signature is intended to provide a secure and accurate identification method for the signatory to provide a seamless transaction.
applicable jurisdiction,Definitions of electronic signatures vary depending on the applicable jurisdiction.
electronic signatures vary depending,Definitions of electronic signatures vary depending on the applicable jurisdiction.
select adder generally consists,The carry-select adder generally consists of ripple-carry adders and a multiplexer.
carry adders,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one. !! The carry-select adder generally consists of ripple-carry adders and a multiplexer."
therefore two ripple,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
calculation twice,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
adding two n,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
select adder,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one. !! A 16-bit carry-select adder with variable size can be similarly created. !! A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder. !! Above is the basic building block of a carry-select adder, where the block size is 4."
one time,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
basic building block,"Above is the basic building block of a carry-select adder, where the block size is 4."
block size,"Above is the basic building block of a carry-select adder, where the block size is 4."
uniform block size,A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
similarly created,A 16-bit carry-select adder with variable size can be similarly created.
variable size,A 16-bit carry-select adder with variable size can be similarly created.
basic numerical methods,"In numerical analysis and scientific computing, the backward Euler method (or implicit Euler method) is one of the most basic numerical methods for the solution of ordinary differential equations."
order one,The backward Euler method has order one. !! The backward Euler method has error of order one in time.
backward euler method follows,and the formula for the backward Euler method follows.
complex plane,"The discrete Fourier transform can be viewed as a special case of the z-transform, evaluated on the unit circle in the complex plane; more general z-transforms correspond to complex shifts a and b above. !! The region of absolute stability for the backward Euler method is the complement in the complex plane of the disk with radius 1 centered at 1, depicted in the figure."
absolute stability,"The region of absolute stability for the backward Euler method is the complement in the complex plane of the disk with radius 1 centered at 1, depicted in the figure."
radius 1 centered,"The region of absolute stability for the backward Euler method is the complement in the complex plane of the disk with radius 1 centered at 1, depicted in the figure."
may also,"From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value. !! The term 'Computational statistics' may also be used to refer to computationally intensive statistical methods including resampling methods, Markov chain Monte Carlo methods, local regression, kernel density estimation, artificial neural networks and generalized additive models. !! A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments. !! Quantum reservoir computing may use the nonlinear nature of quantum mechanical interactions or processes to form the characteristic nonlinear reservoirs but may also be done with linear reservoirs when the injection of the input to the reservoir creates the nonlinearity."
relatively short history,"Though computational statistics is widely used today, it actually has a relatively short history of acceptance in the statistics community."
though computational statistics,"Though computational statistics is widely used today, it actually has a relatively short history of acceptance in the statistics community."
statistics community,"Though computational statistics is widely used today, it actually has a relatively short history of acceptance in the statistics community."
widely used today,"Though computational statistics is widely used today, it actually has a relatively short history of acceptance in the statistics community."
special section,"), ""Special Section: Teaching Computational Statistics"", The American Statistician, 58: 1,"
teaching computational statistics,"), ""Special Section: Teaching Computational Statistics"", The American Statistician, 58: 1,"
american statistician,"), ""Special Section: Teaching Computational Statistics"", The American Statistician, 58: 1,"
single core,"A single-core processor is a microprocessor with a single core on its die. !! Single core processors are still in use in some niche circumstances. !! Single core processors also used in hobbyist computers like the Raspberry Pi and Single-board microcontrollers. !! A computer using a single core CPU is generally slower than a multi-core system. !! Single core processors used to be widespread in desktop computers, but as applications demanded more processing power, the slower speed of single core systems became a detriment to performance."
computer using,A computer using a single core CPU is generally slower than a multi-core system.
generally slower,"recursive ray tracing, distribution ray tracing, photon mapping to path tracing are generally slower and higher fidelity than scanline rendering methods. !! A computer using a single core CPU is generally slower than a multi-core system."
single core processors used,"Single core processors used to be widespread in desktop computers, but as applications demanded more processing power, the slower speed of single core systems became a detriment to performance."
applications demanded,"Single core processors used to be widespread in desktop computers, but as applications demanded more processing power, the slower speed of single core systems became a detriment to performance."
slower speed,"Single core processors used to be widespread in desktop computers, but as applications demanded more processing power, the slower speed of single core systems became a detriment to performance."
single core systems became,"Single core processors used to be widespread in desktop computers, but as applications demanded more processing power, the slower speed of single core systems became a detriment to performance."
niche circumstances,Single core processors are still in use in some niche circumstances.
single core processors also used,Single core processors also used in hobbyist computers like the Raspberry Pi and Single-board microcontrollers.
hobbyist computers like,Single core processors also used in hobbyist computers like the Raspberry Pi and Single-board microcontrollers.
additional storage much less,"In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM."
also called,"The Voronoi diagram is named after Georgy Voronoy, and is also called a Voronoi tessellation, a Voronoi decomposition, a Voronoi partition, or a Dirichlet tessellation (after Peter Gustav Lejeune Dirichlet). !! The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems. !! Some speech recognition systems require ""training"" (also called ""enrollment"") where an individual speaker reads text or isolated vocabulary into the system. !! In Boolean logic, the majority function (also called the median operator) is the Boolean function that evaluates to false when half or more arguments are false and true otherwise, i. e. the value of the function equals the value of the majority of the inputs. !! In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM. !! The travelling salesman problem (also called the travelling salesperson problem or TSP) asks the following question: ""Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city"" !! In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). !! In computer science, a mergeable heap (also called a meldable heap) is an abstract data type, which is a heap supporting a merge operation."
place matrix transposition,"The following briefly summarizes the published algorithms to perform in-place matrix transposition. !! In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM."
published algorithms,The following briefly summarizes the published algorithms to perform in-place matrix transposition.
following briefly summarizes,The following briefly summarizes the published algorithms to perform in-place matrix transposition.
boolean function whose value,"In mathematics, a symmetric Boolean function is a Boolean function whose value does not depend on the order of its input bits, i. e. , it depends only on the number of ones (or zeros) in the input."
symmetric boolean function,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, . !! In mathematics, a symmetric Boolean function is a Boolean function whose value does not depend on the order of its input bits, i. e. , it depends only on the number of ones (or zeros) in the input. !! Symmetric Boolean functions are used to classify Boolean satisfiability problems. !! Effectively, an n-variable symmetric Boolean function corresponds to a log(n)-variable ordinary Boolean function acting on the base-2 representation of the input weight. !! Parity function: their value is 1 if the input vector has odd number of onesThe n-ary versions of AND, OR, XOR, NAND, NOR and XNOR are also symmetric Boolean functions."
represent boolean functions,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
traditionally used,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
truth table,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, . !! The OR gate is a digital logic gate that implements logical disjunction () from mathematical logic it behaves according to the truth table above. !! The AND gate is a basic digital logic gate that implements logical conjunction () from mathematical logic AND gate behaves according to the truth table above. !! A truth table is a mathematical table used in logicspecifically in connection with Boolean algebra, boolean functions, and propositional calculuswhich sets out the functional values of logical expressions on each of their functional arguments, that is, for each combination of values taken by their logical variables."
one may use,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
th entry,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
variable symmetric boolean function,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
compact representation,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
classify boolean satisfiability problems,Symmetric Boolean functions are used to classify Boolean satisfiability problems.
symmetric boolean functions,Symmetric Boolean functions are used to classify Boolean satisfiability problems.
also symmetric boolean functions,"Parity function: their value is 1 if the input vector has odd number of onesThe n-ary versions of AND, OR, XOR, NAND, NOR and XNOR are also symmetric Boolean functions."
ary versions,"Parity function: their value is 1 if the input vector has odd number of onesThe n-ary versions of AND, OR, XOR, NAND, NOR and XNOR are also symmetric Boolean functions."
n - variable ordinary boolean function acting,"Effectively, an n-variable symmetric Boolean function corresponds to a log(n)-variable ordinary Boolean function acting on the base-2 representation of the input weight."
variable symmetric boolean function corresponds,"Effectively, an n-variable symmetric Boolean function corresponds to a log(n)-variable ordinary Boolean function acting on the base-2 representation of the input weight."
artificial intelligence research dedicated,Distributed Artificial Intelligence (DAI) also called Decentralized Artificial Intelligence is a subfield of artificial intelligence research dedicated to the development of distributed solutions for problems.
also called decentralized artificial intelligence,Distributed Artificial Intelligence (DAI) also called Decentralized Artificial Intelligence is a subfield of artificial intelligence research dedicated to the development of distributed solutions for problems.
perception problems,"The objectives of Distributed Artificial Intelligence are to solve the reasoning, planning, learning and perception problems of artificial intelligence, especially if they require large data, by distributing the problem to autonomous processing nodes (agents)."
require large data,"The objectives of Distributed Artificial Intelligence are to solve the reasoning, planning, learning and perception problems of artificial intelligence, especially if they require large data, by distributing the problem to autonomous processing nodes (agents)."
1975 distributed artificial intelligence emerged,In 1975 distributed artificial intelligence emerged as a subfield of artificial intelligence that dealt with interactions of intelligent agents[2].
called agents,"Distributed artificial intelligence systems were conceived as a group of intelligent entities, called agents, that interacted by cooperation, by coexistence or by competition."
continuous manner,"Streaming media is multimedia that is delivered and consumed in a continuous manner from a source, with little or no intermediate storage in network elements."
intermediate storage,"Streaming media is multimedia that is delivered and consumed in a continuous manner from a source, with little or no intermediate storage in network elements."
made possible,"Practical streaming media was only made possible with advances in data compression, due to the impractically high bandwidth requirements of uncompressed media. !! The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907."
impractically high bandwidth requirements,"Practical streaming media was only made possible with advances in data compression, due to the impractically high bandwidth requirements of uncompressed media."
uncompressed media,"Practical streaming media was only made possible with advances in data compression, due to the impractically high bandwidth requirements of uncompressed media."
practical streaming media,"Practical streaming media was only made possible with advances in data compression, due to the impractically high bandwidth requirements of uncompressed media."
originally known,Other early companies that created streaming media technology include RealNetworks (originally known as Progressive Networks) and Protocomm both prior to widespread World Wide Web usage.
early companies,Other early companies that created streaming media technology include RealNetworks (originally known as Progressive Networks) and Protocomm both prior to widespread World Wide Web usage.
widespread world wide web usage,Other early companies that created streaming media technology include RealNetworks (originally known as Progressive Networks) and Protocomm both prior to widespread World Wide Web usage.
supported streaming media,"Microsoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6."
proprietary streaming format,"Microsoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6."
media player known,"Microsoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6."
windows media player 6,"Microsoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6."
microsoft developed,"Microsoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6."
streaming feature later,"Microsoft developed a media player known as ActiveMovie in 1995 that supported streaming media and included a proprietary streaming format, which was the precursor to the streaming feature later in Windows Media Player 6."
recursively enumerable languages,"an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
regular languages,"an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
free languages,"On the other hand, deterministic context-free languages can be accepted in O(n) time by an LR(k) parser. !! Deterministic context-free languages can be recognized by a deterministic Turing machine in polynomial time and O(log2 n) space; as a corollary, DCFL is a subset of the complexity class SC. !! The languages of this class have great practical importance in computer science as they can be parsed much more efficiently than nondeterministic context-free languages. !! In formal language theory, deterministic context-free languages (DCFL) are a proper subset of context-free languages. !! Languages generated by context-free grammars are known as context-free languages (CFL). !! an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
scientific literature,"The term one-class classification (OCC) was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection. !! an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
abstract family,"An abstract family of acceptors (AFA) is a grouping of generalized acceptors. !! an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
abstract family of languages,"an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
formal languages studied,"an abstract family of languages is an abstract mathematical notion generalizing characteristics common to the regular languages, the context-free languages and the recursively enumerable languages, and other families of formal languages studied in the scientific literature."
processing data streams,"In computer science, streaming algorithms are algorithms for processing data streams in which the input is presented as a sequence of items and can be examined in only a few passes (typically just one)."
though streaming algorithms,"Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
mario szegedy,"Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
yossi matias,"Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
first formalized,"Proof by contradiction is based on the law of noncontradiction as first formalized as a metaphysical principle by Aristotle. !! Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
philippe flajolet,"Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
nigel martin,"Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
noga alon,"Though streaming algorithms had already been studied by Munro and Paterson as early as 1978, as well as Philippe Flajolet and G. Nigel Martin in 1982/83, the field of streaming algorithms was first formalized and popularized in a 1996 paper by Noga Alon, Yossi Matias, and Mario Szegedy."
gdel prize,"For this paper, the authors later won the Gdel Prize in 2005 ""for their foundational contribution to streaming algorithms. """
authors later,"For this paper, the authors later won the Gdel Prize in 2005 ""for their foundational contribution to streaming algorithms. """
foundational contribution,"For this paper, the authors later won the Gdel Prize in 2005 ""for their foundational contribution to streaming algorithms. """
diverse spectrum,"There has since been a large body of work centered around data streaming algorithms that spans a diverse spectrum of computer science fields such as theory, databases, networking, and natural language processing."
large body,"There has since been a large body of work centered around data streaming algorithms that spans a diverse spectrum of computer science fields such as theory, databases, networking, and natural language processing."
joint international conference,"Lall, Ashwin; Sekar, Vyas; Ogihara, Mitsunori; Xu, Jun; Zhang, Hui (2006), ""Data streaming algorithms for estimating entropy of network traffic"", Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems (ACM SIGMETRICS 2006) (PDF), p. 145,"
acm sigmetrics 2006,"Lall, Ashwin; Sekar, Vyas; Ogihara, Mitsunori; Xu, Jun; Zhang, Hui (2006), ""Data streaming algorithms for estimating entropy of network traffic"", Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems (ACM SIGMETRICS 2006) (PDF), p. 145,"
various subjective perceptions  subjects,"In computing, subject-oriented programming is an object-oriented software paradigm in which the state (fields) and behavior (methods) of objects are not seen as intrinsic to the objects themselves, but are provided by various subjective perceptions (""subjects"") of the objects."
describe objects,"Subject-oriented programming advocates the organization of the classes that describe objects into ""subjects"", which may be composed to form larger subjects."
form larger subjects,"Subject-oriented programming advocates the organization of the classes that describe objects into ""subjects"", which may be composed to form larger subjects."
1997 raised questions,"The introduction of aspect-oriented programming in 1997 raised questions about its relationship to subject-oriented programming, and about the difference between subjects and aspects."
admit functional extension,"In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension."
field access,"In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension."
deliberately restricted,"In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension."
designed frameworks,"In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension."
like aspect,"Like aspect-oriented programming, subject-oriented programming, composition filters, feature oriented programming and adaptive methods are considered to be aspect-oriented software development approaches."
adaptive methods,"Like aspect-oriented programming, subject-oriented programming, composition filters, feature oriented programming and adaptive methods are considered to be aspect-oriented software development approaches."
oriented software development approaches,"Like aspect-oriented programming, subject-oriented programming, composition filters, feature oriented programming and adaptive methods are considered to be aspect-oriented software development approaches."
valid rules,"In propositional logic and Boolean algebra, De Morgan's laws are a pair of transformation rules that are both valid rules of inference."
general concept,De Morgan's laws are an example of a more general concept of mathematical duality.
normally shown,"De Morgan's laws are normally shown in the compact form above, with the negation of the output on the left and negation of the inputs on the right."
compact form,"De Morgan's laws are normally shown in the compact form above, with the negation of the output on the left and negation of the inputs on the right."
remembered using,"In set notation, De Morgan's laws can be remembered using the mnemonic ""break the line, change the sign""."
set notation,"In set notation, De Morgan's laws can be remembered using the mnemonic ""break the line, change the sign""."
text searching using boolean operators,"De Morgan's laws commonly apply to text searching using Boolean operators AND, OR, and NOT."
laws commonly apply,"De Morgan's laws commonly apply to text searching using Boolean operators AND, OR, and NOT."
sometimes called memory,"In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory."
compare new problem instances,"In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory."
performing explicit generalization,"In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory."
based learning,"One advantage that instance-based learning has over other methods of machine learning is its ability to adapt its model to previously unseen data. !! In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory. !! There are a wide range of alternatives for the term active learning, such as: learning through play, technology-based learning, activity-based learning, group work, project method, etc."
instances seen,"In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory."
one advantage,One advantage that instance-based learning has over other methods of machine learning is its ability to adapt its model to previously unseen data.
based learning algorithms,"Examples of instance-based learning algorithms are the k-nearest neighbors algorithm, kernel machines and RBF networks."
systems architecture depends heavily,"Systems architecture depends heavily on practices and techniques which were developed over thousands of years in many other fields, perhaps the most important being civil architecture."
systems architecture makes use,A systems architecture makes use of elements of both software and hardware and is used to enable design of such a composite system.
enable design,A systems architecture makes use of elements of both software and hardware and is used to enable design of such a composite system.
based encryption,"Certificate-based encryption is a system in which a certificate authority uses ID-based cryptography to produce a certificate. !! The best example of practical use of certificate-based encryption is Content Scrambling System (CSS), which is used to encode DVD movies in such a way as to make them playable only in a part of the world where they are sold. !! Craig Gentry, Certificate-Based Encryption and the Certificate Revocation Problem, Lecture Notes in Computer Science, pp."
certificate-based encryption,"Certificate-based encryption is a system in which a certificate authority uses ID-based cryptography to produce a certificate. !! The best example of practical use of certificate-based encryption is Content Scrambling System (CSS), which is used to encode DVD movies in such a way as to make them playable only in a part of the world where they are sold. !! Craig Gentry, Certificate-Based Encryption and the Certificate Revocation Problem, Lecture Notes in Computer Science, pp."
based cryptography,Certificate-based encryption is a system in which a certificate authority uses ID-based cryptography to produce a certificate.
certificate authority uses id,Certificate-based encryption is a system in which a certificate authority uses ID-based cryptography to produce a certificate.
encode dvd movies,"The best example of practical use of certificate-based encryption is Content Scrambling System (CSS), which is used to encode DVD movies in such a way as to make them playable only in a part of the world where they are sold."
best example,"The best example of practical use of certificate-based encryption is Content Scrambling System (CSS), which is used to encode DVD movies in such a way as to make them playable only in a part of the world where they are sold."
practical use,"The best example of practical use of certificate-based encryption is Content Scrambling System (CSS), which is used to encode DVD movies in such a way as to make them playable only in a part of the world where they are sold."
path expression,"For example, the path expression p. Manager. !! Path expressions have been extended to support regular expression-like flexibility. !! For example, a path expression like "" {read}, write"" might specify that either multiple simultaneous executions of read or a single execution of write but not both are allowed at any point in time. !! In concurrency control, path expressions are a mechanism for expressing permitted sequences of execution. !! XPath is an example of a path expression language."
path expression p,"For example, the path expression p. Manager."
like flexibility,Path expressions have been extended to support regular expression-like flexibility.
support regular expression,Path expressions have been extended to support regular expression-like flexibility.
path expressions,"In concurrency control, path expressions are a mechanism for expressing permitted sequences of execution. !! Path expressions have been extended to support regular expression-like flexibility."
path expression language,XPath is an example of a path expression language.
concurrency control,"In concurrency control, path expressions are a mechanism for expressing permitted sequences of execution."
expressing permitted sequences,"In concurrency control, path expressions are a mechanism for expressing permitted sequences of execution."
might specify,"For example, a path expression like "" {read}, write"" might specify that either multiple simultaneous executions of read or a single execution of write but not both are allowed at any point in time."
single execution,"For example, a path expression like "" {read}, write"" might specify that either multiple simultaneous executions of read or a single execution of write but not both are allowed at any point in time."
path expression like,"For example, a path expression like "" {read}, write"" might specify that either multiple simultaneous executions of read or a single execution of write but not both are allowed at any point in time."
read  write,"For example, a path expression like "" {read}, write"" might specify that either multiple simultaneous executions of read or a single execution of write but not both are allowed at any point in time."
either multiple simultaneous executions,"For example, a path expression like "" {read}, write"" might specify that either multiple simultaneous executions of read or a single execution of write but not both are allowed at any point in time."
declarative programming paradigm concerned,"In computing, reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change."
presently assigned value,"On the other hand, in reactive programming, the value of a is automatically updated whenever the values of b or c change, without the program having to explicit re-execute the statement a := b + c to determine the presently assigned value of a."
automatically updated whenever,"On the other hand, in reactive programming, the value of a is automatically updated whenever the values of b or c change, without the program having to explicit re-execute the statement a := b + c to determine the presently assigned value of a."
reactive programming enables changes,"Another example is a hardware description language such as Verilog, where reactive programming enables changes to be modeled as they propagate through circuits."
underlying model,"For example, in a modelviewcontroller (MVC) architecture, reactive programming can facilitate changes in an underlying model that are reflected automatically in an associated view."
facilitate changes,"For example, in a modelviewcontroller (MVC) architecture, reactive programming can facilitate changes in an underlying model that are reflected automatically in an associated view."
reflected automatically,"For example, in a modelviewcontroller (MVC) architecture, reactive programming can facilitate changes in an underlying model that are reflected automatically in an associated view."
associated view,"For example, in a modelviewcontroller (MVC) architecture, reactive programming can facilitate changes in an underlying model that are reflected automatically in an associated view."
node link,"In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence. !! With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link."
second link field pointing,"In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence."
node contains,"In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence."
empty list consists,"With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link."
sentinel node alone,"With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link."
remote error indication,Remote error indication (REI) or formerly far end block error (FEBE) is an alarm signal used in synchronous optical networking (SONET).
formerly far end block error,Remote error indication (REI) or formerly far end block error (FEBE) is an alarm signal used in synchronous optical networking (SONET).
alarm signal used,Remote error indication (REI) or formerly far end block error (FEBE) is an alarm signal used in synchronous optical networking (SONET).
sometimes called applied linear algebra,"Numerical linear algebra, sometimes called applied linear algebra, is the study of how matrix operations can be used to create computer algorithms which efficiently and accurately provide approximate answers to questions in continuous mathematics."
accurately provide approximate answers,"Numerical linear algebra, sometimes called applied linear algebra, is the study of how matrix operations can be used to create computer algorithms which efficiently and accurately provide approximate answers to questions in continuous mathematics."
continuous mathematics,"Numerical linear algebra, sometimes called applied linear algebra, is the study of how matrix operations can be used to create computer algorithms which efficiently and accurately provide approximate answers to questions in continuous mathematics. !! Numerical linear algebra aims to solve problems of continuous mathematics using finite precision computers, so its applications to the natural and social sciences are as vast as the applications of continuous mathematics."
create computer algorithms,"Numerical linear algebra, sometimes called applied linear algebra, is the study of how matrix operations can be used to create computer algorithms which efficiently and accurately provide approximate answers to questions in continuous mathematics."
develop computer algorithms,"Numerical linear algebra uses properties of vectors and matrices to develop computer algorithms that minimize the error introduced by the computer, and is also concerned with ensuring that the algorithm is as efficient as possible."
numerical linear algebra uses properties,"Numerical linear algebra uses properties of vectors and matrices to develop computer algorithms that minimize the error introduced by the computer, and is also concerned with ensuring that the algorithm is as efficient as possible."
also concerned,"Numerical linear algebra uses properties of vectors and matrices to develop computer algorithms that minimize the error introduced by the computer, and is also concerned with ensuring that the algorithm is as efficient as possible."
error introduced,"Numerical linear algebra uses properties of vectors and matrices to develop computer algorithms that minimize the error introduced by the computer, and is also concerned with ensuring that the algorithm is as efficient as possible."
social sciences,"Path dependence is a concept in economics and the social sciences, referring to processes where past events or decisions constrain later events or decisions. !! Numerical linear algebra aims to solve problems of continuous mathematics using finite precision computers, so its applications to the natural and social sciences are as vast as the applications of continuous mathematics. !! Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences, medicine, business and even the arts."
solve problems,"Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a monolithic system to solve. !! Numerical linear algebra aims to solve problems of continuous mathematics using finite precision computers, so its applications to the natural and social sciences are as vast as the applications of continuous mathematics. !! In mathematics and computer science, symbolic-numeric computation is the use of software that combines symbolic and numeric methods to solve problems."
numerical linear algebra aims,"Numerical linear algebra aims to solve problems of continuous mathematics using finite precision computers, so its applications to the natural and social sciences are as vast as the applications of continuous mathematics."
differential equations  x even though,"Noting the broad applications of numerical linear algebra, Lloyd N. Trefethen and David Bau, III argue that it is ""as fundamental to the mathematical sciences as calculus and differential equations"",:x even though it is a comparatively small field."
comparatively small field,"Noting the broad applications of numerical linear algebra, Lloyd N. Trefethen and David Bau, III argue that it is ""as fundamental to the mathematical sciences as calculus and differential equations"",:x even though it is a comparatively small field."
broad applications,"Noting the broad applications of numerical linear algebra, Lloyd N. Trefethen and David Bau, III argue that it is ""as fundamental to the mathematical sciences as calculus and differential equations"",:x even though it is a comparatively small field."
iii argue,"Noting the broad applications of numerical linear algebra, Lloyd N. Trefethen and David Bau, III argue that it is ""as fundamental to the mathematical sciences as calculus and differential equations"",:x even though it is a comparatively small field."
mathematical sciences,"Noting the broad applications of numerical linear algebra, Lloyd N. Trefethen and David Bau, III argue that it is ""as fundamental to the mathematical sciences as calculus and differential equations"",:x even though it is a comparatively small field."
david bau,"Noting the broad applications of numerical linear algebra, Lloyd N. Trefethen and David Bau, III argue that it is ""as fundamental to the mathematical sciences as calculus and differential equations"",:x even though it is a comparatively small field."
particular emphasis,"Because many properties of matrices and vectors also apply to functions and operators, numerical linear algebra can also be viewed as a type of functional analysis which has a particular emphasis on practical algorithms."
vectors also apply,"Because many properties of matrices and vectors also apply to functions and operators, numerical linear algebra can also be viewed as a type of functional analysis which has a particular emphasis on practical algorithms."
delegated path discovery,Delegated Path Discovery (DPD) is a method for querying a trusted server for information about a public key certificate.
trusted server,Delegated Path Validation (DPV) is a method for offloading to a trusted server the work involved in validating a public key certificate. !! Delegated Path Discovery (DPD) is a method for querying a trusted server for information about a public key certificate.
conditional dependencies via,"A Bayesian network (also known as a Bayes network, Bayes net, belief network, or decision network) is a probabilistic graphical model that represents a set of variables and their conditional dependencies via a directed acyclic graph (DAG)."
several possible known causes,Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor.
bayesian network could represent,"For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms."
perform inference,Efficient algorithms can perform inference and learning in Bayesian networks.
protein sequences,Bayesian networks that model sequences of variables (e. g. speech signals or protein sequences) are called dynamic Bayesian networks.
called dynamic bayesian networks,Bayesian networks that model sequences of variables (e. g. speech signals or protein sequences) are called dynamic Bayesian networks.
model sequences,Bayesian networks that model sequences of variables (e. g. speech signals or protein sequences) are called dynamic Bayesian networks.
proxyimage avoids multiple loading,"Using the proxy pattern, the code of the ProxyImage avoids multiple loading of the image, accessing it from the other system in a memory-saving manner."
saving manner,"Using the proxy pattern, the code of the ProxyImage avoids multiple loading of the image, accessing it from the other system in a memory-saving manner."
advantage made possible,"The lazy loading demonstrated in this example is not part of the proxy pattern, but is merely an advantage made possible by the use of the proxy."
lazy loading demonstrated,"The lazy loading demonstrated in this example is not part of the proxy pattern, but is merely an advantage made possible by the use of the proxy."
proxy pattern description,Proxy pattern description from the Portland Pattern Repository
optimization algorithm based,"In computer science and operations research, the artificial bee colony algorithm (ABC) is an optimization algorithm based on the intelligent foraging behaviour of honey bee swarm, proposed by Dervi Karaboa (Erciyes University) in 2005."
erciyes university,"In computer science and operations research, the artificial bee colony algorithm (ABC) is an optimization algorithm based on the intelligent foraging behaviour of honey bee swarm, proposed by Dervi Karaboa (Erciyes University) in 2005."
dervi karaboa,"In computer science and operations research, the artificial bee colony algorithm (ABC) is an optimization algorithm based on the intelligent foraging behaviour of honey bee swarm, proposed by Dervi Karaboa (Erciyes University) in 2005."
honey bee swarm,"In computer science and operations research, the artificial bee colony algorithm (ABC) is an optimization algorithm based on the intelligent foraging behaviour of honey bee swarm, proposed by Dervi Karaboa (Erciyes University) in 2005."
intelligent foraging behaviour,"In computer science and operations research, the artificial bee colony algorithm (ABC) is an optimization algorithm based on the intelligent foraging behaviour of honey bee swarm, proposed by Dervi Karaboa (Erciyes University) in 2005."
computationally intelligent,"In artificial intelligence, artificial immune systems (AIS) are a class of computationally intelligent, rule-based machine learning systems inspired by the principles and processes of the vertebrate immune system."
based machine learning systems inspired,"In artificial intelligence, artificial immune systems (AIS) are a class of computationally intelligent, rule-based machine learning systems inspired by the principles and processes of the vertebrate immune system."
systems towards solving computational problems,"The field of Artificial Immune Systems (AIS) is concerned with abstracting the structure and function of the immune system to computational systems, and investigating the application of these systems towards solving computational problems from mathematics, engineering, and information technology."
immune system,"Following this work, the dependency network methodology has been applied to the study of the immune system, and semantic networks. !! The field of Artificial Immune Systems (AIS) is concerned with abstracting the structure and function of the immune system to computational systems, and investigating the application of these systems towards solving computational problems from mathematics, engineering, and information technology."
computational systems,"The field of Artificial Immune Systems (AIS) is concerned with abstracting the structure and function of the immune system to computational systems, and investigating the application of these systems towards solving computational problems from mathematics, engineering, and information technology."
observed immune functions,"Artificial Immune Systems (AIS) are adaptive systems, inspired by theoretical immunology and observed immune functions, principles and models, which are applied to problem solving."
problem solving,"Artificial Immune Systems (AIS) are adaptive systems, inspired by theoretical immunology and observed immune functions, principles and models, which are applied to problem solving. !! Reasoning systems have a wide field of application that includes scheduling, business rule processing, problem solving, complex event processing, intrusion detection, predictive analytics, robotics, computer vision, and natural language processing."
theoretical immunology,"Artificial Immune Systems (AIS) are adaptive systems, inspired by theoretical immunology and observed immune functions, principles and models, which are applied to problem solving."
adaptive systems,"Artificial Immune Systems (AIS) are adaptive systems, inspired by theoretical immunology and observed immune functions, principles and models, which are applied to problem solving."
first book,"The first book on Artificial Immune Systems was edited by Dasgupta in 1999. !! Boolean algebra was introduced by George Boole in his first book The Mathematical Analysis of Logic (1847), and set forth more fully in his An Investigation of the Laws of Thought (1854)."
von zuben,"Von Zuben, (1999) ""Artificial Immune Systems: Part I -Basic Theory and Applications"", School of Computing and Electrical Engineering, State University of Campinas, Brazil, No."
basic theory,"Von Zuben, (1999) ""Artificial Immune Systems: Part I -Basic Theory and Applications"", School of Computing and Electrical Engineering, State University of Campinas, Brazil, No."
state university,"Von Zuben, (1999) ""Artificial Immune Systems: Part I -Basic Theory and Applications"", School of Computing and Electrical Engineering, State University of Campinas, Brazil, No."
applications  school,"Von Zuben, (1999) ""Artificial Immune Systems: Part I -Basic Theory and Applications"", School of Computing and Electrical Engineering, State University of Campinas, Brazil, No."
serial dependencies,"In linguistics, cross-serial dependencies (also called crossing dependencies by some authors) occur when the lines representing the dependency relations between two series of words cross over each other. !! For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
lines representing,"In linguistics, cross-serial dependencies (also called crossing dependencies by some authors) occur when the lines representing the dependency relations between two series of words cross over each other."
also called crossing dependencies,"In linguistics, cross-serial dependencies (also called crossing dependencies by some authors) occur when the lines representing the dependency relations between two series of words cross over each other."
words cross,"In linguistics, cross-serial dependencies (also called crossing dependencies by some authors) occur when the lines representing the dependency relations between two series of words cross over each other."
two series,"In linguistics, cross-serial dependencies (also called crossing dependencies by some authors) occur when the lines representing the dependency relations between two series of words cross over each other."
lcfrs grammar,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
lcfrs  one,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
free rewriting systems,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
program authorship attribution,Code stylometry (also known as program authorship attribution or source code authorship analysis) is the application of stylometry to computer code to attribute authorship to anonymous binary or source code.
including plagiarism detection,"Unlike software forensics, code stylometry attributes authorship for purposes other than intellectual property infringement, including plagiarism detection, copyright investigation, and authorship verification."
unlike software forensics,"Unlike software forensics, code stylometry attributes authorship for purposes other than intellectual property infringement, including plagiarism detection, copyright investigation, and authorship verification."
code stylometry attributes authorship,"Unlike software forensics, code stylometry attributes authorship for purposes other than intellectual property infringement, including plagiarism detection, copyright investigation, and authorship verification."
given set,"Topology optimization is a mathematical method that optimizes material layout within a given design space, for a given set of loads, boundary conditions and constraints with the goal of maximizing the performance of the system. !! Global optimization is a branch of applied mathematics and numerical analysis that attempts to find the global minima or maxima of a function or a set of functions on a given set. !! In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects. !! While Steiner tree problems may be formulated in a number of settings, they all require an optimal interconnect for a given set of objects and a predefined objective function. !! Global optimization is distinguished from local optimization by its focus on finding the minimum or maximum over the given set, as opposed to finding local minima or maxima. !! In computational learning theory, induction of regular languages refers to the task of learning a formal description (e. g. grammar) of a regular language from a given set of example strings. !! The vehicle routing problem (VRP) is a combinatorial optimization and integer programming problem which asks ""What is the optimal set of routes for a fleet of vehicles to traverse in order to deliver to a given set of customers""."
formal description,"In computational learning theory, induction of regular languages refers to the task of learning a formal description (e. g. grammar) of a regular language from a given set of example strings."
regular languages refers,"In computational learning theory, induction of regular languages refers to the task of learning a formal description (e. g. grammar) of a regular language from a given set of example strings."
example strings,"In computational learning theory, induction of regular languages refers to the task of learning a formal description (e. g. grammar) of a regular language from a given set of example strings."
induction of regular languages,"In computational learning theory, induction of regular languages refers to the task of learning a formal description (e. g. grammar) of a regular language from a given set of example strings."
core principles,"Digital empathy is the application of the core principles of empathy compassion, cognition, and emotion into technical designs to enhance user experience."
empathy compassion,"Digital empathy is the application of the core principles of empathy compassion, cognition, and emotion into technical designs to enhance user experience."
enhance user experience,"Digital empathy is the application of the core principles of empathy compassion, cognition, and emotion into technical designs to enhance user experience."
digital empathy,"Digital empathy finds its roots in empathy, a human behaviour explained by cognitive and behavioral neuroscientists as, a multifaceted construct used to account for the capacity to share and understand the thoughts and feelings of others. "" !! According to Friesem (2016), digital empathy is the cognitive and emotional ability to be reflective and socially responsible while strategically using digital media. !! Increasingly online communication patterns, and the associated phenomenon of online disinhibition, have led to research on ""digital empathy"". !! Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications. !! Digital empathy is the application of the core principles of empathy compassion, cognition, and emotion into technical designs to enhance user experience."
technical designs,"Digital empathy is the application of the core principles of empathy compassion, cognition, and emotion into technical designs to enhance user experience."
2016  digital empathy,"According to Friesem (2016), digital empathy is the cognitive and emotional ability to be reflective and socially responsible while strategically using digital media."
socially responsible,"According to Friesem (2016), digital empathy is the cognitive and emotional ability to be reflective and socially responsible while strategically using digital media."
emotional ability,"According to Friesem (2016), digital empathy is the cognitive and emotional ability to be reflective and socially responsible while strategically using digital media."
strategically using digital media,"According to Friesem (2016), digital empathy is the cognitive and emotional ability to be reflective and socially responsible while strategically using digital media."
multifaceted construct used,"Digital empathy finds its roots in empathy, a human behaviour explained by cognitive and behavioral neuroscientists as, a multifaceted construct used to account for the capacity to share and understand the thoughts and feelings of others. """
digital empathy finds,"Digital empathy finds its roots in empathy, a human behaviour explained by cognitive and behavioral neuroscientists as, a multifaceted construct used to account for the capacity to share and understand the thoughts and feelings of others. """
behavioral neuroscientists,"Digital empathy finds its roots in empathy, a human behaviour explained by cognitive and behavioral neuroscientists as, a multifaceted construct used to account for the capacity to share and understand the thoughts and feelings of others. """
human behaviour explained,"Digital empathy finds its roots in empathy, a human behaviour explained by cognitive and behavioral neuroscientists as, a multifaceted construct used to account for the capacity to share and understand the thoughts and feelings of others. """
online disinhibition,"Increasingly online communication patterns, and the associated phenomenon of online disinhibition, have led to research on ""digital empathy""."
increasingly online communication patterns,"Increasingly online communication patterns, and the associated phenomenon of online disinhibition, have led to research on ""digital empathy""."
associated phenomenon,"Increasingly online communication patterns, and the associated phenomenon of online disinhibition, have led to research on ""digital empathy""."
research paper,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
traditional empathic characteristics,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
emerging issue,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
christopher terry,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
digital empathy define digital empathy,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
others expressed,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
mediated communications,Christopher Terry and Cain (2015) in their research paper The Emerging Issue of Digital Empathy define digital empathy as the traditional empathic characteristics such as concern and caring for others expressed through computer-mediated communications.
although sequences,"Although sequences that are closer to truly random can be generated using hardware random number generators, pseudorandom number generators are important in practice for their speed in number generation and their reproducibility."
number generation,"Although sequences that are closer to truly random can be generated using hardware random number generators, pseudorandom number generators are important in practice for their speed in number generation and their reproducibility."
quality prngs,"Other higher-quality PRNGs, both in terms of computational and statistical performance, were developed before and after this date; these can be identified in the List of pseudorandom number generators."
computer programming technique used,"Double hashing is a computer programming technique used in conjunction with open addressing in hash tables to resolve hash collisions, by using a secondary hash of the key as an offset when a collision occurs."
secondary hash,"Double hashing is a computer programming technique used in conjunction with open addressing in hash tables to resolve hash collisions, by using a secondary hash of the key as an offset when a collision occurs."
repeatedly steps forward,"The double hashing technique uses one hash value as an index into the table and then repeatedly steps forward an interval until the desired value is located, an empty location is reached, or the entire table has been searched; but this interval is set by a second, independent hash function."
empty location,"The double hashing technique uses one hash value as an index into the table and then repeatedly steps forward an interval until the desired value is located, an empty location is reached, or the entire table has been searched; but this interval is set by a second, independent hash function."
desired value,"The double hashing technique uses one hash value as an index into the table and then repeatedly steps forward an interval until the desired value is located, an empty location is reached, or the entire table has been searched; but this interval is set by a second, independent hash function."
entire table,"The double hashing technique uses one hash value as an index into the table and then repeatedly steps forward an interval until the desired value is located, an empty location is reached, or the entire table has been searched; but this interval is set by a second, independent hash function."
hash table approaches maximum capacity,"Like all other forms of open addressing, double hashing becomes linear as the hash table approaches maximum capacity."
double hashing becomes linear,"Like all other forms of open addressing, double hashing becomes linear as the hash table approaches maximum capacity."
technique known,"(a tetrahedral number), does solve the problem, a technique known as enhanced double hashing. !! To date, the technique known as Reverse Computation has only been applied in software for optimistically synchronized, parallel discrete event simulation."
includes double hashing functionality,klib a C library that includes double hashing functionality.
entropy coding method defined,"Range coding (or range encoding) is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976."
richard clark pasco,"Range coding (or range encoding) is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976."
effectively rediscovered,"Range coding (or range encoding) is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976."
range encoding,"Range coding (or range encoding) is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976."
range coding,"Range coding (or range encoding) is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976."
fifo arithmetic code first introduced,"Range coding (or range encoding) is an entropy coding method defined by G. Nigel N. Martin in a 1979 paper, which effectively rediscovered the FIFO arithmetic code first introduced by Richard Clark Pasco in 1976."
two states,"Digital signals having more than two states are occasionally used; circuitry using such signals is called multivalued logic. !! In quantum mechanics, and especially quantum information and the study of open quantum systems, the trace distance T is a metric on the space of density matrices and gives a measure of the distinguishability between two states."
especially quantum information,"In quantum mechanics, and especially quantum information and the study of open quantum systems, the trace distance T is a metric on the space of density matrices and gives a measure of the distinguishability between two states."
trace distance,"For qubits, the trace distance is equal to half the Euclidean distance in the Bloch representation. !! The trace distance is a generalization of the total variation distance, and for two commuting density matrices, has the same value as the total variation distance of the two corresponding probability distributions. !! The purpose of the factor of two is to restrict the trace distance between two normalized density matrices to the range [0, 1] and to simplify formulas in which the trace distance appears. !! In quantum mechanics, and especially quantum information and the study of open quantum systems, the trace distance T is a metric on the space of density matrices and gives a measure of the distinguishability between two states."
two normalized density matrices,"The purpose of the factor of two is to restrict the trace distance between two normalized density matrices to the range [0, 1] and to simplify formulas in which the trace distance appears."
simplify formulas,"The purpose of the factor of two is to restrict the trace distance between two normalized density matrices to the range [0, 1] and to simplify formulas in which the trace distance appears."
trace distance appears,"The purpose of the factor of two is to restrict the trace distance between two normalized density matrices to the range [0, 1] and to simplify formulas in which the trace distance appears."
bloch representation,"For qubits, the trace distance is equal to half the Euclidean distance in the Bloch representation."
total variation distance,"The trace distance is a generalization of the total variation distance, and for two commuting density matrices, has the same value as the total variation distance of the two corresponding probability distributions."
two commuting density matrices,"The trace distance is a generalization of the total variation distance, and for two commuting density matrices, has the same value as the total variation distance of the two corresponding probability distributions."
two corresponding probability distributions,"The trace distance is a generalization of the total variation distance, and for two commuting density matrices, has the same value as the total variation distance of the two corresponding probability distributions."
becomes necessary,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
two bytes wide using,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
add two numbers,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
first add,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
low bytes,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
byte addition,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
fairly common cause,Unanticipated arithmetic overflow is a fairly common cause of program errors.
unanticipated arithmetic overflow,Unanticipated arithmetic overflow is a fairly common cause of program errors.
ariane 5 rocket,An unhandled arithmetic overflow in the engine steering software was the primary cause of the crash of the 1996 maiden flight of the Ariane 5 rocket.
1996 maiden flight,An unhandled arithmetic overflow in the engine steering software was the primary cause of the crash of the 1996 maiden flight of the Ariane 5 rocket.
primary cause,An unhandled arithmetic overflow in the engine steering software was the primary cause of the crash of the 1996 maiden flight of the Ariane 5 rocket.
unhandled arithmetic overflow,An unhandled arithmetic overflow in the engine steering software was the primary cause of the crash of the 1996 maiden flight of the Ariane 5 rocket.
engine steering software,An unhandled arithmetic overflow in the engine steering software was the primary cause of the crash of the 1996 maiden flight of the Ariane 5 rocket.
optimally separating hyperplane,"In the context of support-vector machines, the optimally separating hyperplane or maximum-margin hyperplane is a hyperplane which separates two convex hulls of points and is equidistant from the two."
separates two convex hulls,"In the context of support-vector machines, the optimally separating hyperplane or maximum-margin hyperplane is a hyperplane which separates two convex hulls of points and is equidistant from the two."
driving cars combine,"Self-driving cars combine a variety of sensors to perceive their surroundings, such as thermographic cameras, radar, lidar, sonar, GPS, odometry and inertial measurement units."
fully self,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
various stages,"In contrast to manifold approaches and techniques in software engineering, software diagnosis does not depend on programming languages, modeling techniques, software development processes or the specific techniques used in the various stages of the software development process. !! Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
several projects,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
everyday consumers,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
take control,"The Union of Concerned Scientists states that self-driving cars are ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle."
safely operate,"The Union of Concerned Scientists states that self-driving cars are ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle."
driving cars,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps. !! The Union of Concerned Scientists states that self-driving cars are ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle."
human drivers,"The Union of Concerned Scientists states that self-driving cars are ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle."
never required,"The Union of Concerned Scientists states that self-driving cars are ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle."
concerned scientists states,"The Union of Concerned Scientists states that self-driving cars are ""cars or trucks in which human drivers are never required to take control to safely operate the vehicle."
multiple sensors,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
modern self,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
current location estimates,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
map updates,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
new system,"Forward compatibility for the older system usually means backward compatibility for the new system, i. e. the ability to process data from the old system; the new system usually has full compatibility with the older one, by being able to both process and generate data in the format of the older system. !! Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
allows self,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
called maplite,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
without using 3d maps,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
distributed object communication realizes communication,"In a distributed computing environment, distributed object communication realizes communication between distributed objects."
client side object participating,"The client side object participating in distributed object communication is known as a stub or proxy, and is an example of a proxy object."
term avoided,The server side object participating in distributed object communication is known as a skeleton (or stub; term avoided here).
server side object participating,The server side object participating in distributed object communication is known as a skeleton (or stub; term avoided here).
proof method,"Structural induction is a proof method that is used in mathematical logic (e. g. , in the proof of o' theorem), computer science, graph theory, and some other mathematical fields."
theorem  computer science,"Structural induction is a proof method that is used in mathematical logic (e. g. , in the proof of o' theorem), computer science, graph theory, and some other mathematical fields."
mathematical fields,"Structural induction is a proof method that is used in mathematical logic (e. g. , in the proof of o' theorem), computer science, graph theory, and some other mathematical fields."
ordinary mathematical induction,Structural recursion is a recursion method bearing the same relationship to structural induction as ordinary recursion bears to ordinary mathematical induction.
ordinary recursion bears,Structural recursion is a recursion method bearing the same relationship to structural induction as ordinary recursion bears to ordinary mathematical induction.
recursion method bearing,Structural recursion is a recursion method bearing the same relationship to structural induction as ordinary recursion bears to ordinary mathematical induction.
must hold,"The structural induction proof is a proof that the proposition holds for all the minimal structures and that if it holds for the immediate substructures of a certain structure S, then it must hold for S also."
immediate substructures,"The structural induction proof is a proof that the proposition holds for all the minimal structures and that if it holds for the immediate substructures of a certain structure S, then it must hold for S also."
certain structure,"The structural induction proof is a proof that the proposition holds for all the minimal structures and that if it holds for the immediate substructures of a certain structure S, then it must hold for S also."
proposition holds,"The structural induction proof is a proof that the proposition holds for all the minimal structures and that if it holds for the immediate substructures of a certain structure S, then it must hold for S also."
particularly easy cases,"Structural recursion is usually proved correct by structural induction; in particularly easy cases, the inductive step is often left out."
usually proved correct,"Structural recursion is usually proved correct by structural induction; in particularly easy cases, the inductive step is often left out."
inductive step,"Structural recursion is usually proved correct by structural induction; in particularly easy cases, the inductive step is often left out."
often left,"Structural recursion is usually proved correct by structural induction; in particularly easy cases, the inductive step is often left out."
must also,"A structural induction proof of some proposition P(L) then consists of two parts: A proof that P([]) is true and a proof that if P(L) is true for some list L, and if L is the tail of list M, then P(M) must also be true."
two parts,"A structural induction proof of some proposition P(L) then consists of two parts: A proof that P([]) is true and a proof that if P(L) is true for some list L, and if L is the tail of list M, then P(M) must also be true."
avoiding problematic issues,"An Internet Routing Registry (IRR) is a database of Internet route objects for determining, and sharing route and related information used for configuring routers, with a view to avoiding problematic issues between Internet service providers."
related information used,"An Internet Routing Registry (IRR) is a database of Internet route objects for determining, and sharing route and related information used for configuring routers, with a view to avoiding problematic issues between Internet service providers."
configuring routers,"An Internet Routing Registry (IRR) is a database of Internet route objects for determining, and sharing route and related information used for configuring routers, with a view to avoiding problematic issues between Internet service providers."
sharing route,"An Internet Routing Registry (IRR) is a database of Internet route objects for determining, and sharing route and related information used for configuring routers, with a view to avoiding problematic issues between Internet service providers."
appropriate format,"The Internet routing registry works by providing an interlinked hierarchy of objects designed to facilitate the organization of IP routing between organizations, and also to provide data in an appropriate format for automatic programming of routers."
objects designed,"The Internet routing registry works by providing an interlinked hierarchy of objects designed to facilitate the organization of IP routing between organizations, and also to provide data in an appropriate format for automatic programming of routers."
internet routing registry works,"The Internet routing registry works by providing an interlinked hierarchy of objects designed to facilitate the organization of IP routing between organizations, and also to provide data in an appropriate format for automatic programming of routers."
provide data,"The Internet routing registry works by providing an interlinked hierarchy of objects designed to facilitate the organization of IP routing between organizations, and also to provide data in an appropriate format for automatic programming of routers."
algorithms for recovery and isolation exploiting semantics,"In computer science, Algorithms for Recovery and Isolation Exploiting Semantics, or ARIES is a recovery algorithm designed to work with a no-force, steal database approach; it is used by IBM DB2, Microsoft SQL Server and many other database systems."
recovery algorithm designed,"In computer science, Algorithms for Recovery and Isolation Exploiting Semantics, or ARIES is a recovery algorithm designed to work with a no-force, steal database approach; it is used by IBM DB2, Microsoft SQL Server and many other database systems."
steal database approach,"In computer science, Algorithms for Recovery and Isolation Exploiting Semantics, or ARIES is a recovery algorithm designed to work with a no-force, steal database approach; it is used by IBM DB2, Microsoft SQL Server and many other database systems."
isolation exploiting semantics,"In computer science, Algorithms for Recovery and Isolation Exploiting Semantics, or ARIES is a recovery algorithm designed to work with a no-force, steal database approach; it is used by IBM DB2, Microsoft SQL Server and many other database systems."
finely quantized versions,"In information theory, information dimension is an information measure for random vectors in Euclidean space, based on the normalized entropy of finely quantized versions of the random vectors."
various regularity constraints,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
analog sources,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
verd gave,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
fundamental limit,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
almost lossless data compression,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
operational characterization,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
rnyi information dimension,"In 2010, Wu and Verd gave an operational characterization of Rnyi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder."
differential entropy,It is shown that information dimension and differential entropy are tightly connected.
tightly connected,It is shown that information dimension and differential entropy are tightly connected.
distribution gives,"The information dimension of a distribution gives a theoretical upper bound on the compression rate, if one wants to compress a variable coming from this distribution."
compression rate,"The information dimension of a distribution gives a theoretical upper bound on the compression rate, if one wants to compress a variable coming from this distribution."
theoretical upper bound,"The information dimension of a distribution gives a theoretical upper bound on the compression rate, if one wants to compress a variable coming from this distribution."
variable coming,"The information dimension of a distribution gives a theoretical upper bound on the compression rate, if one wants to compress a variable coming from this distribution."
one wants,"In combinatorial mathematics, probability, and computer science, in the longest alternating subsequence problem, one wants to find a subsequence of a given sequence in which the elements are in alternating order, and in which the sequence is as long as possible. !! The information dimension of a distribution gives a theoretical upper bound on the compression rate, if one wants to compress a variable coming from this distribution."
capture correlation,Distribution-based clustering produces complex models for clusters that can capture correlation and dependence between attributes.
based clustering produces complex models,Distribution-based clustering produces complex models for clusters that can capture correlation and dependence between attributes.
merge operation,"This feature is central to the merge operation of a binomial heap, which is its major advantage over other conventional heaps. !! In computer science, a mergeable heap (also called a meldable heap) is an abstract data type, which is a heap supporting a merge operation."
fundamental operation,"In most mergeable heap structures, merging is the fundamental operation on which others are based."
mergeable heap structures,"In most mergeable heap structures, merging is the fundamental operation on which others are based."
energy physics,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
high accuracy,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
body systems,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy. !! Coupled cluster (CC) is a numerical technique used for describing many-body systems.
numerical variational technique devised,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
quantum many,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
interdisciplinary subfield,Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers with the main benefit of searchability.
main benefit,Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers with the main benefit of searchability.
develops methodologies,Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers with the main benefit of searchability.
asr  computer speech recognition,"It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT)."
speech recognition systems require,"Some speech recognition systems require ""training"" (also called ""enrollment"") where an individual speaker reads text or isolated vocabulary into the system."
isolated vocabulary,"Some speech recognition systems require ""training"" (also called ""enrollment"") where an individual speaker reads text or isolated vocabulary into the system."
individual speaker reads text,"Some speech recognition systems require ""training"" (also called ""enrollment"") where an individual speaker reads text or isolated vocabulary into the system."
call home  call routing,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
usually termed direct voice input,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
spoken  simple data entry,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
search key words,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
voice dialing,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
collect call  domotic appliance control,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
would like,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
word processors,"Regular expressions are used in search engines, search and replace dialogs of word processors and text editors, in text processing utilities such as sed and AWK and in lexical analysis. !! Version control systems are most commonly run as stand-alone applications, but revision control is also embedded in various types of software, such as word processors and spreadsheets, collaborative web docs, and content management systems, e. g. , Wikipedia's page history. !! Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
particular words,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
radiology report  determining speaker characteristics,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
credit card number  preparation,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
major innovations,"From the technology perspective, speech recognition has a long history with several waves of major innovations."
technology perspective,"From the technology perspective, speech recognition has a long history with several waves of major innovations."
several waves,"From the technology perspective, speech recognition has a long history with several waves of major innovations."
lazy loading,Lazy loading (also known as asynchronous loading) is a design pattern commonly used in computer programming and mostly in web design and development to defer initialization of an object until the point at which it is needed. !! Lazy Loading Mozilla Web Dev !! The opposite of lazy loading is eager loading.
design pattern commonly used,Lazy loading (also known as asynchronous loading) is a design pattern commonly used in computer programming and mostly in web design and development to defer initialization of an object until the point at which it is needed.
defer initialization,Lazy loading (also known as asynchronous loading) is a design pattern commonly used in computer programming and mostly in web design and development to defer initialization of an object until the point at which it is needed.
asynchronous loading,Lazy loading (also known as asynchronous loading) is a design pattern commonly used in computer programming and mostly in web design and development to defer initialization of an object until the point at which it is needed.
eager loading,The opposite of lazy loading is eager loading.
lazy loading mozilla web dev,Lazy Loading Mozilla Web Dev
molecular dynamics models,"Stochastic gradient Langevin dynamics (SGLD) is an optimization technique composed of characteristics from Stochastic gradient descent, a RobbinsMonro optimization algorithm, and Langevin dynamics, a mathematical extension of molecular dynamics models."
langevin dynamics,"Stochastic gradient Langevin dynamics (SGLD) is an optimization technique composed of characteristics from Stochastic gradient descent, a RobbinsMonro optimization algorithm, and Langevin dynamics, a mathematical extension of molecular dynamics models."
optimization technique composed,"Stochastic gradient Langevin dynamics (SGLD) is an optimization technique composed of characteristics from Stochastic gradient descent, a RobbinsMonro optimization algorithm, and Langevin dynamics, a mathematical extension of molecular dynamics models."
mathematical extension,"Stochastic gradient Langevin dynamics (SGLD) is an optimization technique composed of characteristics from Stochastic gradient descent, a RobbinsMonro optimization algorithm, and Langevin dynamics, a mathematical extension of molecular dynamics models."
balancing binary search tree,"In computer science, a self-balancing binary search tree (BST) is any node-based binary search tree that automatically keeps its height (maximal number of levels below the root) small in the face of arbitrary item insertions and deletions. !! This is the case for many binary search trees, such as the AVL trees and the redblack trees the latter was called symmetric binary B-tree and was renamed; it can, however, still be confused with the generic concept of self-balancing binary search tree because of the initials. !! These operations when designed for a self-balancing binary search tree, contain precautionary measures against boundlessly increasing tree height, so that these abstract data structures receive the attribute ""self-balancing""."
arbitrary item insertions,"In computer science, a self-balancing binary search tree (BST) is any node-based binary search tree that automatically keeps its height (maximal number of levels below the root) small in the face of arbitrary item insertions and deletions."
automatically keeps,"In computer science, a self-balancing binary search tree (BST) is any node-based binary search tree that automatically keeps its height (maximal number of levels below the root) small in the face of arbitrary item insertions and deletions."
maximal number,"In computer science, a self-balancing binary search tree (BST) is any node-based binary search tree that automatically keeps its height (maximal number of levels below the root) small in the face of arbitrary item insertions and deletions."
based binary search tree,"In computer science, a self-balancing binary search tree (BST) is any node-based binary search tree that automatically keeps its height (maximal number of levels below the root) small in the face of arbitrary item insertions and deletions."
abstract data structures receive,"These operations when designed for a self-balancing binary search tree, contain precautionary measures against boundlessly increasing tree height, so that these abstract data structures receive the attribute ""self-balancing""."
boundlessly increasing tree height,"These operations when designed for a self-balancing binary search tree, contain precautionary measures against boundlessly increasing tree height, so that these abstract data structures receive the attribute ""self-balancing""."
contain precautionary measures,"These operations when designed for a self-balancing binary search tree, contain precautionary measures against boundlessly increasing tree height, so that these abstract data structures receive the attribute ""self-balancing""."
many binary search trees,"This is the case for many binary search trees, such as the AVL trees and the redblack trees the latter was called symmetric binary B-tree and was renamed; it can, however, still be confused with the generic concept of self-balancing binary search tree because of the initials."
called symmetric binary b,"This is the case for many binary search trees, such as the AVL trees and the redblack trees the latter was called symmetric binary B-tree and was renamed; it can, however, still be confused with the generic concept of self-balancing binary search tree because of the initials."
generic concept,"This is the case for many binary search trees, such as the AVL trees and the redblack trees the latter was called symmetric binary B-tree and was renamed; it can, however, still be confused with the generic concept of self-balancing binary search tree because of the initials."
balancing binary search trees,"Self-balancing binary search trees can be used in a natural way to construct and maintain ordered lists, such as priority queues."
maintain ordered lists,"Self-balancing binary search trees can be used in a natural way to construct and maintain ordered lists, such as priority queues."
natural way,"Self-balancing binary search trees can be used in a natural way to construct and maintain ordered lists, such as priority queues."
modality studied,Subjunctive possibility (also called alethic possibility) is a form of modality studied in modal logic.
subjunctive possibility,"Subjunctive possibility is contrasted with (among other things) epistemic possibility (which deals with how the world may be, for all we know) and deontic possibility (which deals with how the world ought to be). !! Subjunctive possibility (also called alethic possibility) is a form of modality studied in modal logic."
also called alethic possibility,Subjunctive possibility (also called alethic possibility) is a form of modality studied in modal logic.
world ought,"Subjunctive possibility is contrasted with (among other things) epistemic possibility (which deals with how the world may be, for all we know) and deontic possibility (which deals with how the world ought to be)."
epistemic possibility,"Subjunctive possibility is contrasted with (among other things) epistemic possibility (which deals with how the world may be, for all we know) and deontic possibility (which deals with how the world ought to be)."
deontic possibility,"Subjunctive possibility is contrasted with (among other things) epistemic possibility (which deals with how the world may be, for all we know) and deontic possibility (which deals with how the world ought to be)."
world may,"Subjunctive possibility is contrasted with (among other things) epistemic possibility (which deals with how the world may be, for all we know) and deontic possibility (which deals with how the world ought to be)."
represents data,"A digital signal is a signal that represents data as a sequence of discrete values; at any given time it can only take on, at most, one of a finite number of values."
given time,"A digital signal is a signal that represents data as a sequence of discrete values; at any given time it can only take on, at most, one of a finite number of values."
discrete values,"A digital signal is a signal that represents data as a sequence of discrete values; at any given time it can only take on, at most, one of a finite number of values. !! A fuzzy control system is a control system based on fuzzy logica mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true or false, respectively)."
simple digital signals represent information,Simple digital signals represent information in discrete bands of analog levels.
whereas noise always degrades,"As a result, digital signals have noise immunity; electronic noise, provided it is not too great, will not affect digital circuits, whereas noise always degrades the operation of analog signals to some degree."
noise immunity,"As a result, digital signals have noise immunity; electronic noise, provided it is not too great, will not affect digital circuits, whereas noise always degrades the operation of analog signals to some degree."
affect digital circuits,"As a result, digital signals have noise immunity; electronic noise, provided it is not too great, will not affect digital circuits, whereas noise always degrades the operation of analog signals to some degree."
occasionally used,Digital signals having more than two states are occasionally used; circuitry using such signals is called multivalued logic.
called multivalued logic,Digital signals having more than two states are occasionally used; circuitry using such signals is called multivalued logic.
circuitry using,Digital signals having more than two states are occasionally used; circuitry using such signals is called multivalued logic.
variable electric current,"In a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera."
information may,"In a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera."
physical quantity representing,"In a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera."
electromagnetic field,"In a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera."
magnetic storage media,"In a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera."
inherent difficulty,"In computer science, parameterized complexity is a branch of computational complexity theory that focuses on classifying computational problems according to their inherent difficulty with respect to multiple parameters of the input or output."
parameterized complexity,"A parameterized problem that allows for such an fpt-algorithm is said to be a fixed-parameter tractable problem and belongs to the class FPT, and the early name of the theory of parameterized complexity was fixed-parameter tractability. !! In this way, parameterized complexity can be seen as two-dimensional complexity theory. !! Parameterized Complexity. !! The first systematic work on parameterized complexity was done by Downey & Fellows (1999). !! In computer science, parameterized complexity is a branch of computational complexity theory that focuses on classifying computational problems according to their inherent difficulty with respect to multiple parameters of the input or output."
multiple parameters,"In computer science, parameterized complexity is a branch of computational complexity theory that focuses on classifying computational problems according to their inherent difficulty with respect to multiple parameters of the input or output."
first systematic work,The first systematic work on parameterized complexity was done by Downey & Fellows (1999).
parameter tractability,"A parameterized problem that allows for such an fpt-algorithm is said to be a fixed-parameter tractable problem and belongs to the class FPT, and the early name of the theory of parameterized complexity was fixed-parameter tractability."
parameterized problem,"A parameterized problem that allows for such an fpt-algorithm is said to be a fixed-parameter tractable problem and belongs to the class FPT, and the early name of the theory of parameterized complexity was fixed-parameter tractability."
early name,"A parameterized problem that allows for such an fpt-algorithm is said to be a fixed-parameter tractable problem and belongs to the class FPT, and the early name of the theory of parameterized complexity was fixed-parameter tractability."
class fpt,"A parameterized problem that allows for such an fpt-algorithm is said to be a fixed-parameter tractable problem and belongs to the class FPT, and the early name of the theory of parameterized complexity was fixed-parameter tractability."
parameter tractable problem,"A parameterized problem that allows for such an fpt-algorithm is said to be a fixed-parameter tractable problem and belongs to the class FPT, and the early name of the theory of parameterized complexity was fixed-parameter tractability."
dimensional complexity theory,"In this way, parameterized complexity can be seen as two-dimensional complexity theory."
structural risk minimization,Structural risk minimization at the support vector machines website. !! Structural risk minimization (SRM) is an inductive principle of use in machine learning.
support vector machines website,Structural risk minimization at the support vector machines website.
internal state changes,The state pattern is a behavioral software design pattern that allows an object to alter its behavior when its internal state changes.
methods defined,"The state pattern can be interpreted as a strategy pattern, which is able to switch a strategy through invocations of methods defined in the pattern's interface."
encapsulate varying behavior,"The state pattern is used in computer programming to encapsulate varying behavior for the same object, based on its internal state."
internal state,"The state pattern is used in computer programming to encapsulate varying behavior for the same object, based on its internal state."
relational mapping,"Polymorphic association is a term used in discussions of Object-Relational Mapping with respect to the problem of representing in the relational database domain, a relationship from one class to multiple classes."
multiple classes,"Polymorphic association is a term used in discussions of Object-Relational Mapping with respect to the problem of representing in the relational database domain, a relationship from one class to multiple classes."
originally developed,"Ambient intelligence was a projection on the future of consumer electronics, telecommunications and computing that was originally developed in the late 1990s by Eli Zelkha and his team at Palo Alto Ventures for the time frame 20102020. !! Trace scheduling was originally developed for Very Long Instruction Word, or VLIW machines, and is a form of global code motion."
time frame 20102020,"Ambient intelligence was a projection on the future of consumer electronics, telecommunications and computing that was originally developed in the late 1990s by Eli Zelkha and his team at Palo Alto Ventures for the time frame 20102020."
consumer electronics,"Ambient intelligence was a projection on the future of consumer electronics, telecommunications and computing that was originally developed in the late 1990s by Eli Zelkha and his team at Palo Alto Ventures for the time frame 20102020. !! consumer electronics, Philips Semiconductors split off from Philips and became NXP Semiconductors in 2006Consumer electronics companies have successfully dominated this market by designing their own media processors and integrating them into their video products."
eli zelkha,"Ambient intelligence was a projection on the future of consumer electronics, telecommunications and computing that was originally developed in the late 1990s by Eli Zelkha and his team at Palo Alto Ventures for the time frame 20102020."
palo alto ventures,"Ambient intelligence was a projection on the future of consumer electronics, telecommunications and computing that was originally developed in the late 1990s by Eli Zelkha and his team at Palo Alto Ventures for the time frame 20102020."
support people,"Ambient intelligence would allow devices to work in concert to support people in carrying out their everyday life activities, tasks and rituals in an intuitive way using information and intelligence that is hidden in the network connecting these devices (for example: The Internet of Things)."
intuitive way using information,"Ambient intelligence would allow devices to work in concert to support people in carrying out their everyday life activities, tasks and rituals in an intuitive way using information and intelligence that is hidden in the network connecting these devices (for example: The Internet of Things)."
everyday life activities,"Ambient intelligence would allow devices to work in concert to support people in carrying out their everyday life activities, tasks and rituals in an intuitive way using information and intelligence that is hidden in the network connecting these devices (for example: The Internet of Things)."
ambient intelligence would allow devices,"Ambient intelligence would allow devices to work in concert to support people in carrying out their everyday life activities, tasks and rituals in an intuitive way using information and intelligence that is hidden in the network connecting these devices (for example: The Internet of Things)."
working  public spaces,"A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments."
hospital environments,"A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments."
ambient intelligence environment,"A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments."
typical context,"A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments."
work spaces,"A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments."
smart street lights,"A typical context of ambient intelligence environment is home, but may also be extended to work spaces (offices, co-working), public spaces (based on technologies such as smart street lights), and hospital environments."
sensor networks,"Ubiquitous computing touches on distributed computing, mobile computing, location computing, mobile networking, sensor networks, humancomputer interaction, context-aware smart home technologies, and artificial intelligence. !! Ambient intelligence is primarily of interest because of its relationship to user experience and the advancement in sensor technology and sensor networks."
radhia cousot,Abstract interpretation was formalized by the French computer scientist working couple Patrick Cousot and Radhia Cousot in the late 1970s.
section illustrates abstract interpretation,"This section illustrates abstract interpretation by means of real-world, non-computing examples."
computing examples,"This section illustrates abstract interpretation by means of real-world, non-computing examples."
precise answer,"Abstraction is used to allow for generalized answers to questions (for example, answering ""maybe"" to a yes/no question, meaning ""yes or no"", when we (an algorithm of abstract interpretation) cannot compute the precise answer with certainty); this simplifies the problems, making them amenable to automatic solutions."
automatic solutions,"Abstraction is used to allow for generalized answers to questions (for example, answering ""maybe"" to a yes/no question, meaning ""yes or no"", when we (an algorithm of abstract interpretation) cannot compute the precise answer with certainty); this simplifies the problems, making them amenable to automatic solutions."
cannot compute,"Abstraction is used to allow for generalized answers to questions (for example, answering ""maybe"" to a yes/no question, meaning ""yes or no"", when we (an algorithm of abstract interpretation) cannot compute the precise answer with certainty); this simplifies the problems, making them amenable to automatic solutions."
generalized answers,"Abstraction is used to allow for generalized answers to questions (for example, answering ""maybe"" to a yes/no question, meaning ""yes or no"", when we (an algorithm of abstract interpretation) cannot compute the precise answer with certainty); this simplifies the problems, making them amenable to automatic solutions."
giving several semantics linked,"Given a programming or specification language, abstract interpretation consists of giving several semantics linked by relations of abstraction."
abstract interpretation consists,"Given a programming or specification language, abstract interpretation consists of giving several semantics linked by relations of abstraction."
specification language,"Given a programming or specification language, abstract interpretation consists of giving several semantics linked by relations of abstraction."
small memory footprint,"In computing, lightweight software also called lite program and lightweight application, is a computer program that is designed to have a small memory footprint (RAM usage) and low CPU usage, overall a low usage of system resources."
lightweight application,"In computing, lightweight software also called lite program and lightweight application, is a computer program that is designed to have a small memory footprint (RAM usage) and low CPU usage, overall a low usage of system resources."
low cpu usage,"In computing, lightweight software also called lite program and lightweight application, is a computer program that is designed to have a small memory footprint (RAM usage) and low CPU usage, overall a low usage of system resources."
system resources,"Database tuning aims to maximize use of system resources to perform work as efficiently and rapidly as possible. !! In computing, lightweight software also called lite program and lightweight application, is a computer program that is designed to have a small memory footprint (RAM usage) and low CPU usage, overall a low usage of system resources."
mit scheme,"Weight-balanced trees are popular in the functional programming community and are used to implement sets and maps in MIT Scheme, SLIB and implementations of Haskell."
functional programming community,"Weight-balanced trees are popular in the functional programming community and are used to implement sets and maps in MIT Scheme, SLIB and implementations of Haskell."
set difference,"Several set operations have been defined on weight-balanced trees: union, intersection and set difference."
several set operations,"Several set operations have been defined on weight-balanced trees: union, intersection and set difference."
new operations,"With the new operations, the implementation of weight-balanced trees can be more efficient and highly-parallelizable."
tree containing,"Join: The function Join is on two weight-balanced trees t1 and t2 and a key k and will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2."
balanced trees t1,"Join: The function Join is on two weight-balanced trees t1 and t2 and a key k and will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2."
two weight,"Join: The function Join is on two weight-balanced trees t1 and t2 and a key k and will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2."
metacognition concerned,Meta learning is a branch of metacognition concerned with learning about one's own learning and learning processes.
originally described,"Meta learning is originally described by Donald B. Maudsley (1979) as ""the process by which learners become aware of and increasingly in control of habits of perception, inquiry, learning, and growth that they have internalized""."
learners become aware,"Meta learning is originally described by Donald B. Maudsley (1979) as ""the process by which learners become aware of and increasingly in control of habits of perception, inquiry, learning, and growth that they have internalized""."
five principles,Five principles were enunciated to facilitate meta learning.
facilitate meta learning,Five principles were enunciated to facilitate meta learning.
taking control,"The idea of meta learning was later used by John Biggs (1985) to describe the state of ""being aware of and taking control of one's own learning""."
later used,"The idea of meta learning was later used by John Biggs (1985) to describe the state of ""being aware of and taking control of one's own learning"". !! The instances of objects in lazy inheritance are created in ""mixed"" mode on first invocation, a factory is used to modify class prototype which is later used for subsequent object instances creation."
john biggs,"The idea of meta learning was later used by John Biggs (1985) to describe the state of ""being aware of and taking control of one's own learning""."
subject knowledge,Meta learning can be defined as an awareness and understanding of the phenomenon of learning itself as opposed to subject knowledge.
convolutional networks may include local,Convolutional networks may include local and/or global pooling layers along with traditional convolutional layers.
global pooling layers along,Convolutional networks may include local and/or global pooling layers along with traditional convolutional layers.
pooling layers reduce,Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer.
next layer,Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer.
one layer,Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer.
actual word classification,The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.
combined using max pooling,The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.
networks performing,The results of each TDNN over the input signal were combined using max pooling and the outputs of the pooling layers were then passed on to networks performing the actual word classification.
single value,"Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value."
rectangular sub,"Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value."
fu xi,"The full title of Leibniz's article is translated into English as the ""Explanation of Binary Arithmetic, which uses only the characters 1 and 0, with some remarks on its usefulness, and on the light it throws on the ancient Chinese figures of Fu Xi""."
ancient chinese figures,"The full title of Leibniz's article is translated into English as the ""Explanation of Binary Arithmetic, which uses only the characters 1 and 0, with some remarks on its usefulness, and on the light it throws on the ancient Chinese figures of Fu Xi""."
full title,"The full title of Leibniz's article is translated into English as the ""Explanation of Binary Arithmetic, which uses only the characters 1 and 0, with some remarks on its usefulness, and on the light it throws on the ancient Chinese figures of Fu Xi""."
claude shannon produced,"In 1937, Claude Shannon produced his master's thesis at MIT that implemented Boolean algebra and binary arithmetic using electronic relays and switches for the first time in history."
implemented boolean algebra,"In 1937, Claude Shannon produced his master's thesis at MIT that implemented Boolean algebra and binary arithmetic using electronic relays and switches for the first time in history."
first time,"In computer programming, lazy initialization is the tactic of delaying the creation of an object, the calculation of a value, or some other expensive process until the first time it is needed. !! If the system has a cache language model, ""elephant"" will still probably be misrecognized the first time it is spoken and will have to be entered into the text manually; however, from this point on the system is aware that ""elephant"" is likely to occur again the estimated probability of occurrence of ""elephant"" has been increased, making it more likely that if it is spoken it will be recognized correctly. !! In 1937, Claude Shannon produced his master's thesis at MIT that implemented Boolean algebra and binary arithmetic using electronic relays and switches for the first time in history. !! The concept of Evolving Intelligent Systems (EISs) was conceived around the turn of the century with the phrase EIS itself coined for the first time by Angelov and Kasabov in a 2006 IEEE newsletter and expanded in a 2010 text."
binary arithmetic using electronic relays,"In 1937, Claude Shannon produced his master's thesis at MIT that implemented Boolean algebra and binary arithmetic using electronic relays and switches for the first time in history."
binary arithmetic terminate,Fractions in binary arithmetic terminate only if 2 is the only prime factor in the denominator.
prime factor,Fractions in binary arithmetic terminate only if 2 is the only prime factor in the denominator.
unordered lists used,"In graph theory and computer science, an adjacency list is a collection of unordered lists used to represent a finite graph."
particular vertex,Each unordered list within an adjacency list describes the set of neighbors of a particular vertex in the graph.
unordered list within,Each unordered list within an adjacency list describes the set of neighbors of a particular vertex in the graph.
adjacency list describes,Each unordered list within an adjacency list describes the set of neighbors of a particular vertex in the graph.
explicit edge objects allows,"This version of the adjacency list uses more memory than the version in which adjacent vertices are listed directly, but the existence of explicit edge objects allows it extra flexibility in storing additional information about edges."
listed directly,"This version of the adjacency list uses more memory than the version in which adjacent vertices are listed directly, but the existence of explicit edge objects allows it extra flexibility in storing additional information about edges."
adjacency list uses,"This version of the adjacency list uses more memory than the version in which adjacent vertices are listed directly, but the existence of explicit edge objects allows it extra flexibility in storing additional information about edges."
extra flexibility,"This version of the adjacency list uses more memory than the version in which adjacent vertices are listed directly, but the existence of explicit edge objects allows it extra flexibility in storing additional information about edges."
storing additional information,"This version of the adjacency list uses more memory than the version in which adjacent vertices are listed directly, but the existence of explicit edge objects allows it extra flexibility in storing additional information about edges."
main operation performed,The main operation performed by the adjacency list data structure is to report a list of the neighbors of a given vertex.
given vertex,The main operation performed by the adjacency list data structure is to report a list of the neighbors of a given vertex.
certain measure,Robust optimization is a field of optimization theory that deals with optimization problems in which a certain measure of robustness is sought against uncertainty that can be represented as deterministic variability in the value of the parameters of the problem itself and/or its solution.
robust optimization,"This intuitive notion of global robustness is not used often in practice because the robust optimization problems that it induces are usually (not always) very difficult to solve. !! In such cases, online optimization can be used, which is different from other approaches such as robust optimization, stochastic optimization and Markov decision processes. !! Robust optimization is a field of optimization theory that deals with optimization problems in which a certain measure of robustness is sought against uncertainty that can be represented as deterministic variability in the value of the parameters of the problem itself and/or its solution. !! There are a number of classification criteria for robust optimization problems/models. !! Modern robust optimization deals primarily with non-probabilistic models of robustness that are worst case oriented and as such usually deploy Wald's maximin models. !! The origins of robust optimization date back to the establishment of modern decision theory in the 1950s and the use of worst case analysis and Wald's maximin model as a tool for the treatment of severe uncertainty."
severe uncertainty,The origins of robust optimization date back to the establishment of modern decision theory in the 1950s and the use of worst case analysis and Wald's maximin model as a tool for the treatment of severe uncertainty.
worst case analysis,The origins of robust optimization date back to the establishment of modern decision theory in the 1950s and the use of worst case analysis and Wald's maximin model as a tool for the treatment of severe uncertainty.
robust optimization date back,The origins of robust optimization date back to the establishment of modern decision theory in the 1950s and the use of worst case analysis and Wald's maximin model as a tool for the treatment of severe uncertainty.
usually deploy wald,Modern robust optimization deals primarily with non-probabilistic models of robustness that are worst case oriented and as such usually deploy Wald's maximin models.
modern robust optimization deals primarily,Modern robust optimization deals primarily with non-probabilistic models of robustness that are worst case oriented and as such usually deploy Wald's maximin models.
worst case oriented,Modern robust optimization deals primarily with non-probabilistic models of robustness that are worst case oriented and as such usually deploy Wald's maximin models.
global robustness,This intuitive notion of global robustness is not used often in practice because the robust optimization problems that it induces are usually (not always) very difficult to solve.
used often,This intuitive notion of global robustness is not used often in practice because the robust optimization problems that it induces are usually (not always) very difficult to solve.
intuitive notion,"This intuitive notion of global robustness is not used often in practice because the robust optimization problems that it induces are usually (not always) very difficult to solve. !! Computable functions are the formalized analogue of the intuitive notion of algorithms, in the sense that a function is computable if there exists an algorithm that can do the job of the function, i. e. given an input of the function domain it can return the corresponding output."
design modifications must,"In order to account for the unanticipated gaps in the software design, during software construction some design modifications must be made on a smaller or larger scale to flesh out details of the software design."
unanticipated gaps,"In order to account for the unanticipated gaps in the software design, during software construction some design modifications must be made on a smaller or larger scale to flesh out details of the software design."
larger scale,"In order to account for the unanticipated gaps in the software design, during software construction some design modifications must be made on a smaller or larger scale to flesh out details of the software design."
linguistic notations,"Linguistic notations which are distinguished in particular by the use of word-like strings of text to represent complex software constructions, and the combination of such word-like strings into patterns that have a sentence-like syntax."
represent complex software constructions,"Linguistic notations which are distinguished in particular by the use of word-like strings of text to represent complex software constructions, and the combination of such word-like strings into patterns that have a sentence-like syntax."
like syntax,"Linguistic notations which are distinguished in particular by the use of word-like strings of text to represent complex software constructions, and the combination of such word-like strings into patterns that have a sentence-like syntax."
like strings,"Linguistic notations which are distinguished in particular by the use of word-like strings of text to represent complex software constructions, and the combination of such word-like strings into patterns that have a sentence-like syntax."
world entities,A data model (or datamodel) is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities.
organizes elements,A data model (or datamodel) is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities.
one another,"Since two houses may be very different from one another, a design pattern for houses must be broad enough to apply to both of them, but not so vague that it doesn't help the designer make decisions. !! Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another"". !! Embodied conversational agents are embodied agents (usually with a graphical front-end as opposed to a robotic body) that are capable of engaging in conversation with one another and with humans employing the same verbal and nonverbal means that humans do (such as gesture, facial expression, and so forth). !! A data model (or datamodel) is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities. !! Data portability is a concept to protect users from having their data stored in ""silos"" or ""walled gardens"" that are incompatible with one another, i. e. closed platforms, thus subjecting them to vendor lock-in and making the creation of data backups difficult."
data element representing,"For instance, a data model may specify that the data element representing a car be composed of a number of other elements which, in turn, represent the color and size of the car and define its owner."
data model may specify,"For instance, a data model may specify that the data element representing a car be composed of a number of other elements which, in turn, represent the color and size of the car and define its owner."
closely related concepts,"Computer user satisfaction (and closely related concepts such as system satisfaction, user satisfaction, computer system satisfaction, end user computing satisfaction) is the attitude of a user to the computer system (s)he employs in the context of his/her work environments. !! The term data model can refer to two distinct but closely related concepts."
term data model,The term data model can refer to two distinct but closely related concepts.
two distinct,The term data model can refer to two distinct but closely related concepts.
banking application may,"So the ""data model"" of a banking application may be defined using the entity-relationship ""data model""."
defined using,"So the ""data model"" of a banking application may be defined using the entity-relationship ""data model"". !! Random-fuzzy variable (RFV) is a type 2 fuzzy variable, defined using the mathematical possibility theory, used to represent the entire information associated to a measurement result."
data model explicitly determines,A data model explicitly determines the structure of data.
adjusted significance testing,"Chi-square automatic interaction detection (CHAID) is a decision tree technique, based on adjusted significance testing (Bonferroni testing)."
square automatic interaction detection,"Chi-square automatic interaction detection (CHAID) is a decision tree technique, based on adjusted significance testing (Bonferroni testing)."
interactive experience,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory."
generated perceptual information,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory."
real world,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory. !! A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa. !! Some articles on the topic speculate on how artificial imagination may evolve to create an artificial world ""people may be comfortable enough to escape from the real world"". !! The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment."
sometimes across multiple sensory modalities,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory."
including visual,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory."
world environment,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory. !! In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one."
augmented reality alters one,"In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one."
whereas virtual reality completely replaces,"In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one."
ongoing perception,"In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one."
simulated one,"These negative effects on testability of the active record pattern can be reduced by using mocking or dependency injection frameworks to substitute the real data tier with a simulated one. !! In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one."
two largely synonymous terms,Augmented reality is related to two largely synonymous terms: mixed reality and computer-mediated reality.
mediated reality,Augmented reality is related to two largely synonymous terms: mixed reality and computer-mediated reality.
mixed reality,Augmented reality is related to two largely synonymous terms: mixed reality and computer-mediated reality.
digital world blend,"The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment."
natural parts,"The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment."
simple display,"The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment."
primary value,"The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment."
immersive sensations,"The primary value of augmented reality is the manner in which components of the digital world blend into a person's perception of the real world, not as a simple display of data, but through the integration of immersive sensations, which are perceived as natural parts of an environment."
gaming businesses,Commercial augmented reality experiences were first introduced in entertainment and gaming businesses.
first introduced,"The study of communication complexity was first introduced by Andrew Yao in 1979, while studying the problem of computation distributed among several machines. !! Mean dimension was first introduced in 1999 by Gromov. !! The theory was first introduced by Hoerl and Kennard in 1970 in their Technometrics papers RIDGE regressions: biased estimation of nonorthogonal problems and RIDGE regressions: applications in nonorthogonal problems. !! Commercial augmented reality experiences were first introduced in entertainment and gaming businesses. !! The term classification and regression tree (CART) analysis is an umbrella term used to refer to either of the above procedures, first introduced by Breiman et al. !! Dynamic Data Exchange was first introduced in 1987 with the release of Windows 2. !! Topological entropy was first introduced in 1965 by Adler, Konheim and McAndrew. !! Organic user interfaces were first introduced in a special issue of the Communications of the ACM in 2008. !! Remote Touch was first introduced on the 2010 Lexus RX 350 and Lexus RX 450h models, followed by the 2010 Lexus HS 250h. !! First introduced in Microsoft Office 97, the Office Assistant was codenamed TFC during development."
commercial augmented reality experiences,Commercial augmented reality experiences were first introduced in entertainment and gaming businesses.
problematic first,Loop peeling is a special case of loop splitting which splits any problematic first (or last) few iterations from the loop and performs them outside of the loop body.
circular review system,A Circular review system is a system on board some armoured combat vehicles or tanks which provides the crew greater situational awareness (such as a 360 view) outside of the vehicle. !! Circular review system for vehicles
armoured combat vehicles,A Circular review system is a system on board some armoured combat vehicles or tanks which provides the crew greater situational awareness (such as a 360 view) outside of the vehicle.
crew greater situational awareness,A Circular review system is a system on board some armoured combat vehicles or tanks which provides the crew greater situational awareness (such as a 360 view) outside of the vehicle.
oriented code,"Spaghetti code can also describe an anti-pattern in which object-oriented code is written in a procedural style, such as by creating classes whose methods are overly long and messy, or forsaking object-oriented concepts like polymorphism. !! Portable Distributed Objects (PDO) is an application programming interface (API) for creating object-oriented code that can be executed remotely on a network of computers."
creating object,Portable Distributed Objects (PDO) is an application programming interface (API) for creating object-oriented code that can be executed remotely on a network of computers.
subobject classifier,"Note however that subobject classifiers are often much more complicated than the simple binary logic truth values {true, false}. !! As an example, the set = {0,1} is a subobject classifier in the category of sets and functions: to every subset A of S defined by the inclusion function j : A S we can assign the function A from S to that maps precisely the elements of A to 1 (see characteristic function). !! By definition, is a subobject classifier if this morphism is an isomorphism. !! In category theory, a subobject classifier is a special object of a category such that, intuitively, the subobjects of any object X in the category correspond to the morphisms from X to . !! Therefore, a subobject classifier is also known as a ""truth value object"" and the concept is widely used in the categorical description of logic."
special object,"In category theory, a subobject classifier is a special object of a category such that, intuitively, the subobjects of any object X in the category correspond to the morphisms from X to ."
category correspond,"In category theory, a subobject classifier is a special object of a category such that, intuitively, the subobjects of any object X in the category correspond to the morphisms from X to ."
often much,"Note however that subobject classifiers are often much more complicated than the simple binary logic truth values {true, false}. !! Single recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space."
note however,"Note however that subobject classifiers are often much more complicated than the simple binary logic truth values {true, false}."
subobject classifiers,"Note however that subobject classifiers are often much more complicated than the simple binary logic truth values {true, false}."
every subset,"As an example, the set = {0,1} is a subobject classifier in the category of sets and functions: to every subset A of S defined by the inclusion function j : A S we can assign the function A from S to that maps precisely the elements of A to 1 (see characteristic function)."
see characteristic function,"As an example, the set = {0,1} is a subobject classifier in the category of sets and functions: to every subset A of S defined by the inclusion function j : A S we can assign the function A from S to that maps precisely the elements of A to 1 (see characteristic function)."
maps precisely,"As an example, the set = {0,1} is a subobject classifier in the category of sets and functions: to every subset A of S defined by the inclusion function j : A S we can assign the function A from S to that maps precisely the elements of A to 1 (see characteristic function)."
inclusion function j,"As an example, the set = {0,1} is a subobject classifier in the category of sets and functions: to every subset A of S defined by the inclusion function j : A S we can assign the function A from S to that maps precisely the elements of A to 1 (see characteristic function)."
may lack continuous network connectivity,Delay-tolerant networking (DTN) is an approach to computer network architecture that seeks to address the technical issues in heterogeneous networks that may lack continuous network connectivity.
term delay,"In 2002, Kevin Fall started to adapt some of the ideas in the IPN design to terrestrial networks and coined the term delay-tolerant networking and the DTN acronym."
kevin fall started,"In 2002, Kevin Fall started to adapt some of the ideas in the IPN design to terrestrial networks and coined the term delay-tolerant networking and the DTN acronym."
well understood,"This field saw many optimizations on classic ad hoc and delay-tolerant networking algorithms and began to examine factors such as security, reliability, verifiability, and other areas of research that are well understood in traditional computer networking."
examine factors,"This field saw many optimizations on classic ad hoc and delay-tolerant networking algorithms and began to examine factors such as security, reliability, verifiability, and other areas of research that are well understood in traditional computer networking."
field saw many optimizations,"This field saw many optimizations on classic ad hoc and delay-tolerant networking algorithms and began to examine factors such as security, reliability, verifiability, and other areas of research that are well understood in traditional computer networking."
tolerant networking algorithms,"This field saw many optimizations on classic ad hoc and delay-tolerant networking algorithms and began to examine factors such as security, reliability, verifiability, and other areas of research that are well understood in traditional computer networking."
tolerant networking research group,The Delay-Tolerant Networking Research Group.
another form,Static Hashing is another form of the hashing problem which allows users to perform lookups on a finalized dictionary set (all objects in the dictionary are final and not changing).
finalized dictionary set,Static Hashing is another form of the hashing problem which allows users to perform lookups on a finalized dictionary set (all objects in the dictionary are final and not changing).
allows users,Static Hashing is another form of the hashing problem which allows users to perform lookups on a finalized dictionary set (all objects in the dictionary are final and not changing). !! Google's Search by Image is a feature that uses reverse image search and allows users to search for related images just by uploading an image or image URL. !! Google Images (previously Google Image Search) is a search engine owned by Google that allows users to search the World Wide Web for images.
perform lookups,Static Hashing is another form of the hashing problem which allows users to perform lookups on a finalized dictionary set (all objects in the dictionary are final and not changing).
since static hashing requires,"Since static hashing requires that the database, its objects and reference remain the same its applications are limited."
reference remain,"Since static hashing requires that the database, its objects and reference remain the same its applications are limited."
biodiversity information,"Biodiversity informatics is the application of informatics techniques to biodiversity information, such as taxonomy, biogeography or ecology."
numerous studies,"Biodiversity informatics is a term that was only coined around 1992 but with rapidly increasing data sets has become useful in numerous studies and applications, such as the construction of taxonomic databases or geographic information systems."
coined around 1992,"Biodiversity informatics is a term that was only coined around 1992 but with rapidly increasing data sets has become useful in numerous studies and applications, such as the construction of taxonomic databases or geographic information systems."
become useful,"Biodiversity informatics is a term that was only coined around 1992 but with rapidly increasing data sets has become useful in numerous studies and applications, such as the construction of taxonomic databases or geographic information systems."
rapidly increasing data sets,"Biodiversity informatics is a term that was only coined around 1992 but with rapidly increasing data sets has become useful in numerous studies and applications, such as the construction of taxonomic databases or geographic information systems."
specialized area,"Biodiversity informatics contrasts with ""bioinformatics"", which is often used synonymously with the computerized handling of data in the specialized area of molecular biology."
biodiversity informatics contrasts,"Biodiversity informatics contrasts with ""bioinformatics"", which is often used synonymously with the computerized handling of data in the specialized area of molecular biology."
computerized handling,"Biodiversity informatics contrasts with ""bioinformatics"", which is often used synonymously with the computerized handling of data in the specialized area of molecular biology."
often used synonymously,"Biodiversity informatics contrasts with ""bioinformatics"", which is often used synonymously with the computerized handling of data in the specialized area of molecular biology. !! One well-known variant, which is often used synonymously with the term Steiner tree problem, is the Steiner tree problem in graphs."
molecular biology,"Biodiversity informatics contrasts with ""bioinformatics"", which is often used synonymously with the computerized handling of data in the specialized area of molecular biology."
information technology methods,"Biodiversity informatics (different but linked to bioinformatics) is the application of information technology methods to the problems of organizing, accessing, visualizing and analyzing primary biodiversity data."
analyzing primary biodiversity data,"Biodiversity informatics (different but linked to bioinformatics) is the application of information technology methods to the problems of organizing, accessing, visualizing and analyzing primary biodiversity data."
field samples,Biodiversity informatics may also have to cope with managing information from unnamed taxa such as that produced by environmental sampling and sequencing of mixed-field samples.
managing information,Biodiversity informatics may also have to cope with managing information from unnamed taxa such as that produced by environmental sampling and sequencing of mixed-field samples.
unnamed taxa,Biodiversity informatics may also have to cope with managing information from unnamed taxa such as that produced by environmental sampling and sequencing of mixed-field samples.
environmental sampling,Biodiversity informatics may also have to cope with managing information from unnamed taxa such as that produced by environmental sampling and sequencing of mixed-field samples.
biodiversity informatics may also,Biodiversity informatics may also have to cope with managing information from unnamed taxa such as that produced by environmental sampling and sequencing of mixed-field samples.
six degrees,"Measurement of the six degrees of freedom is accomplished today through both AC and DC magnetic or electromagnetic fields in sensors that transmit positional and angular data to a processing unit. !! Humanoid robots typically have 30 or more degrees of freedom, with six degrees of freedom per arm, five or six in each leg, and several more in torso and neck. !! Serial and parallel manipulator systems are generally designed to position an end-effector with six degrees of freedom, consisting of three in translation and three in orientation. !! Six degrees of freedom (6DOF) refers to the freedom of movement of a rigid body in three-dimensional space. !! The term is important in mechanical systems, especially biomechanical systems, for analyzing and measuring properties of these types of systems that need to account for all six degrees of freedom."
rigid body,Six degrees of freedom (6DOF) refers to the freedom of movement of a rigid body in three-dimensional space.
six degrees of freedom,"Measurement of the six degrees of freedom is accomplished today through both AC and DC magnetic or electromagnetic fields in sensors that transmit positional and angular data to a processing unit. !! Humanoid robots typically have 30 or more degrees of freedom, with six degrees of freedom per arm, five or six in each leg, and several more in torso and neck. !! Serial and parallel manipulator systems are generally designed to position an end-effector with six degrees of freedom, consisting of three in translation and three in orientation. !! Six degrees of freedom (6DOF) refers to the freedom of movement of a rigid body in three-dimensional space. !! The term is important in mechanical systems, especially biomechanical systems, for analyzing and measuring properties of these types of systems that need to account for all six degrees of freedom."
generally designed,"Serial and parallel manipulator systems are generally designed to position an end-effector with six degrees of freedom, consisting of three in translation and three in orientation."
humanoid robots typically,"Humanoid robots typically have 30 or more degrees of freedom, with six degrees of freedom per arm, five or six in each leg, and several more in torso and neck."
freedom per arm,"Humanoid robots typically have 30 or more degrees of freedom, with six degrees of freedom per arm, five or six in each leg, and several more in torso and neck."
measuring properties,"The term is important in mechanical systems, especially biomechanical systems, for analyzing and measuring properties of these types of systems that need to account for all six degrees of freedom."
especially biomechanical systems,"The term is important in mechanical systems, especially biomechanical systems, for analyzing and measuring properties of these types of systems that need to account for all six degrees of freedom."
mechanical systems,"The term is important in mechanical systems, especially biomechanical systems, for analyzing and measuring properties of these types of systems that need to account for all six degrees of freedom."
electromagnetic fields,"Eigenmode expansion is a rigorous technique to simulate electromagnetic propagation which relies on the decomposition of the electromagnetic fields into a basis set of local eigenmodes that exists in the cross section of the device. !! Measurement of the six degrees of freedom is accomplished today through both AC and DC magnetic or electromagnetic fields in sensors that transmit positional and angular data to a processing unit. !! Computational electromagnetics (CEM), computational electrodynamics or electromagnetic modeling is the process of modeling the interaction of electromagnetic fields with physical objects and the environment."
transmit positional,Measurement of the six degrees of freedom is accomplished today through both AC and DC magnetic or electromagnetic fields in sensors that transmit positional and angular data to a processing unit.
dc magnetic,Measurement of the six degrees of freedom is accomplished today through both AC and DC magnetic or electromagnetic fields in sensors that transmit positional and angular data to a processing unit.
accomplished today,Measurement of the six degrees of freedom is accomplished today through both AC and DC magnetic or electromagnetic fields in sensors that transmit positional and angular data to a processing unit.
practical artificial neural networks,This provided more processing power for the development of practical artificial neural networks in the 1980s.
two classes,"In a statistical-classification problem with two classes, a decision boundary or decision surface is a hypersurface that partitions the underlying vector space into two sets, one for each class. !! Computer algebra systems may be divided into two classes: specialized and general-purpose. !! Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to. !! In the logistic model, the log-odds (the logarithm of the odds) for the value labeled ""1"" is a linear combination of one or more independent variables (""predictors""); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value)."
one hidden layer,"If it has one hidden layer, then it can learn any continuous function on compact subsets of Rn as shown by the Universal approximation theorem, thus it can have an arbitrary decision boundary."
computational learning theory studies,"In addition to performance bounds, computational learning theory studies the time complexity and feasibility of learning."
proper subset,"In formal grammar theory, the deterministic context-free grammars (DCFGs) are a proper subset of the context-free grammars. !! In formal language theory, deterministic context-free languages (DCFL) are a proper subset of context-free languages."
based sampling,"Pool-Based Sampling: In this scenario, instances are drawn from the entire data pool and assigned a confidence score, a measurement of how well the learner understands the data."
entire data pool,"Pool-Based Sampling: In this scenario, instances are drawn from the entire data pool and assigned a confidence score, a measurement of how well the learner understands the data."
order logic,"Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. !! In the study of graph algorithms, Courcelle's theorem is the statement that every graph property definable in the monadic second-order logic of graphs can be decided in linear time on graphs of bounded treewidth. !! In mathematical logic, a formula of first-order logic is in Skolem normal form if it is in prenex normal form with only universal first-order quantifiers. !! Sometimes, ""theory"" is understood in a more formal sense, which is just a set of sentences in first-order logic. !! It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes zeroth-order logic. !! The superposition calculus is a calculus for reasoning in equational first-order logic. !! This distinguishes it from propositional logic, which does not use quantifiers or relations; in this sense, propositional logic is the foundation of first-order logic. !! The description logic community uses different terminology than the first-order logic (FOL) community for operationally equivalent notions; some examples are given below. !! While the expressive power of combinatory logic typically exceeds that of first-order logic, the expressive power of predicate functor logic is identical to that of first order logic (Quine 1960, 1966, 1976). !! A first-order reduction is a reduction where each component is restricted to be in the class FO of problems calculable in first-order logic. !! With the tools of first-order logic it is possible to formulate a number of theories, either with explicit axioms or by rules of inference, that can themselves be treated as logical calculi. !! In this sense, propositional logic is the foundation of first-order logic and higher-order logic. !! However, all the machinery of propositional logic is included in first-order logic and higher-order logics."
logical objects,"Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. !! First-order logic uses quantified variables over non-logical objects, and allows the use of sentences that contain variables, so that rather than propositions such as ""Socrates is a man"", one can have expressions in the form ""there exists x such that x is Socrates and x is a man"", where ""there exists"" is a quantifier, while x is a variable."
order logics,"However, all the machinery of propositional logic is included in first-order logic and higher-order logics."
propositional logic may,Propositional logic may be studied through a formal system in which formulas of a formal language may be interpreted to represent propositions.
bitwise operation operates,"In computer programming, a bitwise operation operates on a bit string, a bit array or a binary numeral (considered as a bit string) at the level of its individual bits."
operand instructions,Most bitwise operations are presented as two-operand instructions where the result replaces one of the input operands.
case gradient descent,"is convex, all local minima are also global minima, so in this case gradient descent can converge to the global solution."
combines reinforcement learning,Deep reinforcement learning (deep RL) is a subfield of machine learning that combines reinforcement learning (RL) and deep learning.
computer program trained,"Deep reinforcement learning reached another milestone in 2015 when AlphaGo, a computer program trained with deep RL to play Go, became the first computer Go program to beat a human professional Go player without handicap on a full-sized 1919 board."
compiler fails,"Compilation error refers to a state when a compiler fails to compile a piece of computer program source code, either due to errors in the code, or, more unusually, due to errors in the compiler itself."
time errors,"However, dynamic compilation can still technically have compilation errors, although many programmers and sources may identify them as run-time errors."
time compilers,"Most just-in-time compilers, such as the Javascript V8 engine, ambiguously refer to compilation errors as syntax errors since they check for them at run time."
independent processors,"Distributed algorithms are a sub-type of parallel algorithm, typically executed concurrently, with separate parts of the algorithm being run simultaneously on independent processors, and having limited information about what the other parts of the algorithm are doing."
random projection,"Random indexing, as used in representation of language, originates from the work of Pentti Kanerva on sparse distributed memory, and can be described as an incremental formulation of a random projection."
random projection technique,It can be also verified that random indexing is a random projection technique for the construction of Euclidean spacesi.
structured model,"The semi-structured model is a database model where there is no separation between the data and the schema, and the amount of structure used depends on the purpose."
nearest neighbor,"Often, the classification accuracy of k-NN can be improved significantly if the distance metric is learned with specialized algorithms such as Large Margin Nearest Neighbor or Neighbourhood components analysis. !! In statistics, the k-nearest neighbors algorithm (k-NN) is a non-parametric supervised learning method first developed by Evelyn Fix and Joseph Hodges in 1951, and later expanded by Thomas Cover. !! This value is the average of the values of k nearest neighbors. !! If k = 1, then the object is simply assigned to the class of that single nearest neighbor. !! An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small)."
finite sequences,"In machine learning and data mining, a string kernel is a kernel function that operates on strings, i. e. finite sequences of symbols that need not be of the same length."
adjacent layers,Convolutional networks exploit spatially local correlation by enforcing a sparse local connectivity pattern between neurons of adjacent layers: each neuron is connected to only a small region of the input volume.
diagram specially used,A requirement diagram is a diagram specially used in SysML in which requirements and the relations between them and their relationship to other model elements are shown as discussed in the following paragraphs.
minimum cut,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink."
cut theorem,Max-flow min-cut theorem.
objective programming,"Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously."
minimizing cost,"Minimizing cost while maximizing comfort while buying a car, and maximizing performance whilst minimizing fuel consumption and emission of pollutants of a vehicle are examples of multi-objective optimization problems involving two and three objectives, respectively."
optimal one,"In computer science and operations research, approximation algorithms are efficient algorithms that find approximate solutions to optimization problems (in particular NP-hard problems) with provable guarantees on the distance of the returned solution to the optimal one."
typed programming languages,"Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
negative matrix factorization,"Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space. !! Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements. !! In chemometrics non-negative matrix factorization has a long history under the name ""self modeling curve resolution""."
negative matrix approximation,"Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements."
negative matrix factorizations,There are different types of non-negative matrix factorizations. !! Also early work on non-negative matrix factorizations was performed by a Finnish group of researchers in the 1990s under the name positive matrix factorization.
every execution,"The randomization technique would not work if, at every execution of the algorithm, the randomization function always performed the same mapping, or a mapping entirely determined by some externally observable parameter (such as the program's startup time)."
optimal action,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
sparse structure,"When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix."
matrix structures,Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros.
large sparse matrices,Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms. !! Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros.
matrix algorithms,Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.
scale optimization,"Increasingly, operations research uses stochastic programming to model dynamic decisions that adapt to events; such problems can be solved with large-scale optimization and stochastic optimization methods."
communication protocol,"The ITU-T handles telecommunication protocols and formats for the public switched telephone network (PSTN). !! The NCP interface allowed application software to connect across the ARPANET by implementing higher-level communication protocols, an early example of the protocol layering concept. !! A communication protocol is a system of rules that allows two or more entities of a communications system to transmit information via any kind of variation of a physical quantity. !! Server Message Block (SMB) is a communication protocol that Microsoft created for providing shared access to files and printers across nodes on a network. !! Internet communication protocols are published by the Internet Engineering Task Force (IETF). !! Communication protocols have to be agreed upon by the parties involved. !! The Multimodal Architecture and Interfaces recommendation introduces a generic structure and a communication protocol to allow the modules in a multimodal system to communicate with each other."
digital conversion,"A beta encoder is an analog-to-digital conversion (A/D) system in which a real number in the unit interval is represented by a finite representation of a sequence in base beta, with beta being a real number between 1 and 2. !! Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals."
quantized signals,Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals.
narrowband analog,Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals.
original matrix,"In numerical analysis, interpolative decomposition (ID) factors a matrix as the product of two matrices, one of which contains selected columns from the original matrix, and the other of which has a subset of columns consisting of the identity matrix and all its values are no greater than 2 in absolute value."
absolute value,"More formally, in integration theory it is a weak derivative, and in convex function theory the subdifferential of the absolute value at 0 is the interval [1, 1], ""filling in"" the sign function (the subdifferential of the absolute value is not single-valued at 0). !! In numerical analysis, interpolative decomposition (ID) factors a matrix as the product of two matrices, one of which contains selected columns from the original matrix, and the other of which has a subset of columns consisting of the identity matrix and all its values are no greater than 2 in absolute value."
simple dynamic array,"A simple dynamic array can be constructed by allocating an array of fixed-size, typically larger than the number of elements immediately required."
single node,"The root node has depth zero, leaf nodes have height zero, and a tree with only a single node (hence both a root and leaf) has depth and height zero."
computational instantiation,A cognitive architecture refers to both a theory about the structure of the human mind and to a computational instantiation of such a theory used in the fields of artificial intelligence (AI) and computational cognitive science.
core processor,A single-core processor is a microprocessor with a single core on its die.
de morgan,"De Morgan's laws are an example of a more general concept of mathematical duality. !! De Morgan's laws commonly apply to text searching using Boolean operators AND, OR, and NOT. !! In set notation, De Morgan's laws can be remembered using the mnemonic ""break the line, change the sign"". !! De Morgan's laws are normally shown in the compact form above, with the negation of the output on the left and negation of the inputs on the right. !! In propositional logic and Boolean algebra, De Morgan's laws are a pair of transformation rules that are both valid rules of inference."
previously unseen data,One advantage that instance-based learning has over other methods of machine learning is its ability to adapt its model to previously unseen data.
artificial intelligence laboratory,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
automatic programming,"The Internet routing registry works by providing an interlinked hierarchy of objects designed to facilitate the organization of IP routing between organizations, and also to provide data in an appropriate format for automatic programming of routers."
inductive principle,Structural risk minimization (SRM) is an inductive principle of use in machine learning.
single neuron,Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer.
executed remotely,Portable Distributed Objects (PDO) is an application programming interface (API) for creating object-oriented code that can be executed remotely on a network of computers.
simple binary logic truth values,"Note however that subobject classifiers are often much more complicated than the simple binary logic truth values {true, false}."
technical issues,Delay-tolerant networking (DTN) is an approach to computer network architecture that seeks to address the technical issues in heterogeneous networks that may lack continuous network connectivity.
tolerant networking,"In 2002, Kevin Fall started to adapt some of the ideas in the IPN design to terrestrial networks and coined the term delay-tolerant networking and the DTN acronym. !! Delay-tolerant networking (DTN) is an approach to computer network architecture that seeks to address the technical issues in heterogeneous networks that may lack continuous network connectivity."
broadly applicable technique,"In computer science, parallel tree contraction is a broadly applicable technique for the parallel solution of a large number of tree problems, and is used as an algorithm design technique for the design of a large number of parallel graph algorithms."
algorithm design technique,"In computer science, parallel tree contraction is a broadly applicable technique for the parallel solution of a large number of tree problems, and is used as an algorithm design technique for the design of a large number of parallel graph algorithms."
improve efficiency,"Parallel tree contraction was introduced by Gary L. Miller and John H. Reif, and has subsequently been modified to improve efficiency by X."
designing many efficient parallel algorithms,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
finding lowest common ancestors,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
including expression evaluation,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
various algorithms,"Understanding these ""cluster models"" is key to understanding the differences between the various algorithms. !! Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
common subexpression elimination,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
explicit planar embedding,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
connected components,"In computing and graph theory, a dynamic connectivity structure is a data structure that dynamically maintains information about the connected components of a graph. !! Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic. !! More generally, any edge-weighted undirected graph (not necessarily connected) has a minimum spanning forest, which is a union of the minimum spanning trees for its connected components."
planar graphbased,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
proposed targeting,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
traditional assumptions,"Moravec's paradox is the observation by artificial intelligence and robotics researchers that, contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception skills require enormous computational resources."
reasoning requires,"Moravec's paradox is the observation by artificial intelligence and robotics researchers that, contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception skills require enormous computational resources."
robotics researchers,"Moravec's paradox is the observation by artificial intelligence and robotics researchers that, contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception skills require enormous computational resources."
little computation,"Moravec's paradox is the observation by artificial intelligence and robotics researchers that, contrary to traditional assumptions, reasoning requires very little computation, but sensorimotor and perception skills require enormous computational resources."
xkcd comic,Explanation of the XKCD comic about Moravec's paradox
using artificial neural networks requires,Using Artificial neural networks requires an understanding of their characteristics.
found applications,"Because of their ability to reproduce and model nonlinear processes, artificial neural networks have found applications in many disciplines."
model nonlinear processes,"Because of their ability to reproduce and model nonlinear processes, artificial neural networks have found applications in many disciplines."
many disciplines,"Because of their ability to reproduce and model nonlinear processes, artificial neural networks have found applications in many disciplines."
allows simple statistical association,This allows simple statistical association (the basic function of artificial neural networks) to be described as learning or recognition.
computational electrodynamics modelling technique,Eigenmode expansion (EME) is a computational electrodynamics modelling technique.
linear frequency,Eigenmode expansion is a linear frequency-domain method.
domain method,Eigenmode expansion is a linear frequency-domain method. !! A Fourier pseudospectral time-domain method can be applied to wave propagation problems pertinent to computational aeroacoustics.
local eigenmodes,Eigenmode expansion is a rigorous technique to simulate electromagnetic propagation which relies on the decomposition of the electromagnetic fields into a basis set of local eigenmodes that exists in the cross section of the device.
basis set,Eigenmode expansion is a rigorous technique to simulate electromagnetic propagation which relies on the decomposition of the electromagnetic fields into a basis set of local eigenmodes that exists in the cross section of the device.
cross section,Eigenmode expansion is a rigorous technique to simulate electromagnetic propagation which relies on the decomposition of the electromagnetic fields into a basis set of local eigenmodes that exists in the cross section of the device.
simulate electromagnetic propagation,Eigenmode expansion is a rigorous technique to simulate electromagnetic propagation which relies on the decomposition of the electromagnetic fields into a basis set of local eigenmodes that exists in the cross section of the device.
rigorous technique,Eigenmode expansion is a rigorous technique to simulate electromagnetic propagation which relies on the decomposition of the electromagnetic fields into a basis set of local eigenmodes that exists in the cross section of the device.
rigorous solution,"Unlike the beam propagation method, which is only valid under the slowly varying envelope approximation, eigenmode expansion provides a rigorous solution to Maxwell's equations."
eigenmode expansion provides,"Unlike the beam propagation method, which is only valid under the slowly varying envelope approximation, eigenmode expansion provides a rigorous solution to Maxwell's equations."
beam propagation method,"Unlike the beam propagation method, which is only valid under the slowly varying envelope approximation, eigenmode expansion provides a rigorous solution to Maxwell's equations."
slowly varying envelope approximation,"Unlike the beam propagation method, which is only valid under the slowly varying envelope approximation, eigenmode expansion provides a rigorous solution to Maxwell's equations."
key algorithm,The Data Encryption Standard (DES ) is a symmetric-key algorithm for the encryption of digital data.
1973 nbs solicited private industry,In 1973 NBS solicited private industry for a data encryption standard (DES).
security implications,RFC4772 : Security Implications of Using the Data Encryption Standard (DES)
successively fitting parabolas,"Successive parabolic interpolation is a technique for finding the extremum (minimum or maximum) of a continuous unimodal function by successively fitting parabolas (polynomials of degree two) to a function of one variable at three unique points or, in general, a function of n variables at 1+n(n+3)/2 points, and at each iteration replacing the ""oldest"" point with the extremum of the fitted parabola."
three unique points,"Successive parabolic interpolation is a technique for finding the extremum (minimum or maximum) of a continuous unimodal function by successively fitting parabolas (polynomials of degree two) to a function of one variable at three unique points or, in general, a function of n variables at 1+n(n+3)/2 points, and at each iteration replacing the ""oldest"" point with the extremum of the fitted parabola."
degree two,"Successive parabolic interpolation is a technique for finding the extremum (minimum or maximum) of a continuous unimodal function by successively fitting parabolas (polynomials of degree two) to a function of one variable at three unique points or, in general, a function of n variables at 1+n(n+3)/2 points, and at each iteration replacing the ""oldest"" point with the extremum of the fitted parabola."
one variable,"Successive parabolic interpolation is a technique for finding the extremum (minimum or maximum) of a continuous unimodal function by successively fitting parabolas (polynomials of degree two) to a function of one variable at three unique points or, in general, a function of n variables at 1+n(n+3)/2 points, and at each iteration replacing the ""oldest"" point with the extremum of the fitted parabola. !! A near-zero total correlation indicates that the variables in the group are essentially statistically independent; they are completely unrelated, in the sense that knowing the value of one variable does not provide any clue as to the values of the other variables."
fitted parabola,"Successive parabolic interpolation is a technique for finding the extremum (minimum or maximum) of a continuous unimodal function by successively fitting parabolas (polynomials of degree two) to a function of one variable at three unique points or, in general, a function of n variables at 1+n(n+3)/2 points, and at each iteration replacing the ""oldest"" point with the extremum of the fitted parabola."
iteration replacing,"Successive parabolic interpolation is a technique for finding the extremum (minimum or maximum) of a continuous unimodal function by successively fitting parabolas (polynomials of degree two) to a function of one variable at three unique points or, in general, a function of n variables at 1+n(n+3)/2 points, and at each iteration replacing the ""oldest"" point with the extremum of the fitted parabola."
popular alternative,"Moreover, not requiring the computation or approximation of function derivatives makes successive parabolic interpolation a popular alternative to other methods that do require them (such as gradient descent and Newton's method)."
physical electronic device implementing,"A logic gate is an idealized model of computation or a physical electronic device implementing a Boolean function, a logical operation performed on one or more binary inputs that produces a single binary output."
single binary output,"A logic gate is an idealized model of computation or a physical electronic device implementing a Boolean function, a logical operation performed on one or more binary inputs that produces a single binary output."
logical operation performed,"A logic gate is an idealized model of computation or a physical electronic device implementing a Boolean function, a logical operation performed on one or more binary inputs that produces a single binary output."
idealized model,"A logic gate is an idealized model of computation or a physical electronic device implementing a Boolean function, a logical operation performed on one or more binary inputs that produces a single binary output."
term may refer,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
ideal physical device,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
instance zero rise time,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
real op,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
may refer,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison). !! More generally ""primitive data types"" may refer to the standard data types built into a programming language."
unlimited fan,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
see ideal,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
ideal logic gate,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
relay logic  fluidic logic,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
electromagnetic relays,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
transistors acting,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
even mechanical elements,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
constructed using vacuum tubes,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
pneumatic logic,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
primarily implemented using diodes,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
logic gates,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements. !! The simplest family of logic gates uses bipolar transistors, and is called resistortransistor logic (RTL). !! Unlike simple diode logic gates (which do not have a gain element), RTL gates can be cascaded indefinitely to produce more complex logic functions. !! With amplification, logic gates can be cascaded in the same way that Boolean functions can be composed, allowing the construction of a physical model of all of Boolean logic, and therefore, all of the algorithms and mathematics that can be described with Boolean logic. !! Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates."
electronic switches,"Logic gates are primarily implemented using diodes or transistors acting as electronic switches, but can also be constructed using vacuum tubes, electromagnetic relays (relay logic), fluidic logic, pneumatic logic, optics, molecules, or even mechanical elements."
physical model,"With amplification, logic gates can be cascaded in the same way that Boolean functions can be composed, allowing the construction of a physical model of all of Boolean logic, and therefore, all of the algorithms and mathematics that can be described with Boolean logic."
often employed,"Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates. !! Introduced in CART, variance reduction is often employed in cases where the target variable is continuous (regression tree), meaning that use of many other metrics would first require discretization before being applied. !! Because of this, the active record pattern is best and most often employed in simple applications that are all forms-over-data with CRUD functionality, or only as one part of an architecture."
circuit design,Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates.
construction using mosfets,Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates.
individual gates,Compound logic gates AND-OR-Invert (AOI) and OR-AND-Invert (OAI) are often employed in circuit design because their construction using MOSFETs is simpler and more efficient than the sum of the individual gates.
puts elements,"In computer science, a sorting algorithm is an algorithm that puts elements of a list into an order."
betty holberton,"Among the authors of early sorting algorithms around 1951 was Betty Holberton, who worked on ENIAC and UNIVAC."
early sorting algorithms around 1951,"Among the authors of early sorting algorithms around 1951 was Betty Holberton, who worked on ENIAC and UNIVAC."
fundamental requirement,"Comparison sorting algorithms have a fundamental requirement of (n log n) comparisons (some input sequences will require a multiple of n log n comparisons, where n is the number of elements in the array to be sorted)."
problem provides,"Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds."
gentle introduction,"Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds."
introductory computer science classes,"Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds."
lower bounds,"Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds."
average case analysis,"Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds."
core algorithm concepts,"Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds."
good behavior,"For typical serial sorting algorithms, good behavior is O(n log n), with parallel sort in O(log2 n), and bad behavior is O(n2)."
parallel sort,"For typical serial sorting algorithms, good behavior is O(n log n), with parallel sort in O(log2 n), and bad behavior is O(n2)."
typical serial sorting algorithms,"For typical serial sorting algorithms, good behavior is O(n log n), with parallel sort in O(log2 n), and bad behavior is O(n2)."
bad behavior,"For typical serial sorting algorithms, good behavior is O(n log n), with parallel sort in O(log2 n), and bad behavior is O(n2)."
block diagram,"To make an analogy to the map making world, a block diagram is similar to a highway map of an entire nation. !! A block diagram is a diagram of a system in which the principal parts or functions are represented by blocks connected by lines that show the relationships of the blocks. !! Block diagrams rely on the principle of the black box where the contents are hidden from view either to avoid being distracted by the details or because the details are not known. !! As an example, a block diagram of a radio is not expected to show each and every connection and dial and switch, but the schematic diagram is. !! Block diagrams are typically used for higher level, less detailed descriptions that are intended to clarify overall concepts without concern for the details of implementation."
principal parts,A block diagram is a diagram of a system in which the principal parts or functions are represented by blocks connected by lines that show the relationships of the blocks.
blocks connected,A block diagram is a diagram of a system in which the principal parts or functions are represented by blocks connected by lines that show the relationships of the blocks.
higher level,"The process is progressive, and a higher level of database normalization cannot be achieved unless the previous levels have been satisfied. !! Block diagrams are typically used for higher level, less detailed descriptions that are intended to clarify overall concepts without concern for the details of implementation."
clarify overall concepts without concern,"Block diagrams are typically used for higher level, less detailed descriptions that are intended to clarify overall concepts without concern for the details of implementation."
block diagrams,"Block diagrams are typically used for higher level, less detailed descriptions that are intended to clarify overall concepts without concern for the details of implementation."
less detailed descriptions,"Block diagrams are typically used for higher level, less detailed descriptions that are intended to clarify overall concepts without concern for the details of implementation."
every connection,"As an example, a block diagram of a radio is not expected to show each and every connection and dial and switch, but the schematic diagram is."
schematic diagram,"As an example, a block diagram of a radio is not expected to show each and every connection and dial and switch, but the schematic diagram is."
map making world,"To make an analogy to the map making world, a block diagram is similar to a highway map of an entire nation."
entire nation,"To make an analogy to the map making world, a block diagram is similar to a highway map of an entire nation."
highway map,"To make an analogy to the map making world, a block diagram is similar to a highway map of an entire nation."
block diagrams rely,Block diagrams rely on the principle of the black box where the contents are hidden from view either to avoid being distracted by the details or because the details are not known.
black box,Block diagrams rely on the principle of the black box where the contents are hidden from view either to avoid being distracted by the details or because the details are not known.
view either,Block diagrams rely on the principle of the black box where the contents are hidden from view either to avoid being distracted by the details or because the details are not known.
reference modelin systems,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
abstract framework,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication. !! According to OASIS (Organization for the Advancement of Structured Information Standards) a reference model is ""an abstract framework for understanding significant relationships among the entities of some environment, and for the development of consistent standards or specifications supporting that environment."
specific ontology consisting,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
clearly defined concepts produced,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
encourage clear communication,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
software engineeringis,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
reference model,"A reference model is based on a small number of unifying concepts and may be used as a basis for education and explaining standards to a non-specialist. !! Reference models are often illustrated as a set of concepts with some indication of the relationships between the concepts. !! A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication. !! A reference model can represent the component parts of any consistent idea, from business functions to system components, as long as it represents a complete set. !! According to OASIS (Organization for the Advancement of Structured Information Standards) a reference model is ""an abstract framework for understanding significant relationships among the entities of some environment, and for the development of consistent standards or specifications supporting that environment. !! Since then, the Unified Process family has become probably the most popular methodology and reference model for object-oriented analysis and design."
interlinked set,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
business functions,"A reference model can represent the component parts of any consistent idea, from business functions to system components, as long as it represents a complete set."
component parts,"A reference model can represent the component parts of any consistent idea, from business functions to system components, as long as it represents a complete set."
consistent idea,"A reference model can represent the component parts of any consistent idea, from business functions to system components, as long as it represents a complete set."
system components,"The purpose of recommending MSC (Message Sequence Chart) is to provide a trace language for the specification and description of the communication behaviour of system components and their environment by means of message interchange. !! A reference model can represent the component parts of any consistent idea, from business functions to system components, as long as it represents a complete set."
often illustrated,Reference models are often illustrated as a set of concepts with some indication of the relationships between the concepts.
reference models,Reference models are often illustrated as a set of concepts with some indication of the relationships between the concepts.
specifications supporting,"According to OASIS (Organization for the Advancement of Structured Information Standards) a reference model is ""an abstract framework for understanding significant relationships among the entities of some environment, and for the development of consistent standards or specifications supporting that environment."
understanding significant relationships among,"According to OASIS (Organization for the Advancement of Structured Information Standards) a reference model is ""an abstract framework for understanding significant relationships among the entities of some environment, and for the development of consistent standards or specifications supporting that environment."
structured information standards,"According to OASIS (Organization for the Advancement of Structured Information Standards) a reference model is ""an abstract framework for understanding significant relationships among the entities of some environment, and for the development of consistent standards or specifications supporting that environment."
consistent standards,"According to OASIS (Organization for the Advancement of Structured Information Standards) a reference model is ""an abstract framework for understanding significant relationships among the entities of some environment, and for the development of consistent standards or specifications supporting that environment."
explaining standards,A reference model is based on a small number of unifying concepts and may be used as a basis for education and explaining standards to a non-specialist.
unifying concepts,A reference model is based on a small number of unifying concepts and may be used as a basis for education and explaining standards to a non-specialist.
small number,"A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities. !! This large amount of required computer capabilities explains the small number of general-purpose computer algebra systems. !! For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm. !! Locally testable codes are error-correcting codes for which it can be checked probabilistically whether a signal is close to a codeword by only looking at a small number of positions of the signal. !! However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes, and such activation functions are called nonlinearities. !! A reference model is based on a small number of unifying concepts and may be used as a basis for education and explaining standards to a non-specialist. !! A focus group is a group interview involving a small number of demographically similar people or participants who have other common traits/experiences."
access control,"Geographical access control may be enforced by personnel (e. g. border guard, bouncer, ticket checker), or with a device such as a turnstile. !! Directory services are often central to the security design of an IT system and have a correspondingly-fine granularity of access control. !! In the fields of physical security and information security, access control (AC) is the selective restriction of access to a place or other resource, while access management describes the process. !! There may be fences to avoid circumventing this access control. !! Locks and login credentials are two analogous mechanisms of access control. !! An alternative of access control in the strict sense (physically controlling access itself) is a system of checking authorized presence, see e. g. Ticket controller (transportation)."
access management describes,"In the fields of physical security and information security, access control (AC) is the selective restriction of access to a place or other resource, while access management describes the process."
selective restriction,"In the fields of physical security and information security, access control (AC) is the selective restriction of access to a place or other resource, while access management describes the process."
two analogous mechanisms,Locks and login credentials are two analogous mechanisms of access control.
border guard,"Geographical access control may be enforced by personnel (e. g. border guard, bouncer, ticket checker), or with a device such as a turnstile."
ticket checker,"Geographical access control may be enforced by personnel (e. g. border guard, bouncer, ticket checker), or with a device such as a turnstile."
geographical access control may,"Geographical access control may be enforced by personnel (e. g. border guard, bouncer, ticket checker), or with a device such as a turnstile."
avoid circumventing,There may be fences to avoid circumventing this access control.
physically controlling access,"An alternative of access control in the strict sense (physically controlling access itself) is a system of checking authorized presence, see e. g. Ticket controller (transportation)."
checking authorized presence,"An alternative of access control in the strict sense (physically controlling access itself) is a system of checking authorized presence, see e. g. Ticket controller (transportation)."
ticket controller,"An alternative of access control in the strict sense (physically controlling access itself) is a system of checking authorized presence, see e. g. Ticket controller (transportation)."
term floating point refers,"The term floating point refers to the fact that a number's radix point (decimal point, or, more commonly in computers, binary point) can ""float""; that is, it can be placed anywhere relative to the significant digits of the number."
placed anywhere relative,"The term floating point refers to the fact that a number's radix point (decimal point, or, more commonly in computers, binary point) can ""float""; that is, it can be placed anywhere relative to the significant digits of the number."
radix point,"The term floating point refers to the fact that a number's radix point (decimal point, or, more commonly in computers, binary point) can ""float""; that is, it can be placed anywhere relative to the significant digits of the number."
decimal point,"The term floating point refers to the fact that a number's radix point (decimal point, or, more commonly in computers, binary point) can ""float""; that is, it can be placed anywhere relative to the significant digits of the number."
base two,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
hexadecimal floating point  base eight,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
even base 256,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
base ten,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
octal floating point  base four,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
point numbers,"Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans. !! Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
representing floating,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
several number bases,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
quaternary floating point  base three,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
less common varieties,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
base sixteen,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
less costly,"The hardware to manipulate these representations is less costly than floating point, and it can be used to perform normal integer operations, too."
perform normal integer operations,"The hardware to manipulate these representations is less costly than floating point, and it can be used to perform normal integer operations, too."
value distribution,"The value distribution is similar to floating point, but the value-to-representation curve (i. e. , the graph of the logarithm function) is smooth (except at 0)."
representation curve,"The value distribution is similar to floating point, but the value-to-representation curve (i. e. , the graph of the logarithm function) is smooth (except at 0)."
simple rational numbers,"Some simple rational numbers (e. g. , 1/3 and 1/10) cannot be represented exactly in binary floating point, no matter what the precision is."
represented exactly,"Some simple rational numbers (e. g. , 1/3 and 1/10) cannot be represented exactly in binary floating point, no matter what the precision is."
classify patterns,"Time delay neural network (TDNN) is a multilayer artificial neural network architecture whose purpose is to 1) classify patterns with shift-invariance, and 2) model context at each layer of the network."
model context,"Time delay neural network (TDNN) is a multilayer artificial neural network architecture whose purpose is to 1) classify patterns with shift-invariance, and 2) model context at each layer of the network."
multiple interconnected layers,"The Time Delay Neural Network, like other neural networks, operates with multiple interconnected layers of perceptrons, and is implemented as a feedforward neural network."
explicit functionality designed,Matlab: The neural network toolbox has explicit functionality designed to produce a time delay neural network give the step size of time delays and an optional training function.
optional training function,Matlab: The neural network toolbox has explicit functionality designed to produce a time delay neural network give the step size of time delays and an optional training function.
step size,"Matlab: The neural network toolbox has explicit functionality designed to produce a time delay neural network give the step size of time delays and an optional training function. !! In mathematics, a stiff equation is a differential equation for which certain numerical methods for solving the equation are numerically unstable, unless the step size is taken to be extremely small. !! In machine learning and statistics, the learning rate is a tuning parameter in an optimization algorithm that determines the step size at each iteration while moving toward a minimum of a loss function."
time delay neural network give,Matlab: The neural network toolbox has explicit functionality designed to produce a time delay neural network give the step size of time delays and an optional training function.
parameter systems,"Automata theory was initially considered a branch of mathematical systems theory, studying the behavior of discrete-parameter systems."
initially considered,"Automata theory was initially considered a branch of mathematical systems theory, studying the behavior of discrete-parameter systems."
mathematical systems theory,"Automata theory was initially considered a branch of mathematical systems theory, studying the behavior of discrete-parameter systems."
previous work,Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems.
describe information systems rather,Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems.
early work,"According to Condon, the ideas of cognitive engineering were developed later than, and independent from, the early work on the Unix operating system. !! Computational logic has also come to be associated with logic programming, because much of the early work in logic programming in the early 1970s also took place in the Department of Computational Logic in Edinburgh. !! Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems. !! The very early work on agent mining focused on agent-based knowledge discovery, agent-based distributed data mining, and agent-based distributed machine learning, and using data mining to enhance agent intelligence. !! Early work on statistical classification was undertaken by Fisher, in the context of two-group problems, leading to Fisher's linear discriminant function as the rule for assigning a group to a new observation."
automata theory differed,Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems.
using abstract algebra,Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems.
describe material systems,Early work in automata theory differed from previous work on systems by using abstract algebra to describe information systems rather than differential calculus to describe material systems.
automata theory emerged,"With the publication of this volume, ""automata theory emerged as a relatively autonomous discipline""."
relatively autonomous discipline,"With the publication of this volume, ""automata theory emerged as a relatively autonomous discipline""."
1 - tight graphs,"Thus trees are exactly the (1,1)-tight graphs, forests are exactly the (1,1)-sparse graphs, and graphs with arboricity k are exactly the (k,k)-sparse graphs."
k - sparse graphs,"Thus trees are exactly the (1,1)-tight graphs, forests are exactly the (1,1)-sparse graphs, and graphs with arboricity k are exactly the (k,k)-sparse graphs."
1 - sparse graphs,"Thus trees are exactly the (1,1)-tight graphs, forests are exactly the (1,1)-sparse graphs, and graphs with arboricity k are exactly the (k,k)-sparse graphs."
laman graphs arising,"Pseudoforests are exactly the (1,0)-sparse graphs, and the Laman graphs arising in rigidity theory are exactly the (2,3)-tight graphs."
0 - sparse graphs,"Pseudoforests are exactly the (1,0)-sparse graphs, and the Laman graphs arising in rigidity theory are exactly the (2,3)-tight graphs."
3 - tight graphs,"Pseudoforests are exactly the (1,0)-sparse graphs, and the Laman graphs arising in rigidity theory are exactly the (2,3)-tight graphs."
6 - sparse graph,"However, not every (3,6)-sparse graph is planar."
#NAME?,"A sigmoid function is a mathematical function having a characteristic ""S""-shaped curve or sigmoid curve."
bar recursion,The principles of bar induction and bar recursion are the intuitionistic equivalents of the axiom of dependent choices. !! Bar recursion is a generalized form of recursion developed by C. Spector in his 1962 paper.
generalized form,Bar recursion is a generalized form of recursion developed by C. Spector in his 1962 paper.
recursion developed,Bar recursion is a generalized form of recursion developed by C. Spector in his 1962 paper.
bar induction,The principles of bar induction and bar recursion are the intuitionistic equivalents of the axiom of dependent choices.
dependent choices,The principles of bar induction and bar recursion are the intuitionistic equivalents of the axiom of dependent choices.
intuitionistic equivalents,The principles of bar induction and bar recursion are the intuitionistic equivalents of the axiom of dependent choices.
user interfaces,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers. !! The underlying technologies to support ubiquitous computing include Internet, advanced middleware, operating system, mobile code, sensors, microprocessors, new I/O and user interfaces, computer networks, mobile protocols, location and positioning, and new materials. !! Cognitive dimensions or cognitive dimensions of notations are design principles for notations, user interfaces and programming languages, described by researcher Thomas R. G. Green and furthered researched with Marian Petre."
design principles,"Cognitive dimensions or cognitive dimensions of notations are design principles for notations, user interfaces and programming languages, described by researcher Thomas R. G. Green and furthered researched with Marian Petre."
marian petre,"Cognitive dimensions or cognitive dimensions of notations are design principles for notations, user interfaces and programming languages, described by researcher Thomas R. G. Green and furthered researched with Marian Petre."
researcher thomas r,"Cognitive dimensions or cognitive dimensions of notations are design principles for notations, user interfaces and programming languages, described by researcher Thomas R. G. Green and furthered researched with Marian Petre."
cognitive dimensions of notations,"Cognitive dimensions or cognitive dimensions of notations are design principles for notations, user interfaces and programming languages, described by researcher Thomas R. G. Green and furthered researched with Marian Petre."
furthered researched,"Cognitive dimensions or cognitive dimensions of notations are design principles for notations, user interfaces and programming languages, described by researcher Thomas R. G. Green and furthered researched with Marian Petre."
two convex sets,"In computer science, binary space partitioning (BSP) is a method for recursively subdividing a space into two convex sets by using hyperplanes as partitions."
using hyperplanes,"In computer science, binary space partitioning (BSP) is a method for recursively subdividing a space into two convex sets by using hyperplanes as partitions."
recursively subdividing,"In computer science, binary space partitioning (BSP) is a method for recursively subdividing a space into two convex sets by using hyperplanes as partitions."
generic process,Binary space partitioning is a generic process of recursively dividing a scene into two until the partitioning satisfies one or more requirements.
partitioning satisfies one,Binary space partitioning is a generic process of recursively dividing a scene into two until the partitioning satisfies one or more requirements.
recursively dividing,Binary space partitioning is a generic process of recursively dividing a scene into two until the partitioning satisfies one or more requirements.
computer graphics need,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
binary space partitioning arose,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
rapidly draw three,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
dimensional scenes composed,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
human movement primarily used,Fitts's law (often cited as Fitts' law) is a predictive model of human movement primarily used in humancomputer interaction and ergonomics.
often cited,Fitts's law (often cited as Fitts' law) is a predictive model of human movement primarily used in humancomputer interaction and ergonomics.
pointing device,"Fitts's law is used to model the act of pointing, either by physically touching an object with a hand or finger, or virtually, by pointing to an object on a computer monitor using a pointing device."
computer monitor using,"Fitts's law is used to model the act of pointing, either by physically touching an object with a hand or finger, or virtually, by pointing to an object on a computer monitor using a pointing device."
physically touching,"Fitts's law is used to model the act of pointing, either by physically touching an object with a hand or finger, or virtually, by pointing to an object on a computer monitor using a pointing device."
including underwater,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
lower lip,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
user populations,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
drugged participants,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
many different limbs,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
mounted sights  manipulanda,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
input devices  physical environments,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
special educational needs,"Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants)."
parameters show,Both parameters show the linear dependency in Fitts's law.
compare performance,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
directional movement keys,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
first humancomputer interface application,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
ip  interpreted,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
top compared,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
mouse coming,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
different input devices,"The first humancomputer interface application of Fitts's law was by Card, English, and Burr, who used the index of performance (IP), interpreted as 1b, to compare performance of different input devices, with the mouse coming out on top compared to the joystick or directional movement keys."
examples section,Other standard sigmoid functions are given in the Examples section.
large values,Special cases of the sigmoid function include the Gompertz curve (used in modeling systems that saturate at large values of x) and the ogee curve (used in the spillway of some dams).
sigmoid function include,Special cases of the sigmoid function include the Gompertz curve (used in modeling systems that saturate at large values of x) and the ogee curve (used in the spillway of some dams).
modeling systems,Special cases of the sigmoid function include the Gompertz curve (used in modeling systems that saturate at large values of x) and the ogee curve (used in the spillway of some dams).
special cases,"Graph mining, sequential pattern mining and molecule mining are special cases of structured data mining. !! Special cases of the sigmoid function include the Gompertz curve (used in modeling systems that saturate at large values of x) and the ogee curve (used in the spillway of some dams)."
value commonly monotonically increasing,"Sigmoid functions have domain of all real numbers, with return (response) value commonly monotonically increasing but could be decreasing."
digital camera,"In electronics, an analog-to-digital converter (ADC, A/D, or A-to-D) is a system that converts an analog signal, such as a sound picked up by a microphone or light entering a digital camera, into a digital signal."
sound picked,"In electronics, an analog-to-digital converter (ADC, A/D, or A-to-D) is a system that converts an analog signal, such as a sound picked up by a microphone or light entering a digital camera, into a digital signal."
light entering,"In electronics, an analog-to-digital converter (ADC, A/D, or A-to-D) is a system that converts an analog signal, such as a sound picked up by a microphone or light entering a digital camera, into a digital signal."
dithering produces results,"Since the values are added together, the dithering produces results that are more exact than the LSB of the analog-to-digital converter."
added together,"Since the values are added together, the dithering produces results that are more exact than the LSB of the analog-to-digital converter."
signal prior,"A Time-stretch analog-to-digital converter (TS-ADC) digitizes a very wide bandwidth analog signal, that cannot be digitized by a conventional electronic ADC, by time-stretching the signal prior to digitization."
wide bandwidth analog signal,"A Time-stretch analog-to-digital converter (TS-ADC) digitizes a very wide bandwidth analog signal, that cannot be digitized by a conventional electronic ADC, by time-stretching the signal prior to digitization."
stretch analog,"A Time-stretch analog-to-digital converter (TS-ADC) digitizes a very wide bandwidth analog signal, that cannot be digitized by a conventional electronic ADC, by time-stretching the signal prior to digitization."
conventional electronic adc,"A Time-stretch analog-to-digital converter (TS-ADC) digitizes a very wide bandwidth analog signal, that cannot be digitized by a conventional electronic ADC, by time-stretching the signal prior to digitization."
based sound recording,Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
2000s era music reproduction technology,Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
digital converters,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files. !! Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
digital audio workstation,Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
therefore need analog,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
digital music files,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
go onto compact discs,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
code modulation,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files. !! Beta encoders are an alternative to traditional approaches to pulse-code modulation.
people often produce music,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
computers using,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
formal languages,"In data compression and the theory of formal languages, the smallest grammar problem is the problem of finding the smallest context-free grammar that generates a given string of characters (but no other string). !! Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification. !! Carroll, J. , Long, D. , Theory of Finite Automata with an Introduction to Formal Languages. !! Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, discrete event dynamic system and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification. !! How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
considerable overlap,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
computability theorists,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages. !! These are not independent areas of research: each of these areas draws ideas and results from the others, and most computability theorists are familiar with the majority of them."
mathematical computability theorists study,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
reducibility notions,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
computer science field focus,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
formal methods,"Semi-Formal Methods are formalisms and languages that are not considered fully formal. !! Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification. !! Formal methods are best described as the application of a fairly broad variety of theoretical computer science fundamentals, in particular logic calculi, formal languages, automata theory, discrete event dynamic system and program semantics, but also type systems and algebraic data types to problems in software and hardware specification and verification. !! This has been dubbed formal methods lite. !! How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages. !! In computer science, specifically software engineering and hardware engineering, formal methods are a particular kind of mathematically rigorous techniques for the specification, development and verification of software and hardware systems. !! The use of formal methods for software and hardware design is motivated by the expectation that, as in other engineering disciplines, performing appropriate mathematical analysis can contribute to the reliability and robustness of a design."
hierarchy based,"In computer architecture, the memory hierarchy separates computer storage into a hierarchy based on response time. !! How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
relative computability,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
independent areas,"These are not independent areas of research: each of these areas draws ideas and results from the others, and most computability theorists are familiar with the majority of them."
areas draws ideas,"These are not independent areas of research: each of these areas draws ideas and results from the others, and most computability theorists are familiar with the majority of them."
finding software memory problems,A memory debugger is a debugger for finding software memory problems such as memory leaks and buffer overflows.
memory leaks due,"Programs written in languages that have garbage collection, such as managed code, might also need memory debuggers, e. g. for memory leaks due to ""living"" references in collections."
might also need memory debuggers,"Programs written in languages that have garbage collection, such as managed code, might also need memory debuggers, e. g. for memory leaks due to ""living"" references in collections."
programs written,"Programs written in languages that have garbage collection, such as managed code, might also need memory debuggers, e. g. for memory leaks due to ""living"" references in collections."
monitoring memory access,"Some memory debuggers (e. g. Valgrind) work by running the executable in a virtual machine-like environment, monitoring memory access, allocation and deallocation so that no recompilation with special memory allocation libraries is required. !! Memory debuggers work by monitoring memory access, allocations, and deallocation of memory."
memory debuggers work,"Memory debuggers work by monitoring memory access, allocations, and deallocation of memory."
many memory debuggers require applications,"Many memory debuggers require applications to be recompiled with special dynamic memory allocation libraries, whose APIs are mostly compatible with conventional dynamic memory allocation libraries, or else use dynamic linking."
else use dynamic linking,"Many memory debuggers require applications to be recompiled with special dynamic memory allocation libraries, whose APIs are mostly compatible with conventional dynamic memory allocation libraries, or else use dynamic linking."
mostly compatible,"Many memory debuggers require applications to be recompiled with special dynamic memory allocation libraries, whose APIs are mostly compatible with conventional dynamic memory allocation libraries, or else use dynamic linking."
special dynamic memory allocation libraries,"Many memory debuggers require applications to be recompiled with special dynamic memory allocation libraries, whose APIs are mostly compatible with conventional dynamic memory allocation libraries, or else use dynamic linking."
whose apis,"Many memory debuggers require applications to be recompiled with special dynamic memory allocation libraries, whose APIs are mostly compatible with conventional dynamic memory allocation libraries, or else use dynamic linking."
like environment,"MKS Toolkit is a software package produced and maintained by PTC that provides a Unix-like environment for scripting, connectivity and porting Unix and Linux software to Microsoft Windows. !! Some memory debuggers (e. g. Valgrind) work by running the executable in a virtual machine-like environment, monitoring memory access, allocation and deallocation so that no recompilation with special memory allocation libraries is required."
widely known encryption techniques,"In cryptography, a Caesar cipher, also known as Caesar's cipher, the shift cipher, Caesar's code or Caesar shift, is one of the simplest and most widely known encryption techniques."
modern application,"The encryption step performed by a Caesar cipher is often incorporated as part of more complex schemes, such as the Vigenre cipher, and still has modern application in the ROT13 system."
complex schemes,"The encryption step performed by a Caesar cipher is often incorporated as part of more complex schemes, such as the Vigenre cipher, and still has modern application in the ROT13 system."
often incorporated,"The encryption step performed by a Caesar cipher is often incorporated as part of more complex schemes, such as the Vigenre cipher, and still has modern application in the ROT13 system."
encryption step performed,"The encryption step performed by a Caesar cipher is often incorporated as part of more complex schemes, such as the Vigenre cipher, and still has modern application in the ROT13 system."
modern practice offers essentially,"As with all single-alphabet substitution ciphers, the Caesar cipher is easily broken and in modern practice offers essentially no communications security."
communications security,"As with all single-alphabet substitution ciphers, the Caesar cipher is easily broken and in modern practice offers essentially no communications security."
alphabet substitution ciphers,"As with all single-alphabet substitution ciphers, the Caesar cipher is easily broken and in modern practice offers essentially no communications security."
easily broken,"As with all single-alphabet substitution ciphers, the Caesar cipher is easily broken and in modern practice offers essentially no communications security."
julius caesar,"The Caesar cipher is named after Julius Caesar, who, according to Suetonius, used it with a shift of three (A becoming D when encrypting, and D becoming A when decrypting) to protect messages of military significance."
protect messages,"The Caesar cipher is named after Julius Caesar, who, according to Suetonius, used it with a shift of three (A becoming D when encrypting, and D becoming A when decrypting) to protect messages of military significance."
military significance,"The Caesar cipher is named after Julius Caesar, who, according to Suetonius, used it with a shift of three (A becoming D when encrypting, and D becoming A when decrypting) to protect messages of military significance."
reasonably secure,"It is unknown how effective the Caesar cipher was at the time, but it is likely to have been reasonably secure, not least because most of Caesar's enemies would have been illiterate and others would have assumed that the messages were written in an unknown foreign language."
unknown foreign language,"It is unknown how effective the Caesar cipher was at the time, but it is likely to have been reasonably secure, not least because most of Caesar's enemies would have been illiterate and others would have assumed that the messages were written in an unknown foreign language."
enemies would,"It is unknown how effective the Caesar cipher was at the time, but it is likely to have been reasonably secure, not least because most of Caesar's enemies would have been illiterate and others would have assumed that the messages were written in an unknown foreign language."
others would,"It is unknown how effective the Caesar cipher was at the time, but it is likely to have been reasonably secure, not least because most of Caesar's enemies would have been illiterate and others would have assumed that the messages were written in an unknown foreign language."
understand materials,"Computational materials science and engineering uses modeling, simulation, theory, and informatics to understand materials."
engineering uses modeling,"Computational materials science and engineering uses modeling, simulation, theory, and informatics to understand materials."
commercial application,"One notable sub-field of computational materials science is integrated computational materials engineering (ICME), which seeks to use computational results and methods in conjunction with experiments, with a focus on industrial and commercial application."
use computational results,"One notable sub-field of computational materials science is integrated computational materials engineering (ICME), which seeks to use computational results and methods in conjunction with experiments, with a focus on industrial and commercial application."
one notable sub,"One notable sub-field of computational materials science is integrated computational materials engineering (ICME), which seeks to use computational results and methods in conjunction with experiments, with a focus on industrial and commercial application."
engineering began,The Gordon Research Conference on Computational Materials Science and Engineering began in 2020.
gordon research conference,The Gordon Research Conference on Computational Materials Science and Engineering began in 2020.
field include computational materials science,"Those dedicated to the field include Computational Materials Science, Modelling and Simulation in Materials Science and Engineering, and npj Computational Materials."
materials science,"A phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc. ) !! Those dedicated to the field include Computational Materials Science, Modelling and Simulation in Materials Science and Engineering, and npj Computational Materials. !! Structural analysis employs the fields of applied mechanics, materials science and applied mathematics to compute a structure's deformations, internal forces, stresses, support reactions, accelerations, and stability."
one sub,"Computational materials science is one sub-discipline of both computational science and computational engineering, containing significant overlap with computational chemistry and computational physics. !! By extending the sharing to several BDDs, i. e. one sub-graph is used by several BDDs, the data structure Shared Reduced Ordered Binary Decision Diagram is defined."
containing significant overlap,"Computational materials science is one sub-discipline of both computational science and computational engineering, containing significant overlap with computational chemistry and computational physics."
computational chemistry,"Computational materials science is one sub-discipline of both computational science and computational engineering, containing significant overlap with computational chemistry and computational physics."
field related,"Artificial consciousness (AC), also known as machine consciousness (MC) or synthetic consciousness (Gamez 2008; Reggia 2013), is a field related to artificial intelligence and cognitive robotics."
ac  also known,"Artificial consciousness (AC), also known as machine consciousness (MC) or synthetic consciousness (Gamez 2008; Reggia 2013), is a field related to artificial intelligence and cognitive robotics."
mental states,"Android epistemology is an approach to epistemology considering the space of possible machines and their capacities for knowledge, beliefs, attitudes, desires and for action in accord with their mental states. !! Artificial consciousness concepts are also pondered in the philosophy of artificial intelligence through questions about mind, consciousness, and mental states. !! The computational theory of mind is related to the representational theory of mind in that they both require that mental states are representations."
artificial consciousness concepts,"Artificial consciousness concepts are also pondered in the philosophy of artificial intelligence through questions about mind, consciousness, and mental states."
also pondered,"Artificial consciousness concepts are also pondered in the philosophy of artificial intelligence through questions about mind, consciousness, and mental states."
many potential implementations,"As there are many hypothesized types of consciousness, there are many potential implementations of artificial consciousness."
many hypothesized types,"As there are many hypothesized types of consciousness, there are many potential implementations of artificial consciousness."
common objection,"In his article ""Artificial Consciousness: Utopia or Real Possibility,"" Giorgio Buttazzo says that a common objection to artificial consciousness is that ""Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can no longer be reprogrammed, from rethinking), emotions, or free will."
fully automated mode,"In his article ""Artificial Consciousness: Utopia or Real Possibility,"" Giorgio Buttazzo says that a common objection to artificial consciousness is that ""Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can no longer be reprogrammed, from rethinking), emotions, or free will."
rethinking  emotions,"In his article ""Artificial Consciousness: Utopia or Real Possibility,"" Giorgio Buttazzo says that a common objection to artificial consciousness is that ""Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can no longer be reprogrammed, from rethinking), emotions, or free will."
cannot exhibit creativity,"In his article ""Artificial Consciousness: Utopia or Real Possibility,"" Giorgio Buttazzo says that a common objection to artificial consciousness is that ""Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can no longer be reprogrammed, from rethinking), emotions, or free will."
real possibility  giorgio buttazzo says,"In his article ""Artificial Consciousness: Utopia or Real Possibility,"" Giorgio Buttazzo says that a common objection to artificial consciousness is that ""Working in a fully automated mode, they [the computers] cannot exhibit creativity, unreprogrammation (which means can no longer be reprogrammed, from rethinking), emotions, or free will."
second argument,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
minimal evaluation,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
mccarthy evaluation,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
john mccarthy,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
first argument,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
function evaluates,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
overall value must,"Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
circuit evaluation,"10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE. !! Although AND takes precedence over OR in many languages, this is not a universal property of short-circuit evaluation. !! In any programming language that implements short-circuit evaluation, the expression x and y is equivalent to the conditional expression if x then y else x, and the expression x or y is equivalent to if x then x else y. !! Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true."
short-circuit evaluation,"10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE. !! In any programming language that implements short-circuit evaluation, the expression x and y is equivalent to the conditional expression if x then y else x, and the expression x or y is equivalent to if x then x else y. !! In this example, short-circuit evaluation guarantees that myfunc(b) is never called. !! Short-circuit evaluation, minimal evaluation, or McCarthy evaluation (after John McCarthy) is the semantics of some Boolean operators in some programming languages in which the second argument is executed or evaluated only if the first argument does not suffice to determine the value of the expression: when the first argument of the AND function evaluates to false, the overall value must be false; and when the first argument of the OR function evaluates to true, the overall value must be true. !! Although AND takes precedence over OR in many languages, this is not a universal property of short-circuit evaluation."
implements short,"In any programming language that implements short-circuit evaluation, the expression x and y is equivalent to the conditional expression if x then y else x, and the expression x or y is equivalent to if x then x else y."
many languages,"Although AND takes precedence over OR in many languages, this is not a universal property of short-circuit evaluation."
takes precedence,"Although AND takes precedence over OR in many languages, this is not a universal property of short-circuit evaluation."
universal property,"Although AND takes precedence over OR in many languages, this is not a universal property of short-circuit evaluation."
norm iec 61131,10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE.
operators andthen,10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE.
use short,10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE.
actually define,10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE.
circuit evaluation guarantees,"In this example, short-circuit evaluation guarantees that myfunc(b) is never called."
never called,"In this example, short-circuit evaluation guarantees that myfunc(b) is never called."
systemic functional linguistics,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study. !! In systemic functional linguistics, this has been described as the trinocular perspective. !! To avoid confusion, the full designationsystemic functional linguisticsis typically used, rather than functional grammar or functional linguistics. !! The term rank scale was developed by Michael Halliday and is associated with systemic functional linguistics, the school of linguistic theory and description of which he is the originator. !! Systemic functional linguistics (SFL) is an approach to linguistics, among functional linguistics, that considers language as a social semiotic system. !! As the name suggests, the notion of system is a defining aspect of systemic functional linguistics."
linguistic theory,"The term rank scale was developed by Michael Halliday and is associated with systemic functional linguistics, the school of linguistic theory and description of which he is the originator."
term rank scale,"The term rank scale was developed by Michael Halliday and is associated with systemic functional linguistics, the school of linguistic theory and description of which he is the originator."
michael halliday,"Systemic functional grammar (SFG) is a form of grammatical description originated by Michael Halliday. !! The term rank scale was developed by Michael Halliday and is associated with systemic functional linguistics, the school of linguistic theory and description of which he is the originator."
rank scale,"The term rank scale was developed by Michael Halliday and is associated with systemic functional linguistics, the school of linguistic theory and description of which he is the originator."
class selected,"For classification tasks, the output of the random forest is the class selected by most trees."
leo breiman,"The idea of gradient boosting originated in the observation by Leo Breiman that boosting can be interpreted as an optimization algorithm on a suitable cost function. !! An extension of the algorithm was developed by Leo Breiman and Adele Cutler, who registered ""Random Forests"" as a trademark in 2006 (as of 2019, owned by Minitab, Inc. )."
adele cutler,"An extension of the algorithm was developed by Leo Breiman and Adele Cutler, who registered ""Random Forests"" as a trademark in 2006 (as of 2019, owned by Minitab, Inc. )."
frequently used,"Time-compressed speech is frequently used in television and radio advertising. !! Random forests are frequently used as ""blackbox"" models in businesses, as they generate reasonable predictions across a wide range of data while requiring little configuration. !! Structured programming is most frequently used with deviations that allow for clearer programs in some particular cases, such as when exception handling has to be performed. !! The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! Polynomial-time reductions are frequently used in complexity theory for defining both complexity classes and complete problems for those classes."
generate reasonable predictions across,"Random forests are frequently used as ""blackbox"" models in businesses, as they generate reasonable predictions across a wide range of data while requiring little configuration."
requiring little configuration,"Random forests are frequently used as ""blackbox"" models in businesses, as they generate reasonable predictions across a wide range of data while requiring little configuration."
garbage collection handbook,The Garbage Collection Handbook: The Art of Automatic Memory Management.
separates two,"Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events."
lda  normal discriminant analysis,"Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events."
linear discriminant,"Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events."
method used,"Partial concurrent thinking aloud (or partial concurrent think-aloud, or PCTA) is a method used to gather data in usability testing with screen reader users. !! Linear discriminant analysis (LDA), normal discriminant analysis (NDA), or discriminant function analysis is a generalization of Fisher's linear discriminant, a method used in statistics and other fields, to find a linear combination of features that characterizes or separates two or more classes of objects or events. !! Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scaling. !! In computer graphics, texture filtering or texture smoothing is the method used to determine the texture color for a texture mapped pixel, using the colors of nearby texels (pixels of the texture)."
single abstract comparison operation,"A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list."
two elements,"A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list."
occur first,"A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list."
list elements,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements. !! A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list."
way comparison,"A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list. !! When implementing a three-way comparison where a three-way comparison operator or method is not already available, it is common to combine two comparisons, such as A = B and A < B, or A < B and A > B. !! In some cases, three-way comparison can be simulated by subtracting A and B and examining the sign of the result, exploiting special instructions for examining the sign of a number. !! Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object. !! In C, the functions strcmp and memcmp perform a three-way comparison between strings and memory buffers, respectively."
final sorted list,"A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list."
unlabelled weights,A metaphor for thinking about comparison sorts is that someone has a set of unlabelled weights and a balance scale.
balance scale,A metaphor for thinking about comparison sorts is that someone has a set of unlabelled weights and a balance scale.
fundamental limits,There are fundamental limits on the performance of comparison sorts.
comparison sort must,"A comparison sort must have an average-case lower bound of (n log n) comparison operations, which is known as linearithmic time."
case lower bound,"A comparison sort must have an average-case lower bound of (n log n) comparison operations, which is known as linearithmic time."
comparison operations,"A comparison sort must have an average-case lower bound of (n log n) comparison operations, which is known as linearithmic time."
examples discussed,"Non-comparison sorts (such as the examples discussed below) can achieve O(n) performance by using operations other than comparisons, allowing them to sidestep this lower bound (assuming elements are constant-sized)."
lower bound,"To determine the similarity of objects such as genomes, languages, music, internet attacks and worms, software programs, and so on, information distance is normalized and the Kolmogorov complexity terms approximated by real-world compressors (the Kolmogorov complexity is a lower bound to the length in bits of a compressed version of the object). !! Non-comparison sorts (such as the examples discussed below) can achieve O(n) performance by using operations other than comparisons, allowing them to sidestep this lower bound (assuming elements are constant-sized). !! Counting sort is not a comparison sort; it uses key values as indexes into an array and the (n log n) lower bound for comparison sorting will not apply."
using operations,"Non-comparison sorts (such as the examples discussed below) can achieve O(n) performance by using operations other than comparisons, allowing them to sidestep this lower bound (assuming elements are constant-sized)."
assuming elements,"Non-comparison sorts (such as the examples discussed below) can achieve O(n) performance by using operations other than comparisons, allowing them to sidestep this lower bound (assuming elements are constant-sized)."
replaces runtime computation,"In computer science, a lookup table (LUT) is an array that replaces runtime computation with a simpler array indexing operation."
simpler array indexing operation,"In computer science, a lookup table (LUT) is an array that replaces runtime computation with a simpler array indexing operation."
matching input,"Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input."
validate input values,"Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input."
may include pointer functions,"Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input."
also used extensively,"Lookup tables are also used extensively to validate input values by matching against a list of valid (or invalid) items in an array and, in some programming languages, may include pointer functions (or offsets to labels) to process the matching input."
fpgas also make extensive use,"FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup tables to provide programmable hardware functionality."
provide programmable hardware functionality,"FPGAs also make extensive use of reconfigurable, hardware-implemented, lookup tables to provide programmable hardware functionality."
hand calculations,"Before the advent of computers, lookup tables of values were used to speed up hand calculations of complex functions, such as in trigonometry, logarithms, and statistical density functions."
commonly occurring data items,It made sense to reduce expensive read operations by a form of manual caching by creating either static lookup tables (embedded in the program) or dynamic prefetched arrays to contain only the most commonly occurring data items.
made sense,It made sense to reduce expensive read operations by a form of manual caching by creating either static lookup tables (embedded in the program) or dynamic prefetched arrays to contain only the most commonly occurring data items.
creating either static lookup tables,It made sense to reduce expensive read operations by a form of manual caching by creating either static lookup tables (embedded in the program) or dynamic prefetched arrays to contain only the most commonly occurring data items.
reduce expensive read operations,It made sense to reduce expensive read operations by a form of manual caching by creating either static lookup tables (embedded in the program) or dynamic prefetched arrays to contain only the most commonly occurring data items.
specific types provided,Generic programming is a style of computer programming in which algorithms are written in terms of types to-be-specified-later that are then instantiated when needed for specific types provided as parameters.
typically using language genericity mechanisms,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
across concrete examples,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above. !! The ""generic programming"" paradigm is an approach to software decomposition whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, analogously to the abstraction of algebraic theories in abstract algebra."
david musser,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
originally coined,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
programming paradigm whereby fundamental requirements,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
specific sense,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
alexander stepanov,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
generic functions implemented,"The term ""generic programming"" was originally coined by David Musser and Alexander Stepanov in a more specific sense than the above, to describe a programming paradigm whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, with generic functions implemented in terms of these concepts, typically using language genericity mechanisms as described above."
wide variety,"Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software. !! In addition to its uses in digital forensics, research has shown that perceptual hashing can be applied to a wide variety of situations. !! A wide variety of projects for robotics middleware exist, but no one of these dominates - and in fact many robotic systems do not use any middleware. !! Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring. !! :911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics. !! Structured prediction is also used in a wide variety of application domains including bioinformatics, natural language processing, speech recognition, and computer vision. !! Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. !! In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images."
generic programming centers around,"Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software."
useful software,"Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software."
different data representations,"Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software."
obtain generic algorithms,"Generic programming centers around the idea of abstracting from concrete, efficient algorithms to obtain generic algorithms that can be combined with different data representations to produce a wide variety of useful software."
software decomposition whereby fundamental requirements,"The ""generic programming"" paradigm is an approach to software decomposition whereby fundamental requirements on types are abstracted from across concrete examples of algorithms and data structures and formalized as concepts, analogously to the abstraction of algebraic theories in abstract algebra."
current value,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
data structure returns,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
generic programming approach,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
instead written generically,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
iterator concept,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
simple value type,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
iterators pointing,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
another value,"However, in the generic programming approach, each data structure returns a model of an iterator concept (a simple value type that can be dereferenced to retrieve the current value, or changed to point to another value in the sequence) and each algorithm is instead written generically with arguments of such iterators, e. g. a pair of iterators pointing to the beginning and end of the subsequence or range to process."
often abbreviated data viz,Data visualization (often abbreviated data viz) is an interdisciplinary field that deals with the graphic representation of data.
interdisciplinary field,"Community informatics (CI) is an interdisciplinary field that is concerned with using information and communication technology (ICT) to empower members of communities and support their social, cultural, and economic development. !! Data visualization (often abbreviated data viz) is an interdisciplinary field that deals with the graphic representation of data. !! Quantum information science is an interdisciplinary field that seeks to understand the analysis, processing, and transmission of information using quantum mechanics principles. !! Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. !! Embodied cognitive science is an interdisciplinary field of research, the aim of which is to explain the mechanisms underlying intelligent behavior. !! Computational anatomy is an interdisciplinary field of biology focused on quantitative investigation and modelling of anatomical shapes variability."
core competency,"Since the graphic design of the mapping can adversely affect the readability of a chart, mapping is a core competency of Data visualization."
adversely affect,"Since the graphic design of the mapping can adversely affect the readability of a chart, mapping is a core competency of Data visualization."
therefore generally considered,Data visualization has its roots in the field of statistics and is therefore generally considered a branch of descriptive Statistics.
communicate information clearly,"To communicate information clearly and efficiently, data visualization uses statistical graphics, plots, information graphics and other tools."
data visualization uses statistical graphics,"To communicate information clearly and efficiently, data visualization uses statistical graphics, plots, information graphics and other tools."
communicate data,"Data visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e. g. , points, lines, or bars) contained in graphics."
data visualization refers,"Data visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e. g. , points, lines, or bars) contained in graphics."
techniques used,"Computer graphics lighting is the collection of techniques used to simulate light in computer graphics scenes. !! Data visualization refers to the techniques used to communicate data or information by encoding it as visual objects (e. g. , points, lines, or bars) contained in graphics. !! Spectral methods are a class of techniques used in applied mathematics and scientific computing to numerically solve certain differential equations, potentially involving the use of the fast Fourier transform."
multiple edges,"In this variation of graph minor theory, a graph is always simplified after any edge contraction to eliminate its self-loops and multiple edges."
always simplified,"In this variation of graph minor theory, a graph is always simplified after any edge contraction to eliminate its self-loops and multiple edges."
longer periods,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
traditional electroencephalogram,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
monitoring brain function,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
intensive care settings,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
amplitude integrated electroencephalography,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
eeg  typically hours,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
conventionally drawing,"Conversely, given an ordered tree, and conventionally drawing the root at the top, then the child vertices in an ordered tree can be drawn left-to-right, yielding an essentially unique planar embedding."
drawn left,"Conversely, given an ordered tree, and conventionally drawing the root at the top, then the child vertices in an ordered tree can be drawn left-to-right, yielding an essentially unique planar embedding."
essentially unique planar embedding,"Conversely, given an ordered tree, and conventionally drawing the root at the top, then the child vertices in an ordered tree can be drawn left-to-right, yielding an essentially unique planar embedding."
common industrial robots,Serial manipulators are the most common industrial robots and they are designed as a series of links connected by motor-actuated joints that extend from a base to an end-effector.
links connected,Serial manipulators are the most common industrial robots and they are designed as a series of links connected by motor-actuated joints that extend from a base to an end-effector.
actuated joints,Serial manipulators are the most common industrial robots and they are designed as a series of links connected by motor-actuated joints that extend from a base to an end-effector.
main advantage,"The main advantage of a serial manipulator is a large workspace with respect to the size of the robot and the floor space it occupies. !! The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
large workspace,The main advantage of a serial manipulator is a large workspace with respect to the size of the robot and the floor space it occupies.
floor space,The main advantage of a serial manipulator is a large workspace with respect to the size of the robot and the floor space it occupies.
longer completely define,A singularity is a configuration of a serial manipulator in which the joint parameters no longer completely define the position and orientation of the end-effector.
joint parameters,A singularity is a configuration of a serial manipulator in which the joint parameters no longer completely define the position and orientation of the end-effector.
fully extended,For example when a serial manipulator is fully extended it is in what is known as the boundary singularity.
lazy inheritance,"The instances of objects in lazy inheritance are created in ""mixed"" mode on first invocation, a factory is used to modify class prototype which is later used for subsequent object instances creation. !! Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class. !! Lazy inheritance on SourceForge !! Lazy inheritance is a design pattern used in JavaScript computer programming."
design pattern used,Lazy inheritance is a design pattern used in JavaScript computer programming.
combine process,"Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class."
since lazy inheritance called,"Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class."
first object instance creation,"Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class."
resolving necessary dependencies,"Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class."
seems logical,"Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class."
first invocation,"The instances of objects in lazy inheritance are created in ""mixed"" mode on first invocation, a factory is used to modify class prototype which is later used for subsequent object instances creation."
subsequent object instances creation,"The instances of objects in lazy inheritance are created in ""mixed"" mode on first invocation, a factory is used to modify class prototype which is later used for subsequent object instances creation."
modify class prototype,"The instances of objects in lazy inheritance are created in ""mixed"" mode on first invocation, a factory is used to modify class prototype which is later used for subsequent object instances creation."
printers across nodes,Server Message Block (SMB) is a communication protocol that Microsoft created for providing shared access to files and printers across nodes on a network.
providing shared access,Server Message Block (SMB) is a communication protocol that Microsoft created for providing shared access to files and printers across nodes on a network.
microsoft created,Server Message Block (SMB) is a communication protocol that Microsoft created for providing shared access to files and printers across nodes on a network.
printer sharing,"Server Message Block (SMB) enables file sharing, printer sharing, network browsing, and inter-process communication (through named pipes) over a computer network."
process communication,"Server Message Block (SMB) enables file sharing, printer sharing, network browsing, and inter-process communication (through named pipes) over a computer network. !! In computer science, inter-process communication or interprocess communication (IPC) refers specifically to the mechanisms an operating system provides to allow the processes to manage shared data."
enables file sharing,"Server Message Block (SMB) enables file sharing, printer sharing, network browsing, and inter-process communication (through named pipes) over a computer network."
named pipes,"Server Message Block (SMB) enables file sharing, printer sharing, network browsing, and inter-process communication (through named pipes) over a computer network."
smb  server message block,[MS-SMB]: Server Message Block (SMB) Protocol.
existing common internet file system,"Specifies the Server Message Block (SMB) Protocol, which defines extensions to the existing Common Internet File System (CIFS) specification that have been implemented by Microsoft since the publication of the CIFS specification."
defines extensions,"Specifies the Server Message Block (SMB) Protocol, which defines extensions to the existing Common Internet File System (CIFS) specification that have been implemented by Microsoft since the publication of the CIFS specification."
microsoft since,"Specifies the Server Message Block (SMB) Protocol, which defines extensions to the existing Common Internet File System (CIFS) specification that have been implemented by Microsoft since the publication of the CIFS specification."
cifs specification,"Specifies the Server Message Block (SMB) Protocol, which defines extensions to the existing Common Internet File System (CIFS) specification that have been implemented by Microsoft since the publication of the CIFS specification."
protocol versions 2,[MS-SMB2]: Server Message Block (SMB) Protocol Versions 2 and 3.
smb2  server message block,[MS-SMB2]: Server Message Block (SMB) Protocol Versions 2 and 3.
different classes,"In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so few points are close to each other but in different classes. !! The definition can be extended in several ways, leading to different classes of generalized bent functions that share many of the useful properties of the original."
smoothness assumption additionally yields,"In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so few points are close to each other but in different classes."
density regions,"In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so few points are close to each other but in different classes."
gives rise,This is a special case of the smoothness assumption and gives rise to feature learning with clustering algorithms.
particular outputs,"Generative adversarial networks are examples of this class of generative models, and are judged primarily by the similarity of particular outputs to potential inputs."
potential inputs,"Generative adversarial networks are examples of this class of generative models, and are judged primarily by the similarity of particular outputs to potential inputs."
judged primarily,"Generative adversarial networks are examples of this class of generative models, and are judged primarily by the similarity of particular outputs to potential inputs."
necessarily perform better,They don't necessarily perform better than generative models at classification and regression tasks.
called deep generative models,"With the rise of deep learning, a new family of methods, called deep generative models (DGMs), is formed through the combination of generative models and deep neural networks."
new family,"With the rise of deep learning, a new family of methods, called deep generative models (DGMs), is formed through the combination of generative models and deep neural networks. !! In 2019 a new family of sinusoidal-hyperbolic transform functions, which have comparable properties and performance with DCT, were proposed for lossy compression."
large deep generative models,"Recently, there has been a trend to build very large deep generative models."
machine learning technique used,"Gradient boosting is a machine learning technique used in regression and classification tasks, among others."
among others,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures. !! With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others. !! Gradient boosting is a machine learning technique used in regression and classification tasks, among others."
gradient boosting originated,The idea of gradient boosting originated in the observation by Leo Breiman that boosting can be interpreted as an optimization algorithm on a suitable cost function.
suitable cost function,The idea of gradient boosting originated in the observation by Leo Breiman that boosting can be interpreted as an optimization algorithm on a suitable cost function.
peter bartlett,"Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman, simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean."
subsequently developed,"Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman, simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean."
marcus frean,"Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman, simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean."
llew mason,"Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman, simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean."
general functional gradient boosting perspective,"Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman, simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean."
jonathan baxter,"Explicit regression gradient boosting algorithms were subsequently developed, by Jerome H. Friedman, simultaneously with the more general functional gradient boosting perspective of Llew Mason, Jonathan Baxter, Peter Bartlett and Marcus Frean."
section follows,(This section follows the exposition of gradient boosting by Li. )
gradient boosting combines weak,"Like other boosting methods, gradient boosting combines weak ""learners"" into a single strong learner in an iterative fashion."
iterative fashion,"Like other boosting methods, gradient boosting combines weak ""learners"" into a single strong learner in an iterative fashion."
single strong learner,"Like other boosting methods, gradient boosting combines weak ""learners"" into a single strong learner in an iterative fashion."
inspired computing,"Bio-inspired computing is a major subset of natural computation. !! Bio-Inspired computing can be distinguished from traditional artificial intelligence by its approach to computer learning. !! Bio-inspired computing, short for biologically inspired computing, is a field of study which seeks to solve computer science problems using models of biology."
within computer science,"Within computer science, bio-inspired computing relates to artificial intelligence and machine learning."
inspired computing relates,"Within computer science, bio-inspired computing relates to artificial intelligence and machine learning."
major subset,Bio-inspired computing is a major subset of natural computation.
inspired computing uses,"Bio-inspired computing uses an evolutionary approach, while traditional A. I. uses a 'creationist' approach."
evolutionary approach,"Bio-inspired computing uses an evolutionary approach, while traditional A. I. uses a 'creationist' approach."
smaller bit width,"Bit slicing is a technique for constructing a processor from modules of processors of smaller bit width, for the purpose of increasing the word length; in theory to make an arbitrary n-bit central processing unit (CPU)."
bit central processing unit,"Bit slicing is a technique for constructing a processor from modules of processors of smaller bit width, for the purpose of increasing the word length; in theory to make an arbitrary n-bit central processing unit (CPU)."
word length,"Bit slicing is a technique for constructing a processor from modules of processors of smaller bit width, for the purpose of increasing the word length; in theory to make an arbitrary n-bit central processing unit (CPU)."
less died,Bit slicing more or less died out due to the advent of the microprocessor.
scale integration circuits,"Bit slicing, although not called that at the time, was also used in computers before large-scale integrated circuits (LSI, the predecessor to today's VLSI, or very-large-scale integration circuits)."
scale integrated circuits,"Bit slicing, although not called that at the time, was also used in computers before large-scale integrated circuits (LSI, the predecessor to today's VLSI, or very-large-scale integration circuits)."
cmos transistors,"The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
use bipolar transistors,"The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
bit slicing made,"The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
switch much faster,"The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
smaller processors,"The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
economically possible,"The main advantage was that bit slicing made it economically possible in smaller processors to use bipolar transistors, which switch much faster than NMOS or CMOS transistors."
instruction multiple,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
perform single,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
term bit slicing,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
purpose cpu,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
matthew kwan,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
recent times,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
activities used,Database tuning describes a group of activities used to optimize and homogenize the performance of a database.
database tuning describes,Database tuning describes a group of activities used to optimize and homogenize the performance of a database.
database tuning aims,Database tuning aims to maximize use of system resources to perform work as efficiently and rapidly as possible.
maximize use,Database tuning aims to maximize use of system resources to perform work as efficiently and rapidly as possible.
perform work,Database tuning aims to maximize use of system resources to perform work as efficiently and rapidly as possible.
mrf  markov network,"In the domain of physics and probability, a Markov random field (MRF), Markov network or undirected graphical model is a set of random variables having a Markov property described by an undirected graph."
random variables,"Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures. !! In information theory, units of information are also used to measure information contained in messages and the entropy of random variables. !! In the domain of physics and probability, a Markov random field (MRF), Markov network or undirected graphical model is a set of random variables having a Markov property described by an undirected graph. !! The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e. g. time or space. !! In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i. e. every finite linear combination of them is normally distributed. !! A graphical model or probabilistic graphical model (PGM) or structured probabilistic model is a probabilistic model for which a graph expresses the conditional dependence structure between random variables."
markov property described,"In the domain of physics and probability, a Markov random field (MRF), Markov network or undirected graphical model is a set of random variables having a Markov property described by an undirected graph."
satisfies markov properties,"In other words, a random field is said to be a Markov random field if it satisfies Markov properties."
markov random field may,The underlying graph of a Markov random field may be finite or infinite.
underlying graph,The underlying graph of a Markov random field may be finite or infinite.
general setting,"The prototypical Markov random field is the Ising model; indeed, the Markov random field was introduced as the general setting for the Ising model."
model various low,"In the domain of artificial intelligence, a Markov random field is used to model various low- to mid-level tasks in image processing and computer vision."
level tasks,"In the domain of artificial intelligence, a Markov random field is used to model various low- to mid-level tasks in image processing and computer vision."
image search,"Google Images (previously Google Image Search) is a search engine owned by Google that allows users to search the World Wide Web for images. !! Google paired a recently hired engineer Huican Zhu with product manager Susan Wojcicki (now the current CEO of YouTube) to build the feature, and they launched Google Image Search in July 2001. !! Google's developers worked on developing this further, and they realized that an image search tool was required to answer ""the most popular search query"" they had seen to date: the green Versace dress of Jennifer Lopez worn in February 2000. !! In 2011, reverse image search functionality was added. !! That year, 250 million images were indexed in Image Search."
google images,Google Images (previously Google Image Search) is a search engine owned by Google that allows users to search the World Wide Web for images.
previously google image search,Google Images (previously Google Image Search) is a search engine owned by Google that allows users to search the World Wide Web for images.
search engine owned,Google Images (previously Google Image Search) is a search engine owned by Google that allows users to search the World Wide Web for images.
jennifer lopez worn,"Google's developers worked on developing this further, and they realized that an image search tool was required to answer ""the most popular search query"" they had seen to date: the green Versace dress of Jennifer Lopez worn in February 2000."
popular search query,"Google's developers worked on developing this further, and they realized that an image search tool was required to answer ""the most popular search query"" they had seen to date: the green Versace dress of Jennifer Lopez worn in February 2000."
green versace dress,"Google's developers worked on developing this further, and they realized that an image search tool was required to answer ""the most popular search query"" they had seen to date: the green Versace dress of Jennifer Lopez worn in February 2000."
developers worked,"Google's developers worked on developing this further, and they realized that an image search tool was required to answer ""the most popular search query"" they had seen to date: the green Versace dress of Jennifer Lopez worn in February 2000."
product manager susan wojcicki,"Google paired a recently hired engineer Huican Zhu with product manager Susan Wojcicki (now the current CEO of YouTube) to build the feature, and they launched Google Image Search in July 2001."
recently hired engineer huican zhu,"Google paired a recently hired engineer Huican Zhu with product manager Susan Wojcicki (now the current CEO of YouTube) to build the feature, and they launched Google Image Search in July 2001."
google paired,"Google paired a recently hired engineer Huican Zhu with product manager Susan Wojcicki (now the current CEO of YouTube) to build the feature, and they launched Google Image Search in July 2001."
launched google image search,"Google paired a recently hired engineer Huican Zhu with product manager Susan Wojcicki (now the current CEO of YouTube) to build the feature, and they launched Google Image Search in July 2001."
current ceo,"Google paired a recently hired engineer Huican Zhu with product manager Susan Wojcicki (now the current CEO of YouTube) to build the feature, and they launched Google Image Search in July 2001."
250 million images,"That year, 250 million images were indexed in Image Search."
reports defects,Runtime error detection is a software verification method that analyzes a software application as it executes and reports defects that are detected during that execution.
running slowly,"Runtime error detection can identify defects that manifest themselves only at runtime (for example, file overwrites) and zeroing in on the root causes of the application crashing, running slowly, or behaving unpredictably."
root causes,"Runtime error detection can identify defects that manifest themselves only at runtime (for example, file overwrites) and zeroing in on the root causes of the application crashing, running slowly, or behaving unpredictably."
behaving unpredictably,"Runtime error detection can identify defects that manifest themselves only at runtime (for example, file overwrites) and zeroing in on the root causes of the application crashing, running slowly, or behaving unpredictably."
identify defects,"Runtime error detection can identify defects that manifest themselves only at runtime (for example, file overwrites) and zeroing in on the root causes of the application crashing, running slowly, or behaving unpredictably."
achieve significant compression,"While, in principle, any general-purpose lossless compression algorithm (general-purpose meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress."
purpose meaning,"While, in principle, any general-purpose lossless compression algorithm (general-purpose meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress."
purpose lossless compression algorithm,"While, in principle, any general-purpose lossless compression algorithm (general-purpose meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress."
section limitations,No lossless compression algorithm can efficiently compress all possible data (see the section Limitations below for details).
common lossless compression algorithms,Some of the most common lossless compression algorithms are listed below.
predictable output,"However, many ordinary lossless compression algorithms produce headers, wrappers, tables, or other predictable output that might instead make cryptanalysis easier."
might instead make cryptanalysis easier,"However, many ordinary lossless compression algorithms produce headers, wrappers, tables, or other predictable output that might instead make cryptanalysis easier."
academic conference,The Annual ACM Symposium on Theory of Computing (STOC) is an academic conference in the field of theoretical computer science.
annual acm symposium,The Annual ACM Symposium on Theory of Computing (STOC) is an academic conference in the field of theoretical computer science.
symposium on theory of computing,"The Annual ACM Symposium on Theory of Computing (STOC) is an academic conference in the field of theoretical computer science. !! Lance Fortnow (2005), ""Beyond NP: the work and legacy of Larry Stockmeyer"", Proceedings of the thirty-seventh annual ACM symposium on Theory of computing - STOC '05, p. 120, !! "", Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04, p. 579, !! va Tardos (2004), ""Network games"", Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04, pp. !! Prabhakar Raghavan (2006), ""The changing face of web search: algorithms, auctions and advertising"", Proceedings of the thirty-eighth annual ACM symposium on Theory of computing - STOC '06, p. 129,"
sixth annual acm symposium,"va Tardos (2004), ""Network games"", Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04, pp. !! "", Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04, p. 579,"
network games  proceedings,"va Tardos (2004), ""Network games"", Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04, pp."
va tardos,"va Tardos (2004), ""Network games"", Proceedings of the thirty-sixth annual ACM symposium on Theory of computing - STOC '04, pp."
seventh annual acm symposium,"Lance Fortnow (2005), ""Beyond NP: the work and legacy of Larry Stockmeyer"", Proceedings of the thirty-seventh annual ACM symposium on Theory of computing - STOC '05, p. 120,"
larry stockmeyer  proceedings,"Lance Fortnow (2005), ""Beyond NP: the work and legacy of Larry Stockmeyer"", Proceedings of the thirty-seventh annual ACM symposium on Theory of computing - STOC '05, p. 120,"
lance fortnow,"Lance Fortnow (2005), ""Beyond NP: the work and legacy of Larry Stockmeyer"", Proceedings of the thirty-seventh annual ACM symposium on Theory of computing - STOC '05, p. 120,"
beyond np,"Lance Fortnow (2005), ""Beyond NP: the work and legacy of Larry Stockmeyer"", Proceedings of the thirty-seventh annual ACM symposium on Theory of computing - STOC '05, p. 120,"
eighth annual acm symposium,"Prabhakar Raghavan (2006), ""The changing face of web search: algorithms, auctions and advertising"", Proceedings of the thirty-eighth annual ACM symposium on Theory of computing - STOC '06, p. 129,"
changing face,"Prabhakar Raghavan (2006), ""The changing face of web search: algorithms, auctions and advertising"", Proceedings of the thirty-eighth annual ACM symposium on Theory of computing - STOC '06, p. 129,"
advertising  proceedings,"Prabhakar Raghavan (2006), ""The changing face of web search: algorithms, auctions and advertising"", Proceedings of the thirty-eighth annual ACM symposium on Theory of computing - STOC '06, p. 129,"
prabhakar raghavan,"Prabhakar Raghavan (2006), ""The changing face of web search: algorithms, auctions and advertising"", Proceedings of the thirty-eighth annual ACM symposium on Theory of computing - STOC '06, p. 129,"
expression computational intelligence,The expression computational intelligence (CI) usually refers to the ability of a computer to learn a specific task from data or experimental observation.
usually refers,"By itself, the term ""digital image"" usually refers to raster images or bitmapped images (as opposed to vector images). !! While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech. !! The expression computational intelligence (CI) usually refers to the ability of a computer to learn a specific task from data or experimental observation."
specific task,The expression computational intelligence (CI) usually refers to the ability of a computer to learn a specific task from data or experimental observation.
experimental observation,The expression computational intelligence (CI) usually refers to the ability of a computer to learn a specific task from data or experimental observation.
commonly accepted definition,"Even though it is commonly considered a synonym of soft computing, there is still no commonly accepted definition of computational intelligence."
even though,"Even though it is commonly considered a synonym of soft computing, there is still no commonly accepted definition of computational intelligence. !! Parallel coordinates were often said to be invented by Philbert Maurice d'Ocagne in 1885, but even though the words ""Coordonnes parallles"" appear in the book title this work has nothing to do with the visualization techniques of the same name; the book only describes a method of coordinate transformation. !! Whether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean. !! Temporal coding allows the sequence 000111000111 to mean something different from 001100110011, even though the mean firing rate is the same for both sequences."
process might simply,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
mathematical reasoning,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
traditional modelling,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
inspired computational methodologies,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
processes might,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
world problems,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature. !! Although the idea of trajectory optimization has been around for hundreds of years (calculus of variations, brachystochrone problem), it only became practical for real-world problems with the advent of the computer."
address complex real,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
might contain,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
computational intelligence therefore provides solutions,Computational Intelligence therefore provides solutions for such problems.
main principles,"Except those main principles, currently popular approaches include biologically inspired algorithms such as swarm intelligence and artificial immune systems, which can be seen as a part of evolutionary computation, image processing, data mining, natural language processing, and artificial intelligence, which tends to be confused with Computational Intelligence."
target value,Binary search compares the target value to the middle element of the array. !! An associative classifier (AC) is a kind of supervised learning model that uses association rules to assign a target value. !! A linear search sequentially checks each element of the list until it finds an element that matches the target value.
uses association rules,An associative classifier (AC) is a kind of supervised learning model that uses association rules to assign a target value.
first graphical standard,The 3D Core Graphics System (or Core) was the first graphical standard to be developed.
osaka university developed,"In the field of realistic rendering, Japan's Osaka University developed the LINKS-1 Computer Graphics System, a supercomputer that used up to 257 Zilog Z8001 microprocessors, in 1982, for the purpose of rendering realistic 3D computer graphics."
rendering realistic 3d computer graphics,"In the field of realistic rendering, Japan's Osaka University developed the LINKS-1 Computer Graphics System, a supercomputer that used up to 257 Zilog Z8001 microprocessors, in 1982, for the purpose of rendering realistic 3D computer graphics."
1 computer graphics system,"In the field of realistic rendering, Japan's Osaka University developed the LINKS-1 Computer Graphics System, a supercomputer that used up to 257 Zilog Z8001 microprocessors, in 1982, for the purpose of rendering realistic 3D computer graphics."
257 zilog z8001 microprocessors,"In the field of realistic rendering, Japan's Osaka University developed the LINKS-1 Computer Graphics System, a supercomputer that used up to 257 Zilog Z8001 microprocessors, in 1982, for the purpose of rendering realistic 3D computer graphics."
realistic rendering,"In the field of realistic rendering, Japan's Osaka University developed the LINKS-1 Computer Graphics System, a supercomputer that used up to 257 Zilog Z8001 microprocessors, in 1982, for the purpose of rendering realistic 3D computer graphics."
complex images,Primitives are basic units which a graphics system may combine to create more complex images or models.
basic units,Primitives are basic units which a graphics system may combine to create more complex images or models.
graphics system may combine,Primitives are basic units which a graphics system may combine to create more complex images or models.
bruce irons,"A frontal solver, conceived by Bruce Irons, is an approach to solving sparse linear systems which is used extensively in finite element analysis."
finite element analysis,"A frontal solver, conceived by Bruce Irons, is an approach to solving sparse linear systems which is used extensively in finite element analysis."
solving sparse linear systems,"A frontal solver, conceived by Bruce Irons, is an approach to solving sparse linear systems which is used extensively in finite element analysis."
used extensively,"A frontal solver, conceived by Bruce Irons, is an approach to solving sparse linear systems which is used extensively in finite element analysis. !! CFT (Cross File Transfer) (product name: Axway Transfer CFT) is a secure computer file transfer program and protocol from Axway Inc, used extensively in Finance and banking industries in Europe, by companies like AG2R La Mondiale and Swiss Post. !! Three key terms are used extensively in relational database models: relations, attributes, and domains."
element matrices,A frontal solver builds a LU or Cholesky decomposition of a sparse matrix given as the assembly of element matrices by assembling the matrix and eliminating equations only on a subset of elements at a time.
eliminating equations,A frontal solver builds a LU or Cholesky decomposition of a sparse matrix given as the assembly of element matrices by assembling the matrix and eliminating equations only on a subset of elements at a time.
sparse matrix given,A frontal solver builds a LU or Cholesky decomposition of a sparse matrix given as the assembly of element matrices by assembling the matrix and eliminating equations only on a subset of elements at a time.
uses several independent fronts,A multifrontal solver of Duff and Reid is an improvement of the frontal solver that uses several independent fronts at the same time.
hardware architecture devoted,"Fuzzy Markup Language (FML) is a specific purpose markup language based on XML, used for describing the structure and behavior of a fuzzy system independently of the hardware architecture devoted to host and run it."
fuzzy system independently,"Fuzzy Markup Language (FML) is a specific purpose markup language based on XML, used for describing the structure and behavior of a fuzzy system independently of the hardware architecture devoted to host and run it."
specific purpose markup language based,"Fuzzy Markup Language (FML) is a specific purpose markup language based on XML, used for describing the structure and behavior of a fuzzy system independently of the hardware architecture devoted to host and run it."
fuzzy markup language edited,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
hui wang,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
complete overview,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
vincenzo loia,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
series studies,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
shing lee,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
giovanni acampora,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
related applications,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
book titled,"A complete overview of FML and related applications can be found in the book titled On the power of Fuzzy Markup Language edited by Giovanni Acampora, Chang-Shing Lee, Vincenzo Loia and Mei-Hui Wang, and published by Springer in the series Studies on Fuzziness and Soft Computing."
diet assessment based,Diet assessment based on type-2 fuzzy ontology and fuzzy markup language.
2 fuzzy ontology,Diet assessment based on type-2 fuzzy ontology and fuzzy markup language.
geometric variation inferred,The point distribution model is a model for representing the mean geometry of a shape and some statistical modes of geometric variation inferred from a training set of shapes.
taylor et al,"The point distribution model concept has been developed by Cootes, Taylor et al."
point distribution model concept,"The point distribution model concept has been developed by Cootes, Taylor et al."
point distribution models rely,Point distribution models rely on landmark points.
landmark points,Point distribution models rely on landmark points.
numerically unstable,"In mathematics, a stiff equation is a differential equation for which certain numerical methods for solving the equation are numerically unstable, unless the step size is taken to be extremely small. !! The biconjugate gradient method is numerically unstable (compare to the biconjugate gradient stabilized method), but very important from a theoretical point of view."
biconjugate gradient stabilized method,"In numerical linear algebra, the biconjugate gradient stabilized method, often abbreviated as BiCGSTAB, is an iterative method developed by H. A. van der Vorst for the numerical solution of nonsymmetric linear systems. !! The biconjugate gradient method is numerically unstable (compare to the biconjugate gradient stabilized method), but very important from a theoretical point of view."
theoretical point,"The biconjugate gradient method is numerically unstable (compare to the biconjugate gradient stabilized method), but very important from a theoretical point of view."
software architect simon brown,C4 model was created by the software architect Simon Brown between 2006 and 2011 on the roots of Unified Modelling Language (UML) and the 4+1 architectural view model.
1 architectural view model,C4 model was created by the software architect Simon Brown between 2006 and 2011 on the roots of Unified Modelling Language (UML) and the 4+1 architectural view model.
showing multiple points,"C4 model documents the architecture of a software system, by showing multiple points of view that explain the decomposition of a system into containers and components, the relationship between these elements, and, where appropriate, the relation with its users."
c4 model relies,"C4 model relies at this level on existing notations such as Unified Modelling Language (UML), Entity Relation Diagrams (ERD) or diagrams generated by Integrated Development Environments (IDE)."
integrated development environments,"C4 model relies at this level on existing notations such as Unified Modelling Language (UML), Entity Relation Diagrams (ERD) or diagrams generated by Integrated Development Environments (IDE)."
existing notations,"C4 model relies at this level on existing notations such as Unified Modelling Language (UML), Entity Relation Diagrams (ERD) or diagrams generated by Integrated Development Environments (IDE)."
uml  entity relation diagrams,"C4 model relies at this level on existing notations such as Unified Modelling Language (UML), Entity Relation Diagrams (ERD) or diagrams generated by Integrated Development Environments (IDE)."
diagrams generated,"C4 model relies at this level on existing notations such as Unified Modelling Language (UML), Entity Relation Diagrams (ERD) or diagrams generated by Integrated Development Environments (IDE)."
c4 model uses 5 basic diagramming elements,"For level 1 to 3, the C4 model uses 5 basic diagramming elements: persons, software systems, containers, components and relationships."
physical addresses,"A memory management unit (MMU), sometimes called paged memory management unit (PMMU), is a computer hardware unit having all memory references passed through itself, primarily performing the translation of virtual memory addresses to physical addresses."
primarily performing,"A memory management unit (MMU), sometimes called paged memory management unit (PMMU), is a computer hardware unit having all memory references passed through itself, primarily performing the translation of virtual memory addresses to physical addresses."
original sun 1 memory management unit,"It includes the original Sun 1 memory management unit that provides address translation, memory protection, memory sharing and memory allocation for multiple processes running on the CPU."
provides address translation,"It includes the original Sun 1 memory management unit that provides address translation, memory protection, memory sharing and memory allocation for multiple processes running on the CPU."
denotational semantics,"In programming language semantics, normalisation by evaluation (NBE) is a style of obtaining the normal form of terms in the -calculus by appealing to their denotational semantics."
solve tridiagonal systems,"In numerical linear algebra, the tridiagonal matrix algorithm, also known as the Thomas algorithm (named after Llewellyn Thomas), is a simplified form of Gaussian elimination that can be used to solve tridiagonal systems of equations."
llewellyn thomas,"In numerical linear algebra, the tridiagonal matrix algorithm, also known as the Thomas algorithm (named after Llewellyn Thomas), is a simplified form of Gaussian elimination that can be used to solve tridiagonal systems of equations."
thomas algorithm,"In numerical linear algebra, the tridiagonal matrix algorithm, also known as the Thomas algorithm (named after Llewellyn Thomas), is a simplified form of Gaussian elimination that can be used to solve tridiagonal systems of equations."
simplified form,"The stable model semantics, which is used to give a semantics to logic programming with negation as failure, can be seen as a simplified form of autoepistemic logic. !! In numerical linear algebra, the tridiagonal matrix algorithm, also known as the Thomas algorithm (named after Llewellyn Thomas), is a simplified form of Gaussian elimination that can be used to solve tridiagonal systems of equations."
done efficiently,"This can be done efficiently if both solutions are computed at once, as the forward portion of the pure tridiagonal matrix algorithm can be shared."
pure tridiagonal matrix algorithm,"This can be done efficiently if both solutions are computed at once, as the forward portion of the pure tridiagonal matrix algorithm can be shared."
forward portion,"This can be done efficiently if both solutions are computed at once, as the forward portion of the pure tridiagonal matrix algorithm can be shared."
switching circuit theory,"Switching circuit theory provided the mathematical foundations and tools for digital system design in almost all areas of modern technology. !! Switching circuit theory is applicable to the design of telephone systems, computers, and similar systems. !! Switching circuit theory is the mathematical study of the properties of networks of idealized switches."
idealized switches,Switching circuit theory is the mathematical study of the properties of networks of idealized switches.
similar systems,"Switching circuit theory is applicable to the design of telephone systems, computers, and similar systems."
telephone systems,"Switching circuit theory is applicable to the design of telephone systems, computers, and similar systems."
switching circuit theory provided,Switching circuit theory provided the mathematical foundations and tools for digital system design in almost all areas of modern technology.
mathematical foundations,Switching circuit theory provided the mathematical foundations and tools for digital system design in almost all areas of modern technology.
modern technology,Switching circuit theory provided the mathematical foundations and tools for digital system design in almost all areas of modern technology.
systems design,"Systems design could be seen as the application of systems theory to product development. !! Systems design is therefore the process of defining and developing systems to satisfy specified requirements of the user. !! Until the 1990s, systems design had a crucial and respected role in the data processing industry. !! Systems design is the process of defining the architecture, product design, modules, interfaces, and data for a system to satisfy specified requirements."
satisfy specified requirements,"Systems design is therefore the process of defining and developing systems to satisfy specified requirements of the user. !! Systems design is the process of defining the architecture, product design, modules, interfaces, and data for a system to satisfy specified requirements."
systems design could,Systems design could be seen as the application of systems theory to product development.
product development,Systems design could be seen as the application of systems theory to product development.
developing systems,Systems design is therefore the process of defining and developing systems to satisfy specified requirements of the user.
respected role,"Until the 1990s, systems design had a crucial and respected role in the data processing industry."
data processing industry,"Until the 1990s, systems design had a crucial and respected role in the data processing industry."
key greater,"In computer science, a binary search tree (BST), also called an ordered or sorted binary tree, is a rooted binary tree data structure whose internal nodes each store a key greater than all the keys in the node's left subtree and less than those in its right subtree."
bst  also called,"In computer science, a binary search tree (BST), also called an ordered or sorted binary tree, is a rooted binary tree data structure whose internal nodes each store a key greater than all the keys in the node's left subtree and less than those in its right subtree."
right subtree,"In computer science, a binary search tree (BST), also called an ordered or sorted binary tree, is a rooted binary tree data structure whose internal nodes each store a key greater than all the keys in the node's left subtree and less than those in its right subtree."
left subtree,"In computer science, a binary search tree (BST), also called an ordered or sorted binary tree, is a rooted binary tree data structure whose internal nodes each store a key greater than all the keys in the node's left subtree and less than those in its right subtree."
directly proportional,The time complexity of operations on the binary search tree is directly proportional to the height of the tree.
data items,"Data architectures address data in storage, data in use, and data in motion; descriptions of data stores, data groups, and data items; and mappings of those data artifacts to data qualities, applications, locations, etc. !! Binary search trees allow binary search for fast lookup, addition, and removal of data items, and can be used to implement dynamic sets and lookup tables."
fast lookup,"Binary search trees allow binary search for fast lookup, addition, and removal of data items, and can be used to implement dynamic sets and lookup tables."
implement dynamic sets,"Binary search trees allow binary search for fast lookup, addition, and removal of data items, and can be used to implement dynamic sets and lookup tables."
several variations,The performance of a binary search tree is dependent on the order of insertion of the nodes into the tree; several variations of the binary search tree can be built with guaranteed worst-case performance.
case performance,The performance of a binary search tree is dependent on the order of insertion of the nodes into the tree; several variations of the binary search tree can be built with guaranteed worst-case performance.
guaranteed worst,The performance of a binary search tree is dependent on the order of insertion of the nodes into the tree; several variations of the binary search tree can be built with guaranteed worst-case performance.
discovered independently,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
andrew donald booth,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
several researchers,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
david wheeler,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
storing labeled data,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
magnetic tapes,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
andrew colin,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
conway berners,"The binary search tree algorithm was discovered independently by several researchers, including P. F. Windley, Andrew Donald Booth, Andrew Colin, Thomas N. Hibbard, and attributed to Conway Berners-Lee and David Wheeler, in 1960 for storing labeled data in magnetic tapes."
order reduction,"In computer science, a first-order reduction is a very strong type of reduction between two computational problems in computational complexity theory. !! A first-order reduction is a reduction where each component is restricted to be in the class FO of problems calculable in first-order logic."
two computational problems,"In computer science, a first-order reduction is a very strong type of reduction between two computational problems in computational complexity theory."
strong type,"In computer science, a first-order reduction is a very strong type of reduction between two computational problems in computational complexity theory."
problems calculable,A first-order reduction is a reduction where each component is restricted to be in the class FO of problems calculable in first-order logic.
class fo,A first-order reduction is a reduction where each component is restricted to be in the class FO of problems calculable in first-order logic.
order reductions,"Many important complexity classes are closed under first-order reductions, and many of the traditional complete problems are first-order complete as well (Immerman 1999 p. 49-50). !! , the first-order reductions are stronger reductions than the logspace reductions."
stronger reductions,", the first-order reductions are stronger reductions than the logspace reductions."
many important complexity classes,"Many important complexity classes are closed under first-order reductions, and many of the traditional complete problems are first-order complete as well (Immerman 1999 p. 49-50)."
order complete,"Many important complexity classes are closed under first-order reductions, and many of the traditional complete problems are first-order complete as well (Immerman 1999 p. 49-50)."
traditional complete problems,"Many important complexity classes are closed under first-order reductions, and many of the traditional complete problems are first-order complete as well (Immerman 1999 p. 49-50)."
separate executions,"A deterministic encryption scheme (as opposed to a probabilistic encryption scheme) is a cryptosystem which always produces the same ciphertext for a given plaintext and key, even over separate executions of the encryption algorithm."
always produces,"A deterministic encryption scheme (as opposed to a probabilistic encryption scheme) is a cryptosystem which always produces the same ciphertext for a given plaintext and key, even over separate executions of the encryption algorithm."
given plaintext,"A deterministic encryption scheme (as opposed to a probabilistic encryption scheme) is a cryptosystem which always produces the same ciphertext for a given plaintext and key, even over separate executions of the encryption algorithm."
without encryption padding,"Examples of deterministic encryption algorithms include RSA cryptosystem (without encryption padding), and many block ciphers when used in ECB mode or with a constant initialization vector."
many block ciphers,"Examples of deterministic encryption algorithms include RSA cryptosystem (without encryption padding), and many block ciphers when used in ECB mode or with a constant initialization vector."
constant initialization vector,"Examples of deterministic encryption algorithms include RSA cryptosystem (without encryption padding), and many block ciphers when used in ECB mode or with a constant initialization vector."
may recognize known ciphertexts,"Deterministic encryption can leak information to an eavesdropper, who may recognize known ciphertexts."
leak information,"Deterministic encryption can leak information to an eavesdropper, who may recognize known ciphertexts."
semantically secure,"While deterministic encryption schemes can never be semantically secure, they have some advantages over probabilistic schemes."
one primary motivation,One primary motivation for the use of deterministic encryption is the efficient searching of encrypted data.
converts strings,"A programming language is any set of rules that converts strings, or graphical program elements in the case of visual programming languages, to various kinds of machine code output."
implement algorithms,"Programming languages are one kind of computer language, and are used in computer programming to implement algorithms."
one kind,"Programming languages are one kind of computer language, and are used in computer programming to implement algorithms."
programming languages consist,Most programming languages consist of instructions for computers.
general programming languages,"There are programmable machines that use a set of specific instructions, rather than general programming languages."
specific instructions,"There are programmable machines that use a set of specific instructions, rather than general programming languages."
created every year,"Thousands of different programming languages have been created, and more are being created every year."
different programming languages,"Thousands of different programming languages have been created, and more are being created every year."
numerically solve certain differential equations,"Spectral methods are a class of techniques used in applied mathematics and scientific computing to numerically solve certain differential equations, potentially involving the use of the fast Fourier transform."
potentially involving,"Spectral methods are a class of techniques used in applied mathematics and scientific computing to numerically solve certain differential equations, potentially involving the use of the fast Fourier transform."
main difference,"Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains. !! The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible."
small subdomains,"Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains."
whole domain,"Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains."
spectral methods use basis functions,"Spectral methods and finite element methods are closely related and built on the same ideas; the main difference between them is that spectral methods use basis functions that are nonzero over the whole domain, while finite element methods use basis functions that are nonzero only on small subdomains."
global approach,"In other words, spectral methods take on a global approach while finite element methods use a local approach."
spectral methods take,"In other words, spectral methods take on a global approach while finite element methods use a local approach."
local approach,"In other words, spectral methods take on a global approach while finite element methods use a local approach."
finite element methods use,"In other words, spectral methods take on a global approach while finite element methods use a local approach."
excellent error properties,"Partially for this reason, spectral methods have excellent error properties, with the so-called ""exponential convergence"" being the fastest possible, when the solution is smooth."
fastest possible,"Partially for this reason, spectral methods have excellent error properties, with the so-called ""exponential convergence"" being the fastest possible, when the solution is smooth. !! Primitive data types which are native to the processor have a one-to-one correspondence with objects in the computer's memory, and operations on these types are often the fastest possible in most cases."
solve ordinary differential equations,"Spectral methods can be used to solve ordinary differential equations (ODEs), partial differential equations (PDEs) and eigenvalue problems involving differential equations."
odes  partial differential equations,"Spectral methods can be used to solve ordinary differential equations (ODEs), partial differential equations (PDEs) and eigenvalue problems involving differential equations."
eigenvalue problems involving differential equations,"Spectral methods can be used to solve ordinary differential equations (ODEs), partial differential equations (PDEs) and eigenvalue problems involving differential equations."
hash join designed,The symmetric hash join is a special type of hash join designed for data streams.
special type,"In quantum computing, a graph state is a special type of multi-qubit state that can be represented by a graph. !! In the mathematical field of combinatorics, a bent function is a special type of Boolean function which is maximally non-linear; it is as different as possible from the set of all linear and affine functions when measured by Hamming distance between truth tables. !! The symmetric hash join is a special type of hash join designed for data streams."
bit instruction set architecture,"The Advanced Computing Environment (ACE) was defined by an industry consortium in the early 1990s to be the next generation commodity computing platform, the successor to personal computers based on Intel's 32-bit instruction set architecture."
personal computers based,"The Advanced Computing Environment (ACE) was defined by an industry consortium in the early 1990s to be the next generation commodity computing platform, the successor to personal computers based on Intel's 32-bit instruction set architecture."
industry consortium,"The Advanced Computing Environment (ACE) was defined by an industry consortium in the early 1990s to be the next generation commodity computing platform, the successor to personal computers based on Intel's 32-bit instruction set architecture."
next generation commodity computing platform,"The Advanced Computing Environment (ACE) was defined by an industry consortium in the early 1990s to be the next generation commodity computing platform, the successor to personal computers based on Intel's 32-bit instruction set architecture."
simulate human affects,"Affective computing is the study and development of systems and devices that can recognize, interpret, process, and simulate human affects."
far back,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
early philosophical inquiries,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
mit press,"Android Epistemology, Cambridge: AAAI Press / MIT Press. !! Thinking about Android Epistemology, Cambridge: AAAI Press / MIT Press. !! While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
core ideas,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
rosalind picard,"Affectiva is a company (co-founded by Rosalind Picard and Rana El Kaliouby) directly related to affective computing and aims at investigating solutions and software for facial affect detection. !! While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
modern branch,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
field may,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
book affective computing published,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
computer science originated,"While some core ideas in the field may be traced as far back as to early philosophical inquiries into emotion, the more modern branch of computer science originated with Rosalind Picard's 1995 paper on affective computing and her book Affective Computing published by MIT Press."
another area within affective computing,Another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions.
convincingly simulating emotions,Another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions.
computational devices proposed,Another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions.
exhibit either innate emotional capabilities,Another area within affective computing is the design of computational devices proposed to exhibit either innate emotional capabilities or that are capable of convincingly simulating emotions.
directly related,"Affectiva is a company (co-founded by Rosalind Picard and Rana El Kaliouby) directly related to affective computing and aims at investigating solutions and software for facial affect detection. !! However, the TLB cache is part of the memory management unit (MMU) and not directly related to the CPU caches. !! Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures."
investigating solutions,Affectiva is a company (co-founded by Rosalind Picard and Rana El Kaliouby) directly related to affective computing and aims at investigating solutions and software for facial affect detection.
facial affect detection,Affectiva is a company (co-founded by Rosalind Picard and Rana El Kaliouby) directly related to affective computing and aims at investigating solutions and software for facial affect detection.
rana el kaliouby,Affectiva is a company (co-founded by Rosalind Picard and Rana El Kaliouby) directly related to affective computing and aims at investigating solutions and software for facial affect detection.
learning state,"Using affective computing technology, computers can judge the learners' affection and learning state by recognizing their facial expressions."
facial expressions,"Using affective computing technology, computers can judge the learners' affection and learning state by recognizing their facial expressions."
using affective computing technology,"Using affective computing technology, computers can judge the learners' affection and learning state by recognizing their facial expressions."
generates animated imagery based,"Music visualization or music visualisation, a feature found in electronic music visualizers and media player software, generates animated imagery based on a piece of music."
feature found,"Music visualization or music visualisation, a feature found in electronic music visualizers and media player software, generates animated imagery based on a piece of music."
electronic music visualizers,"Music visualization or music visualisation, a feature found in electronic music visualizers and media player software, generates animated imagery based on a piece of music."
effective music visualization aims,Effective music visualization aims to attain a high degree of visual correlation between a musical track's spectral characteristics such as frequency and amplitude and the objects or components of the visual image being rendered and displayed.
musical track,Effective music visualization aims to attain a high degree of visual correlation between a musical track's spectral characteristics such as frequency and amplitude and the objects or components of the visual image being rendered and displayed.
visual correlation,Effective music visualization aims to attain a high degree of visual correlation between a musical track's spectral characteristics such as frequency and amplitude and the objects or components of the visual image being rendered and displayed.
previous existing pre,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
example music videos,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
generated music plus visualization combinations,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
time generated,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
music visualization systems,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
audio every time,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
create different visualizations,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
laser lighting display,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
always show,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
another possible distinction,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
music videos,"Another possible distinction is seen by some in the ability of some music visualization systems (such as Geiss' MilkDrop) to create different visualizations for each song or audio every time the program is run, in contrast to other forms of music visualization (such as music videos or a laser lighting display) which always show the same visualization."
6th dimensions,"Music visualization may be achieved in a 2D or a 3D coordinate system where up to 6 dimensions can be modified, the 4th, 5th and 6th dimensions being color, intensity and transparency."
3d coordinate system,"Music visualization may be achieved in a 2D or a 3D coordinate system where up to 6 dimensions can be modified, the 4th, 5th and 6th dimensions being color, intensity and transparency."
music visualization may,"Music visualization may be achieved in a 2D or a 3D coordinate system where up to 6 dimensions can be modified, the 4th, 5th and 6th dimensions being color, intensity and transparency."
use artificial intelligence,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents."
made machines,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents."
otherwise known,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents."
artificial intelligence concerned,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents. !! Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data."
ensuring moral behaviors,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents."
machine ethics differs,Machine ethics differs from other ethical fields related to engineering and technology.
ethical fields related,Machine ethics differs from other ethical fields related to engineering and technology.
human use,"Machine ethics should not be confused with computer ethics, which focuses on human use of computers."
responsibility  however,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
one thing,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
embody values,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
1987 ai magazine article,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
evolved since,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
mitchell waldrop,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
programmers consciously intend,"Although the definition of ""Machine Ethics"" has evolved since, the term was coined by Mitchell Waldrop in the 1987 AI Magazine article ""A Question of Responsibility"":""However, one thing that is apparent from the above discussion is that intelligent machines will embody values, assumptions, and purposes, whether their programmers consciously intend them to or not."
asimovs three laws,"Perhaps what we need is, in fact, a theory and practice of machine ethics, in the spirit of Asimovs three laws of robotics. """
randomized algorithm whose output may,"In computing, a Monte Carlo algorithm is a randomized algorithm whose output may be incorrect with a certain (typically small) probability."
minimum feedback arc set,Two examples of such algorithms are KargerStein algorithm and Monte Carlo algorithm for minimum Feedback arc set.
two examples,Two examples of such algorithms are KargerStein algorithm and Monte Carlo algorithm for minimum Feedback arc set.
incorrect answer,Las Vegas algorithms are a dual of Monte Carlo algorithms that never return an incorrect answer.
never return,Las Vegas algorithms are a dual of Monte Carlo algorithms that never return an incorrect answer.
eventually give,"If there is a procedure for verifying whether the answer given by a Monte Carlo algorithm is correct, and the probability of a correct answer is bounded above zero, then with probability one running the algorithm repeatedly while testing the answers will eventually give a correct answer."
verifying whether,"If there is a procedure for verifying whether the answer given by a Monte Carlo algorithm is correct, and the probability of a correct answer is bounded above zero, then with probability one running the algorithm repeatedly while testing the answers will eventually give a correct answer."
probability one running,"If there is a procedure for verifying whether the answer given by a Monte Carlo algorithm is correct, and the probability of a correct answer is bounded above zero, then with probability one running the algorithm repeatedly while testing the answers will eventually give a correct answer."
algorithm repeatedly,"If there is a procedure for verifying whether the answer given by a Monte Carlo algorithm is correct, and the probability of a correct answer is bounded above zero, then with probability one running the algorithm repeatedly while testing the answers will eventually give a correct answer."
correct answer,"If there is a procedure for verifying whether the answer given by a Monte Carlo algorithm is correct, and the probability of a correct answer is bounded above zero, then with probability one running the algorithm repeatedly while testing the answers will eventually give a correct answer."
answer given,"If there is a procedure for verifying whether the answer given by a Monte Carlo algorithm is correct, and the probability of a correct answer is bounded above zero, then with probability one running the algorithm repeatedly while testing the answers will eventually give a correct answer."
answer returned,"While the answer returned by a deterministic algorithm is always expected to be correct, this is not the case for Monte Carlo algorithms."
always expected,"While the answer returned by a deterministic algorithm is always expected to be correct, this is not the case for Monte Carlo algorithms."
remotely connecting,Remote access policy is a document which outlines and defines acceptable methods of remotely connecting to the internal network.
remote access policy,This remote access policy specifies how remote users can connect to the main organizational network and the requirements for each of their systems before they are allowed to connect. !! Remote access policy is a document which outlines and defines acceptable methods of remotely connecting to the internal network. !! Cable modemThis remote access policy defines standards for connecting to the organizational network and security standards for computers that are allowed to connect to the organizational network.
defines acceptable methods,Remote access policy is a document which outlines and defines acceptable methods of remotely connecting to the internal network.
security standards,Cable modemThis remote access policy defines standards for connecting to the organizational network and security standards for computers that are allowed to connect to the organizational network.
remote users,This remote access policy specifies how remote users can connect to the main organizational network and the requirements for each of their systems before they are allowed to connect.
main organizational network,This remote access policy specifies how remote users can connect to the main organizational network and the requirements for each of their systems before they are allowed to connect.
remote access policy specifies,This remote access policy specifies how remote users can connect to the main organizational network and the requirements for each of their systems before they are allowed to connect.
stores multiple elements,"In computer programming, an unrolled linked list is a variation on the linked list which stores multiple elements in each node."
primary benefits,One of the primary benefits of unrolled linked lists is decreased storage requirements.
decreased storage requirements,One of the primary benefits of unrolled linked lists is decreased storage requirements.
unrolled linked lists effectively spread,Unrolled linked lists effectively spread the overhead v over a number of elements of the list.
many popular memory allocators,"Moreover, many popular memory allocators will keep a small amount of metadata for each node allocated, increasing the effective overhead v. Both of these make unrolled linked lists more attractive."
effective overhead v,"Moreover, many popular memory allocators will keep a small amount of metadata for each node allocated, increasing the effective overhead v. Both of these make unrolled linked lists more attractive."
make unrolled linked lists,"Moreover, many popular memory allocators will keep a small amount of metadata for each node allocated, increasing the effective overhead v. Both of these make unrolled linked lists more attractive."
node allocated,"Moreover, many popular memory allocators will keep a small amount of metadata for each node allocated, increasing the effective overhead v. Both of these make unrolled linked lists more attractive."
kth element,"Because unrolled linked list nodes each store a count next to the next field, retrieving the kth element of an unrolled linked list (indexing) can be done in n/m + 1 cache misses, up to a factor of m better than ordinary linked lists."
count next,"Because unrolled linked list nodes each store a count next to the next field, retrieving the kth element of an unrolled linked list (indexing) can be done in n/m + 1 cache misses, up to a factor of m better than ordinary linked lists."
ordinary linked lists,"Because unrolled linked list nodes each store a count next to the next field, retrieving the kth element of an unrolled linked list (indexing) can be done in n/m + 1 cache misses, up to a factor of m better than ordinary linked lists."
1 cache misses,"Because unrolled linked list nodes each store a count next to the next field, retrieving the kth element of an unrolled linked list (indexing) can be done in n/m + 1 cache misses, up to a factor of m better than ordinary linked lists."
unrolled linked list nodes,"Because unrolled linked list nodes each store a count next to the next field, retrieving the kth element of an unrolled linked list (indexing) can be done in n/m + 1 cache misses, up to a factor of m better than ordinary linked lists."
next field,"Because unrolled linked list nodes each store a count next to the next field, retrieving the kth element of an unrolled linked list (indexing) can be done in n/m + 1 cache misses, up to a factor of m better than ordinary linked lists."
human language,"Character encoding is the process of assigning numbers to graphical characters, especially the written characters of human language, allowing them to be stored, transmitted, and transformed using digital computers. !! Self-documenting code is ostensibly written using human-readable names, typically consisting of a phrase in a human language which reflects the symbol's meaning, such as article. !! Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data."
transformed using digital computers,"Character encoding is the process of assigning numbers to graphical characters, especially the written characters of human language, allowing them to be stored, transmitted, and transformed using digital computers."
written characters,"Character encoding is the process of assigning numbers to graphical characters, especially the written characters of human language, allowing them to be stored, transmitted, and transformed using digital computers."
assigning numbers,"Character encoding is the process of assigning numbers to graphical characters, especially the written characters of human language, allowing them to be stored, transmitted, and transformed using digital computers."
numerical values,"The numerical values that make up a character encoding are known as ""code points"" and collectively comprise a ""code space"", a ""code page"", or a ""character map""."
collectively comprise,"The numerical values that make up a character encoding are known as ""code points"" and collectively comprise a ""code space"", a ""code page"", or a ""character map""."
electronic form,Character encoding using internationally accepted standards permits worldwide interchange of text in electronic form.
american standard code,"Common examples of character encoding systems include Morse code, the Baudot code, the American Standard Code for Information Interchange (ASCII) and Unicode."
common examples,"Common examples of character encoding systems include Morse code, the Baudot code, the American Standard Code for Information Interchange (ASCII) and Unicode."
fairly well known,"Unicode, a well defined and extensible encoding system, has supplanted most earlier character encodings, but the path of code development to the present is fairly well known."
earlier character encodings,"Unicode, a well defined and extensible encoding system, has supplanted most earlier character encodings, but the path of code development to the present is fairly well known."
extensible encoding system,"Unicode, a well defined and extensible encoding system, has supplanted most earlier character encodings, but the path of code development to the present is fairly well known."
temperature phase,"In physics, topological order is a kind of order in the zero-temperature phase of matter (also known as quantum matter)."
quantum matter,"In physics, topological order is a kind of order in the zero-temperature phase of matter (also known as quantum matter)."
topological order,"Macroscopically, topological order is defined and described by robust ground state degeneracy and quantized non-Abelian geometric phases of degenerate ground states. !! States with different topological orders (or different patterns of long range entanglements) cannot change into each other without a phase transition. !! In physics, topological order is a kind of order in the zero-temperature phase of matter (also known as quantum matter). !! Microscopically, topological orders correspond to patterns of long-range quantum entanglement. !! Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc. !! In the field of computer science, a pre-topological order or pre-topological ordering of a directed graph is a linear ordering of its vertices such that if there is a directed path from vertex u to vertex v and v comes before u in the ordering, then there is also a directed path from vertex v to vertex u. !! A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
abelian geometric phases,"Macroscopically, topological order is defined and described by robust ground state degeneracy and quantized non-Abelian geometric phases of degenerate ground states."
degenerate ground states,"Macroscopically, topological order is defined and described by robust ground state degeneracy and quantized non-Abelian geometric phases of degenerate ground states."
robust ground state degeneracy,"Macroscopically, topological order is defined and described by robust ground state degeneracy and quantized non-Abelian geometric phases of degenerate ground states."
quantized non,"Macroscopically, topological order is defined and described by robust ground state degeneracy and quantized non-Abelian geometric phases of degenerate ground states."
topological orders correspond,"Microscopically, topological orders correspond to patterns of long-range quantum entanglement."
range quantum entanglement,"Microscopically, topological orders correspond to patterns of long-range quantum entanglement."
different patterns,States with different topological orders (or different patterns of long range entanglements) cannot change into each other without a phase transition.
long range entanglements,States with different topological orders (or different patterns of long range entanglements) cannot change into each other without a phase transition.
phase transition,States with different topological orders (or different patterns of long range entanglements) cannot change into each other without a phase transition.
cannot change,States with different topological orders (or different patterns of long range entanglements) cannot change into each other without a phase transition.
different topological orders,States with different topological orders (or different patterns of long range entanglements) cannot change into each other without a phase transition.
topological entanglement entropy,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
important device applications,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
entanglement origin,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
perfect conducting edge states,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
fermi statistics,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
abelian statistics,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
interesting properties,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
emergent gauge field,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
quantum information origin,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
various topologically ordered states,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
topological degeneracy,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
fractional statistics,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
elementary particles,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
suitable programming language,The use of optimization software requires that the function f is defined in a suitable programming language and connected at compile or run time to the optimization software.
optimization software requires,The use of optimization software requires that the function f is defined in a suitable programming language and connected at compile or run time to the optimization software.
computed value f,"The optimization software will deliver input values in A, the software module realizing f will deliver the computed value f(x) and, in some cases, additional information about the function like derivatives."
deliver input values,"The optimization software will deliver input values in A, the software module realizing f will deliver the computed value f(x) and, in some cases, additional information about the function like derivatives."
function like derivatives,"The optimization software will deliver input values in A, the software module realizing f will deliver the computed value f(x) and, in some cases, additional information about the function like derivatives."
additional information,"All this additional information, plus the original service data unit from the higher layer, constitutes the protocol data unit at this layer. !! The optimization software will deliver input values in A, the software module realizing f will deliver the computed value f(x) and, in some cases, additional information about the function like derivatives."
software module realizing f,"The optimization software will deliver input values in A, the software module realizing f will deliver the computed value f(x) and, in some cases, additional information about the function like derivatives."
following tables provide,The following tables provide a list of notable optimization software organized according to license and business model type.
business model type,The following tables provide a list of notable optimization software organized according to license and business model type.
notable optimization software organized according,The following tables provide a list of notable optimization software organized according to license and business model type.
astos aerospace trajectory optimization software,"ASTOS AeroSpace Trajectory Optimization Software for launcher, re-entry and generic aerospace problems."
generic aerospace problems,"ASTOS AeroSpace Trajectory Optimization Software for launcher, re-entry and generic aerospace problems."
unscrambler x product formulation,The Unscrambler X product formulation and process optimization software.
cluster centroid  serving,"k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster."
nearest mean,"k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster."
means clustering,"k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster."
partition n observations,"k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster."
observation belongs,"k-means clustering is a method of vector quantization, originally from signal processing, that aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean (cluster centers or cluster centroid), serving as a prototype of the cluster."
geometric median minimizes euclidean distances,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
means clustering minimizes within,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
cluster variances,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
difficult weber problem,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
regular euclidean distances,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
mean optimizes squared errors,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
find clusters,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
comparable spatial extent,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
use cluster centers,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
different shapes,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
gaussian mixture model allows clusters,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
means clustering tends,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
dimensional real vector,", xn), where each observation is a d-dimensional real vector, k-means clustering aims to partition the n observations into k ( n) sets S = {S1, S2, ."
means clustering aims,", xn), where each observation is a d-dimensional real vector, k-means clustering aims to partition the n observations into k ( n) sets S = {S1, S2, ."
means clustering algorithm,The Spherical k-means clustering algorithm is suitable for textual data.
probabilistic roadmap methods,Stochastic roadmap simulation is inspired by probabilistic roadmap methods (PRM) developed for robot motion planning.
robot motion planning,Stochastic roadmap simulation is inspired by probabilistic roadmap methods (PRM) developed for robot motion planning.
simultaneously examining multiple pathways,Stochastic roadmap simulation is used to explore the kinetics of molecular motion by simultaneously examining multiple pathways in the roadmap.
molecular motion,"Stochastic roadmap simulation is used to explore the kinetics of molecular motion by simultaneously examining multiple pathways in the roadmap. !! Ensemble properties of molecular motion (e. g. , probability of folding (PFold), escape time in ligand-protein binding) is computed efficiently and accurately with stochastic roadmap simulation."
protein binding,"Ensemble properties of molecular motion (e. g. , probability of folding (PFold), escape time in ligand-protein binding) is computed efficiently and accurately with stochastic roadmap simulation."
pfold  escape time,"Ensemble properties of molecular motion (e. g. , probability of folding (PFold), escape time in ligand-protein binding) is computed efficiently and accurately with stochastic roadmap simulation."
ensemble properties,"Ensemble properties of molecular motion (e. g. , probability of folding (PFold), escape time in ligand-protein binding) is computed efficiently and accurately with stochastic roadmap simulation."
computed efficiently,"Ensemble properties of molecular motion (e. g. , probability of folding (PFold), escape time in ligand-protein binding) is computed efficiently and accurately with stochastic roadmap simulation."
learning method,"In machine learning, lazy learning is a learning method in which generalization of the training data is, in theory, delayed until a query is made to the system, as opposed to eager learning, where the system tries to generalize the training data before receiving queries."
receiving queries,"In machine learning, lazy learning is a learning method in which generalization of the training data is, in theory, delayed until a query is made to the system, as opposed to eager learning, where the system tries to generalize the training data before receiving queries."
system tries,"In machine learning, lazy learning is a learning method in which generalization of the training data is, in theory, delayed until a query is made to the system, as opposed to eager learning, where the system tries to generalize the training data before receiving queries."
online recommendation systems  people,"The primary motivation for employing lazy learning, as in the K-nearest neighbors algorithm, used by online recommendation systems (""people who viewed/purchased/listened to this movie/item/tune also ."
primary motivation,"The primary motivation for employing lazy learning, as in the K-nearest neighbors algorithm, used by online recommendation systems (""people who viewed/purchased/listened to this movie/item/tune also ."
employing lazy learning,"The primary motivation for employing lazy learning, as in the K-nearest neighbors algorithm, used by online recommendation systems (""people who viewed/purchased/listened to this movie/item/tune also ."
tune also,"The primary motivation for employing lazy learning, as in the K-nearest neighbors algorithm, used by online recommendation systems (""people who viewed/purchased/listened to this movie/item/tune also ."
approximated locally,"Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain. !! The main advantage gained in employing a lazy learning method is that the target function will be approximated locally, such as in the k-nearest neighbor algorithm."
main advantage gained,"The main advantage gained in employing a lazy learning method is that the target function will be approximated locally, such as in the k-nearest neighbor algorithm."
target function,"Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain. !! The main advantage gained in employing a lazy learning method is that the target function will be approximated locally, such as in the k-nearest neighbor algorithm."
lazy learning systems,"Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain."
simultaneously solve multiple problems,"Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain."
deal successfully,"Because the target function is approximated locally for each query to the system, lazy learning systems can simultaneously solve multiple problems and deal successfully with changes in the problem domain."
advance soon becomes obsolete,"In practice, as stated earlier, lazy learning is applied to situations where any learning performed in advance soon becomes obsolete because of changes in the data."
stated earlier,"In practice, as stated earlier, lazy learning is applied to situations where any learning performed in advance soon becomes obsolete because of changes in the data."
learning performed,"In practice, as stated earlier, lazy learning is applied to situations where any learning performed in advance soon becomes obsolete because of changes in the data."
also called double playfair,"The Two-square cipher, also called double Playfair, is a manual symmetric encryption technique."
square cipher,"The two-square cipher is not described in some other 20th century popular cryptography books e. g. by Helen Fouch Gaines (1939) or William Maxwell Bowers (1959), although both describe the Playfair cipher and four-square cipher. !! A good tutorial on reconstructing the key for a two-square cipher can be found in chapter 7, ""Solution to Polygraphic Substitution Systems,"" of Field Manual 34-40-2, produced by the United States Army. !! Like most pre-modern era ciphers, the two-square cipher can be easily cracked if there is enough text. !! The Two-square cipher, also called double Playfair, is a manual symmetric encryption technique."
manual symmetric encryption technique,"The Two-square cipher, also called double Playfair, is a manual symmetric encryption technique."
william maxwell bowers,"The two-square cipher is not described in some other 20th century popular cryptography books e. g. by Helen Fouch Gaines (1939) or William Maxwell Bowers (1959), although both describe the Playfair cipher and four-square cipher."
helen fouch gaines,"The two-square cipher is not described in some other 20th century popular cryptography books e. g. by Helen Fouch Gaines (1939) or William Maxwell Bowers (1959), although both describe the Playfair cipher and four-square cipher."
20th century popular cryptography books e,"The two-square cipher is not described in some other 20th century popular cryptography books e. g. by Helen Fouch Gaines (1939) or William Maxwell Bowers (1959), although both describe the Playfair cipher and four-square cipher."
square cipher uses two 5x5 matrices,"The two-square cipher uses two 5x5 matrices and comes in two varieties, horizontal and vertical."
two varieties,"The two-square cipher uses two 5x5 matrices and comes in two varieties, horizontal and vertical."
easily cracked,"Like most pre-modern era ciphers, the two-square cipher can be easily cracked if there is enough text."
enough text,"Like most pre-modern era ciphers, the two-square cipher can be easily cracked if there is enough text."
modern era ciphers,"Like most pre-modern era ciphers, the two-square cipher can be easily cracked if there is enough text."
united states army,"A good tutorial on reconstructing the key for a two-square cipher can be found in chapter 7, ""Solution to Polygraphic Substitution Systems,"" of Field Manual 34-40-2, produced by the United States Army."
polygraphic substitution systems,"A good tutorial on reconstructing the key for a two-square cipher can be found in chapter 7, ""Solution to Polygraphic Substitution Systems,"" of Field Manual 34-40-2, produced by the United States Army."
field manual 34,"A good tutorial on reconstructing the key for a two-square cipher can be found in chapter 7, ""Solution to Polygraphic Substitution Systems,"" of Field Manual 34-40-2, produced by the United States Army."
good tutorial,"A good tutorial on reconstructing the key for a two-square cipher can be found in chapter 7, ""Solution to Polygraphic Substitution Systems,"" of Field Manual 34-40-2, produced by the United States Army."
fixed topological properties,"Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them."
fixed number,"The digital image contains a fixed number of rows and columns of pixels. !! Whereas round-robin cycles over the queues or tasks and gives one service opportunity per cycle, weighted round robin offers to each a fixed number of opportunities, as specified by the configured weight which serves to influence the portion of capacity received by each queue or task. !! Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them."
allowable shapes,"Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them."
help work around,Topological optimization techniques can then help work around the limitations of pure shape optimization.
topological optimization techniques,Topological optimization techniques can then help work around the limitations of pure shape optimization.
pure shape optimization,Topological optimization techniques can then help work around the limitations of pure shape optimization.
dimensional optimization problem,Shape optimization is an infinite-dimensional optimization problem.
usually solved numerically,"Shape optimization problems are usually solved numerically, by using iterative methods."
shape optimization problems,"Shape optimization problems are usually solved numerically, by using iterative methods."
using iterative methods,"Shape optimization problems are usually solved numerically, by using iterative methods."
computer program whose loops,"In computability theory, a primitive recursive function is roughly speaking a function that can be computed by a computer program whose loops are all ""for"" loops (that is, an upper bound of the number of iterations of every loop can be determined before entering the loop)."
roughly speaking,"In computability theory, a primitive recursive function is roughly speaking a function that can be computed by a computer program whose loops are all ""for"" loops (that is, an upper bound of the number of iterations of every loop can be determined before entering the loop)."
upper bound,"In computability theory, a primitive recursive function is roughly speaking a function that can be computed by a computer program whose loops are all ""for"" loops (that is, an upper bound of the number of iterations of every loop can be determined before entering the loop)."
every loop,"In computability theory, a primitive recursive function is roughly speaking a function that can be computed by a computer program whose loops are all ""for"" loops (that is, an upper bound of the number of iterations of every loop can be determined before entering the loop)."
primitive recursive functions form,Primitive recursive functions form a strict subset of those general recursive functions that are also total functions.
also total functions,Primitive recursive functions form a strict subset of those general recursive functions that are also total functions.
strict subset,Primitive recursive functions form a strict subset of those general recursive functions that are also total functions.
primitive recursive,"The importance of primitive recursive functions lies on the fact that most computable functions that are studied in number theory (and more generally in mathematics) are primitive recursive. !! In fact, for showing that a computable function is primitive recursive, it suffices to show that its time complexity is bounded above by a primitive recursive function of the input size."
number theory,"The importance of primitive recursive functions lies on the fact that most computable functions that are studied in number theory (and more generally in mathematics) are primitive recursive. !! Number theory (or arithmetic or higher arithmetic in older usage) is a branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions. !! Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory). !! By the early twentieth century, it had been superseded by ""number theory"". !! The older term for number theory is arithmetic. !! Computational number theory has applications to cryptography, including RSA, elliptic curve cryptography and post-quantum cryptography, and is used to investigate conjectures and open problems in number theory, including the Riemann hypothesis, the Birch and Swinnerton-Dyer conjecture, the ABC conjecture, the modularity conjecture, the Sato-Tate conjecture, and explicit aspects of the Langlands program. !! German mathematician Carl Friedrich Gauss (17771855) said, ""Mathematics is the queen of the sciencesand number theory is the queen of mathematics. """
primitive recursive functions lies,The importance of primitive recursive functions lies on the fact that most computable functions that are studied in number theory (and more generally in mathematics) are primitive recursive.
input size,"In fact, for showing that a computable function is primitive recursive, it suffices to show that its time complexity is bounded above by a primitive recursive function of the input size. !! Run-time analysis is a theoretical classification that estimates and anticipates the increase in running time (or run-time or execution time) of an algorithm as its input size (usually denoted as n) increases."
node defines,"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs."
node given,"In artificial neural networks, the activation function of a node defines the output of that node given an input or set of inputs."
standard integrated circuit,"A standard integrated circuit can be seen as a digital network of activation functions that can be ""ON"" (1) or ""OFF"" (0), depending on input."
nonlinear activation functions allow,"However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes, and such activation functions are called nonlinearities."
called nonlinearities,"However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes, and such activation functions are called nonlinearities."
compute nontrivial problems using,"However, only nonlinear activation functions allow such networks to compute nontrivial problems using only a small number of nodes, and such activation functions are called nonlinearities."
common activation functions,"The most common activation functions can be divided in three categories: ridge functions, radial functions and fold functions."
three categories,"Models of computation can be classified into three categories: sequential models, functional models, and concurrent models. !! The most common activation functions can be divided in three categories: ridge functions, radial functions and fold functions."
abstraction representing,"In biologically inspired neural networks, the activation function is usually an abstraction representing the rate of action potential firing in the cell."
action potential firing,"In biologically inspired neural networks, the activation function is usually an abstraction representing the rate of action potential firing in the cell."
biologically inspired neural networks,"In biologically inspired neural networks, the activation function is usually an abstraction representing the rate of action potential firing in the cell."
john von neumann,"Some pioneers of the theory of computation were Ramon Llull, Alonzo Church, Kurt Gdel, Alan Turing, Stephen Kleene, Rzsa Pter, John von Neumann and Claude Shannon. !! In physics, the von Neumann entropy, named after John von Neumann, is an extension of the concept of Gibbs entropy from classical statistical mechanics to quantum statistical mechanics."
classical statistical mechanics,"In physics, the von Neumann entropy, named after John von Neumann, is an extension of the concept of Gibbs entropy from classical statistical mechanics to quantum statistical mechanics."
von neumann entropy,"The von Neumann entropy is also strongly subadditive. !! In physics, the von Neumann entropy, named after John von Neumann, is an extension of the concept of Gibbs entropy from classical statistical mechanics to quantum statistical mechanics. !! This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift. !! The von Neumann entropy is also used in different forms (conditional entropies, relative entropies, etc. )"
quantum statistical mechanics,"In physics, the von Neumann entropy, named after John von Neumann, is an extension of the concept of Gibbs entropy from classical statistical mechanics to quantum statistical mechanics."
gibbs entropy,"In physics, the von Neumann entropy, named after John von Neumann, is an extension of the concept of Gibbs entropy from classical statistical mechanics to quantum statistical mechanics."
conditional entropies,"The von Neumann entropy is also used in different forms (conditional entropies, relative entropies, etc. )"
different forms,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others. !! The von Neumann entropy is also used in different forms (conditional entropies, relative entropies, etc. )"
relative entropies,"The von Neumann entropy is also used in different forms (conditional entropies, relative entropies, etc. )"
hilbert space one,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
phase space formulation,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
expected value,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
offset shift,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
von neumann entropy amounts,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
wigner function,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
f log f dx dp,"This may be more intuitive in the phase space formulation, instead of Hilbert space one, where the Von Neumann entropy amounts to minus the expected value of the -logarithm of the Wigner function, f log f dx dp, up to an offset shift."
also strongly subadditive,The von Neumann entropy is also strongly subadditive.
without routing,File eXchange Protocol (FXP or FXSP) is a method of data transfer which uses FTP to transfer data from one remote server to another (inter-server) without routing this data through the client's connection.
uses ftp,File eXchange Protocol (FXP or FXSP) is a method of data transfer which uses FTP to transfer data from one remote server to another (inter-server) without routing this data through the client's connection.
transfer data,File eXchange Protocol (FXP or FXSP) is a method of data transfer which uses FTP to transfer data from one remote server to another (inter-server) without routing this data through the client's connection. !! The data link layer provides the functional and procedural means to transfer data between network entities and may also provide the means to detect and possibly correct errors that can occur in the physical layer.
one remote server,File eXchange Protocol (FXP or FXSP) is a method of data transfer which uses FTP to transfer data from one remote server to another (inter-server) without routing this data through the client's connection.
data transfer,File eXchange Protocol (FXP or FXSP) is a method of data transfer which uses FTP to transfer data from one remote server to another (inter-server) without routing this data through the client's connection. !! Spatial capacity focuses not only on bit rates for data transfer but on bit rates available in confined spaces defined by short transmission ranges.
computational anatomy,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms. !! Computational anatomy is an interdisciplinary field of biology focused on quantitative investigation and modelling of anatomical shapes variability. !! The flows between coordinates in computational anatomy are constrained to be geodesic flows satisfying the principle of least action for the Kinetic energy of the flow. !! Computational anatomy intersects the study of Riemannian manifolds and nonlinear global analysis, where groups of diffeomorphisms are the central focus. !! Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
anatomical shapes variability,Computational anatomy is an interdisciplinary field of biology focused on quantitative investigation and modelling of anatomical shapes variability.
biology focused,Computational anatomy is an interdisciplinary field of biology focused on quantitative investigation and modelling of anatomical shapes variability.
quantitative investigation,Computational anatomy is an interdisciplinary field of biology focused on quantitative investigation and modelling of anatomical shapes variability.
least action,The flows between coordinates in computational anatomy are constrained to be geodesic flows satisfying the principle of least action for the Kinetic energy of the flow.
kinetic energy,The flows between coordinates in computational anatomy are constrained to be geodesic flows satisfying the principle of least action for the Kinetic energy of the flow.
geodesic flows satisfying,The flows between coordinates in computational anatomy are constrained to be geodesic flows satisfying the principle of least action for the Kinetic energy of the flow.
nonlinear global analysis,"Computational anatomy intersects the study of Riemannian manifolds and nonlinear global analysis, where groups of diffeomorphisms are the central focus."
central focus,"Computational anatomy intersects the study of Riemannian manifolds and nonlinear global analysis, where groups of diffeomorphisms are the central focus. !! A central focus of database theory is on understanding the complexity and power of query languages and their connection to logic."
computational anatomy intersects,"Computational anatomy intersects the study of Riemannian manifolds and nonlinear global analysis, where groups of diffeomorphisms are the central focus."
riemannian manifolds,"Computational anatomy intersects the study of Riemannian manifolds and nonlinear global analysis, where groups of diffeomorphisms are the central focus."
fledgling field,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
many studies,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
questions emerging,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
emerging high,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
shape statistics,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
dimensional theories,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
metric structures,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
metric space study,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
computational anatomy focuses,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
coordinate systems via diffeomorphisms,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
coordinate systems transformed,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
terminology diffeomorphometry,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
central use,"The metric structures in computational anatomy are related in spirit to morphometrics, with the distinction that Computational anatomy focuses on an infinite-dimensional space of coordinate systems transformed by a diffeomorphism, hence the central use of the terminology diffeomorphometry, the metric space study of coordinate systems via diffeomorphisms."
constituent organizations,"The Alliance of Digital Humanities Organizations (ADHO) is a digital humanities umbrella organization formed in 2005 to coordinate the activities of several regional DH organizations, referred to as constituent organizations."
digital humanities organizations,"The Alliance of Digital Humanities Organizations (ADHO) is a digital humanities umbrella organization formed in 2005 to coordinate the activities of several regional DH organizations, referred to as constituent organizations. !! The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
several regional dh organizations,"The Alliance of Digital Humanities Organizations (ADHO) is a digital humanities umbrella organization formed in 2005 to coordinate the activities of several regional DH organizations, referred to as constituent organizations."
alliance of digital humanities organizations,"The Alliance of Digital Humanities Organizations (ADHO) is a digital humanities umbrella organization formed in 2005 to coordinate the activities of several regional DH organizations, referred to as constituent organizations. !! The Alliance of Digital Humanities Organizations sponsors special interest groups to facilitate the sharing of ideas about new and innovative problems. !! The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
digital humanities umbrella organization formed,"The Alliance of Digital Humanities Organizations (ADHO) is a digital humanities umbrella organization formed in 2005 to coordinate the activities of several regional DH organizations, referred to as constituent organizations."
umbrella organisation whose goals,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
drawing together humanists engaged,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
teaching across arts,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
support digital research,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
areas reflected,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
assisted research,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
humanities disciplines,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
diverse membership,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
innovative problems,The Alliance of Digital Humanities Organizations sponsors special interest groups to facilitate the sharing of ideas about new and innovative problems.
methods comprise,"In statistics, Markov chain Monte Carlo (MCMC) methods comprise a class of algorithms for sampling from a probability distribution."
known function,"Markov chain Monte Carlo methods create samples from a continuous random variable, with probability density proportional to a known function."
continuous random variable,"Markov chain Monte Carlo methods create samples from a continuous random variable, with probability density proportional to a known function."
probability density proportional,"Markov chain Monte Carlo methods create samples from a continuous random variable, with probability density proportional to a known function."
grand canonical ensemble,"Markov chain Monte Carlo methods that change dimensionality have long been used in statistical physics applications, where for some problems a distribution that is a grand canonical ensemble is used (e. g. , when the number of molecules in a box is variable)."
change dimensionality,"Markov chain Monte Carlo methods that change dimensionality have long been used in statistical physics applications, where for some problems a distribution that is a grand canonical ensemble is used (e. g. , when the number of molecules in a box is variable)."
statistical physics applications,"Markov chain Monte Carlo methods that change dimensionality have long been used in statistical physics applications, where for some problems a distribution that is a grand canonical ensemble is used (e. g. , when the number of molecules in a box is variable)."
chinese restaurant process,"But the reversible-jump variant is useful when doing Markov chain Monte Carlo or Gibbs sampling over nonparametric Bayesian models such as those involving the Dirichlet process or Chinese restaurant process, where the number of mixing components/clusters/etc."
jump variant,"But the reversible-jump variant is useful when doing Markov chain Monte Carlo or Gibbs sampling over nonparametric Bayesian models such as those involving the Dirichlet process or Chinese restaurant process, where the number of mixing components/clusters/etc."
mixing components,"But the reversible-jump variant is useful when doing Markov chain Monte Carlo or Gibbs sampling over nonparametric Bayesian models such as those involving the Dirichlet process or Chinese restaurant process, where the number of mixing components/clusters/etc."
order execution microprocessors,"Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time. !! Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order."
execute memory access operations,"Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time."
predict true dependencies,"Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time."
instruction execution time,"Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time."
program order,"Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time. !! Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order. !! ""To understand this statement, it is essential to understand one key property of sequential consistency: execution order of program in the same processor (or thread) is the same as the program order, while execution order of program between processors (or threads) is undefined."
memory location,"In general, memory dependence prediction predicts whether two memory operations are dependent, that is, if they interact by accessing the same memory location."
order scheduling,"Besides using store to load (RAW or true) memory dependence prediction for the out-of-order scheduling of loads and stores, other applications of memory dependence prediction have been proposed."
besides using store,"Besides using store to load (RAW or true) memory dependence prediction for the out-of-order scheduling of loads and stores, other applications of memory dependence prediction have been proposed."
memory dependency speculation,Memory dependence prediction is an optimization on top of memory dependency speculation.
violation may occur,Selective memory dependence prediction stalls specific loads until it is certain that no violation may occur.
language intended specifically,A model transformation language in systems and software engineering is a language intended specifically for model transformation.
model transformation language,"A model transformation language in systems and software engineering is a language intended specifically for model transformation. !! The OMG has standardised a family of model transformation languages called QVT, but the field is still immature. !! Currently, most model transformation languages are being developed in academia. !! For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately. !! However, special-purpose model transformation languages can offer advantages, such as syntax that makes it easy to refer to model elements."
model transformation,A model transformation language in systems and software engineering is a language intended specifically for model transformation.
offer advantages,"However, special-purpose model transformation languages can offer advantages, such as syntax that makes it easy to refer to model elements."
purpose model transformation languages,"However, special-purpose model transformation languages can offer advantages, such as syntax that makes it easy to refer to model elements."
writing bidirectional model transformations,"For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
specialist bidirectional model transformation language,"For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
maintain consistency,"For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
help avoid,"For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
would result,"For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
particularly important,"Quality of service is particularly important for the transport of traffic with special requirements. !! Full backward compatibility is particularly important in computer instruction set architectures, one of the most successful being the x86 family of microprocessors. !! For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
transformation separately,"For writing bidirectional model transformations, which maintain consistency between two or more models, a specialist bidirectional model transformation language is particularly important, because it can help avoid the duplication that would result from writing each direction of the transformation separately."
model transformation languages,"Currently, most model transformation languages are being developed in academia."
still immature,"The OMG has standardised a family of model transformation languages called QVT, but the field is still immature."
model transformation languages called qvt,"The OMG has standardised a family of model transformation languages called QVT, but the field is still immature."
considered simultaneously,Symbolic simulation is a form of simulation where many possible executions of a system are considered simultaneously.
symbolic simulation,"Techniques such as symbolic trajectory evaluation (STE) and generalized symbolic trajectory evaluation (GSTE) are based on this idea of symbolic simulation. !! Because symbolic simulation can cover many system executions in a single simulation, it can greatly reduce the size of verification problems. !! Symbolic simulation is a form of simulation where many possible executions of a system are considered simultaneously. !! Symbolic trajectory evaluation (STE) is a lattice-based model checking technology that uses a form of symbolic simulation."
many possible executions,Symbolic simulation is a form of simulation where many possible executions of a system are considered simultaneously.
greatly reduce,"Because symbolic simulation can cover many system executions in a single simulation, it can greatly reduce the size of verification problems."
verification problems,"Because symbolic simulation can cover many system executions in a single simulation, it can greatly reduce the size of verification problems."
cover many system executions,"Because symbolic simulation can cover many system executions in a single simulation, it can greatly reduce the size of verification problems."
single simulation,"Because symbolic simulation can cover many system executions in a single simulation, it can greatly reduce the size of verification problems."
symbolic trajectory evaluation,Techniques such as symbolic trajectory evaluation (STE) and generalized symbolic trajectory evaluation (GSTE) are based on this idea of symbolic simulation. !! Symbolic trajectory evaluation (STE) is a lattice-based model checking technology that uses a form of symbolic simulation.
generalized symbolic trajectory evaluation,Techniques such as symbolic trajectory evaluation (STE) and generalized symbolic trajectory evaluation (GSTE) are based on this idea of symbolic simulation.
many well,Many well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.
known recursive algorithms generate,Many well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.
given data,Many well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.
entirely new piece,Many well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.
repeated function calls,"Recursive algorithms are often inefficient for small data, due to the overhead of repeated function calls and returns."
small data,"Recursive algorithms are often inefficient for small data, due to the overhead of repeated function calls and returns."
often inefficient,"Recursive algorithms are often inefficient for small data, due to the overhead of repeated function calls and returns."
recursive algorithms often start,"For this reason efficient implementations of recursive algorithms often start with the recursive algorithm, but then switch to a different algorithm when the input becomes small."
different algorithm,"For this reason efficient implementations of recursive algorithms often start with the recursive algorithm, but then switch to a different algorithm when the input becomes small."
input becomes small,"For this reason efficient implementations of recursive algorithms often start with the recursive algorithm, but then switch to a different algorithm when the input becomes small."
reason efficient implementations,"For this reason efficient implementations of recursive algorithms often start with the recursive algorithm, but then switch to a different algorithm when the input becomes small."
insertion sort,"Hybrid recursive algorithms can often be further refined, as in Timsort, derived from a hybrid merge sort/insertion sort. !! In computer science, merge-insertion sort or the FordJohnson algorithm is a comparison sorting algorithm published in 1959 by L. R. Ford Jr. and Selmer M. Johnson. !! For 20 years, merge-insertion sort was the sorting algorithm with the fewest comparisons known for all input lengths. !! Block sort, or block merge sort, is a sorting algorithm combining at least two merge operations with an insertion sort to arrive at O(n log n) in-place stable sorting."
much less,"In some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms."
recursive algorithms tend,"In some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms."
maximum size,"In some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms."
space available,"In some programming languages, the maximum size of the call stack is much less than the space available in the heap, and recursive algorithms tend to require more stack space than iterative algorithms."
units of information,"In information theory, units of information are also used to measure information contained in messages and the entropy of random variables."
measure information contained,"In information theory, units of information are also used to measure information contained in messages and the entropy of random variables."
square matrix used,"In graph theory and computer science, an adjacency matrix is a square matrix used to represent a finite graph. !! In mathematics, a stochastic matrix is a square matrix used to describe the transitions of a Markov chain."
first developed,"The lexicographic breadth-first search algorithm is based on the idea of partition refinement and was first developed by Donald J. !! Inline caching is an optimization technique employed by some language runtimes, and first developed for Smalltalk. !! :911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
population genetics,":911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
scientific fields,":911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
andrey markov,":911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
20th century,"The development of the computer algebra systems in the second half of the 20th century is part of the discipline of ""computer algebra"" or ""symbolic computation"", which has spurred work in algorithms over mathematical objects such as polynomials. !! :911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics. !! The history of quantum information theory began at the turn of the 20th century when classical physics was revolutionized into quantum physics."
including probability theory,":911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
found use throughout,":911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
mathematical finance,":911 The stochastic matrix was first developed by Andrey Markov at the beginning of the 20th century, and has found use throughout a wide variety of scientific fields, including probability theory, statistics, mathematical finance and linear algebra, as well as computer science and population genetics."
row summing,"A right stochastic matrix is a real square matrix, with each row summing to 1."
real square matrix,"A left stochastic matrix is a real square matrix, with each column summing to 1. !! A right stochastic matrix is a real square matrix, with each row summing to 1."
column summing,"A doubly stochastic matrix is a square matrix of nonnegative real numbers with each row and column summing to 1. !! A left stochastic matrix is a real square matrix, with each column summing to 1."
nonnegative real numbers,A doubly stochastic matrix is a square matrix of nonnegative real numbers with each row and column summing to 1.
square matrix,"Consequently, if all singular values of a square matrix M are non-degenerate and non-zero, then its singular value decomposition is unique, up to multiplication of a column of U by a unit-phase factor and simultaneous multiplication of the corresponding column of V by the same unit-phase factor. !! A doubly stochastic matrix is a square matrix of nonnegative real numbers with each row and column summing to 1. !! In the mathematical discipline of linear algebra, a triangular matrix is a special kind of square matrix. !! In linear algebra, a circulant matrix is a square matrix in which all row vectors are composed of the same elements and each row vector is rotated one element to the right relative to the preceding row vector."
doubly stochastic matrix,A doubly stochastic matrix is a square matrix of nonnegative real numbers with each row and column summing to 1.
singleton set,The only non-singleton set with this property is the empty set. !! The statement above shows that the singleton sets are precisely the terminal objects in the category Set of sets. !! Every singleton set is an ultra prefilter.
ultra prefilter,Every singleton set is an ultra prefilter.
every singleton set,Every singleton set is an ultra prefilter.
singleton sets,The statement above shows that the singleton sets are precisely the terminal objects in the category Set of sets.
category set,The statement above shows that the singleton sets are precisely the terminal objects in the category Set of sets.
terminal objects,The statement above shows that the singleton sets are precisely the terminal objects in the category Set of sets.
jacobi method for complex hermitian matrices,"In mathematics, the Jacobi method for complex Hermitian matrices is a generalization of the Jacobi iteration method."
creating objects without,"In class-based programming, the factory method pattern is a creational pattern that uses factory methods to deal with the problem of creating objects without having to specify the exact class of the object that will be created."
exact class,"In class-based programming, the factory method pattern is a creational pattern that uses factory methods to deal with the problem of creating objects without having to specify the exact class of the object that will be created."
uses factory methods,"In class-based programming, the factory method pattern is a creational pattern that uses factory methods to deal with the problem of creating objects without having to specify the exact class of the object that will be created."
base class,"This is done by creating objects by calling a factory methodeither specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classesrather than by calling a constructor."
factory methodeither specified,"This is done by creating objects by calling a factory methodeither specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classesrather than by calling a constructor."
child classes,"This is done by creating objects by calling a factory methodeither specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classesrather than by calling a constructor."
creating objects,"This is done by creating objects by calling a factory methodeither specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classesrather than by calling a constructor."
optionally overridden,"This is done by creating objects by calling a factory methodeither specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classesrather than by calling a constructor."
derived classesrather,"This is done by creating objects by calling a factory methodeither specified in an interface and implemented by child classes, or implemented in a base class and optionally overridden by derived classesrather than by calling a constructor."
separate operation,Define a separate operation (factory method) for creating an object.
class defer instantiation,"The Factory method lets a class defer instantiation it uses to subclasses. """
factory method lets,"The Factory method lets a class defer instantiation it uses to subclasses. """
undirected graph along,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed or undirected graph along a temporal sequence.
nodes form,A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed or undirected graph along a temporal sequence.
infinite impulse response,"The term ""recurrent neural network"" is used to refer to the class of networks with an infinite impulse response, whereas ""convolutional neural network"" refers to the class of finite impulse response."
finite impulse response,"The term ""recurrent neural network"" is used to refer to the class of networks with an infinite impulse response, whereas ""convolutional neural network"" refers to the class of finite impulse response."
discourage theft,"A car alarm is an electronic device installed in a vehicle in an attempt to discourage theft of the vehicle itself, its contents, or both."
electronic device installed,"A car alarm is an electronic device installed in a vehicle in an attempt to discourage theft of the vehicle itself, its contents, or both."
car alarm,"A car alarm is an electronic device installed in a vehicle in an attempt to discourage theft of the vehicle itself, its contents, or both. !! An early version of a car alarm for use as a theft deterrent was invented by an unknown prisoner from Denver in 1913. !! Remote car alarms typically consist of an additional radio receiver that allows the owner to wirelessly control the alarm from a key fob. !! Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met. !! Car alarms should not be confused with immobilizers; although the purpose of both may be to deter car theft, they operate in a dissimilar fashion."
car alarms work,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
volume sound,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
recorded verbal warning,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
emitting high,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
conditions necessary,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
mounted siren,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
unknown prisoner,An early version of a car alarm for use as a theft deterrent was invented by an unknown prisoner from Denver in 1913.
theft deterrent,An early version of a car alarm for use as a theft deterrent was invented by an unknown prisoner from Denver in 1913.
early version,An early version of a car alarm for use as a theft deterrent was invented by an unknown prisoner from Denver in 1913.
car alarms,"Car alarms should not be confused with immobilizers; although the purpose of both may be to deter car theft, they operate in a dissimilar fashion."
dissimilar fashion,"Car alarms should not be confused with immobilizers; although the purpose of both may be to deter car theft, they operate in a dissimilar fashion."
deter car theft,"Car alarms should not be confused with immobilizers; although the purpose of both may be to deter car theft, they operate in a dissimilar fashion."
key fob,Remote car alarms typically consist of an additional radio receiver that allows the owner to wirelessly control the alarm from a key fob.
wirelessly control,Remote car alarms typically consist of an additional radio receiver that allows the owner to wirelessly control the alarm from a key fob.
additional radio receiver,Remote car alarms typically consist of an additional radio receiver that allows the owner to wirelessly control the alarm from a key fob.
remote car alarms typically consist,Remote car alarms typically consist of an additional radio receiver that allows the owner to wirelessly control the alarm from a key fob.
consistent manner,URI normalization is the process by which URIs are modified and standardized in a consistent manner.
duplicate pages,Search engines employ URI normalization in order to assign importance to web pages and to reduce indexing of duplicate pages.
search engines employ uri normalization,Search engines employ URI normalization in order to assign importance to web pages and to reduce indexing of duplicate pages.
assign importance,Search engines employ URI normalization in order to assign importance to web pages and to reduce indexing of duplicate pages.
reduce indexing,Search engines employ URI normalization in order to assign importance to web pages and to reduce indexing of duplicate pages.
avoid crawling,Web crawlers perform URI normalization in order to avoid crawling the same resource more than once.
web crawlers perform uri normalization,Web crawlers perform URI normalization in order to avoid crawling the same resource more than once.
chart used,"A phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc. )"
phase diagram,"A phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc. ) !! Common components of a phase diagram are lines of equilibrium or phase boundaries, which refer to lines that mark conditions under which multiple phases can coexist at equilibrium. !! For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium (273. !! Triple points are points on phase diagrams where lines of equilibrium intersect. !! Metastable phases are not shown in phase diagrams as, despite their common occurrence, they are not equilibrium phases."
physical chemistry,"A phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc. )"
show conditions,"A phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc. )"
common components,"Common components of a phase diagram are lines of equilibrium or phase boundaries, which refer to lines that mark conditions under which multiple phases can coexist at equilibrium."
phase boundaries,"Common components of a phase diagram are lines of equilibrium or phase boundaries, which refer to lines that mark conditions under which multiple phases can coexist at equilibrium."
mark conditions,"Common components of a phase diagram are lines of equilibrium or phase boundaries, which refer to lines that mark conditions under which multiple phases can coexist at equilibrium."
multiple phases,"Common components of a phase diagram are lines of equilibrium or phase boundaries, which refer to lines that mark conditions under which multiple phases can coexist at equilibrium."
equilibrium phases,"Metastable phases are not shown in phase diagrams as, despite their common occurrence, they are not equilibrium phases."
metastable phases,"Metastable phases are not shown in phase diagrams as, despite their common occurrence, they are not equilibrium phases."
phase diagrams,"Triple points are points on phase diagrams where lines of equilibrium intersect. !! Metastable phases are not shown in phase diagrams as, despite their common occurrence, they are not equilibrium phases."
common occurrence,"Metastable phases are not shown in phase diagrams as, despite their common occurrence, they are not equilibrium phases."
equilibrium intersect,Triple points are points on phase diagrams where lines of equilibrium intersect.
triple points,Triple points are points on phase diagrams where lines of equilibrium intersect.
triple point corresponding,"For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium (273."
stable equilibrium,"For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium (273."
gaseous water,"For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium (273."
single temperature,"For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium (273."
water phase diagram,"For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium (273."
assembling sequences,"Quantum programming is the process of assembling sequences of instructions, called quantum programs, that are capable of running on a quantum computer."
called quantum programs,"Quantum programming is the process of assembling sequences of instructions, called quantum programs, that are capable of running on a quantum computer."
level constructs,Quantum programming languages help express quantum algorithms using high-level constructs.
optimizing compiler developed,"A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
several quantum hardware back,"A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
cambridge quantum computing,"A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
targets simulators,"A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
quantum programming environment,"A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
two main groups,There are two main groups of quantum programming languages: imperative quantum programming languages and functional quantum programming languages.
first implemented quantum programming languages,Quantum Computation Language (QCL) is one of the first implemented quantum programming languages.
density matrix,"The density matrix is a representation of a linear operator called the density operator. !! In practice, the terms density matrix and density operator are often used interchangeably. !! The density matrix is obtained from the density operator by choice of basis in the underlying space. !! The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed. !! Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures. !! In quantum mechanics, a density matrix is a matrix that describes the quantum state of a physical system."
quantum state,"In quantum mechanics, a density matrix is a matrix that describes the quantum state of a physical system."
physical system,"In quantum mechanics, a density matrix is a matrix that describes the quantum state of a physical system."
linear operator called,The density matrix is a representation of a linear operator called the density operator.
density operator,"The density matrix is obtained from the density operator by choice of basis in the underlying space. !! In practice, the terms density matrix and density operator are often used interchangeably. !! The density matrix is a representation of a linear operator called the density operator."
underlying space,The density matrix is obtained from the density operator by choice of basis in the underlying space.
terms density matrix,"In practice, the terms density matrix and density operator are often used interchangeably."
often used interchangeably,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably. !! In practice, the terms density matrix and density operator are often used interchangeably. !! Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
partial trace,"The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed."
two photons together,"The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed."
joint density matrix,"The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed."
photon individually,"The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed."
completely mixed,"The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed."
joint state,"The joint state of the two photons together is pure, but the density matrix for each photon individually, found by taking the partial trace of the joint density matrix, is completely mixed."
specific algorithms,"In computer science, a search algorithm is an algorithm (typically involving a multitude of other, more specific algorithms ) which solves a search problem."
typically involving,"In computer science, a search algorithm is an algorithm (typically involving a multitude of other, more specific algorithms ) which solves a search problem."
retrieve information stored within,"Search algorithms work to retrieve information stored within some data structure, or calculated in the search space of a problem domain, with either discrete or continuous values."
either discrete,"Search algorithms work to retrieve information stored within some data structure, or calculated in the search space of a problem domain, with either discrete or continuous values."
search space,"This approach has the disadvantage of having a much larger space to search, because not only the search space in symbolic regression is infinite, but there are an infinite number of models which will perfectly fit a finite data set (provided that the model complexity isn't artificially limited). !! Interpolation search resembles the method by which people search a telephone directory for a name (the key value by which the book's entries are ordered): in each step the algorithm calculates where in the remaining search space the sought item might be, based on the key values at the bounds of the search space and the value of the sought key, usually via a linear interpolation. !! Search algorithms work to retrieve information stored within some data structure, or calculated in the search space of a problem domain, with either discrete or continuous values."
continuous values,"Search algorithms work to retrieve information stored within some data structure, or calculated in the search space of a problem domain, with either discrete or continuous values. !! A fuzzy control system is a control system based on fuzzy logica mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true or false, respectively)."
search algorithms work,"Search algorithms work to retrieve information stored within some data structure, or calculated in the search space of a problem domain, with either discrete or continuous values."
typically evaluated,"Classic search algorithms are typically evaluated on how fast they can find a solution, and whether that solution is guaranteed to be optimal."
may also include prior knowledge,"The appropriate search algorithm often depends on the data structure being searched, and may also include prior knowledge about the data."
appropriate search algorithm often depends,"The appropriate search algorithm often depends on the data structure being searched, and may also include prior knowledge about the data."
made faster,"Search algorithms can be made faster or more efficient by specially constructed database structures, such as search trees, hash maps, and database indexes."
specially constructed database structures,"Search algorithms can be made faster or more efficient by specially constructed database structures, such as search trees, hash maps, and database indexes."
17 without rounding,"Some programming languages provide a built-in (primitive) rational data type to represent rational numbers like 1/3 and -11/17 without rounding, and to do arithmetic on them."
programming languages provide,"Some programming languages provide a built-in (primitive) rational data type to represent rational numbers like 1/3 and -11/17 without rounding, and to do arithmetic on them. !! Some programming languages provide a complex data type for complex number storage and arithmetic as a built-in (primitive) data type."
represent rational numbers like 1,"Some programming languages provide a built-in (primitive) rational data type to represent rational numbers like 1/3 and -11/17 without rounding, and to do arithmetic on them."
basic arithmetic operations     integer powers,"Languages that support a rational data type usually provide special syntax for building such values, and also extend the basic arithmetic operations ('+', '', '', '/', integer powers) and comparisons ('=', '<', '>', '') to act on them either natively or through operator overloading facilities provided by the language."
operator overloading facilities provided,"Languages that support a rational data type usually provide special syntax for building such values, and also extend the basic arithmetic operations ('+', '', '', '/', integer powers) and comparisons ('=', '<', '>', '') to act on them either natively or through operator overloading facilities provided by the language."
also extend,"Languages that support a rational data type usually provide special syntax for building such values, and also extend the basic arithmetic operations ('+', '', '', '/', integer powers) and comparisons ('=', '<', '>', '') to act on them either natively or through operator overloading facilities provided by the language."
either natively,"Languages that support a rational data type usually provide special syntax for building such values, and also extend the basic arithmetic operations ('+', '', '', '/', integer powers) and comparisons ('=', '<', '>', '') to act on them either natively or through operator overloading facilities provided by the language."
california digital library,"eXtensible Text Framework (XTF) is a programming and data representation framework created and maintained by the California Digital Library (CDL) based on XML data, XSLT 2."
data representation framework created,"eXtensible Text Framework (XTF) is a programming and data representation framework created and maintained by the California Digital Library (CDL) based on XML data, XSLT 2."
map input items,Semantic hashing is a technique that attempts to map input items to addresses such that closer inputs have higher semantic similarity.
closer inputs,Semantic hashing is a technique that attempts to map input items to addresses such that closer inputs have higher semantic similarity.
higher semantic similarity,Semantic hashing is a technique that attempts to map input items to addresses such that closer inputs have higher semantic similarity.
algorithmically manipulating bits,Bit manipulation is the act of algorithmically manipulating bits or other pieces of data shorter than a word.
data shorter,Bit manipulation is the act of algorithmically manipulating bits or other pieces of data shorter than a word.
level device control,"Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization."
require bit manipulation include low,"Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization."
computer programming tasks,"Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization."
find high,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
low one,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
scatter bits,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
specified bit positions,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
operations analogous,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
bit manipulation makes use,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
count ones,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
insert fields,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
also bit shifts,"Source code that does bit manipulation makes use of the bitwise operations: AND, OR, XOR, NOT, and possibly other operations analogous to the boolean operators; there are also bit shifts and operations to count ones and zeros, find high and low one or zero, set, reset and test bits, extract and insert fields, mask and zero fields, gather and scatter bits to and from specified bit positions or fields."
fold speed ups,"Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel."
give many,"Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel."
challenging low,"Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
obvious ways,"Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
sometimes exclusively refer,"Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
ordered pair,"The order in which the objects appear in the pair is significant: the ordered pair (a, b) is different from the ordered pair (b, a) unless a = b. !! Ordered pairs of scalars are sometimes called 2-dimensional vectors. !! Ordered pairs are also called 2-tuples, or sequences (sometimes, lists in a computer science context) of length 2. !! In mathematics, an ordered pair (a, b) is a pair of objects. !! (In contrast, the unordered pair {a, b} equals the unordered pair {b, a}. )"
objects appear,"The order in which the objects appear in the pair is significant: the ordered pair (a, b) is different from the ordered pair (b, a) unless a = b."
unordered pair,"(In contrast, the unordered pair {a, b} equals the unordered pair {b, a}. )"
computer science context,"Ordered pairs are also called 2-tuples, or sequences (sometimes, lists in a computer science context) of length 2."
also called 2,"Ordered pairs are also called 2-tuples, or sequences (sometimes, lists in a computer science context) of length 2."
ordered pairs,"Ordered pairs are also called 2-tuples, or sequences (sometimes, lists in a computer science context) of length 2. !! Ordered pairs of scalars are sometimes called 2-dimensional vectors."
sometimes called 2,Ordered pairs of scalars are sometimes called 2-dimensional vectors.
dimensional vectors,Ordered pairs of scalars are sometimes called 2-dimensional vectors.
one problem,"In computational complexity theory and game complexity, a parsimonious reduction is a transformation from one problem to another (a reduction) that preserves the number of solutions. !! In the computational complexity theory of counting problems, a polynomial-time counting reduction is a type of reduction (a transformation from one problem to another) used to define the notion of completeness for the complexity class P."
parsimonious reduction,"In computational complexity theory and game complexity, a parsimonious reduction is a transformation from one problem to another (a reduction) that preserves the number of solutions. !! Specific types of parsimonious reductions may be defined by the computational complexity or other properties of the transformation algorithm. !! Just as many-one reductions are important for proving NP-completeness, parsimonious reductions are important for proving completeness for counting complexity classes such as P. !! Because parsimonious reductions preserve the property of having a unique solution, they are also used in game complexity, to show the hardness of puzzles such as sudoku where the uniqueness of the solution is an important part of the definition of the puzzle. !! Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require."
game complexity,"In computational complexity theory and game complexity, a parsimonious reduction is a transformation from one problem to another (a reduction) that preserves the number of solutions. !! Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require. !! Because parsimonious reductions preserve the property of having a unique solution, they are also used in game complexity, to show the hardness of puzzles such as sudoku where the uniqueness of the solution is an important part of the definition of the puzzle."
commonly used,"A popular normalized spectral clustering technique is the normalized cuts algorithm or ShiMalik algorithm introduced by Jianbo Shi and Jitendra Malik, commonly used for image segmentation. !! Factor analysis is commonly used in psychometrics, personality psychology, biology, marketing, product management, operations research, finance, and machine learning. !! Distributed Key Generation is commonly used to decrypt shared ciphertexts or create group digital signatures. !! Access levels modifiers are commonly used in Java as well as C#, which further provides the internal level. !! Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection. !! Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require. !! The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems."
counting problems,"Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require. !! In the computational complexity theory of counting problems, a polynomial-time counting reduction is a type of reduction (a transformation from one problem to another) used to define the notion of completeness for the complexity class P."
computational complexity,"Computational complexity is central to computational geometry, with great practical significance if algorithms are used on very large datasets containing tens or hundreds of millions of points. !! Specific types of parsimonious reductions may be defined by the computational complexity or other properties of the transformation algorithm. !! In computer science, the computational complexity or simply complexity of an algorithm is the amount of resources required to run it. !! In computer science, the time complexity is the computational complexity that describes the amount of computer time it takes to run an algorithm. !! The study of the complexity of explicitly given algorithms is called analysis of algorithms, while the study of the complexity of problems is called computational complexity theory. !! There are many methods of texture filtering, which make different trade-offs between computational complexity, memory bandwidth and image quality. !! Arora, Sanjeev; Barak, Boaz (2009), Computational Complexity: A Modern Approach, Cambridge, ISBN 978-0-521-42426-4, Zbl 1193. !! The computational complexity of computing the rotation distance is unknown. !! Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require. !! In computer science, the analysis of algorithms is the process of finding the computational complexity of algorithmsthe amount of time, storage, or other resources needed to execute them. !! Papadimitriou, Christos (1994), Computational Complexity (1st ed."
design hard puzzles,"Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require."
counting complexity classes,"Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require. !! Just as many-one reductions are important for proving NP-completeness, parsimonious reductions are important for proving completeness for counting complexity classes such as P."
puzzles require,"Parsimonious reductions are commonly used in computational complexity for proving the hardness of counting problems, for counting complexity classes such as #P. Additionally, they are used in game complexity, as a way to design hard puzzles that have a unique solution, as many types of puzzles require."
proving np,"Just as many-one reductions are important for proving NP-completeness, parsimonious reductions are important for proving completeness for counting complexity classes such as P."
proving completeness,"Just as many-one reductions are important for proving NP-completeness, parsimonious reductions are important for proving completeness for counting complexity classes such as P."
one reductions,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions. !! Just as many-one reductions are important for proving NP-completeness, parsimonious reductions are important for proving completeness for counting complexity classes such as P."
important part,"Algorithm analysis is an important part of a broader computational complexity theory, which provides theoretical estimates for the resources needed by any algorithm which solves a given computational problem. !! Therefore, lazy evaluation naturally becomes an important part of the construction of purely functional data structures. !! Because parsimonious reductions preserve the property of having a unique solution, they are also used in game complexity, to show the hardness of puzzles such as sudoku where the uniqueness of the solution is an important part of the definition of the puzzle."
parsimonious reductions preserve,"Because parsimonious reductions preserve the property of having a unique solution, they are also used in game complexity, to show the hardness of puzzles such as sudoku where the uniqueness of the solution is an important part of the definition of the puzzle."
parsimonious reductions may,Specific types of parsimonious reductions may be defined by the computational complexity or other properties of the transformation algorithm.
probabilistic parsing mechanism,"A Functional Presence Engine, or FPE, is a probabilistic parsing mechanism that uses at least four components to respond to input patterns."
input patterns,"A Functional Presence Engine, or FPE, is a probabilistic parsing mechanism that uses at least four components to respond to input patterns."
least four components,"A Functional Presence Engine, or FPE, is a probabilistic parsing mechanism that uses at least four components to respond to input patterns."
elicit response patterns,"A Functional Presence Engines is, subsequently, a stimulus-response mechanism that allows for a higher variability of inputs to elicit response patterns with a high likelihood of correctness, even from incomplete training."
incomplete training,"A Functional Presence Engines is, subsequently, a stimulus-response mechanism that allows for a higher variability of inputs to elicit response patterns with a high likelihood of correctness, even from incomplete training."
higher variability,"A Functional Presence Engines is, subsequently, a stimulus-response mechanism that allows for a higher variability of inputs to elicit response patterns with a high likelihood of correctness, even from incomplete training."
high likelihood,"A Functional Presence Engines is, subsequently, a stimulus-response mechanism that allows for a higher variability of inputs to elicit response patterns with a high likelihood of correctness, even from incomplete training."
response mechanism,"A Functional Presence Engines is, subsequently, a stimulus-response mechanism that allows for a higher variability of inputs to elicit response patterns with a high likelihood of correctness, even from incomplete training."
first functional presence engine,The first Functional Presence Engine was deployed in 2001 by Spectre AI Incorporated.
spectre ai incorporated,The first Functional Presence Engine was deployed in 2001 by Spectre AI Incorporated.
simply type,"In computer science and computer programming, a data type or simply type is an attribute of data which tells the compiler or interpreter how the programmer intends to use the data."
data type,"Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans. !! A data type provides a set of values from which an expression (i. e. variable, function, etc. ) !! In computer programming, run-time type information or run-time type identification (RTTI) is a feature of some programming languages (such as C++, Object Pascal, and Ada) that exposes information about an object's data type at runtime. !! A data type constrains the values that an expression, such as a variable or a function, might take. !! In computer science and computer programming, access level denotes the set of permissions or restrictions provided to a data type. !! Some programming languages provide a complex data type for complex number storage and arithmetic as a built-in (primitive) data type. !! In computer science and computer programming, a data type or simply type is an attribute of data which tells the compiler or interpreter how the programmer intends to use the data. !! This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored."
programmer intends,"In computer science and computer programming, a data type or simply type is an attribute of data which tells the compiler or interpreter how the programmer intends to use the data."
varying sizes  floating,"Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans."
approximate real numbers  characters,"Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans."
integer numbers,"Most programming languages support basic data types of integer numbers (of varying sizes), floating-point numbers (which approximate real numbers), characters and Booleans."
might take,"A data type constrains the values that an expression, such as a variable or a function, might take."
data type constrains,"A data type constrains the values that an expression, such as a variable or a function, might take."
way values,"This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored."
data type defines,"This data type defines the operations that can be done on the data, the meaning of the data, and the way values of that type can be stored."
data type provides,"A data type provides a set of values from which an expression (i. e. variable, function, etc. )"
keep track,"A stack machine has 2 or more stack registers one of them keeps track of a call stack, the other(s) keep track of other stack(s). !! A stack register is a computer central processor register whose purpose is to keep track of a call stack. !! While adding or removing a node in a doubly linked list requires changing more links than the same operations on a singly linked list, the operations are simpler and potentially more efficient (for nodes other than first nodes) because there is no need to keep track of the previous node during traversal or no need to traverse the list to find the previous node, so that its link can be modified."
stack registers one,"A stack machine has 2 or more stack registers one of them keeps track of a call stack, the other(s) keep track of other stack(s)."
keeps track,"A stack machine has 2 or more stack registers one of them keeps track of a call stack, the other(s) keep track of other stack(s)."
called stack pointer,"In 8086, the main stack register is called stack pointer - SP."
describes design work,Immersive design (Experimental Design) describes design work which ranges in levels of interaction and leads users to be fully absorbed in an experience.
immersive design,"In recent years, immersive design has been promoted as a design philosophy where it has been appropriated for the purposes of describing design for narrative media and the process of Worldbuilding. !! Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies. !! Immersive design (Experimental Design) describes design work which ranges in levels of interaction and leads users to be fully absorbed in an experience. !! With immersive design being applied to a variety of topics and discussions, there is great benefit to how immersive design can benefit the future of technology. !! Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying some groundwork for immersive design to be a distinct design philosophy."
leads users,Immersive design (Experimental Design) describes design work which ranges in levels of interaction and leads users to be fully absorbed in an experience.
fully absorbed,Immersive design (Experimental Design) describes design work which ranges in levels of interaction and leads users to be fully absorbed in an experience.
experimental design,Immersive design (Experimental Design) describes design work which ranges in levels of interaction and leads users to be fully absorbed in an experience.
discussion around,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
addresses story,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
design discipline,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
virtual technologies,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
based media within,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
alex mcdowell coined,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
long beach 2008,"Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying some groundwork for immersive design to be a distinct design philosophy."
museum director chris scoates co,"Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying some groundwork for immersive design to be a distinct design philosophy."
distinct design philosophy,"Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying some groundwork for immersive design to be a distinct design philosophy."
immersive design conference,"Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying some groundwork for immersive design to be a distinct design philosophy."
together mcdowell,"Together McDowell and museum director Chris Scoates co-directed 5D | The Future of Immersive Design conference in Long Beach 2008, laying some groundwork for immersive design to be a distinct design philosophy."
narrative media,"In recent years, immersive design has been promoted as a design philosophy where it has been appropriated for the purposes of describing design for narrative media and the process of Worldbuilding."
design philosophy,"The Design Philosophy of the DARPA Internet Protocols. !! In recent years, immersive design has been promoted as a design philosophy where it has been appropriated for the purposes of describing design for narrative media and the process of Worldbuilding."
recent years,"In recent years, investment in quantum computing research has increased in the public and private sectors. !! In recent years, a number of markup languages have been developed with ease of use as a key goal, and without input from standards organizations, aimed at allowing authors to create formatted text via web browsers, for example in wikis and in web forums. !! In recent years, immersive design has been promoted as a design philosophy where it has been appropriated for the purposes of describing design for narrative media and the process of Worldbuilding."
describing design,"In recent years, immersive design has been promoted as a design philosophy where it has been appropriated for the purposes of describing design for narrative media and the process of Worldbuilding."
great benefit,"With immersive design being applied to a variety of topics and discussions, there is great benefit to how immersive design can benefit the future of technology."
electronic device,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
ambient data,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
wearable technology,"Wearable technology has a variety of applications which grows as the field itself expands. !! Apart from commercial uses, wearable technology is being incorporated into navigation systems, advanced textiles, and healthcare. !! As wearable technology is being proposed for use in critical applications, it has to be vetted for its reliability and security properties. !! Wearable technology which tracks information such as walking and heart rate is part of the quantified self movement. !! Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
vital signs,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
body signals,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
streetwear tech,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
fashion electronics,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
skin electronics,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
transmit information concerning e,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
tech togs,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
fashion technology,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
worn close,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
cases immediate biofeedback,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
smart electronic devices,"Wearable technology, wearables, fashion technology, smartwear, tech togs, streetwear tech, skin electronics or fashion electronics are smart electronic devices (electronic device with micro-controllers) that are worn close to and/or on the surface of the skin, where they detect, analyze, and transmit information concerning e. g. body signals such as vital signs, and/or ambient data and which allow in some cases immediate biofeedback to the wearer."
navigation systems,"Apart from commercial uses, wearable technology is being incorporated into navigation systems, advanced textiles, and healthcare. !! This article will present an overview of the skill of navigation and try to identify the basic blocks of a robot navigation system, types of navigation systems, and closer look at its related building components."
commercial uses,"Apart from commercial uses, wearable technology is being incorporated into navigation systems, advanced textiles, and healthcare."
advanced textiles,"Apart from commercial uses, wearable technology is being incorporated into navigation systems, advanced textiles, and healthcare."
security properties,"As wearable technology is being proposed for use in critical applications, it has to be vetted for its reliability and security properties."
critical applications,"As wearable technology is being proposed for use in critical applications, it has to be vetted for its reliability and security properties."
tracks information,Wearable technology which tracks information such as walking and heart rate is part of the quantified self movement.
heart rate,Wearable technology which tracks information such as walking and heart rate is part of the quantified self movement.
quantified self movement,Wearable technology which tracks information such as walking and heart rate is part of the quantified self movement.
system whose resources,"In computer architecture, Amdahl's law (or Amdahl's argument) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved."
theoretical speedup,"In computer architecture, Amdahl's law (or Amdahl's argument) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved. !! Amdahl's law is often used in parallel computing to predict the theoretical speedup when using multiple processors."
fixed workload,"In computer architecture, Amdahl's law (or Amdahl's argument) is a formula which gives the theoretical speedup in latency of the execution of a task at fixed workload that can be expected of a system whose resources are improved."
using multiple processors,Amdahl's law is often used in parallel computing to predict the theoretical speedup when using multiple processors.
law applies,Amdahl's law applies only to the cases where the problem size is fixed.
problem size,"Therefore, brute-force search is typically used when the problem size is limited, or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size. !! Amdahl's law applies only to the cases where the problem size is fixed."
law demonstrates law,"Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates law of diminishing returns."
often conflated,"Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates law of diminishing returns."
diminishing returns,"Amdahl's law does represent the law of diminishing returns if on considering what sort of return one gets by adding more processors to a machine, if one is running a fixed-size computation that will use all available processors to their capacity. !! Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates law of diminishing returns."
applying amdahl,"Amdahl's law is often conflated with the law of diminishing returns, whereas only a special case of applying Amdahl's law demonstrates law of diminishing returns."
size computation,"Amdahl's law does represent the law of diminishing returns if on considering what sort of return one gets by adding more processors to a machine, if one is running a fixed-size computation that will use all available processors to their capacity."
available processors,"Amdahl's law does represent the law of diminishing returns if on considering what sort of return one gets by adding more processors to a machine, if one is running a fixed-size computation that will use all available processors to their capacity."
return one gets,"Amdahl's law does represent the law of diminishing returns if on considering what sort of return one gets by adding more processors to a machine, if one is running a fixed-size computation that will use all available processors to their capacity."
peripheral nervous system,"A peripheral nerve interface is the bridge between the peripheral nervous system and a computer interface which serves as a bidirectional information transducer recording and sending signals between the human body and a machine processor. !! Peripheral nerve interfaces also enable electrical stimulation and recording of the peripheral nervous system to study the form and function of the peripheral nervous system. !! Neurocomputational speech processing is computer-simulation of speech production and speech perception by referring to the natural neuronal processes of speech production and speech perception, as they occur in the human nervous system (central nervous system and peripheral nervous system)."
sending signals,A peripheral nerve interface is the bridge between the peripheral nervous system and a computer interface which serves as a bidirectional information transducer recording and sending signals between the human body and a machine processor.
peripheral nerve interface,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training. !! A peripheral nerve interface is the bridge between the peripheral nervous system and a computer interface which serves as a bidirectional information transducer recording and sending signals between the human body and a machine processor. !! The function of a peripheral nerve interface is to assist the nervous system when peripheral nerve function is compromised. !! Research in this area is focused on developing peripheral nerve interfaces for the restoration of function following disease or injury to minimize associated losses. !! Peripheral nerve interfaces also enable electrical stimulation and recording of the peripheral nervous system to study the form and function of the peripheral nervous system."
bidirectional information transducer recording,A peripheral nerve interface is the bridge between the peripheral nervous system and a computer interface which serves as a bidirectional information transducer recording and sending signals between the human body and a machine processor.
function following disease,Research in this area is focused on developing peripheral nerve interfaces for the restoration of function following disease or injury to minimize associated losses.
developing peripheral nerve interfaces,Research in this area is focused on developing peripheral nerve interfaces for the restoration of function following disease or injury to minimize associated losses.
minimize associated losses,Research in this area is focused on developing peripheral nerve interfaces for the restoration of function following disease or injury to minimize associated losses.
perioperative testing,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training."
include appropriate indication,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training."
differentiated planning,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training."
peripheral nerve interfaces depend,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training."
successful implantation,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training."
functional training,"Successful implantation of peripheral nerve interfaces depend on a number of factors which include appropriate indication, perioperative testing, differentiated planning, and functional training."
nervous system,The function of a peripheral nerve interface is to assist the nervous system when peripheral nerve function is compromised.
peripheral nerve function,The function of a peripheral nerve interface is to assist the nervous system when peripheral nerve function is compromised.
basic entity,"It is the basic entity of study in quantum information theory, and can be manipulated using quantum information processing techniques."
quantum information theory began,The history of quantum information theory began at the turn of the 20th century when classical physics was revolutionized into quantum physics.
classical physics,The history of quantum information theory began at the turn of the 20th century when classical physics was revolutionized into quantum physics.
quantum physics,"Although the logic has also been studied for its own sake, more broadly, ideas from linear logic have been influential in fields such as programming languages, game semantics, and quantum physics (because linear logic can be seen as the logic of quantum information theory), as well as linguistics, particularly because of its emphasis on resource-boundedness, duality, and interaction. !! The history of quantum information theory began at the turn of the 20th century when classical physics was revolutionized into quantum physics."
first historical appearance,This was the first historical appearance of quantum information theory.
earliest results,The theorem was one of the earliest results of quantum information theory.
studying isolated quantum systems,"Despite all the excitement and interest over studying isolated quantum systems and trying to find a way to circumvent the theory of relativity, research in quantum information theory became stagnant in the 1980s."
quantum information theory became stagnant,"Despite all the excitement and interest over studying isolated quantum systems and trying to find a way to circumvent the theory of relativity, research in quantum information theory became stagnant in the 1980s."
analyze visual imagery,"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of Artificial Neural Network(ANN), most commonly applied to analyze visual imagery."
commonly applied,"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of Artificial Neural Network(ANN), most commonly applied to analyze visual imagery. !! The mountain car problem, although fairly simple, is commonly applied because it requires a reinforcement learning agent to learn on two continuous variables: position and velocity."
mathematical operation called convolution,"The name ""convolutional neural network"" indicates that the network employs a mathematical operation called convolution."
network employs,"The name ""convolutional neural network"" indicates that the network employs a mathematical operation called convolution."
artificial neural network used,"or in other words ""A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data. """
specifically designed,"or in other words ""A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data. """
process pixel data,"or in other words ""A convolutional neural network (CNN) is a type of artificial neural network used in image recognition and processing that is specifically designed to process pixel data. """
convolutional neural network consists,"A convolutional neural network consists of an input layer, hidden layers and an output layer."
numerical solutions,Iterative refinement is an iterative method proposed by James H. Wilkinson to improve the accuracy of numerical solutions to systems of linear equations.
iterative method proposed,Iterative refinement is an iterative method proposed by James H. Wilkinson to improve the accuracy of numerical solutions to systems of linear equations.
using quad,"As a rule of thumb, iterative refinement for Gaussian elimination produces a solution correct to working precision if double the working precision is used in the computation of r, e. g. by using quad or double extended precision IEEE 754 floating point, and if A is not too ill-conditioned (and the iteration and the rate of convergence are determined by the condition number of A)."
working precision,"As a rule of thumb, iterative refinement for Gaussian elimination produces a solution correct to working precision if double the working precision is used in the computation of r, e. g. by using quad or double extended precision IEEE 754 floating point, and if A is not too ill-conditioned (and the iteration and the rate of convergence are determined by the condition number of A)."
condition number,"As a rule of thumb, iterative refinement for Gaussian elimination produces a solution correct to working precision if double the working precision is used in the computation of r, e. g. by using quad or double extended precision IEEE 754 floating point, and if A is not too ill-conditioned (and the iteration and the rate of convergence are determined by the condition number of A)."
solution correct,"As a rule of thumb, iterative refinement for Gaussian elimination produces a solution correct to working precision if double the working precision is used in the computation of r, e. g. by using quad or double extended precision IEEE 754 floating point, and if A is not too ill-conditioned (and the iteration and the rate of convergence are determined by the condition number of A)."
gaussian elimination produces,"As a rule of thumb, iterative refinement for Gaussian elimination produces a solution correct to working precision if double the working precision is used in the computation of r, e. g. by using quad or double extended precision IEEE 754 floating point, and if A is not too ill-conditioned (and the iteration and the rate of convergence are determined by the condition number of A)."
thus run faster,"Quasilinear time algorithms are also O(n1+) for every constant > 0, and thus run faster than any polynomial time algorithm whose time bound includes a term nc for any c > 1."
every constant,"Quasilinear time algorithms are also O(n1+) for every constant > 0, and thus run faster than any polynomial time algorithm whose time bound includes a term nc for any c > 1."
term nc,"Quasilinear time algorithms are also O(n1+) for every constant > 0, and thus run faster than any polynomial time algorithm whose time bound includes a term nc for any c > 1."
complexity class p,"An algorithm is said to be of polynomial time if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm, that is, T(n) = O(nk) for some positive constant k. Problems for which a deterministic polynomial time algorithm exists belong to the complexity class P, which is central in the field of computational complexity theory. !! In the computational complexity theory of counting problems, a polynomial-time counting reduction is a type of reduction (a transformation from one problem to another) used to define the notion of completeness for the complexity class P."
polynomial expression,"An algorithm is said to be of polynomial time if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm, that is, T(n) = O(nk) for some positive constant k. Problems for which a deterministic polynomial time algorithm exists belong to the complexity class P, which is central in the field of computational complexity theory."
running time,"An algorithm is said to be of polynomial time if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm, that is, T(n) = O(nk) for some positive constant k. Problems for which a deterministic polynomial time algorithm exists belong to the complexity class P, which is central in the field of computational complexity theory. !! There have been a number of attempts to prove lower bounds on the predecessor problem, or find what the running time of asymptotically optimal solutions would be. !! Run-time analysis is a theoretical classification that estimates and anticipates the increase in running time (or run-time or execution time) of an algorithm as its input size (usually denoted as n) increases. !! In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is a polynomial in the numeric value of the input (the largest integer present in the input)but not necessarily in the length of the input (the number of bits required to represent it), which is the case for polynomial time algorithms."
positive constant k,"An algorithm is said to be of polynomial time if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm, that is, T(n) = O(nk) for some positive constant k. Problems for which a deterministic polynomial time algorithm exists belong to the complexity class P, which is central in the field of computational complexity theory."
upper bounded,"An algorithm is said to be of polynomial time if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm, that is, T(n) = O(nk) for some positive constant k. Problems for which a deterministic polynomial time algorithm exists belong to the complexity class P, which is central in the field of computational complexity theory."
thesis states,"Cobham's thesis states that polynomial time is a synonym for ""tractable"", ""feasible"", ""efficient"", or ""fast""."
combinatorial optimization,"Variable neighborhood search (VNS), proposed by Mladenovi & Hansen in 1997, is a metaheuristic method for solving a set of combinatorial optimization and global optimization problems. !! Typical combinatorial optimization problems are the travelling salesman problem (""TSP""), the minimum spanning tree problem (""MST""), and the knapsack problem. !! Some research literature considers discrete optimization to consist of integer programming together with combinatorial optimization (which in turn is composed of optimization problems dealing with graph structures), although all of these topics have closely intertwined research literature. !! Combinatorial optimization is related to operations research, algorithm theory, and computational complexity theory. !! Combinatorial optimization is a subfield of mathematical optimization that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set. !! The Steiner tree problem, or minimum Steiner tree problem, named after Jakob Steiner, is an umbrella term for a class of problems in combinatorial optimization. !! Some examples of combinatorial optimization problems that are covered by this framework are shortest paths and shortest-path trees, flows and circulations, spanning trees, matching, and matroid problems. !! The vehicle routing problem (VRP) is a combinatorial optimization and integer programming problem which asks ""What is the optimal set of routes for a fleet of vehicles to traverse in order to deliver to a given set of customers""."
optimal object,"Combinatorial optimization is a subfield of mathematical optimization that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set."
finite set,"Infinite sets may be countable or uncountable. !! The power set of an infinite set is infinite. !! Any superset of an infinite set is infinite. !! The existence of any other infinite set can be proved in ZermeloFraenkel set theory (ZFC), but only by showing that it follows from the existence of the natural numbers. !! Combinatorial optimization is a subfield of mathematical optimization that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set. !! Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements. !! For any fixed constant k, the partial k-trees are closed under the operation of graph minors, and therefore, by the RobertsonSeymour theorem, this family can be characterized in terms of a finite set of forbidden minors. !! In set theory, an infinite set is a set that is not a finite set."
discrete set,"A Boolean network consists of a discrete set of boolean variables each of which has a Boolean function (possibly different for each variable) assigned to it which takes inputs from a subset of those variables and output that determines the state of the variable it is assigned to. !! The SternGerlach experiment, proposed in 1921 and implemented in 1922, became a prototypical example of a quantum measurement having a discrete set of possible outcomes. !! Combinatorial optimization is a subfield of mathematical optimization that consists of finding an optimal object from a finite set of objects, where the set of feasible solutions is discrete or can be reduced to a discrete set."
minimum spanning tree problem  mst,"Typical combinatorial optimization problems are the travelling salesman problem (""TSP""), the minimum spanning tree problem (""MST""), and the knapsack problem."
travelling salesman problem  tsp,"Typical combinatorial optimization problems are the travelling salesman problem (""TSP""), the minimum spanning tree problem (""MST""), and the knapsack problem."
typical combinatorial optimization problems,"Typical combinatorial optimization problems are the travelling salesman problem (""TSP""), the minimum spanning tree problem (""MST""), and the knapsack problem."
optimization problems dealing,"Some research literature considers discrete optimization to consist of integer programming together with combinatorial optimization (which in turn is composed of optimization problems dealing with graph structures), although all of these topics have closely intertwined research literature."
closely intertwined research literature,"Some research literature considers discrete optimization to consist of integer programming together with combinatorial optimization (which in turn is composed of optimization problems dealing with graph structures), although all of these topics have closely intertwined research literature."
research literature considers discrete optimization,"Some research literature considers discrete optimization to consist of integer programming together with combinatorial optimization (which in turn is composed of optimization problems dealing with graph structures), although all of these topics have closely intertwined research literature."
graph structures  although,"Some research literature considers discrete optimization to consist of integer programming together with combinatorial optimization (which in turn is composed of optimization problems dealing with graph structures), although all of these topics have closely intertwined research literature."
integer programming together,"Some research literature considers discrete optimization to consist of integer programming together with combinatorial optimization (which in turn is composed of optimization problems dealing with graph structures), although all of these topics have closely intertwined research literature."
path trees,"Some examples of combinatorial optimization problems that are covered by this framework are shortest paths and shortest-path trees, flows and circulations, spanning trees, matching, and matroid problems."
shortest paths,"Some examples of combinatorial optimization problems that are covered by this framework are shortest paths and shortest-path trees, flows and circulations, spanning trees, matching, and matroid problems."
the unfinished revolution,The Unfinished Revolution is a 2001 book by Michael Dertouzos that proposes why and how technology should be made to work for humans.
unfinished revolution,The Unfinished Revolution is a 2001 book by Michael Dertouzos that proposes why and how technology should be made to work for humans.
michael dertouzos,The Unfinished Revolution is a 2001 book by Michael Dertouzos that proposes why and how technology should be made to work for humans.
logical structure,A database model is a type of data model that determines the logical structure of a database.
based format,"The most popular example of a database model is the relational model, which uses a table-based format."
popular example,"The most popular example of a database model is the relational model, which uses a table-based format."
hierarchical database modelit,Hierarchical database modelIt is the oldest form of data base model.
oldest form,Hierarchical database modelIt is the oldest form of data base model.
three key terms,"Three key terms are used extensively in relational database models: relations, attributes, and domains."
relational database contains multiple tables,"A relational database contains multiple tables, each similar to the one in the ""flat"" database model."
ip address 8,"For example, to do a reverse lookup of the IP address 8."
usable data,"To provide more human-usable data, these programs often perform a reverse lookup before writing the log, thus writing a name rather than the IP address."
name rather,"To provide more human-usable data, these programs often perform a reverse lookup before writing the log, thus writing a name rather than the IP address."
thus writing,"To provide more human-usable data, these programs often perform a reverse lookup before writing the log, thus writing a name rather than the IP address."
programs often perform,"To provide more human-usable data, these programs often perform a reverse lookup before writing the log, thus writing a name rather than the IP address."
matrix splitting,"These matrix equations can often be solved directly and efficiently when written as a matrix splitting. !! In the mathematical discipline of numerical linear algebra, a matrix splitting is an expression which represents a given matrix as a sum or difference of matrices. !! Many iterative methods can be described as a matrix splitting."
mathematical discipline,"In the mathematical discipline of linear algebra, a triangular matrix is a special kind of square matrix. !! In the mathematical discipline of numerical linear algebra, a matrix splitting is an expression which represents a given matrix as a sum or difference of matrices."
given matrix,"In the mathematical discipline of numerical linear algebra, a matrix splitting is an expression which represents a given matrix as a sum or difference of matrices. !! In mathematics, low-rank approximation is a minimization problem, in which the cost function measures the fit between a given matrix (the data) and an approximating matrix (the optimization variable), subject to a constraint that the approximating matrix has reduced rank."
matrix equations,These matrix equations can often be solved directly and efficiently when written as a matrix splitting.
solved directly,"These matrix equations can often be solved directly and efficiently when written as a matrix splitting. !! A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly."
many iterative methods,Many iterative methods can be described as a matrix splitting.
interpretations of quantum mechanics,"""Interpretations of Quantum Mechanics"" by Peter J. Lewis. !! A uniqueness theorem for interpretations of quantum mechanics. !! Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics. !! Time-symmetric interpretations of quantum mechanics were first suggested by Walter Schottky in 1921. !! Modal interpretations of quantum mechanics were first conceived of in 1972 by Bas van Fraassen, in his paper ""A formal approach to the philosophy of science. """
first conceived,"Modal interpretations of quantum mechanics were first conceived of in 1972 by Bas van Fraassen, in his paper ""A formal approach to the philosophy of science. """
bas van fraassen,"Modal interpretations of quantum mechanics were first conceived of in 1972 by Bas van Fraassen, in his paper ""A formal approach to the philosophy of science. """
formal approach,"Modal interpretations of quantum mechanics were first conceived of in 1972 by Bas van Fraassen, in his paper ""A formal approach to the philosophy of science. """
modal interpretations,"Modal interpretations of quantum mechanics were first conceived of in 1972 by Bas van Fraassen, in his paper ""A formal approach to the philosophy of science. """
symmetric interpretations,Time-symmetric interpretations of quantum mechanics were first suggested by Walter Schottky in 1921.
walter schottky,Time-symmetric interpretations of quantum mechanics were first suggested by Walter Schottky in 1921.
orthodox interpretations,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
willis lamb,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
like nico van kampen,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
openly criticized non,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
uniqueness theorem,A uniqueness theorem for interpretations of quantum mechanics.
enable processes,Computer network programming involves writing computer programs that enable processes to communicate with each other across a computer network.
model pseudo,"In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems."
stochastic model used,"In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems."
randomly changing systems,"In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems."
simplest markov model,The simplest Markov model is the Markov chain.
noisily observable,A hidden Markov model is a Markov chain for which the state is only partially observable or noisily observable.
partially observable,A hidden Markov model is a Markov chain for which the state is only partially observable or noisily observable.
several well,Several well-known algorithms for hidden Markov models exist.
known algorithms,Several well-known algorithms for hidden Markov models exist.
hidden markov models exist,Several well-known algorithms for hidden Markov models exist.
observation function,"For example, given a sequence of observations, the Viterbi algorithm will compute the most-likely corresponding sequence of states, the forward algorithm will compute the probability of the sequence of observations, and the BaumWelch algorithm will estimate the starting probabilities, the transition function, and the observation function of a hidden Markov model."
likely corresponding sequence,"For example, given a sequence of observations, the Viterbi algorithm will compute the most-likely corresponding sequence of states, the forward algorithm will compute the probability of the sequence of observations, and the BaumWelch algorithm will estimate the starting probabilities, the transition function, and the observation function of a hidden Markov model."
starting probabilities,"For example, given a sequence of observations, the Viterbi algorithm will compute the most-likely corresponding sequence of states, the forward algorithm will compute the probability of the sequence of observations, and the BaumWelch algorithm will estimate the starting probabilities, the transition function, and the observation function of a hidden Markov model."
reverse index,"Reverse indexes are just as efficient as unreversed indexes for finding specific values, although they aren't helpful for range queries. !! In a reverse index, if 14538 goes before 24538 arrives, 24538 can reuse 14538's space."
finding specific values,"Reverse indexes are just as efficient as unreversed indexes for finding specific values, although they aren't helpful for range queries."
industrial automation applications,The Common Industrial Protocol (CIP) is an industrial protocol for industrial automation applications.
common industrial protocol,ODVA is the organization that supports network technologies built on the Common Industrial Protocol (CIP). !! The Common Industrial Protocol (CIP) is an industrial protocol for industrial automation applications.
supports network technologies built,ODVA is the organization that supports network technologies built on the Common Industrial Protocol (CIP).
technical innovations,The ACM Symposium on User Interface Software and Technology (UIST) is an annual conference for technical innovations in humancomputer interfaces.
acm symposium,The ACM Symposium on User Interface Software and Technology (UIST) is an annual conference for technical innovations in humancomputer interfaces. !! The main research conferences in the area are the ACM Symposium on Principles of Database Systems (PODS) and the International Conference on Database Theory (ICDT).
acm symposium on user interface software and technology,The ACM Symposium on User Interface Software and Technology (UIST) is an annual conference for technical innovations in humancomputer interfaces.
annual conference,The ACM Symposium on User Interface Software and Technology (UIST) is an annual conference for technical innovations in humancomputer interfaces.
human nervous system,"Neurocomputational speech processing is computer-simulation of speech production and speech perception by referring to the natural neuronal processes of speech production and speech perception, as they occur in the human nervous system (central nervous system and peripheral nervous system)."
speech production,"Neurocomputational speech processing is computer-simulation of speech production and speech perception by referring to the natural neuronal processes of speech production and speech perception, as they occur in the human nervous system (central nervous system and peripheral nervous system)."
natural neuronal processes,"Neurocomputational speech processing is computer-simulation of speech production and speech perception by referring to the natural neuronal processes of speech production and speech perception, as they occur in the human nervous system (central nervous system and peripheral nervous system)."
central nervous system,"Probabilistic Neural Networks to the Class Prediction of Leukemia and Embryonal Tumor of Central Nervous System. !! Neurocomputational speech processing is computer-simulation of speech production and speech perception by referring to the natural neuronal processes of speech production and speech perception, as they occur in the human nervous system (central nervous system and peripheral nervous system)."
available knowledge using logical techniques,In information technology a reasoning system is a software system that generates conclusions from available knowledge using logical techniques such as deduction and induction.
generates conclusions,In information technology a reasoning system is a software system that generates conclusions from available knowledge using logical techniques such as deduction and induction.
reasoning systems play,Reasoning systems play an important role in the implementation of artificial intelligence and knowledge-based systems.
based systems,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers. !! Reasoning systems play an important role in the implementation of artificial intelligence and knowledge-based systems. !! Knowledge engineering (KE) refers to all technical, scientific and social aspects involved in building, maintaining and using knowledge-based systems."
everyday usage definition,"By the everyday usage definition of the phrase, all computer systems are reasoning systems in that they all automate some type of logic or decision."
reasoning systems come,Reasoning systems come in two modes: interactive and batch processing.
two modes,"Reasoning systems come in two modes: interactive and batch processing. !! Self-organizing maps, like most artificial neural networks, operate in two modes: training and mapping."
batch processing,"Reasoning systems come in two modes: interactive and batch processing. !! Accidental complexity relates to problems which engineers create and can fix; for example, the details of writing and optimizing assembly code or the delays caused by batch processing."
includes scheduling,"Reasoning systems have a wide field of application that includes scheduling, business rule processing, problem solving, complex event processing, intrusion detection, predictive analytics, robotics, computer vision, and natural language processing."
wide field,"Reasoning systems have a wide field of application that includes scheduling, business rule processing, problem solving, complex event processing, intrusion detection, predictive analytics, robotics, computer vision, and natural language processing."
hard decision,There are hard decision and soft decision Viterbi decoders.
simple bitstream,"A hard decision Viterbi decoder receives a simple bitstream on its input, and a Hamming distance is used as a metric."
hard decision viterbi decoder receives,"A hard decision Viterbi decoder receives a simple bitstream on its input, and a Hamming distance is used as a metric."
received symbol,A soft decision Viterbi decoder receives a bitstream containing information about the reliability of each received symbol.
bitstream containing information,A soft decision Viterbi decoder receives a bitstream containing information about the reliability of each received symbol.
soft decision viterbi decoder receives,A soft decision Viterbi decoder receives a bitstream containing information about the reliability of each received symbol.
correct order,"Since it does it in inverse direction, a viterbi decoder comprises a FILO (first-in-last-out) buffer to reconstruct a correct order."
viterbi decoder comprises,"Since it does it in inverse direction, a viterbi decoder comprises a FILO (first-in-last-out) buffer to reconstruct a correct order."
inverse direction,"Since it does it in inverse direction, a viterbi decoder comprises a FILO (first-in-last-out) buffer to reconstruct a correct order."
human speech,"Speech synthesis is the artificial production of human speech. !! Voice activity detection (VAD), also known as speech activity detection or speech detection, is the detection of the presence or absence of human speech, used in speech processing."
vad  also known,"Voice activity detection (VAD), also known as speech activity detection or speech detection, is the detection of the presence or absence of human speech, used in speech processing."
voice activity detection,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded. !! Voice activity detection is usually independent of language. !! Voice activity detection (VAD), also known as speech activity detection or speech detection, is the detection of the presence or absence of human speech, used in speech processing."
usually independent,Voice activity detection is usually independent of language.
speech frames,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
often discarded,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
speech processing applications,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
important role since non,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
voice activity detection plays,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
solving one problem,Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.
related problem,Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.
research problem,Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.
storing knowledge gained,Transfer learning (TL) is a research problem in machine learning (ML) that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem.
neural networks training,"In 1976, Stevo Bozinovski and Ante Fulgosi published a paper explicitly addressing transfer learning in neural networks training."
paper explicitly addressing transfer learning,"In 1976, Stevo Bozinovski and Ante Fulgosi published a paper explicitly addressing transfer learning in neural networks training."
ante fulgosi published,"In 1976, Stevo Bozinovski and Ante Fulgosi published a paper explicitly addressing transfer learning in neural networks training."
stevo bozinovski,"In 1976, Stevo Bozinovski and Ante Fulgosi published a paper explicitly addressing transfer learning in neural networks training."
geometrical model,The paper gives a mathematical and geometrical model of transfer learning.
paper gives,The paper gives a mathematical and geometrical model of transfer learning.
images representing letters,"In 1981, a report was given on the application of transfer learning in training a neural network on a dataset of images representing letters of computer terminals."
experimentally demonstrated,Both positive and negative transfer learning was experimentally demonstrated.
qubit state,"In quantum computing, a graph state is a special type of multi-qubit state that can be represented by a graph."
measurement based quantum computing models,"Graph states are useful in quantum error-correcting codes, entanglement measurement and purification and for characterization of computational resources in measurement based quantum computing models."
two equivalent ways,Quantum graph states can be defined in two equivalent ways: through the notion of quantum circuits and stabilizer formalism.
stabilizer formalism,Quantum graph states can be defined in two equivalent ways: through the notion of quantum circuits and stabilizer formalism.
quantum circuits,Quantum graph states can be defined in two equivalent ways: through the notion of quantum circuits and stabilizer formalism.
two graph states,"More generally, two graph states are locally equivalent if and only if the corresponding graphs are related by a sequence of so-called ""local complementation"" steps, as shown by Van den Nest et al."
locally equivalent,"More generally, two graph states are locally equivalent if and only if the corresponding graphs are related by a sequence of so-called ""local complementation"" steps, as shown by Van den Nest et al."
local complementation,"More generally, two graph states are locally equivalent if and only if the corresponding graphs are related by a sequence of so-called ""local complementation"" steps, as shown by Van den Nest et al."
corresponding graphs,"More generally, two graph states are locally equivalent if and only if the corresponding graphs are related by a sequence of so-called ""local complementation"" steps, as shown by Van den Nest et al."
van den nest et al,"More generally, two graph states are locally equivalent if and only if the corresponding graphs are related by a sequence of so-called ""local complementation"" steps, as shown by Van den Nest et al."
multiparty entanglement,Multiparty entanglement in graph states.
large amount,"This large amount of required computer capabilities explains the small number of general-purpose computer algebra systems. !! In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host. !! However, compared to counting sort, bucket sort requires linked lists, dynamic arrays, or a large amount of pre-allocated memory to hold the sets of items within each bucket, whereas counting sort stores a single number (the count of items) per bucket. !! Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training."
supervised learning falls,Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data).
great practical value,"In such situations, semi-supervised learning can be of great practical value."
human learning,Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.
theoretical interest,Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning.
obtained either,Semi-supervised learning combines this information to surpass the classification performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.
supervised learning combines,Semi-supervised learning combines this information to surpass the classification performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.
classification performance,Semi-supervised learning combines this information to surpass the classification performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.
parallels hardware pipelining,"In computer science, software pipelining is a technique used to optimize loops, in a manner that parallels hardware pipelining."
technique used,"In computer programming, the Schwartzian transform is a technique used to improve the efficiency of sorting a list of items. !! In computer science, software pipelining is a technique used to optimize loops, in a manner that parallels hardware pipelining. !! Reward-based selection is a technique used in evolutionary algorithms for selecting potentially useful solutions for recombination. !! Bayesian poisoning is a technique used by e-mail spammers to attempt to degrade the effectiveness of spam filters that rely on Bayesian spam filtering. !! In telecommunication, information theory, and coding theory, forward error correction (FEC) or channel coding is a technique used for controlling errors in data transmission over unreliable or noisy communication channels. !! Retrospective think aloud protocol is a technique used in usability, and eye tracking in particular, to gather qualitative information on the user intents and reasoning during a test. !! Callback verification, also known as callout verification or Sender Address Verification, is a technique used by SMTP software in order to validate e-mail addresses. !! In computer programming, DLL injection is a technique used for running code within the address space of another process by forcing it to load a dynamic-link library."
optimize loops,"In computer science, software pipelining is a technique used to optimize loops, in a manner that parallels hardware pipelining."
order execution,"Software pipelining is a type of out-of-order execution, except that the reordering is done by a compiler (or in the case of hand written assembly code, by the programmer) instead of the processor."
hand written assembly code,"Software pipelining is a type of out-of-order execution, except that the reordering is done by a compiler (or in the case of hand written assembly code, by the programmer) instead of the processor."
notably intel,"Some computer architectures have explicit support for software pipelining, notably Intel's IA-64 architecture."
explicit support,"Some computer architectures have explicit support for software pipelining, notably Intel's IA-64 architecture."
overlapping loop iterations,"It is important to distinguish software pipelining, which is a target code technique for overlapping loop iterations, from modulo scheduling, the currently most effective known compiler technique for generating software pipelined loops."
effective known compiler technique,"It is important to distinguish software pipelining, which is a target code technique for overlapping loop iterations, from modulo scheduling, the currently most effective known compiler technique for generating software pipelined loops."
generating software pipelined loops,"It is important to distinguish software pipelining, which is a target code technique for overlapping loop iterations, from modulo scheduling, the currently most effective known compiler technique for generating software pipelined loops."
distinguish software pipelining,"It is important to distinguish software pipelining, which is a target code technique for overlapping loop iterations, from modulo scheduling, the currently most effective known compiler technique for generating software pipelined loops."
target code technique,"It is important to distinguish software pipelining, which is a target code technique for overlapping loop iterations, from modulo scheduling, the currently most effective known compiler technique for generating software pipelined loops."
architectures existed,Software pipelining has been known to assembly language programmers of machines with instruction-level parallelism since such architectures existed.
level parallelism since,Software pipelining has been known to assembly language programmers of machines with instruction-level parallelism since such architectures existed.
simple iterative procedure used,"In statistics, the backfitting algorithm is a simple iterative procedure used to fit a generalized additive model."
generalized additive model,"In statistics, the backfitting algorithm is a simple iterative procedure used to fit a generalized additive model."
certain linear system,"In most cases, the backfitting algorithm is equivalent to the GaussSeidel method algorithm for solving a certain linear system of equations."
backfitting algorithm explicitly,"Following, we can formulate the backfitting algorithm explicitly for the two dimensional case."
two dimensional case,"Following, we can formulate the backfitting algorithm explicitly for the two dimensional case."
backfitting algorithm involving projections onto,A modification of the backfitting algorithm involving projections onto the eigenspace of S can remedy this problem.
level symbolic,"In artificial intelligence, symbolic artificial intelligence is the term for the collection of all methods in artificial intelligence research that are based on high-level symbolic (human-readable) representations of problems, logic and search."
alternative approaches,"Subsymbolic artificial intelligence is the set of alternative approaches which do not use explicit high level symbols, such as mathematical optimization, statistical classifiers and neural networks."
use explicit high level symbols,"Subsymbolic artificial intelligence is the set of alternative approaches which do not use explicit high level symbols, such as mathematical optimization, statistical classifiers and neural networks."
technical report,"Symbolic Artificial Intelligence, Connectionist Networks & Beyond (Technical report)."
also called log,"In computer log management and intelligence, log analysis (or system and network log analysis) is an art and science seeking to make sense out of computer-generated records (also called log or audit trail records)."
science seeking,"In computer log management and intelligence, log analysis (or system and network log analysis) is an art and science seeking to make sense out of computer-generated records (also called log or audit trail records)."
generated records,"In computer log management and intelligence, log analysis (or system and network log analysis) is an art and science seeking to make sense out of computer-generated records (also called log or audit trail records)."
make sense,"In computer log management and intelligence, log analysis (or system and network log analysis) is an art and science seeking to make sense out of computer-generated records (also called log or audit trail records)."
make useful comparisons,"Hence, log analysis must interpret messages within the context of an application, vendor, system or configuration in order to make useful comparisons to messages from different log sources."
different log sources,"Hence, log analysis must interpret messages within the context of an application, vendor, system or configuration in order to make useful comparisons to messages from different log sources."
reverse engineering,"Hence, log analysis practices exist on the continuum from text retrieval to reverse engineering of software."
log analysis practices exist,"Hence, log analysis practices exist on the continuum from text retrieval to reverse engineering of software."
text retrieval,"Hence, log analysis practices exist on the continuum from text retrieval to reverse engineering of software."
normal operation,"In log analysis, this means recognizing and ignoring the regular, common log messages that result from the normal operation of the system, and therefore are not too interesting."
common log messages,"In log analysis, this means recognizing and ignoring the regular, common log messages that result from the normal operation of the system, and therefore are not too interesting."
means recognizing,"In log analysis, this means recognizing and ignoring the regular, common log messages that result from the normal operation of the system, and therefore are not too interesting."
often compared,Log Analysis is often compared to other analytics tools such as application performance management (APM) and error monitoring.
analytics tools,Log Analysis is often compared to other analytics tools such as application performance management (APM) and error monitoring.
application performance management,Log Analysis is often compared to other analytics tools such as application performance management (APM) and error monitoring.
dependency network approach provides,The dependency network approach provides a system level analysis of the activity and topology of directed networks.
partial correlation based dependency network,"The partial correlation based dependency network is a class of correlation network, capable of uncovering hidden relationships between its nodes."
uncovering hidden relationships,"The partial correlation based dependency network is a class of correlation network, capable of uncovering hidden relationships between its nodes."
financial sector,"One of the main results of this work is that for the investigated time period (20012003), the structure of the network is dominated by companies belonging to the financial sector, which are the hubs in the dependency network."
companies belonging,"One of the main results of this work is that for the investigated time period (20012003), the structure of the network is dominated by companies belonging to the financial sector, which are the hubs in the dependency network."
investigated time period,"One of the main results of this work is that for the investigated time period (20012003), the structure of the network is dominated by companies belonging to the financial sector, which are the hubs in the dependency network."
main results,"One of the main results of this work is that for the investigated time period (20012003), the structure of the network is dominated by companies belonging to the financial sector, which are the hubs in the dependency network."
dependency network methodology,"Following this work, the dependency network methodology has been applied to the study of the immune system, and semantic networks."
finite objects,The Kolmogorov complexity of a single finite object is the information in that object; the information distance between a pair of finite objects is the minimum information required to go from one object to the other or vice versa.
minimum information required,The Kolmogorov complexity of a single finite object is the information in that object; the information distance between a pair of finite objects is the minimum information required to go from one object to the other or vice versa.
vice versa,"The transpose of an upper triangular matrix is a lower triangular matrix and vice versa. !! For subtractive operations, two (opposite) conventions are employed as most machines set the carry flag on borrow while some machines (such as the 6502 and the PIC) instead reset the carry flag on borrow (and vice versa). !! A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa. !! The Kolmogorov complexity of a single finite object is the information in that object; the information distance between a pair of finite objects is the minimum information required to go from one object to the other or vice versa. !! If the graph is a directed acyclic graph (DAG), topological orderings are pre-topological orderings and vice versa."
one object,The Kolmogorov complexity of a single finite object is the information in that object; the information distance between a pair of finite objects is the minimum information required to go from one object to the other or vice versa.
single finite object,The Kolmogorov complexity of a single finite object is the information in that object; the information distance between a pair of finite objects is the minimum information required to go from one object to the other or vice versa.
thermodynamic principles,"Information distance was first defined and investigated in based on thermodynamic principles, see also."
first defined,"Information distance was first defined and investigated in based on thermodynamic principles, see also. !! Rotation distance was first defined by Karel ulk II and Derick Wood in 1982."
see also,"Information distance was first defined and investigated in based on thermodynamic principles, see also. !! The following table shows features of AMD's APUs (see also: List of AMD accelerated processing units)."
world compressors,"To determine the similarity of objects such as genomes, languages, music, internet attacks and worms, software programs, and so on, information distance is normalized and the Kolmogorov complexity terms approximated by real-world compressors (the Kolmogorov complexity is a lower bound to the length in bits of a compressed version of the object)."
kolmogorov complexity terms approximated,"To determine the similarity of objects such as genomes, languages, music, internet attacks and worms, software programs, and so on, information distance is normalized and the Kolmogorov complexity terms approximated by real-world compressors (the Kolmogorov complexity is a lower bound to the length in bits of a compressed version of the object)."
internet attacks,"To determine the similarity of objects such as genomes, languages, music, internet attacks and worms, software programs, and so on, information distance is normalized and the Kolmogorov complexity terms approximated by real-world compressors (the Kolmogorov complexity is a lower bound to the length in bits of a compressed version of the object)."
total correlations,"A python package for computing all information distances and volumes, multivariate mutual information, conditional mutual information, joint entropies, total correlations, in a dataset of n variables is available ."
quantified variables,"Combinatory logic is a notation to eliminate the need for quantified variables in mathematical logic. !! Combinatory logic was originally intended as a 'pre-logic' that would clarify the role of quantified variables in logic, essentially by eliminating them."
originally intended,"Combinatory logic was originally intended as a 'pre-logic' that would clarify the role of quantified variables in logic, essentially by eliminating them."
would clarify,"Combinatory logic was originally intended as a 'pre-logic' that would clarify the role of quantified variables in logic, essentially by eliminating them."
combinatory logic typically exceeds,"While the expressive power of combinatory logic typically exceeds that of first-order logic, the expressive power of predicate functor logic is identical to that of first order logic (Quine 1960, 1966, 1976)."
original inventor,"The original inventor of combinatory logic, Moses Schnfinkel, published nothing on combinatory logic after his original 1924 paper."
moses schnfinkel,"The original inventor of combinatory logic, Moses Schnfinkel, published nothing on combinatory logic after his original 1924 paper."
original 1924 paper,"The original inventor of combinatory logic, Moses Schnfinkel, published nothing on combinatory logic after his original 1924 paper."
published nothing,"The original inventor of combinatory logic, Moses Schnfinkel, published nothing on combinatory logic after his original 1924 paper."
princeton invented,"In the late 1930s, Alonzo Church and his students at Princeton invented a rival formalism for functional abstraction, the lambda calculus, which proved more popular than combinatory logic."
alonzo church,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post. !! Two influential type theories that were proposed as foundations are Alonzo Church's typed -calculus and Per Martin-Lf's intuitionistic type theory. !! Anonymous functions originate in the work of Alonzo Church in his invention of the lambda calculus, in which all functions are anonymous, in 1936, before electronic computers. !! Some pioneers of the theory of computation were Ramon Llull, Alonzo Church, Kurt Gdel, Alan Turing, Stephen Kleene, Rzsa Pter, John von Neumann and Claude Shannon. !! In the late 1930s, Alonzo Church and his students at Princeton invented a rival formalism for functional abstraction, the lambda calculus, which proved more popular than combinatory logic."
rival formalism,"In the late 1930s, Alonzo Church and his students at Princeton invented a rival formalism for functional abstraction, the lambda calculus, which proved more popular than combinatory logic."
greedy randomized adaptive search procedure,The greedy randomized adaptive search procedure (also known as GRASP) is a metaheuristic algorithm commonly applied to combinatorial optimization problems.
metaheuristic algorithm commonly applied,The greedy randomized adaptive search procedure (also known as GRASP) is a metaheuristic algorithm commonly applied to combinatorial optimization problems.
extracting useful information,Structure mining or structured data mining is the process of finding and extracting useful information from semi-structured data sets.
message facilitates structure mining,The addition of these data types related to the structure of a document or message facilitates structure mining.
data types related,The addition of these data types related to the structure of a document or message facilitates structure mining.
based education research laboratory,Symbolic Sound Corporation was founded by Carla Scaletti and Kurt J. Hebel in 1989 as a spinoff of the CERL Sound Group at the Computer-based Education Research Laboratory of the University of Illinois at UrbanaChampaign.
carla scaletti,Symbolic Sound Corporation was founded by Carla Scaletti and Kurt J. Hebel in 1989 as a spinoff of the CERL Sound Group at the Computer-based Education Research Laboratory of the University of Illinois at UrbanaChampaign.
cerl sound group,Symbolic Sound Corporation was founded by Carla Scaletti and Kurt J. Hebel in 1989 as a spinoff of the CERL Sound Group at the Computer-based Education Research Laboratory of the University of Illinois at UrbanaChampaign.
symbolic sound corporation,"Symbolic Sound Corporation was founded by Carla Scaletti and Kurt J. Hebel in 1989 as a spinoff of the CERL Sound Group at the Computer-based Education Research Laboratory of the University of Illinois at UrbanaChampaign. !! Originally named Kymatics, the company was incorporated as Symbolic Sound Corporation in March 1990."
originally named kymatics,"Originally named Kymatics, the company was incorporated as Symbolic Sound Corporation in March 1990."
accra declaration,The Accra Declaration confirmed the support of the two main healthcare interoperability standards by the open source community.
open source community,The Accra Declaration confirmed the support of the two main healthcare interoperability standards by the open source community.
two main healthcare interoperability standards,The Accra Declaration confirmed the support of the two main healthcare interoperability standards by the open source community.
accra declaration confirmed,The Accra Declaration confirmed the support of the two main healthcare interoperability standards by the open source community.
nonempty set together,"In computer science, an abstract state machine (ASM) is a state machine operating on states that are arbitrary data structures (structure in the sense of mathematical logic, that is a nonempty set together with a number of functions (operations) and relations over the set)."
computational logic 1,"Y. Gurevich, Sequential Abstract State Machines capture Sequential Algorithms, ACM Transactions on Computational Logic 1(1) (July 2000), 77111."
level system design,"E. Brger and R. Strk, Abstract State Machines: A Method for High-Level System Design and Analysis, Springer-Verlag, 2003."
tracking technologies,"3D user interaction systems are based primarily on motion tracking technologies, to obtain all the necessary information from the user through the analysis of their movements or gestures, these technologies are called, tracking technologies."
based primarily,"3D user interaction systems are based primarily on motion tracking technologies, to obtain all the necessary information from the user through the analysis of their movements or gestures, these technologies are called, tracking technologies."
motion tracking technologies,"3D user interaction systems are based primarily on motion tracking technologies, to obtain all the necessary information from the user through the analysis of their movements or gestures, these technologies are called, tracking technologies."
necessary information,"3D user interaction systems are based primarily on motion tracking technologies, to obtain all the necessary information from the user through the analysis of their movements or gestures, these technologies are called, tracking technologies."
full development,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
absolute position,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
least partially,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
basic parameters,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
relative position,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
based system,"A media processor, mostly used as an image/video processor, is a microprocessor-based system-on-a-chip which is designed to deal with digital streaming data in real-time (e. g. display refresh) rates. !! It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp. !! Knowledge acquisition is the process used to define the rules and ontologies required for a knowledge-based system. !! For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height. !! While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
rotation data,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
angular velocity,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
mixed reality user interfaces workshop,"Towards a Universal Implementation of 3D User Interaction Techniques [Proceedings of Specification, Authoring, Adaptation of Mixed Reality User Interfaces Workshop, IEEE VR]."
ieee vr,"Towards a Universal Implementation of 3D User Interaction Techniques [Proceedings of Specification, Authoring, Adaptation of Mixed Reality User Interfaces Workshop, IEEE VR]."
universal implementation,"Towards a Universal Implementation of 3D User Interaction Techniques [Proceedings of Specification, Authoring, Adaptation of Mixed Reality User Interfaces Workshop, IEEE VR]."
quantum cryptography,"Message authentication codes and data origin authentication have been also discussed in the framework of quantum cryptography. !! The best known example of quantum cryptography is quantum key distribution which offers an information-theoretically secure solution to the key exchange problem. !! Quantum cryptography attributes its beginning by the work of Stephen Wiesner and Gilles Brassard. !! The advantage of quantum cryptography lies in the fact that it allows the completion of various cryptographic tasks that are proven or conjectured to be impossible using only classical (i. e. non-quantum) communication. !! Computational number theory has applications to cryptography, including RSA, elliptic curve cryptography and post-quantum cryptography, and is used to investigate conjectures and open problems in number theory, including the Riemann hypothesis, the Birch and Swinnerton-Dyer conjecture, the ABC conjecture, the modularity conjecture, the Sato-Tate conjecture, and explicit aspects of the Langlands program. !! Companies that manufacture quantum cryptography systems include MagiQ Technologies, Inc. (Boston, Massachusetts, United States), ID Quantique (Geneva, Switzerland), QuintessenceLabs (Canberra, Australia), Toshiba (Tokyo, Japan), QNu Labs and SeQureNet (Paris, France). !! Quantum cryptography is the science of exploiting quantum mechanical properties to perform cryptographic tasks."
different parameters,"ISO/IEC 29192-6 Lightweight cryptography - Message authentication codesISO/IEC 9797-1 and -2 define generic models and algorithms that can be used with any block cipher or hash function, and a variety of different parameters."
6 lightweight cryptography,"ISO/IEC 29192-6 Lightweight cryptography - Message authentication codesISO/IEC 9797-1 and -2 define generic models and algorithms that can be used with any block cipher or hash function, and a variety of different parameters."
message authentication codesiso,"ISO/IEC 29192-6 Lightweight cryptography - Message authentication codesISO/IEC 9797-1 and -2 define generic models and algorithms that can be used with any block cipher or hash function, and a variety of different parameters."
2 define generic models,"ISO/IEC 29192-6 Lightweight cryptography - Message authentication codesISO/IEC 9797-1 and -2 define generic models and algorithms that can be used with any block cipher or hash function, and a variety of different parameters."
open standard application layer protocol,The Advanced Message Queuing Protocol (AMQP) is an open standard application layer protocol for message-oriented middleware.
oriented middleware,"Message-oriented middleware (MOM) is software or hardware infrastructure supporting sending and receiving messages between distributed systems. !! Historically, there was a lack of standards governing the use of message-oriented middleware that has caused problems. !! The Advanced Message Queuing Protocol (AMQP) is an open standard application layer protocol for message-oriented middleware."
deeper problem,"In computer programming, a code smell is any characteristic in the source code of a program that possibly indicates a deeper problem."
possibly indicates,"In computer programming, a code smell is any characteristic in the source code of a program that possibly indicates a deeper problem."
code smell,"Determining what is and is not a code smell is subjective, and varies by language, developer, and development methodology. !! Robert C. Martin calls a list of code smells a ""value system"" for software craftsmanship. !! In computer programming, a code smell is any characteristic in the source code of a program that possibly indicates a deeper problem. !! Bad code smells can be an indicator of factors that contribute to technical debt. !! Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning."
development methodology,"Determining what is and is not a code smell is subjective, and varies by language, developer, and development methodology."
code smells,"Robert C. Martin calls a list of code smells a ""value system"" for software craftsmanship. !! Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning."
technically incorrect,Code smells are usually not bugs; they are not technically incorrect and do not prevent the program from functioning.
bad code smells,Bad code smells can be an indicator of factors that contribute to technical debt.
technical debt,Bad code smells can be an indicator of factors that contribute to technical debt.
martin calls,"Robert C. Martin calls a list of code smells a ""value system"" for software craftsmanship."
software craftsmanship,"Robert C. Martin calls a list of code smells a ""value system"" for software craftsmanship."
value system,"Robert C. Martin calls a list of code smells a ""value system"" for software craftsmanship."
site attacker,Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server.
site cooking,"Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc. !! Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server. !! However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries. !! Cross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site."
another site server,Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server.
browser exploit,Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server. !! However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries.
cross-site cooking,"Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server. !! Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc. !! But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack. !! Cross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site. !! However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries."
cookie domain,Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server.
malicious site,"Cross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site."
another site,"Cross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site."
perform session fixation attacks,"Cross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site."
unintentionally perform,"But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack."
site cooking could,"But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack."
administrator password,"But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack."
security vulnerability requires e,"But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack."
fool innocent users,"But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack."
zone scripting etc,"Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc."
site scripting,"Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc. !! Cross-site scripting (XSS) is a type of security vulnerability that can be found in some web applications."
site tracing,"Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc."
site request forgery,"Cross-Site Request Forgery from The Web Application Security Consortium Threat Classification Project !! Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc. !! Cross-site request forgery, also known as one-click attack or session riding and abbreviated as CSRF (sometimes pronounced sea-surf) or XSRF, is a type of malicious exploit of a website where unauthorized commands are submitted from a user that the web application trusts. !! Cross-site request forgery is an example of a confused deputy attack against a web browser because the web browser is tricked into submitting a forged request by a less privileged attacker."
move things across,However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries.
logical security boundaries,However a browser exploit such as cross-site cooking can be used to move things across the logical security boundaries.
analyzing complex decisions,"The analytic hierarchy process (AHP), also analytical hierarchy process, is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology."
structured technique,"The analytic hierarchy process (AHP), also analytical hierarchy process, is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology."
analytical hierarchy,"Saaty, Thomas L. Decision Making for Leaders: The Analytical Hierarchy Process for Decisions in a Complex World (1982). !! The analytic hierarchy process (AHP), also analytical hierarchy process, is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology. !! As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes."
ahp  also analytical hierarchy process,"The analytic hierarchy process (AHP), also analytical hierarchy process, is a structured technique for organizing and analyzing complex decisions, based on mathematics and psychology."
various nodes,"As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes."
analytical hierarchy process moves forward,"As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes."
default values,"As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes."
decision makers input information,"As the Analytical Hierarchy Process moves forward, the priorities will change from their default values as the decision makers input information about the importance of the various nodes."
complex world,"Saaty, Thomas L. Decision Making for Leaders: The Analytical Hierarchy Process for Decisions in a Complex World (1982)."
international standard iso,The Software Engineering Body of Knowledge (SWEBOK ( SWEE-bok)) is an international standard ISO/IEC TR 19759:2005 specifying a guide to the generally accepted software engineering body of knowledge.
generally accepted software engineering body,The Software Engineering Body of Knowledge (SWEBOK ( SWEE-bok)) is an international standard ISO/IEC TR 19759:2005 specifying a guide to the generally accepted software engineering body of knowledge.
software engineering body,The Software Engineering Body of Knowledge (SWEBOK ( SWEE-bok)) is an international standard ISO/IEC TR 19759:2005 specifying a guide to the generally accepted software engineering body of knowledge. !! The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide) has been created through cooperation among several professional bodies and members of industry and is published by the IEEE Computer Society (IEEE).
software engineering body of knowledge,The Software Engineering Body of Knowledge (SWEBOK ( SWEE-bok)) is an international standard ISO/IEC TR 19759:2005 specifying a guide to the generally accepted software engineering body of knowledge. !! The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide) has been created through cooperation among several professional bodies and members of industry and is published by the IEEE Computer Society (IEEE).
iec tr 19759,The Software Engineering Body of Knowledge (SWEBOK ( SWEE-bok)) is an international standard ISO/IEC TR 19759:2005 specifying a guide to the generally accepted software engineering body of knowledge.
ieee computer society,The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide) has been created through cooperation among several professional bodies and members of industry and is published by the IEEE Computer Society (IEEE).
swebok guide,The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide) has been created through cooperation among several professional bodies and members of industry and is published by the IEEE Computer Society (IEEE).
cooperation among several professional bodies,The Guide to the Software Engineering Body of Knowledge (SWEBOK Guide) has been created through cooperation among several professional bodies and members of industry and is published by the IEEE Computer Society (IEEE).
biased estimation,The theory was first introduced by Hoerl and Kennard in 1970 in their Technometrics papers RIDGE regressions: biased estimation of nonorthogonal problems and RIDGE regressions: applications in nonorthogonal problems.
technometrics papers ridge regressions,The theory was first introduced by Hoerl and Kennard in 1970 in their Technometrics papers RIDGE regressions: biased estimation of nonorthogonal problems and RIDGE regressions: applications in nonorthogonal problems.
independent variablesby creating,Ridge regression was developed as a possible solution to the imprecision of least square estimators when linear regression models have some multicollinear (highly correlated) independent variablesby creating a ridge regression estimator (RR).
possible solution,Ridge regression was developed as a possible solution to the imprecision of least square estimators when linear regression models have some multicollinear (highly correlated) independent variablesby creating a ridge regression estimator (RR).
undecidable problems,"Undecidable problems can be related to different topics, such as logic, abstract machines or topology. !! Since there are uncountably many undecidable problems, any list, even one of infinite length, is necessarily incomplete."
different topics,"Undecidable problems can be related to different topics, such as logic, abstract machines or topology."
infinite length,"Since there are uncountably many undecidable problems, any list, even one of infinite length, is necessarily incomplete."
even one,"Since there are uncountably many undecidable problems, any list, even one of infinite length, is necessarily incomplete."
necessarily incomplete,"Since there are uncountably many undecidable problems, any list, even one of infinite length, is necessarily incomplete."
uncountably many undecidable problems,"Since there are uncountably many undecidable problems, any list, even one of infinite length, is necessarily incomplete."
use named temporary arrays,The Schwartzian transform is notable in that it does not use named temporary arrays.
input items,"The Schwartzian transform is a version of a Lisp idiom known as decorate-sort-undecorate, which avoids recomputing the sort keys by temporarily associating them with the input items."
temporarily associating,"The Schwartzian transform is a version of a Lisp idiom known as decorate-sort-undecorate, which avoids recomputing the sort keys by temporarily associating them with the input items."
avoids recomputing,"The Schwartzian transform is a version of a Lisp idiom known as decorate-sort-undecorate, which avoids recomputing the sort keys by temporarily associating them with the input items."
lisp idiom known,"The Schwartzian transform is a version of a Lisp idiom known as decorate-sort-undecorate, which avoids recomputing the sort keys by temporarily associating them with the input items."
similar idioms,"The term ""Schwartzian transform"" applied solely to Perl programming for a number of years, but it has later been adopted by some users of other languages, such as Python, to refer to similar idioms in those languages."
applied solely,"The term ""Schwartzian transform"" applied solely to Perl programming for a number of years, but it has later been adopted by some users of other languages, such as Python, to refer to similar idioms in those languages."
specific idiom,"The term ""Schwartzian transform"" indicates a specific idiom, and not the algorithm in general."
network scheduler suited,Weighted random early detection (WRED) is a queueing discipline for a network scheduler suited for congestion avoidance.
weighted random early detection,Weighted random early detection (WRED) is a queueing discipline for a network scheduler suited for congestion avoidance.
queueing discipline,Weighted random early detection (WRED) is a queueing discipline for a network scheduler suited for congestion avoidance.
congestion avoidance,Weighted random early detection (WRED) is a queueing discipline for a network scheduler suited for congestion avoidance.
natural phenoma,Spatiotemporal patterns are patterns that occur in a wide range of natural phenoma and are characterized by a spatial and a temporal patterning.
full complexity,"In contrast to ""static"", pure spatial patterns, the full complexity of spatiotemporal patterns can only be recognized over time."
static  pure spatial patterns,"In contrast to ""static"", pure spatial patterns, the full complexity of spatiotemporal patterns can only be recognized over time."
traveling wave,Any kind of traveling wave is a good example of a spatiotemporal pattern.
good example,Any kind of traveling wave is a good example of a spatiotemporal pattern.
thus apt,It is thus apt to say that spatiotemporal patterns in nature are the rule rather than the exception.
rule rather,It is thus apt to say that spatiotemporal patterns in nature are the rule rather than the exception.
produces spatial patterns,"Any type of reactiondiffusion system that produces spatial patterns will also, due to the time-dependency of both reactions and diffusion, produce spatiotemporal patterns."
produce spatiotemporal patterns,"Any type of reactiondiffusion system that produces spatial patterns will also, due to the time-dependency of both reactions and diffusion, produce spatiotemporal patterns."
reactiondiffusion system,"Any type of reactiondiffusion system that produces spatial patterns will also, due to the time-dependency of both reactions and diffusion, produce spatiotemporal patterns."
matching algorithm,"Stochastic diffusion search (SDS) was first described in 1989 as a population-based, pattern-matching algorithm."
first described,"Matrix multiplication was first described by the French mathematician Jacques Philippe Marie Binet in 1812, to represent the composition of linear maps that are represented by matrices. !! Stochastic diffusion search (SDS) was first described in 1989 as a population-based, pattern-matching algorithm. !! The Fibonacci numbers were first described in Indian mathematics, as early as 200 BC in work by Pingala on enumerating possible patterns of Sanskrit poetry formed from syllables of two lengths. !! Trial division was first described by Fibonacci in his book Liber Abaci (1202). !! The relational model (RM) for database management is an approach to managing data using a structure and language consistent with first-order predicate logic, first described in 1969 by English computer scientist Edgar F. Codd, where all data is represented in terms of tuples, grouped into relations. !! A particularly interesting example of the use of partial evaluation, first described in the 1970s by Yoshihiko Futamura, is when prog is an interpreter for a programming language."
problem delegates decide,To solve the problem delegates decide to employ a stochastic diffusion search.
electronics letters,Minimum Stable Convergence Criteria for Stochastic Diffusion Search To be published in Electronics Letters.
minimum stable convergence criteria,Minimum Stable Convergence Criteria for Stochastic Diffusion Search To be published in Electronics Letters.
several used,"The residual bit error rate (RBER) is a receive quality metric in digital transmission, one of several used to quantify the accuracy of the received data."
received data,"The residual bit error rate (RBER) is a receive quality metric in digital transmission, one of several used to quantify the accuracy of the received data."
minimum acceptable signal,"When digital communication systems are being designed, the maximum acceptable residual bit error rate can be used, along with other quality metrics, to calculate the minimum acceptable signal to noise ratio in the system."
digital communication systems,"When digital communication systems are being designed, the maximum acceptable residual bit error rate can be used, along with other quality metrics, to calculate the minimum acceptable signal to noise ratio in the system."
real number,"In mathematics, the sign function or signum function (from signum, Latin for ""sign"") is an odd mathematical function that extracts the sign of a real number. !! Regression tree analysis is when the predicted outcome can be considered a real number (e. g. the price of a house, or a patient's length of stay in a hospital). !! A real data type is a data type used in a computer program to represent an approximation of a real number. !! A beta encoder is an analog-to-digital conversion (A/D) system in which a real number in the unit interval is represented by a finite representation of a sequence in base beta, with beta being a real number between 1 and 2. !! Fuzzy logic is a form of many-valued logic in which the truth value of variables may be any real number between 0 and 1."
finite representation,"A beta encoder is an analog-to-digital conversion (A/D) system in which a real number in the unit interval is represented by a finite representation of a sequence in base beta, with beta being a real number between 1 and 2."
base beta,"In practice, beta encoders have attempted to exploit the redundancy provided by the non-uniqueness of the expansion in base beta to produce more robust results. !! A beta encoder is an analog-to-digital conversion (A/D) system in which a real number in the unit interval is represented by a finite representation of a sequence in base beta, with beta being a real number between 1 and 2."
beta encoder,"In practice, beta encoders have attempted to exploit the redundancy provided by the non-uniqueness of the expansion in base beta to produce more robust results. !! An early beta encoder, the Golden ratio encoder used the golden ratio base for its value of beta, but was susceptible to hardware errors. !! A beta encoder is an analog-to-digital conversion (A/D) system in which a real number in the unit interval is represented by a finite representation of a sequence in base beta, with beta being a real number between 1 and 2. !! Beta encoders are an alternative to traditional approaches to pulse-code modulation. !! Rather than using base 2, beta encoders use base beta as a beta-expansion."
traditional approaches,Beta encoders are an alternative to traditional approaches to pulse-code modulation.
beta encoders,"In practice, beta encoders have attempted to exploit the redundancy provided by the non-uniqueness of the expansion in base beta to produce more robust results. !! Beta encoders are an alternative to traditional approaches to pulse-code modulation."
using base 2,"Rather than using base 2, beta encoders use base beta as a beta-expansion."
beta encoders use base beta,"Rather than using base 2, beta encoders use base beta as a beta-expansion."
redundancy provided,"In practice, beta encoders have attempted to exploit the redundancy provided by the non-uniqueness of the expansion in base beta to produce more robust results."
robust results,"In practice, beta encoders have attempted to exploit the redundancy provided by the non-uniqueness of the expansion in base beta to produce more robust results."
golden ratio base,"An early beta encoder, the Golden ratio encoder used the golden ratio base for its value of beta, but was susceptible to hardware errors."
golden ratio encoder used,"An early beta encoder, the Golden ratio encoder used the golden ratio base for its value of beta, but was susceptible to hardware errors."
hardware errors,"An early beta encoder, the Golden ratio encoder used the golden ratio base for its value of beta, but was susceptible to hardware errors."
early beta encoder,"An early beta encoder, the Golden ratio encoder used the golden ratio base for its value of beta, but was susceptible to hardware errors."
necessarily known,"Unlike tree traversal, graph traversal may require that some vertices be visited more than once, since it is not necessarily known before transitioning to a vertex that it has already been explored."
unlike tree traversal,"Unlike tree traversal, graph traversal may require that some vertices be visited more than once, since it is not necessarily known before transitioning to a vertex that it has already been explored."
graph traversal may require,"Unlike tree traversal, graph traversal may require that some vertices be visited more than once, since it is not necessarily known before transitioning to a vertex that it has already been explored."
regular graph,A universal traversal sequence is a sequence of instructions comprising a graph traversal for any regular graph with a set number of vertices and for any starting vertex.
starting vertex,A universal traversal sequence is a sequence of instructions comprising a graph traversal for any regular graph with a set number of vertices and for any starting vertex.
set number,A universal traversal sequence is a sequence of instructions comprising a graph traversal for any regular graph with a set number of vertices and for any starting vertex.
instructions comprising,A universal traversal sequence is a sequence of instructions comprising a graph traversal for any regular graph with a set number of vertices and for any starting vertex.
universal traversal sequence,A universal traversal sequence is a sequence of instructions comprising a graph traversal for any regular graph with a set number of vertices and for any starting vertex.
using knowledge,"Knowledge engineering (KE) refers to all technical, scientific and social aspects involved in building, maintaining and using knowledge-based systems."
social aspects involved,"Knowledge engineering (KE) refers to all technical, scientific and social aspects involved in building, maintaining and using knowledge-based systems."
custom methodologies specifically designed,These issues led to the second approach to knowledge engineering: development of custom methodologies specifically designed to build expert systems.
issues led,These issues led to the second approach to knowledge engineering: development of custom methodologies specifically designed to build expert systems.
build expert systems,These issues led to the second approach to knowledge engineering: development of custom methodologies specifically designed to build expert systems.
second approach,These issues led to the second approach to knowledge engineering: development of custom methodologies specifically designed to build expert systems.
knowledge engineering wiley,Expert Systems: The Journal of Knowledge Engineering Wiley-Blackwell
expert systems,Expert Systems: The Journal of Knowledge Engineering Wiley-Blackwell
ground state energy,and that is the main problem of the quantum LC circuit: energies stored on capacitance and inductance are not equal to the ground state energy of the quantum oscillator.
main problem,and that is the main problem of the quantum LC circuit: energies stored on capacitance and inductance are not equal to the ground state energy of the quantum oscillator.
quantum oscillator,and that is the main problem of the quantum LC circuit: energies stored on capacitance and inductance are not equal to the ground state energy of the quantum oscillator.
energies stored,and that is the main problem of the quantum LC circuit: energies stored on capacitance and inductance are not equal to the ground state energy of the quantum oscillator.
quantum lc circuit,"This energy problem produces the quantum LC circuit paradox (QLCCP). !! So, there are no electric or magnetic charges in the quantum LC circuit, but electric and magnetic fluxes only. !! Now one should consider the quantum LC circuit as a ""black wave box"" (BWB), which has no electric or magnetic charges, but waves. !! and that is the main problem of the quantum LC circuit: energies stored on capacitance and inductance are not equal to the ground state energy of the quantum oscillator. !! Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
energy problem produces,This energy problem produces the quantum LC circuit paradox (QLCCP).
quantum lc circuit paradox,This energy problem produces the quantum LC circuit paradox (QLCCP).
magnetic fluxes,"So, there are no electric or magnetic charges in the quantum LC circuit, but electric and magnetic fluxes only."
magnetic charges,"Now one should consider the quantum LC circuit as a ""black wave box"" (BWB), which has no electric or magnetic charges, but waves. !! Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only. !! So, there are no electric or magnetic charges in the quantum LC circuit, but electric and magnetic fluxes only."
quantum waveguide,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
minimal geometrical,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
topological value,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
electromagnetic waves,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
black wave box,"Now one should consider the quantum LC circuit as a ""black wave box"" (BWB), which has no electric or magnetic charges, but waves."
randomized meldable heap,"The randomized meldable heap supports a number of common operations. !! In computer science, a randomized meldable heap (also Meldable Heap or Randomized Meldable Priority Queue) is a priority queue based data structure in which the underlying structure is also a heap-ordered binary tree. !! It offers greater simplicity: all operations for the randomized meldable heap are easy to implement and the constant factors in their complexity bounds are small. !! While the randomized meldable heap is the simplest form of a meldable heap implementation, others do exist. !! Possibly the easiest operation for the randomized meldable heap, FindMin() simply returns the element currently stored in the heap's root node."
ordered binary tree,"In computer science, a randomized meldable heap (also Meldable Heap or Randomized Meldable Priority Queue) is a priority queue based data structure in which the underlying structure is also a heap-ordered binary tree."
underlying structure,"In computer science, a randomized meldable heap (also Meldable Heap or Randomized Meldable Priority Queue) is a priority queue based data structure in which the underlying structure is also a heap-ordered binary tree."
also meldable heap,"In computer science, a randomized meldable heap (also Meldable Heap or Randomized Meldable Priority Queue) is a priority queue based data structure in which the underlying structure is also a heap-ordered binary tree."
complexity bounds,It offers greater simplicity: all operations for the randomized meldable heap are easy to implement and the constant factors in their complexity bounds are small.
offers greater simplicity,It offers greater simplicity: all operations for the randomized meldable heap are easy to implement and the constant factors in their complexity bounds are small.
constant factors,It offers greater simplicity: all operations for the randomized meldable heap are easy to implement and the constant factors in their complexity bounds are small.
randomized meldable heap supports,The randomized meldable heap supports a number of common operations.
common operations,The randomized meldable heap supports a number of common operations.
findmin  simply returns,"Possibly the easiest operation for the randomized meldable heap, FindMin() simply returns the element currently stored in the heap's root node."
element currently stored,"Possibly the easiest operation for the randomized meldable heap, FindMin() simply returns the element currently stored in the heap's root node."
easiest operation,"Possibly the easiest operation for the randomized meldable heap, FindMin() simply returns the element currently stored in the heap's root node."
simplest form,"While the randomized meldable heap is the simplest form of a meldable heap implementation, others do exist."
nimrod megiddo,Prune and search is a method of solving optimization problems suggested by Nimrod Megiddo in 1983.
solving optimization problems suggested,Prune and search is a method of solving optimization problems suggested by Nimrod Megiddo in 1983.
whole input must,In prune and search algorithms S(n) is typically at least linear (since the whole input must be processed).
least linear,In prune and search algorithms S(n) is typically at least linear (since the whole input must be processed).
graph expresses,A graphical model or probabilistic graphical model (PGM) or structured probabilistic model is a probabilistic model for which a graph expresses the conditional dependence structure between random variables.
based representation,"Generally, probabilistic graphical models use a graph-based representation as the foundation for encoding a distribution over a multi-dimensional space and a graph that is a compact or factorized representation of a set of independences that hold in the specific distribution."
probabilistic graphical models use,"Generally, probabilistic graphical models use a graph-based representation as the foundation for encoding a distribution over a multi-dimensional space and a graph that is a compact or factorized representation of a set of independences that hold in the specific distribution."
factorized representation,"Generally, probabilistic graphical models use a graph-based representation as the foundation for encoding a distribution over a multi-dimensional space and a graph that is a compact or factorized representation of a set of independences that hold in the specific distribution."
specific distribution,"Generally, probabilistic graphical models use a graph-based representation as the foundation for encoding a distribution over a multi-dimensional space and a graph that is a compact or factorized representation of a set of independences that hold in the specific distribution."
next figure depicts,The next figure depicts a graphical model with a cycle.
plate notation,A graphical model with many repeated subunits can be represented with plate notation.
many repeated subunits,A graphical model with many repeated subunits can be represented with plate notation.
based technique,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
backpropagation through structure,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
extensively described,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
training recursive neural nets,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
1996 paper written,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
andreas kchler,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
christoph goller,Backpropagation through structure (BPTS) is a gradient-based technique for training recursive neural nets (a superset of recurrent neural nets) and is extensively described in a 1996 paper written by Christoph Goller and Andreas Kchler.
linear least squares include inverting,Numerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods.
orthogonal decomposition methods,Numerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods.
numerical methods,"Computational mathematics involves mathematical research in mathematics as well as in areas of science where computation plays a central and essential role, and emphasizes algorithms, numerical methods, and symbolic computations. !! Computational aeroacoustics is a branch of aeroacoustics that aims to analyze the generation of noise by turbulent flows through numerical methods. !! Numerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods."
numerical methods for linear least squares,Numerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods.
normal equations,Numerical methods for linear least squares include inverting the matrix of the normal equations and orthogonal decomposition methods.
automatically adapts,An adaptive equalizer is an equalizer that automatically adapts to time-varying properties of the communication channel.
varying properties,An adaptive equalizer is an equalizer that automatically adapts to time-varying properties of the communication channel.
communication channel,"Statistically, a communication channel is usually modeled as a triple consisting of an input alphabet, an output alphabet, and for each pair (i, o) of input and output elements a transition probability p(i, o). !! Communication channels are also studied in a discrete-alphabet setting. !! These pathways, called communication channels, use two types of media: cable (twisted-pair wire, cable, and fiber-optic cable) and broadcast (microwave, satellite, radio, and infrared). !! In this more general view, a storage device is also a communication channel, which can be sent to (written) and received from (reading) and allows communicating an information signal over time. !! An adaptive equalizer is an equalizer that automatically adapts to time-varying properties of the communication channel. !! A communication channel refers either to a physical transmission medium such as a wire, or to a logical connection over a multiplexed medium such as a radio channel in telecommunications and computer networking."
symmetric positive definite matrix,"In numerical analysis, an incomplete Cholesky factorization of a symmetric positive definite matrix is a sparse approximation of the Cholesky factorization."
sparse approximation,"In numerical analysis, an incomplete Cholesky factorization of a symmetric positive definite matrix is a sparse approximation of the Cholesky factorization."
incomplete cholesky factorization,"An incomplete Cholesky factorization is given by a sparse lower triangular matrix K that is in some sense close to L. The corresponding preconditioner is KK*. !! An incomplete Cholesky factorization is often used as a preconditioner for algorithms like the conjugate gradient method. !! Implementation of the incomplete Cholesky factorization in the Octave scripting language. !! In numerical analysis, an incomplete Cholesky factorization of a symmetric positive definite matrix is a sparse approximation of the Cholesky factorization. !! This gives an incomplete Cholesky factorization which is as sparse as the matrix A."
algorithms like,An incomplete Cholesky factorization is often used as a preconditioner for algorithms like the conjugate gradient method.
conjugate gradient method,"The conjugate gradient method can also be used to solve unconstrained optimization problems such as energy minimization. !! The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition. !! The biconjugate gradient method provides a generalization to non-symmetric matrices. !! Various nonlinear conjugate gradient methods seek minima of nonlinear optimization problems. !! An incomplete Cholesky factorization is often used as a preconditioner for algorithms like the conjugate gradient method. !! In mathematics, the conjugate gradient method is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is positive-definite."
sense close,An incomplete Cholesky factorization is given by a sparse lower triangular matrix K that is in some sense close to L. The corresponding preconditioner is KK*.
sparse lower triangular matrix k,An incomplete Cholesky factorization is given by a sparse lower triangular matrix K that is in some sense close to L. The corresponding preconditioner is KK*.
corresponding preconditioner,An incomplete Cholesky factorization is given by a sparse lower triangular matrix K that is in some sense close to L. The corresponding preconditioner is KK*.
agent creates,"Software design is the process by which an agent creates a specification of a software artifact intended to accomplish goals, using a set of primitive components and subject to constraints."
accomplish goals,"Software design is the process by which an agent creates a specification of a software artifact intended to accomplish goals, using a set of primitive components and subject to constraints."
primitive components,"Software design is the process by which an agent creates a specification of a software artifact intended to accomplish goals, using a set of primitive components and subject to constraints."
software artifact intended,"Software design is the process by which an agent creates a specification of a software artifact intended to accomplish goals, using a set of primitive components and subject to constraints."
activity following requirements specification,"Software design may refer to either ""all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems"" or ""the activity following requirements specification and before programming, as ."
activity involved,"Software design may refer to either ""all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems"" or ""the activity following requirements specification and before programming, as ."
software design may refer,"Software design may refer to either ""all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems"" or ""the activity following requirements specification and before programming, as ."
ultimately modifying complex systems,"Software design may refer to either ""all the activity involved in conceptualizing, framing, implementing, commissioning, and ultimately modifying complex systems"" or ""the activity following requirements specification and before programming, as ."
software design usually involves problem,"""Software design usually involves problem-solving and planning a software solution."
defining software solutions,Software design is the process of envisioning and defining software solutions to one or more sets of problems.
main components,One of the main components of software design is the software requirements analysis (SRA).
random points,Alignments of random points in a plane can be demonstrated by statistics to be counter-intuitively easy to find when a large number of random points are marked on a bounded flat surface.
alignments of random points,Alignments of random points in a plane can be demonstrated by statistics to be counter-intuitively easy to find when a large number of random points are marked on a bounded flat surface.
bounded flat surface,Alignments of random points in a plane can be demonstrated by statistics to be counter-intuitively easy to find when a large number of random points are marked on a bounded flat surface.
intuitively easy,Alignments of random points in a plane can be demonstrated by statistics to be counter-intuitively easy to find when a large number of random points are marked on a bounded flat surface.
acoustical devices,An audio analyzer is a test and measurement instrument used to objectively quantify the audio performance of electronic and electro-acoustical devices.
audio performance,An audio analyzer is a test and measurement instrument used to objectively quantify the audio performance of electronic and electro-acoustical devices.
audio analyzer,"An audio analyzer is a test and measurement instrument used to objectively quantify the audio performance of electronic and electro-acoustical devices. !! For example, while a commercial CD player can achieve a total harmonic distortion plus noise (THD+N) ratio of approximately 98 dB at 1 kHz, a high quality audio analyzer may exhibit THD+N as low as 121 dB (this is the specified typical performance of the Audio Precision APx555). !! High quality audio analyzers must demonstrate vanishingly low levels of noise, distortion and interference in order to be deemed worthwhile, and must do so consistently and reliably to be trusted by engineers and designers. !! As test and measurement equipment, audio analyzers are required to provide performance well beyond that of the typical devices under test (DUTs). !! Audio analyzers are used in both development and production of products."
measurement instrument used,An audio analyzer is a test and measurement instrument used to objectively quantify the audio performance of electronic and electro-acoustical devices.
objectively quantify,An audio analyzer is a test and measurement instrument used to objectively quantify the audio performance of electronic and electro-acoustical devices.
audio analyzers,"Audio analyzers are used in both development and production of products. !! As test and measurement equipment, audio analyzers are required to provide performance well beyond that of the typical devices under test (DUTs)."
measurement equipment,"As test and measurement equipment, audio analyzers are required to provide performance well beyond that of the typical devices under test (DUTs)."
provide performance well beyond,"As test and measurement equipment, audio analyzers are required to provide performance well beyond that of the typical devices under test (DUTs)."
typical devices,"As test and measurement equipment, audio analyzers are required to provide performance well beyond that of the typical devices under test (DUTs)."
deemed worthwhile,"High quality audio analyzers must demonstrate vanishingly low levels of noise, distortion and interference in order to be deemed worthwhile, and must do so consistently and reliably to be trusted by engineers and designers."
specified typical performance,"For example, while a commercial CD player can achieve a total harmonic distortion plus noise (THD+N) ratio of approximately 98 dB at 1 kHz, a high quality audio analyzer may exhibit THD+N as low as 121 dB (this is the specified typical performance of the Audio Precision APx555)."
audio precision apx555,"For example, while a commercial CD player can achieve a total harmonic distortion plus noise (THD+N) ratio of approximately 98 dB at 1 kHz, a high quality audio analyzer may exhibit THD+N as low as 121 dB (this is the specified typical performance of the Audio Precision APx555)."
total harmonic distortion plus noise,"For example, while a commercial CD player can achieve a total harmonic distortion plus noise (THD+N) ratio of approximately 98 dB at 1 kHz, a high quality audio analyzer may exhibit THD+N as low as 121 dB (this is the specified typical performance of the Audio Precision APx555)."
approximately 98 db,"For example, while a commercial CD player can achieve a total harmonic distortion plus noise (THD+N) ratio of approximately 98 dB at 1 kHz, a high quality audio analyzer may exhibit THD+N as low as 121 dB (this is the specified typical performance of the Audio Precision APx555)."
commercial cd player,"For example, while a commercial CD player can achieve a total harmonic distortion plus noise (THD+N) ratio of approximately 98 dB at 1 kHz, a high quality audio analyzer may exhibit THD+N as low as 121 dB (this is the specified typical performance of the Audio Precision APx555)."
bit microprocessors,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die."
amd  designed,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die."
marketing term,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die."
amd accelerated processing unit,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die."
apu  formerly known,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die."
advanced micro devices,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die. !! The average CPU power (ACP) is the power consumption of central processing units, especially server processors, under ""average"" daily usage as defined by Advanced Micro Devices (AMD) for use in its line of processors based on the K10 microarchitecture (Opteron 8300 and 2300 series processors)."
single die,"The AMD Accelerated Processing Unit (APU), formerly known as Fusion, is the marketing term for a series of 64-bit microprocessors from Advanced Micro Devices (AMD), designed to act as a central processing unit (CPU) and graphics processing unit (GPU) on a single die."
amd accelerated processing units,The following table shows features of AMD's APUs (see also: List of AMD accelerated processing units).
following table shows features,The following table shows features of AMD's APUs (see also: List of AMD accelerated processing units).
early explanation,An early explanation of transductive learning.
expected risk,"In statistical learning theory, a learnable function class is a set of functions for which an algorithm can be devised to asymptotically minimize the expected risk, uniformly over all probability distributions."
asymptotically minimize,"In statistical learning theory, a learnable function class is a set of functions for which an algorithm can be devised to asymptotically minimize the expected risk, uniformly over all probability distributions."
usable form,A design pattern is the re-usable form of a solution to a design problem.
particular field,An organized collection of design patterns that relate to a particular field is called a pattern language.
design patterns,"Pattern gardening, in gardeningBusiness models also have design patterns. !! An organized collection of design patterns that relate to a particular field is called a pattern language."
organized collection,An organized collection of design patterns that relate to a particular field is called a pattern language.
pattern language,An organized collection of design patterns that relate to a particular field is called a pattern language.
houses must,"Since two houses may be very different from one another, a design pattern for houses must be broad enough to apply to both of them, but not so vague that it doesn't help the designer make decisions."
designer make decisions,"Since two houses may be very different from one another, a design pattern for houses must be broad enough to apply to both of them, but not so vague that it doesn't help the designer make decisions."
broad enough,"Since two houses may be very different from one another, a design pattern for houses must be broad enough to apply to both of them, but not so vague that it doesn't help the designer make decisions."
since two houses may,"Since two houses may be very different from one another, a design pattern for houses must be broad enough to apply to both of them, but not so vague that it doesn't help the designer make decisions."
gardeningbusiness models also,"Pattern gardening, in gardeningBusiness models also have design patterns."
pattern gardening,"Pattern gardening, in gardeningBusiness models also have design patterns."
computational logic,"The term computational logic came to prominence with the founding of the ACM Transactions on Computational Logic in 2000. !! Computational logic has also come to be associated with logic programming, because much of the early work in logic programming in the early 1970s also took place in the Department of Computational Logic in Edinburgh. !! Computational logic is the use of logic to perform or reason about computation. !! ACM Transactions on Computational Logic (ACM TOCL) is a scientific journal that aims to disseminate the latest findings of note in the field of logic in computer science. !! In 1972 the Metamathematics Unit at the University of Edinburgh was renamed The Department of Computational Logic in the School of Artificial Intelligence. !! The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
term computational logic came,The term computational logic came to prominence with the founding of the ACM Transactions on Computational Logic in 2000.
second paragraph,"The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
better phrase,"The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
theorem proving,"Runtime verification avoids the complexity of traditional formal verification techniques, such as model checking and theorem proving, by analyzing only one or a few execution traces and by working directly with the actual system, thus scaling up relatively well and giving more confidence in the results of the analysis (because it avoids the tedious and error-prone step of formally modelling the system), at the expense of less coverage. !! The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
deduction efficiently,"The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
footnote claiming,"The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
make machines,"The expression is used in the second paragraph with a footnote claiming that ""computational logic"" is ""surely a better phrase than 'theorem proving', for the branch of artificial intelligence which deals with how to make machines do deduction efficiently""."
metamathematics unit,In 1972 the Metamathematics Unit at the University of Edinburgh was renamed The Department of Computational Logic in the School of Artificial Intelligence.
early 1970s also took place,"Computational logic has also come to be associated with logic programming, because much of the early work in logic programming in the early 1970s also took place in the Department of Computational Logic in Edinburgh."
also come,"Computational logic has also come to be associated with logic programming, because much of the early work in logic programming in the early 1970s also took place in the Department of Computational Logic in Edinburgh."
string generation,"Applications of string generation include test data generation, Captchas and random essay generation. !! In computer science, string generation is the process of creating a set of strings from a collection of rules."
random essay generation,"Applications of string generation include test data generation, Captchas and random essay generation."
polynomials indexed,"In mathematics, a polynomial sequence is a sequence of polynomials indexed by the nonnegative integers 0, 1, 2, 3, ."
nonnegative integers 0,"In mathematics, a polynomial sequence is a sequence of polynomials indexed by the nonnegative integers 0, 1, 2, 3, ."
polynomial sequence,"In mathematics, the Fibonacci polynomials are a polynomial sequence which can be considered as a generalization of the Fibonacci numbers. !! In mathematics, a polynomial sequence is a sequence of polynomials indexed by the nonnegative integers 0, 1, 2, 3, . !! Polynomial sequences are a topic of interest in enumerative combinatorics and algebraic combinatorics, as well as applied mathematics."
enumerative combinatorics,"Polynomial sequences are a topic of interest in enumerative combinatorics and algebraic combinatorics, as well as applied mathematics."
algebraic combinatorics,"Polynomial sequences are a topic of interest in enumerative combinatorics and algebraic combinatorics, as well as applied mathematics. !! The order polynomial is a polynomial studied in mathematics, in particular in algebraic graph theory and algebraic combinatorics."
polynomial sequences,"Polynomial sequences are a topic of interest in enumerative combinatorics and algebraic combinatorics, as well as applied mathematics."
data retrieval operations,A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and storage space to maintain the index data structure.
index data structure,A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and storage space to maintain the index data structure.
additional writes,A database index is a data structure that improves the speed of data retrieval operations on a database table at the cost of additional writes and storage space to maintain the index data structure.
resolving collisions,"Linear probing is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of keyvalue pairs and looking up the value associated with a given key."
keyvalue pairs,"Linear probing is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of keyvalue pairs and looking up the value associated with a given key."
given key,"Linear probing is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of keyvalue pairs and looking up the value associated with a given key."
value associated,"Linear probing is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of keyvalue pairs and looking up the value associated with a given key."
already occupied,"When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there."
another key,"When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there."
new key,"When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there."
linear probing searches,"When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there."
closest following free location,"When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there."
hash function causes,"When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there."
standard hardware uses linear probing,"As Thorup & Zhang (2012) write, ""Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple. """
popular implementation,"As Thorup & Zhang (2012) write, ""Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple. """
commonly used nontrivial data structures,"As Thorup & Zhang (2012) write, ""Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple. """
provide high performance,"Linear probing can provide high performance because of its good locality of reference, but is more sensitive to the quality of its hash function than some other collision resolution schemes."
good locality,"Linear probing can provide high performance because of its good locality of reference, but is more sensitive to the quality of its hash function than some other collision resolution schemes."
quantum system,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments. !! Relational quantum mechanics (RQM) is an interpretation of quantum mechanics which treats the state of a quantum system as being observer-dependent, that is, the state is the relation between the observer and the system. !! Quantum simulators permit the study of quantum system in a programmable fashion."
relational quantum mechanics,"Laudisa, F. & Rovelli, C. : ""Relational Quantum Mechanics""; The Stanford Encyclopedia of Philosophy (Fall 2005 Edition), Edward N. Zalta (ed. !! Relational quantum mechanics (RQM) is an interpretation of quantum mechanics which treats the state of a quantum system as being observer-dependent, that is, the state is the relation between the observer and the system. !! Relational quantum mechanics arose from a comparison of the quandaries posed by the interpretations of quantum mechanics with those resulting from Lorentz transformations prior to the development of special relativity. !! Rovelli, C. : ""Relational Quantum Mechanics""; International Journal of Theoretical Physics 35; 1996: 1637-1678; arXiv:quant-ph/9609002. !! The assumption rejected by relational quantum mechanics is the existence of an observer-independent state of a system."
relational quantum mechanics arose,Relational quantum mechanics arose from a comparison of the quandaries posed by the interpretations of quantum mechanics with those resulting from Lorentz transformations prior to the development of special relativity.
lorentz transformations prior,Relational quantum mechanics arose from a comparison of the quandaries posed by the interpretations of quantum mechanics with those resulting from Lorentz transformations prior to the development of special relativity.
special relativity,Relational quantum mechanics arose from a comparison of the quandaries posed by the interpretations of quantum mechanics with those resulting from Lorentz transformations prior to the development of special relativity.
quandaries posed,Relational quantum mechanics arose from a comparison of the quandaries posed by the interpretations of quantum mechanics with those resulting from Lorentz transformations prior to the development of special relativity.
independent state,The assumption rejected by relational quantum mechanics is the existence of an observer-independent state of a system.
assumption rejected,The assumption rejected by relational quantum mechanics is the existence of an observer-independent state of a system.
fall 2005 edition  edward n,"Laudisa, F. & Rovelli, C. : ""Relational Quantum Mechanics""; The Stanford Encyclopedia of Philosophy (Fall 2005 Edition), Edward N. Zalta (ed."
stanford encyclopedia,"Laudisa, F. & Rovelli, C. : ""Relational Quantum Mechanics""; The Stanford Encyclopedia of Philosophy (Fall 2005 Edition), Edward N. Zalta (ed."
theoretical physics 35,"Rovelli, C. : ""Relational Quantum Mechanics""; International Journal of Theoretical Physics 35; 1996: 1637-1678; arXiv:quant-ph/9609002."
relational quantum mechanics  international journal,"Rovelli, C. : ""Relational Quantum Mechanics""; International Journal of Theoretical Physics 35; 1996: 1637-1678; arXiv:quant-ph/9609002."
turing test proposed,"The minimum intelligent signal test, or MIST, is a variation of the Turing test proposed by Chris McKinstry in which only boolean (yes/no or true/false) answers may be given to questions."
chris mckinstry,"The minimum intelligent signal test, or MIST, is a variation of the Turing test proposed by Chris McKinstry in which only boolean (yes/no or true/false) answers may be given to questions."
minimum intelligent signal test,"Open source software for performing the Minimum Intelligent Signal Test !! The minimum intelligent signal test, or MIST, is a variation of the Turing test proposed by Chris McKinstry in which only boolean (yes/no or true/false) answers may be given to questions."
answers may,"The minimum intelligent signal test, or MIST, is a variation of the Turing test proposed by Chris McKinstry in which only boolean (yes/no or true/false) answers may be given to questions."
open source software,Open source software for performing the Minimum Intelligent Signal Test
underlying fitness landscape,Evolutionary algorithms often perform well approximating solutions to all types of problems because they ideally do not make any assumption about the underlying fitness landscape.
generally limited,Techniques from evolutionary algorithms applied to the modeling of biological evolution are generally limited to explorations of microevolutionary processes and planning models based upon cellular processes.
microevolutionary processes,Techniques from evolutionary algorithms applied to the modeling of biological evolution are generally limited to explorations of microevolutionary processes and planning models based upon cellular processes.
evolutionary algorithms applied,Techniques from evolutionary algorithms applied to the modeling of biological evolution are generally limited to explorations of microevolutionary processes and planning models based upon cellular processes.
biological evolution,"Techniques from evolutionary algorithms applied to the modeling of biological evolution are generally limited to explorations of microevolutionary processes and planning models based upon cellular processes. !! In computer science, evolutionary computation is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms."
clear genotypephenotype distinction,A possible limitation of many evolutionary algorithms is their lack of a clear genotypephenotype distinction.
many evolutionary algorithms,A possible limitation of many evolutionary algorithms is their lack of a clear genotypephenotype distinction.
possible limitation,A possible limitation of many evolutionary algorithms is their lack of a clear genotypephenotype distinction.
1996  evolutionary algorithms,"Bck, T. (1996), Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms, Oxford Univ."
oxford univ,"Bck, T. (1996), Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms, Oxford Univ."
partial discharges,"Hidden Markov models are known for their applications to thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory, pattern recognition - such as speech, handwriting, gesture recognition, part-of-speech tagging, musical score following, partial discharges and bioinformatics."
musical score following,"Hidden Markov models are known for their applications to thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory, pattern recognition - such as speech, handwriting, gesture recognition, part-of-speech tagging, musical score following, partial discharges and bioinformatics."
several inference problems,"Several inference problems are associated with hidden Markov models, as outlined below."
second half,"The development of the computer algebra systems in the second half of the 20th century is part of the discipline of ""computer algebra"" or ""symbolic computation"", which has spurred work in algorithms over mathematical objects such as polynomials. !! Hidden Markov models were described in a series of statistical papers by Leonard E. Baum and other authors in the second half of the 1960s."
statistical papers,Hidden Markov models were described in a series of statistical papers by Leonard E. Baum and other authors in the second half of the 1960s.
categorical distribution,"In the hidden Markov models considered above, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution). !! In the standard type of hidden Markov model considered here, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution)."
hidden markov models considered,"In the hidden Markov models considered above, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution)."
typically generated,"In the hidden Markov models considered above, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution). !! In the standard type of hidden Markov model considered here, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution)."
allow continuous state spaces,Hidden Markov models can also be generalized to allow continuous state spaces.
security vulnerability,Cross-site scripting (XSS) is a type of security vulnerability that can be found in some web applications.
origin policy,A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy.
site scripting vulnerability may,A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy.
bypass access controls,A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy.
site scripting carried,Cross-site scripting carried out on websites accounted for roughly 84% of all security vulnerabilities documented by Symantec up until 2007.
security vulnerabilities documented,Cross-site scripting carried out on websites accounted for roughly 84% of all security vulnerabilities documented by Symantec up until 2007.
websites accounted,Cross-site scripting carried out on websites accounted for roughly 84% of all security vulnerabilities documented by Symantec up until 2007.
based applications,"Cross-site scripting attacks use known vulnerabilities in web-based applications, their servers, or the plug-in systems on which they rely. !! Today most geometric modeling is done with computers and for computer-based applications."
code injection,Cross-site scripting attacks are a case of code injection.
site scripting attacks,Cross-site scripting attacks are a case of code injection.
improve performance,"The breakdown of Dennard scaling and resulting inability to increase clock frequencies significantly has caused most CPU manufacturers to focus on multicore processors as an alternative way to improve performance. !! To improve performance, priority queues are typically based on a heap, giving O(log n) performance for inserts and removals, and O(n) to build the heap initially from a set of n elements. !! Differentiable neural computers are an outgrowth of Neural Turing machines, with attention mechanisms that control where the memory is active, and improve performance."
whether neurons use rate coding,"Whether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean."
intense debate within,"Whether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean."
neuroscience community,"Whether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean."
terms mean,"Whether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean."
clear definition,"Whether neurons use rate coding or temporal coding is a topic of intense debate within the neuroscience community, even though there is no clear definition of what these terms mean."
alternate explanation,"Temporal coding supplies an alternate explanation for the noise,"" suggesting that it actually encodes information and affects neural processing."
affects neural processing,"Temporal coding supplies an alternate explanation for the noise,"" suggesting that it actually encodes information and affects neural processing."
noise  suggesting,"Temporal coding supplies an alternate explanation for the noise,"" suggesting that it actually encodes information and affects neural processing."
temporal coding supplies,"Temporal coding supplies an alternate explanation for the noise,"" suggesting that it actually encodes information and affects neural processing."
actually encodes information,"Temporal coding supplies an alternate explanation for the noise,"" suggesting that it actually encodes information and affects neural processing."
mean something different,"Temporal coding allows the sequence 000111000111 to mean something different from 001100110011, even though the mean firing rate is the same for both sequences."
mean firing rate,"Temporal coding allows the sequence 000111000111 to mean something different from 001100110011, even though the mean firing rate is the same for both sequences."
temporal coding allows,"Temporal coding allows the sequence 000111000111 to mean something different from 001100110011, even though the mean firing rate is the same for both sequences."
dependent synaptic delay modifications,"In temporal coding, learning can be explained by activity-dependent synaptic delay modifications."
dependent plasticity,"The modifications can themselves depend on spike timing patterns (temporal coding), i. e. , can be a special case of spike-timing-dependent plasticity."
spike timing patterns,"The modifications can themselves depend on spike timing patterns (temporal coding), i. e. , can be a special case of spike-timing-dependent plasticity."
unchangeable object,"In object-oriented and functional programming, an immutable object (unchangeable object) is an object whose state cannot be modified after it is created."
immutable object,"In object-oriented programming, ""immutable interface"" is a pattern for designing an immutable object. !! Strings and other concrete objects are typically expressed as immutable objects to improve readability and runtime efficiency in object-oriented programming. !! In object-oriented and functional programming, an immutable object (unchangeable object) is an object whose state cannot be modified after it is created. !! Immutable objects are also useful because they are inherently thread-safe. !! For example, an object that uses memoization to cache the results of expensive computations could still be considered an immutable object. !! A technique that blends the advantages of mutable and immutable objects, and is supported directly in almost all modern hardware, is copy-on-write (COW)."
object whose state cannot,"In object-oriented and functional programming, an immutable object (unchangeable object) is an object whose state cannot be modified after it is created."
uses memoization,"For example, an object that uses memoization to cache the results of expensive computations could still be considered an immutable object."
expensive computations could still,"For example, an object that uses memoization to cache the results of expensive computations could still be considered an immutable object."
typically expressed,"Runtime verification specifications are typically expressed in trace predicate formalisms, such as finite state machines, regular expressions, context-free patterns, linear temporal logics, etc. !! Strings and other concrete objects are typically expressed as immutable objects to improve readability and runtime efficiency in object-oriented programming."
improve readability,Strings and other concrete objects are typically expressed as immutable objects to improve readability and runtime efficiency in object-oriented programming.
concrete objects,"In normal usage, the client software creates a concrete implementation of the abstract factory and then uses the generic interface of the factory to create the concrete objects that are part of the theme. !! Strings and other concrete objects are typically expressed as immutable objects to improve readability and runtime efficiency in object-oriented programming."
also useful,"Immutable objects are also useful because they are inherently thread-safe. !! Brute-force search is also useful as a baseline method when benchmarking other algorithms or metaheuristics. !! "":xxvii,30 Beyond the digital aspect, interaction design is also useful when creating physical (non-digital) products, exploring how a user might interact with it."
inherently thread,Immutable objects are also useful because they are inherently thread-safe.
supported directly,"A technique that blends the advantages of mutable and immutable objects, and is supported directly in almost all modern hardware, is copy-on-write (COW)."
modern hardware,"A technique that blends the advantages of mutable and immutable objects, and is supported directly in almost all modern hardware, is copy-on-write (COW)."
enforce technical standards,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
level design choices,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
including software coding standards,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
makes high,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
software development expert,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
software architect concept began,"The software architect concept began to take hold when object-oriented programming or OOP, was coming into more widespread use (in the late 1990s and early years of the 21st century)."
early years,"The software architect concept began to take hold when object-oriented programming or OOP, was coming into more widespread use (in the late 1990s and early years of the 21st century)."
widespread use,"The term ""digital identity"" also denotes certain aspects of civil and personal identity that have resulted from the widespread use of identity information to represent people in an acceptable and trusted digital format in computer systems. !! The software architect concept began to take hold when object-oriented programming or OOP, was coming into more widespread use (in the late 1990s and early years of the 21st century)."
take hold,"The software architect concept began to take hold when object-oriented programming or OOP, was coming into more widespread use (in the late 1990s and early years of the 21st century)."
21st century,"The software architect concept began to take hold when object-oriented programming or OOP, was coming into more widespread use (in the late 1990s and early years of the 21st century)."
international association,International Association of Software Architects (IASA)
efficient slink,"ELKI includes multiple hierarchical clustering algorithms, various linkage strategies and also includes the efficient SLINK, CLINK and Anderberg algorithms, flexible cluster extraction from dendrograms and various other cluster analysis algorithms."
also includes,"ELKI includes multiple hierarchical clustering algorithms, various linkage strategies and also includes the efficient SLINK, CLINK and Anderberg algorithms, flexible cluster extraction from dendrograms and various other cluster analysis algorithms."
various linkage strategies,"ELKI includes multiple hierarchical clustering algorithms, various linkage strategies and also includes the efficient SLINK, CLINK and Anderberg algorithms, flexible cluster extraction from dendrograms and various other cluster analysis algorithms."
complex number storage,Some programming languages provide a complex data type for complex number storage and arithmetic as a built-in (primitive) data type.
complex data type,"Languages that support a complex data type usually provide special syntax for building such values, and extend the basic arithmetic operations ('+', '', '', '') to act on them. !! The C99 standard of the C programming language includes complex data types and complex-math functions in the standard library header <complex. !! In some programming environments the term complex data type (in contrast to primitive data types) is a synonym for the composite data type. !! Some programming languages provide a complex data type for complex number storage and arithmetic as a built-in (primitive) data type."
basic arithmetic operations,"Languages that support a complex data type usually provide special syntax for building such values, and extend the basic arithmetic operations ('+', '', '', '') to act on them."
math functions,The C99 standard of the C programming language includes complex data types and complex-math functions in the standard library header <complex.
standard library header,The C99 standard of the C programming language includes complex data types and complex-math functions in the standard library header <complex.
normalized compression distance,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few. !! The normalized compression distance has been used to fully automatically reconstruct language and phylogenetic trees."
two programs,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few. !! The functional principle is similar to the one SDL Trados, XTM and memoQ feature: Just like the server solutions of these two programs, Across Language Server also saves translation units or terminology entries (depending on the project's configuration) into a local or a central MSSQL database."
two languages,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two systems,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two objects,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two pictures,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two music scores,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two genomes,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two emails,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two letters,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
two documents,"Normalized compression distance (NCD) is a way of measuring the similarity between two objects, be it two documents, two letters, two emails, two music scores, two languages, two programs, two pictures, two systems, two genomes, to name a few."
phylogenetic trees,The normalized compression distance has been used to fully automatically reconstruct language and phylogenetic trees.
fully automatically reconstruct language,The normalized compression distance has been used to fully automatically reconstruct language and phylogenetic trees.
takes input,A human interface device or HID is a type of computer device usually used by humans that takes input from humans and gives output to humans.
computer device usually used,A human interface device or HID is a type of computer device usually used by humans that takes input from humans and gives output to humans.
gives output,A human interface device or HID is a type of computer device usually used by humans that takes input from humans and gives output to humans.
human interface device,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication. !! The USB human interface device class describes a USB HID. !! A human interface device or HID is a type of computer device usually used by humans that takes input from humans and gives output to humans.
working group,"The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication. !! The BOF session in December 1996 showed sufficient interest in developing a printing protocol, leading to the creation of the IETF Internet Printing Protocol (ipp) working group, which concluded in 2005."
human interface device class,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication.
proposed standard supported bi,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication.
directional communication,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication.
tom schmidt,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication.
usb hid,The USB human interface device class describes a USB HID.
mountain car problem,"The mountain car problem appeared first in Andrew Moore's PhD Thesis (1990). !! The mountain car problem has undergone many iterations. !! The mountain car problem, although fairly simple, is commonly applied because it requires a reinforcement learning agent to learn on two continuous variables: position and velocity."
two continuous variables,"The mountain car problem, although fairly simple, is commonly applied because it requires a reinforcement learning agent to learn on two continuous variables: position and velocity."
although fairly simple,"The mountain car problem, although fairly simple, is commonly applied because it requires a reinforcement learning agent to learn on two continuous variables: position and velocity."
mountain car problem appeared first,The mountain car problem appeared first in Andrew Moore's PhD Thesis (1990).
phd thesis,The mountain car problem appeared first in Andrew Moore's PhD Thesis (1990).
andrew moore,The mountain car problem appeared first in Andrew Moore's PhD Thesis (1990).
undergone many iterations,The mountain car problem has undergone many iterations.
streaming service,"In October 2021, Quebecor Content acquired exclusive French Canadian rights to Peacock Original programming for its streaming service, Club Illico. !! Peacock is an American over-the-top video streaming service owned and operated by the Television and Streaming division of NBCUniversal, a subsidiary of Comcast. !! This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021. !! This included the launch of an over-the-top streaming service, named ""Peacock"" and made available in April 2020. !! On January 25, 2021, NBCUniversal, which already televised WWE's weekly programs Raw and NXT on USA Network, acquired the exclusive U. S. distribution rights to the WWE Network streaming service beginning March 18, 2021."
streaming division,"Peacock is an American over-the-top video streaming service owned and operated by the Television and Streaming division of NBCUniversal, a subsidiary of Comcast."
top video streaming service owned,"Peacock is an American over-the-top video streaming service owned and operated by the Television and Streaming division of NBCUniversal, a subsidiary of Comcast."
top streaming service,"This included the launch of an over-the-top streaming service, named ""Peacock"" and made available in April 2020."
made available,"Social translucence mechanisms have been made available in many web 2. !! This included the launch of an over-the-top streaming service, named ""Peacock"" and made available in April 2020."
rival streaming services expired,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
recreation joining,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
amazon prime video,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
exclusive streaming rights,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
rival streaming services netflix,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
office joining,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
nbc series,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
nbcu property reboots,"This move also included new original programming, NBCU property reboots, while NBC series The Office and Parks and Recreation were taken off rival streaming services Netflix, Hulu, and Amazon Prime Video and joined the service once their exclusive streaming rights to rival streaming services expired, with Parks and Recreation joining in October 2020 and The Office joining in January 2021."
weekly programs raw,"On January 25, 2021, NBCUniversal, which already televised WWE's weekly programs Raw and NXT on USA Network, acquired the exclusive U. S. distribution rights to the WWE Network streaming service beginning March 18, 2021."
usa network,"On January 25, 2021, NBCUniversal, which already televised WWE's weekly programs Raw and NXT on USA Network, acquired the exclusive U. S. distribution rights to the WWE Network streaming service beginning March 18, 2021."
already televised wwe,"On January 25, 2021, NBCUniversal, which already televised WWE's weekly programs Raw and NXT on USA Network, acquired the exclusive U. S. distribution rights to the WWE Network streaming service beginning March 18, 2021."
distribution rights,"On January 25, 2021, NBCUniversal, which already televised WWE's weekly programs Raw and NXT on USA Network, acquired the exclusive U. S. distribution rights to the WWE Network streaming service beginning March 18, 2021."
peacock original programming,"In October 2021, Quebecor Content acquired exclusive French Canadian rights to Peacock Original programming for its streaming service, Club Illico."
club illico,"In October 2021, Quebecor Content acquired exclusive French Canadian rights to Peacock Original programming for its streaming service, Club Illico."
errors introduced thereby,"In mathematics, approximation theory is concerned with how functions can best be approximated with simpler functions, and with quantitatively characterizing the errors introduced thereby."
quantitatively characterizing,"In mathematics, approximation theory is concerned with how functions can best be approximated with simpler functions, and with quantitatively characterizing the errors introduced thereby."
simpler functions,"In mathematics, approximation theory is concerned with how functions can best be approximated with simpler functions, and with quantitatively characterizing the errors introduced thereby."
bernstein  birkhauser,"K. -G. Steffens, ""The History of Approximation Theory: From Euler to Bernstein,"" Birkhauser, Boston 2006 ISBN 0-8176-4353-2."
boston 2006 isbn 0,"K. -G. Steffens, ""The History of Approximation Theory: From Euler to Bernstein,"" Birkhauser, Boston 2006 ISBN 0-8176-4353-2."
approximation practice  siam 2013,"L. N. Trefethen, ""Approximation theory and approximation practice"", SIAM 2013."
demographically similar people,A focus group is a group interview involving a small number of demographically similar people or participants who have other common traits/experiences.
common traits,A focus group is a group interview involving a small number of demographically similar people or participants who have other common traits/experiences.
focus group,"A focus group is also used by sociologists, psychologists, and researchers in communication studies, education, political science, and public health. !! A focus group is a group interview involving a small number of demographically similar people or participants who have other common traits/experiences. !! In market research, focus groups can explore a group's response to a new product or service. !! Focus groups are used in market research to understand better people's reactions to products or services or participants' perceptions of shared experiences. !! Thus, focus groups constitute a research or evaluation method that researchers organize to collect qualitative data through interactive and directed discussions."
group interview involving,A focus group is a group interview involving a small number of demographically similar people or participants who have other common traits/experiences.
market research,"In market research, focus groups can explore a group's response to a new product or service. !! Web analytics is not just a process for measuring web traffic but can be used as a tool for business and market research and assess and improve website effectiveness. !! Focus groups are used in market research to understand better people's reactions to products or services or participants' perceptions of shared experiences."
understand better people,Focus groups are used in market research to understand better people's reactions to products or services or participants' perceptions of shared experiences.
shared experiences,Focus groups are used in market research to understand better people's reactions to products or services or participants' perceptions of shared experiences.
focus groups,"In market research, focus groups can explore a group's response to a new product or service. !! Focus groups are used in market research to understand better people's reactions to products or services or participants' perceptions of shared experiences."
new product,"In market research, focus groups can explore a group's response to a new product or service."
collect qualitative data,"Thus, focus groups constitute a research or evaluation method that researchers organize to collect qualitative data through interactive and directed discussions."
directed discussions,"Thus, focus groups constitute a research or evaluation method that researchers organize to collect qualitative data through interactive and directed discussions."
focus groups constitute,"Thus, focus groups constitute a research or evaluation method that researchers organize to collect qualitative data through interactive and directed discussions."
researchers organize,"Thus, focus groups constitute a research or evaluation method that researchers organize to collect qualitative data through interactive and directed discussions."
evaluation method,"Thus, focus groups constitute a research or evaluation method that researchers organize to collect qualitative data through interactive and directed discussions."
public health,"A focus group is also used by sociologists, psychologists, and researchers in communication studies, education, political science, and public health."
political science,"Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies. !! A focus group is also used by sociologists, psychologists, and researchers in communication studies, education, political science, and public health."
finite simple graph,"In the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal."
contains information,"The adjacency matrix of a graph should be distinguished from its incidence matrix, a different matrix representation whose elements indicate whether vertexedge pairs are incident or not, and its degree matrix, which contains information about the degree of each vertex. !! The status register is a hardware register that contains information about the state of the processor."
distributed among two,"In theoretical computer science, communication complexity studies the amount of communication required to solve a problem when the input to the problem is distributed among two or more parties."
communication required,"In theoretical computer science, communication complexity studies the amount of communication required to solve a problem when the input to the problem is distributed among two or more parties."
communication complexity,"The study of communication complexity was first introduced by Andrew Yao in 1979, while studying the problem of computation distributed among several machines. !! answers this question by defining randomized communication complexity. !! This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts. !! Note that, unlike in computational complexity theory, communication complexity is not concerned with the amount of computation performed by Alice or Bob, or the size of the memory used, as we generally assume nothing about the computational power of either Alice or Bob. !! In theoretical computer science, communication complexity studies the amount of communication required to solve a problem when the input to the problem is distributed among two or more parties."
communication complexity studies,"In theoretical computer science, communication complexity studies the amount of communication required to solve a problem when the input to the problem is distributed among two or more parties."
andrew yao,"The study of communication complexity was first introduced by Andrew Yao in 1979, while studying the problem of computation distributed among several machines."
computation distributed among several machines,"The study of communication complexity was first introduced by Andrew Yao in 1979, while studying the problem of computation distributed among several machines."
memory used,"Note that, unlike in computational complexity theory, communication complexity is not concerned with the amount of computation performed by Alice or Bob, or the size of the memory used, as we generally assume nothing about the computational power of either Alice or Bob."
generally assume nothing,"Note that, unlike in computational complexity theory, communication complexity is not concerned with the amount of computation performed by Alice or Bob, or the size of the memory used, as we generally assume nothing about the computational power of either Alice or Bob."
computation performed,"Note that, unlike in computational complexity theory, communication complexity is not concerned with the amount of computation performed by Alice or Bob, or the size of the memory used, as we generally assume nothing about the computational power of either Alice or Bob."
either alice,"Note that, unlike in computational complexity theory, communication complexity is not concerned with the amount of computation performed by Alice or Bob, or the size of the memory used, as we generally assume nothing about the computational power of either Alice or Bob."
party communication complexity,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
general form,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
many contexts,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
abstract problem,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
two parties,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
called two,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
defining randomized communication complexity,answers this question by defining randomized communication complexity.
subjective information,"Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information."
study affective states,"Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information."
opinion mining,"Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information."
emotion ai,"Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information."
systematically identify,"Sentiment analysis (also known as opinion mining or emotion AI) is the use of natural language processing, text analysis, computational linguistics, and biometrics to systematically identify, extract, quantify, and study affective states and subjective information."
widely applied,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
customer materials,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
clinical medicine,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
healthcare materials,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
social media,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
survey responses,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
customer service,"Sentiment analysis is widely applied to voice of the customer materials such as reviews and survey responses, online and social media, and healthcare materials for applications that range from marketing to customer service to clinical medicine."
simple examples,The objective and challenges of sentiment analysis can be shown through some simple examples.
entity feature,"A basic task in sentiment analysis is classifying the polarity of a given text at the document, sentence, or feature/aspect levelwhether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral."
expressed opinion,"A basic task in sentiment analysis is classifying the polarity of a given text at the document, sentence, or feature/aspect levelwhether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral."
given text,"A basic task in sentiment analysis is classifying the polarity of a given text at the document, sentence, or feature/aspect levelwhether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral. !! The particular characteristic of a cache language model is that it contains a cache component and assigns relatively high probabilities to words or word sequences that occur elsewhere in a given text."
aspect levelwhether,"A basic task in sentiment analysis is classifying the polarity of a given text at the document, sentence, or feature/aspect levelwhether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral."
basic task,"A basic task in sentiment analysis is classifying the polarity of a given text at the document, sentence, or feature/aspect levelwhether the expressed opinion in a document, a sentence or an entity feature/aspect is positive, negative, or neutral. !! Similar to the traditional sentiment analysis, one of the most basic task in multimodal sentiment analysis is sentiment classification, which classifies different sentiments into categories such as positive, negative, or neutral."
aspect based sentiment analysis,"There are various other types of sentiment analysis like- Aspect Based sentiment analysis, Grading sentiment analysis (positive, negative, neutral), Multilingual sentiment analysis and detection of emotions."
sentiment analysis like,"There are various other types of sentiment analysis like- Aspect Based sentiment analysis, Grading sentiment analysis (positive, negative, neutral), Multilingual sentiment analysis and detection of emotions."
neutral  multilingual sentiment analysis,"There are various other types of sentiment analysis like- Aspect Based sentiment analysis, Grading sentiment analysis (positive, negative, neutral), Multilingual sentiment analysis and detection of emotions."
mean field annealing,Mean field annealing is a deterministic approximation to the simulated annealing technique of solving optimization problems.
solving optimization problems,Mean field annealing is a deterministic approximation to the simulated annealing technique of solving optimization problems.
simulated annealing technique,Mean field annealing is a deterministic approximation to the simulated annealing technique of solving optimization problems.
deterministic approximation,Mean field annealing is a deterministic approximation to the simulated annealing technique of solving optimization problems.
systematic formal theory,"Computability logic (CoL) is a research program and mathematical framework for redeveloping logic as a systematic formal theory of computability, as opposed to classical logic which is a formal theory of truth."
formal theory,"Computability logic (CoL) is a research program and mathematical framework for redeveloping logic as a systematic formal theory of computability, as opposed to classical logic which is a formal theory of truth."
redeveloping logic,"Computability logic (CoL) is a research program and mathematical framework for redeveloping logic as a systematic formal theory of computability, as opposed to classical logic which is a formal theory of truth."
research program,"Computability logic (CoL) is a research program and mathematical framework for redeveloping logic as a systematic formal theory of computability, as opposed to classical logic which is a formal theory of truth."
mathematical framework,"Computability logic (CoL) is a research program and mathematical framework for redeveloping logic as a systematic formal theory of computability, as opposed to classical logic which is a formal theory of truth."
computationally meaningful,"Computability logic is more expressive, constructive and computationally meaningful than classical logic."
computability logic homepage comprehensive survey,Computability Logic Homepage Comprehensive survey of the subject.
downloadable equivalent,A Survey of Computability Logic (PDF) Downloadable equivalent of the above homepage.
practical approach  auerbach publications,"Wagner, F. , ""Modeling Software with Finite State Machines: A Practical Approach"", Auerbach Publications, 2006, ISBN 0-8493-8086-3."
finite state machine,"Grammar induction (or grammatical inference) is the process in machine learning of learning a formal grammar (usually as a collection of re-write rules or productions or alternatively as a finite state machine or automaton of some kind) from a set of observations, thus constructing a model which accounts for the characteristics of the observed objects. !! Timothy Kam, Synthesis of Finite State Machines: Functional Optimization. !! Tiziano Villa, Synthesis of Finite State Machines: Logic Optimization. !! Wagner, F. , ""Modeling Software with Finite State Machines: A Practical Approach"", Auerbach Publications, 2006, ISBN 0-8493-8086-3."
timothy kam,"Timothy Kam, Synthesis of Finite State Machines: Functional Optimization."
tiziano villa,"Tiziano Villa, Synthesis of Finite State Machines: Logic Optimization."
plane spanned,"In numerical linear algebra, a Givens rotation is a rotation in the plane spanned by two coordinates axes."
two coordinates axes,"In numerical linear algebra, a Givens rotation is a rotation in the plane spanned by two coordinates axes."
givens rotation,"In numerical linear algebra, a Givens rotation is a rotation in the plane spanned by two coordinates axes. !! Givens rotations are named after Wallace Givens, who introduced them to numerical analysts in the 1950s while he was working at Argonne National Laboratory. !! The main use of Givens rotations in numerical linear algebra is to introduce zeros in vectors or matrices. !! The product G(i,j,)x represents a counterclockwise rotation of the vector x in the (i,j) plane of radians, hence the name Givens rotation. !! When a Givens rotation matrix, G(i,j,), multiplies another matrix, A, from the left, GA, only rows i and j of A are affected."
numerical analysts,"Givens rotations are named after Wallace Givens, who introduced them to numerical analysts in the 1950s while he was working at Argonne National Laboratory."
wallace givens,"Givens rotations are named after Wallace Givens, who introduced them to numerical analysts in the 1950s while he was working at Argonne National Laboratory."
argonne national laboratory,"Givens rotations are named after Wallace Givens, who introduced them to numerical analysts in the 1950s while he was working at Argonne National Laboratory."
givens rotations,"The main use of Givens rotations in numerical linear algebra is to introduce zeros in vectors or matrices. !! Givens rotations are named after Wallace Givens, who introduced them to numerical analysts in the 1950s while he was working at Argonne National Laboratory. !! There are several methods for actually computing the QR decomposition, such as by means of the GramSchmidt process, Householder transformations, or Givens rotations."
counterclockwise rotation,"The product G(i,j,)x represents a counterclockwise rotation of the vector x in the (i,j) plane of radians, hence the name Givens rotation."
name givens rotation,"The product G(i,j,)x represents a counterclockwise rotation of the vector x in the (i,j) plane of radians, hence the name Givens rotation."
main use,The main use of Givens rotations in numerical linear algebra is to introduce zeros in vectors or matrices.
introduce zeros,The main use of Givens rotations in numerical linear algebra is to introduce zeros in vectors or matrices.
j  multiplies another matrix,"When a Givens rotation matrix, G(i,j,), multiplies another matrix, A, from the left, GA, only rows i and j of A are affected."
givens rotation matrix,"When a Givens rotation matrix, G(i,j,), multiplies another matrix, A, from the left, GA, only rows i and j of A are affected."
based centralized management server,Red Hat Virtualization uses the SPICE protocol and VDSM (Virtual Desktop Server Manager) with a RHEL-based centralized management server.
virtual desktop server manager,Red Hat Virtualization uses the SPICE protocol and VDSM (Virtual Desktop Server Manager) with a RHEL-based centralized management server.
red hat virtualization uses,Red Hat Virtualization uses the SPICE protocol and VDSM (Virtual Desktop Server Manager) with a RHEL-based centralized management server.
red hat virtualization came,Some of the technologies of Red Hat Virtualization came from Red Hat's acquisition of Qumranet.
red hat,Some of the technologies of Red Hat Virtualization came from Red Hat's acquisition of Qumranet.
independent variables,"Degrees of Freedom (often abbreviated df or DOF) refers to the number of independent variables or parameters of a system. !! In statistics, linear regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables). !! In the logistic model, the log-odds (the logarithm of the odds) for the value labeled ""1"" is a linear combination of one or more independent variables (""predictors""); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value)."
linear approach,"In statistics, linear regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables (also known as dependent and independent variables)."
one explanatory variable,"The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression."
called multiple linear regression,"The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression."
called simple linear regression,"The case of one explanatory variable is called simple linear regression; for more than one, the process is called multiple linear regression."
single scalar variable,"This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable."
multiple correlated dependent variables,"This term is distinct from multivariate linear regression, where multiple correlated dependent variables are predicted, rather than a single scalar variable."
response given,"Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis."
linear regression focuses,"Like all forms of regression analysis, linear regression focuses on the conditional probability distribution of the response given the values of the predictors, rather than on the joint probability distribution of all of these variables, which is the domain of multivariate analysis."
many flaws,"He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats."
also argues,"He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats."
programming language concepts,"He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats."
input formats,"He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats."
even graphical input formats,"He also argues that textual and even graphical input formats that affect the behavior of a computer are programming languages, despite the fact they are commonly not Turing-complete, and remarks that ignorance of programming language concepts is the reason for many flaws in input formats."
ai alignment,"In artificial intelligence (AI) and philosophy, AI alignment and the AI control problem are aspects of how to build AI systems such that they will aid rather than harm their creators."
build ai systems,"In artificial intelligence (AI) and philosophy, AI alignment and the AI control problem are aspects of how to build AI systems such that they will aid rather than harm their creators."
aid rather,"In artificial intelligence (AI) and philosophy, AI alignment and the AI control problem are aspects of how to build AI systems such that they will aid rather than harm their creators."
scholars argue,"In addition, some scholars argue that research into the AI control problem might be useful in preventing unintended consequences from existing weak AI."
existing weak ai,"In addition, some scholars argue that research into the AI control problem might be useful in preventing unintended consequences from existing weak AI."
ai control problem might,"In addition, some scholars argue that research into the AI control problem might be useful in preventing unintended consequences from existing weak AI."
preventing unintended consequences,"In addition, some scholars argue that research into the AI control problem might be useful in preventing unintended consequences from existing weak AI."
use numerical approximation,Numerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics).
symbolic manipulations,Numerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics).
discrete mathematics,"In discrete mathematics and theoretical computer science, the rotation distance between two binary trees with the same number of nodes is the minimum number of tree rotations needed to reconfigure one tree into another. !! It is a theory in theoretical computer science, under discrete mathematics (a section of mathematics and also of computer science). !! Numerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics)."
mathematical analysis,"In mathematics and computer science, computable analysis is the study of mathematical analysis from the perspective of computability theory. !! Boolean algebra was introduced by George Boole in his first book The Mathematical Analysis of Logic (1847), and set forth more fully in his An Investigation of the Laws of Thought (1854). !! Numerical analysis is the study of algorithms that use numerical approximation (as opposed to symbolic manipulations) for the problems of mathematical analysis (as distinguished from discrete mathematics)."
21st century also,"Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences, medicine, business and even the arts."
physical sciences,"Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences, medicine, business and even the arts."
numerical analysis finds application,"Numerical analysis finds application in all fields of engineering and the physical sciences, and in the 21st century also the life and social sciences, medicine, business and even the arts."
current growth,"Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering."
computing power,"Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering."
complex numerical analysis,"Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering."
realistic mathematical models,"Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering."
providing detailed,"Current growth in computing power has enabled the use of more complex numerical analysis, providing detailed and realistic mathematical models in science and engineering."
simulating living cells,"Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicine and biology."
numerical analysis include,"Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicine and biology."
galaxies  numerical linear algebra,"Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicine and biology."
celestial mechanics,"Examples of numerical analysis include: ordinary differential equations as found in celestial mechanics (predicting the motions of planets, stars and galaxies), numerical linear algebra in data analysis, and stochastic differential equations and Markov chains for simulating living cells in medicine and biology."
world measurements,"Numerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used."
numerical analysis continues,"Numerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used."
long tradition,"Numerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used."
giving exact symbolic answers translated,"Numerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used."
specifically convolutional neural networks,"Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines."
modern deep learning models,"Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines."
also include propositional formulas,"Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines."
interacting objects,Object-oriented design is the process of planning a system of interacting objects for the purpose of solving a software problem.
oriented design,"Object-oriented design is the discipline of defining the objects and their interactions to solve a problem that was identified and documented during object-oriented analysis. !! In computing, data-oriented design is a program optimization approach motivated by efficient usage of the CPU cache, used in video game development. !! What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects. !! The parallel array (or structure of arrays) is the main example of data-oriented design. !! The input for object-oriented design is provided by the output of object-oriented analysis. !! In object-oriented design, the dependency inversion principle is a specific methodology for loosely coupling software modules. !! Object-oriented design is a method of design encompassing the process of object-oriented decomposition and a notation for depicting both logical and physical as well as state and dynamic models of the system under design. !! Object-oriented design is the process of planning a system of interacting objects for the purpose of solving a software problem."
oriented analysis,"Object-oriented design is the discipline of defining the objects and their interactions to solve a problem that was identified and documented during object-oriented analysis. !! Article Object-Oriented Analysis and Design with UML and RUP an overview (also about CRC cards). !! The service-orientation design principles are applied during the service-oriented analysis and design process. !! Object-oriented analysis and design (OOAD) is a technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality. !! The input for object-oriented design is provided by the output of object-oriented analysis. !! Since then, the Unified Process family has become probably the most popular methodology and reference model for object-oriented analysis and design. !! ""Object-oriented Analysis and Design with Applications, 3rd edition"":http://www."
based approaches,"In bioinformatics, alignment-free sequence analysis approaches to molecular sequence and structure data provide alternatives over alignment-based approaches. !! Humanistic informatics departments were generally started in the 1990s when universities rarely taught humanities-based approaches to the rapidly developing computerized society. !! What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
include object prototype,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
instantiating classes,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
typically obtained,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
based subset,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
oriented decomposition,Object-oriented design is a method of design encompassing the process of object-oriented decomposition and a notation for depicting both logical and physical as well as state and dynamic models of the system under design.
dynamic models,Object-oriented design is a method of design encompassing the process of object-oriented decomposition and a notation for depicting both logical and physical as well as state and dynamic models of the system under design.
design encompassing,Object-oriented design is a method of design encompassing the process of object-oriented decomposition and a notation for depicting both logical and physical as well as state and dynamic models of the system under design.
mitigate system failures,"In computer security, a sandbox is a security mechanism for separating running programs, usually in an effort to mitigate system failures and/or software vulnerabilities from spreading."
security mechanism,"In computer security, a sandbox is a security mechanism for separating running programs, usually in an effort to mitigate system failures and/or software vulnerabilities from spreading."
separating running programs,"In computer security, a sandbox is a security mechanism for separating running programs, usually in an effort to mitigate system failures and/or software vulnerabilities from spreading."
software vulnerabilities,"In computer security, a sandbox is a security mechanism for separating running programs, usually in an effort to mitigate system failures and/or software vulnerabilities from spreading."
solve problems relating,Ambient networks is a network integration design that seeks to solve problems relating to switching between networks to maintain contact with the outside world.
maintain contact,Ambient networks is a network integration design that seeks to solve problems relating to switching between networks to maintain contact with the outside world.
latent variables organized layer,"Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines."
network integration design,Ambient networks is a network integration design that seeks to solve problems relating to switching between networks to maintain contact with the outside world.
ambient network,"The concept of Ambient Networks comes from the IST Ambient Network project, which was a research project sponsored by the European Commission within the Sixth Framework Programme (FP6). !! Ambient Networks was a collaborative project within the European Union's Sixth Framework Programme that investigates future communications systems beyond fixed and 3rd generation mobile networks. !! Ambient Networks aimed to provide a unified networking concept that can adapt to the very heterogeneous environment of different radio technologies and service and network environments. !! Ambient networks is a network integration design that seeks to solve problems relating to switching between networks to maintain contact with the outside world. !! The project worked at a new concept called Ambient Networking, to provide suitable mobile networking technology for the future mobile and wireless communications environment."
outside world,"Ambient networks is a network integration design that seeks to solve problems relating to switching between networks to maintain contact with the outside world. !! However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
ist ambient network project,"The concept of Ambient Networks comes from the IST Ambient Network project, which was a research project sponsored by the European Commission within the Sixth Framework Programme (FP6)."
european commission within,"The concept of Ambient Networks comes from the IST Ambient Network project, which was a research project sponsored by the European Commission within the Sixth Framework Programme (FP6)."
sixth framework programme,"The concept of Ambient Networks comes from the IST Ambient Network project, which was a research project sponsored by the European Commission within the Sixth Framework Programme (FP6). !! Ambient Networks was a collaborative project within the European Union's Sixth Framework Programme that investigates future communications systems beyond fixed and 3rd generation mobile networks."
ambient networks comes,"The concept of Ambient Networks comes from the IST Ambient Network project, which was a research project sponsored by the European Commission within the Sixth Framework Programme (FP6)."
research project sponsored,"The concept of Ambient Networks comes from the IST Ambient Network project, which was a research project sponsored by the European Commission within the Sixth Framework Programme (FP6). !! In 1986, the PRISM architecture framework was developed as a result of the research project sponsored by a group of companies, including IBM, which was seemingly the first published EA framework."
european union,Ambient Networks was a collaborative project within the European Union's Sixth Framework Programme that investigates future communications systems beyond fixed and 3rd generation mobile networks.
3rd generation mobile networks,Ambient Networks was a collaborative project within the European Union's Sixth Framework Programme that investigates future communications systems beyond fixed and 3rd generation mobile networks.
collaborative project within,Ambient Networks was a collaborative project within the European Union's Sixth Framework Programme that investigates future communications systems beyond fixed and 3rd generation mobile networks.
wireless communications environment,"The project worked at a new concept called Ambient Networking, to provide suitable mobile networking technology for the future mobile and wireless communications environment."
new concept called ambient networking,"The project worked at a new concept called Ambient Networking, to provide suitable mobile networking technology for the future mobile and wireless communications environment."
project worked,"The project worked at a new concept called Ambient Networking, to provide suitable mobile networking technology for the future mobile and wireless communications environment."
future mobile,"The project worked at a new concept called Ambient Networking, to provide suitable mobile networking technology for the future mobile and wireless communications environment."
provide suitable mobile networking technology,"The project worked at a new concept called Ambient Networking, to provide suitable mobile networking technology for the future mobile and wireless communications environment."
different radio technologies,Ambient Networks aimed to provide a unified networking concept that can adapt to the very heterogeneous environment of different radio technologies and service and network environments.
network environments,Ambient Networks aimed to provide a unified networking concept that can adapt to the very heterogeneous environment of different radio technologies and service and network environments.
ambient networks aimed,Ambient Networks aimed to provide a unified networking concept that can adapt to the very heterogeneous environment of different radio technologies and service and network environments.
unified networking concept,Ambient Networks aimed to provide a unified networking concept that can adapt to the very heterogeneous environment of different radio technologies and service and network environments.
heterogeneous environment,Ambient Networks aimed to provide a unified networking concept that can adapt to the very heterogeneous environment of different radio technologies and service and network environments.
fibonacci numbers,"Fibonacci numbers are strongly related to the golden ratio: Binet's formula expresses the nth Fibonacci number in terms of n and the golden ratio, and implies that the ratio of two consecutive Fibonacci numbers tends to the golden ratio as n increases. !! The Fibonacci numbers were first described in Indian mathematics, as early as 200 BC in work by Pingala on enumerating possible patterns of Sanskrit poetry formed from syllables of two lengths. !! Fibonacci numbers appear unexpectedly often in mathematics, so much so that there is an entire journal dedicated to their study, the Fibonacci Quarterly. !! In mathematics, the Fibonacci polynomials are a polynomial sequence which can be considered as a generalization of the Fibonacci numbers. !! Applications of Fibonacci numbers include computer algorithms such as the Fibonacci search technique and the Fibonacci heap data structure, and graphs called Fibonacci cubes used for interconnecting parallel and distributed systems. !! In mathematics, the Fibonacci numbers, commonly denoted Fn, form a sequence, the Fibonacci sequence, in which each number is the sum of the two preceding ones. !! In computer science, the Fibonacci search technique is a method of searching a sorted array using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers. !! Fibonacci heaps are named after the Fibonacci numbers, which are used in their running time analysis."
conquer algorithm,"In computer science, the Fibonacci search technique is a method of searching a sorted array using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers. !! The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations. !! Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm""."
possible locations,"In computer science, the Fibonacci search technique is a method of searching a sorted array using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers."
sorted array using,"In computer science, the Fibonacci search technique is a method of searching a sorted array using a divide and conquer algorithm that narrows down possible locations with the aid of Fibonacci numbers."
provide availability,"An application delivery network (ADN) is a suite of technologies that, when deployed together, provide availability, security, visibility, and acceleration for Internet applications such as websites."
application delivery network,"Gartner defines application delivery networking as the combination of WAN optimization controllers (WOCs) and application delivery controllers (ADCs). !! An application delivery network (ADN) is a suite of technologies that, when deployed together, provide availability, security, visibility, and acceleration for Internet applications such as websites. !! An Application Delivery Network (ADN) enhances the delivery of applications across the Internet by employing a number of optimization techniques. !! Application delivery networks are also offered by some CDN vendors. !! Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
deployed together,"An application delivery network (ADN) is a suite of technologies that, when deployed together, provide availability, security, visibility, and acceleration for Internet applications such as websites."
wan optimization controllers,Gartner defines application delivery networking as the combination of WAN optimization controllers (WOCs) and application delivery controllers (ADCs).
application delivery controllers,Gartner defines application delivery networking as the combination of WAN optimization controllers (WOCs) and application delivery controllers (ADCs).
gartner defines application delivery networking,Gartner defines application delivery networking as the combination of WAN optimization controllers (WOCs) and application delivery controllers (ADCs).
cdn vendors,Application delivery networks are also offered by some CDN vendors.
also offered,Application delivery networks are also offered by some CDN vendors.
application delivery networks,Application delivery networks are also offered by some CDN vendors.
optimization techniques,An Application Delivery Network (ADN) enhances the delivery of applications across the Internet by employing a number of optimization techniques.
applications across,An Application Delivery Network (ADN) enhances the delivery of applications across the Internet by employing a number of optimization techniques.
network layer including redundancy,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
content delivery network,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
practices employed,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
load balancing,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
efficiently route traffic,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
established best,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
locally optimal choice,A greedy algorithm is any algorithm that follows the problem-solving heuristic of making the locally optimal choice at each stage.
solving heuristic,A greedy algorithm is any algorithm that follows the problem-solving heuristic of making the locally optimal choice at each stage.
give constant,"In mathematical optimization, greedy algorithms optimally solve combinatorial problems having the properties of matroids and give constant-factor approximations to optimization problems with the submodular structure."
submodular structure,"In mathematical optimization, greedy algorithms optimally solve combinatorial problems having the properties of matroids and give constant-factor approximations to optimization problems with the submodular structure."
factor approximations,"In mathematical optimization, greedy algorithms optimally solve combinatorial problems having the properties of matroids and give constant-factor approximations to optimization problems with the submodular structure."
greedy algorithms produce good solutions,"Greedy algorithms produce good solutions on some mathematical problems, but not on others."
mathematical problems,"Greedy algorithms produce good solutions on some mathematical problems, but not on others."
future choices,"The choice made by a greedy algorithm may depend on choices made so far, but not on future choices or all the solutions to the subproblem."
choices made,"The choice made by a greedy algorithm may depend on choices made so far, but not on future choices or all the solutions to the subproblem."
greedy algorithm may depend,"The choice made by a greedy algorithm may depend on choices made so far, but not on future choices or all the solutions to the subproblem."
choice made,"The choice made by a greedy algorithm may depend on choices made so far, but not on future choices or all the solutions to the subproblem."
greedy algorithm never reconsiders,"In other words, a greedy algorithm never reconsiders its choices."
bilinear form,"In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
multilinear algebra,"In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
multilinear map,"The notion of alternatization (or alternatisation) is used to derive an alternating multilinear map from any multilinear map with all arguments belonging to the same space. !! In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
multilinear form,"In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
alternating multilinear map,"The notion of alternatization (or alternatisation) is used to derive an alternating multilinear map from any multilinear map with all arguments belonging to the same space. !! In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
arguments belonging,"The notion of alternatization (or alternatisation) is used to derive an alternating multilinear map from any multilinear map with all arguments belonging to the same space. !! In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
zero whenever,"In mathematics, more specifically in multilinear algebra, an alternating multilinear map is a multilinear map with all arguments belonging to the same vector space (for example, a bilinear form or a multilinear form) that is zero whenever any pair of arguments is equal."
dot products,"Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
basic linear algebra subprograms,"Dodson, D. S. ; Grimes, R. G. (1982), ""Remark on algorithm 539: Basic Linear Algebra Subprograms for Fortran usage"", ACM Trans. !! Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
performing common linear algebra operations,"Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
level routines,"Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
scalar multiplication,"Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
basic linear algebra,"Dodson, D. S. (1983), ""Corrigendum: Remark on ""Algorithm 539: Basic Linear Algebra Subroutines for FORTRAN usage"""", ACM Trans. !! Dodson, D. S. ; Grimes, R. G. (1982), ""Remark on algorithm 539: Basic Linear Algebra Subprograms for Fortran usage"", ACM Trans. !! A specification for these kernel operations using scalars and vectors, the level-1 Basic Linear Algebra Subroutines (BLAS), was published in 1979. !! Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication. !! Du Croz, S. Hammarling, and R. J. Hanson, Algorithm 656: An extended set of FORTRAN Basic Linear Algebra Subprograms, ACM Trans."
matrix multiplication,"For matrix multiplication, the number of columns in the first matrix must be equal to the number of rows in the second matrix. !! Because matrix multiplication is such a central operation in many numerical algorithms, much work has been invested in making matrix multiplication algorithms efficient. !! In linear algebra, the Strassen algorithm, named after Volker Strassen, is an algorithm for matrix multiplication. !! In mathematics, particularly in linear algebra, matrix multiplication is a binary operation that produces a matrix from two matrices. !! Matrix multiplication is thus a basic tool of linear algebra, and as such has numerous applications in many areas of mathematics, as well as in applied mathematics, statistics, physics, economics, and engineering. !! The Strassen algorithm is only slightly better than that, but its publication resulted in much more research about matrix multiplication that led to faster approaches, such as the CoppersmithWinograd algorithm. !! Historically, matrix multiplication has been introduced for facilitating and clarifying computations in linear algebra. !! Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication. !! Matrix multiplication was first described by the French mathematician Jacques Philippe Marie Binet in 1812, to represent the composition of linear maps that are represented by matrices."
vector addition,"Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
1 basic linear algebra subroutines,"A specification for these kernel operations using scalars and vectors, the level-1 Basic Linear Algebra Subroutines (BLAS), was published in 1979."
kernel operations using scalars,"A specification for these kernel operations using scalars and vectors, the level-1 Basic Linear Algebra Subroutines (BLAS), was published in 1979."
fortran usage  acm trans,"Dodson, D. S. ; Grimes, R. G. (1982), ""Remark on algorithm 539: Basic Linear Algebra Subprograms for Fortran usage"", ACM Trans. !! Dodson, D. S. (1983), ""Corrigendum: Remark on ""Algorithm 539: Basic Linear Algebra Subroutines for FORTRAN usage"""", ACM Trans."
basic linear algebra subroutines,"Dodson, D. S. (1983), ""Corrigendum: Remark on ""Algorithm 539: Basic Linear Algebra Subroutines for FORTRAN usage"""", ACM Trans."
extended set,"Du Croz, S. Hammarling, and R. J. Hanson, Algorithm 656: An extended set of FORTRAN Basic Linear Algebra Subprograms, ACM Trans."
fortran basic linear algebra subprograms,"Du Croz, S. Hammarling, and R. J. Hanson, Algorithm 656: An extended set of FORTRAN Basic Linear Algebra Subprograms, ACM Trans."
acm trans,"Du Croz, S. Hammarling, and R. J. Hanson, Algorithm 656: An extended set of FORTRAN Basic Linear Algebra Subprograms, ACM Trans."
du croz,"Du Croz, S. Hammarling, and R. J. Hanson, Algorithm 656: An extended set of FORTRAN Basic Linear Algebra Subprograms, ACM Trans."
strict division,Phase Distinction is a property of programming languages that observe a strict division between types and terms.
time term,"A concise rule for determining whether phase distinction is preserved in a language or not has been proposed by Luca Cardelli - If A is a compile-time term and B is a subterm of A, then B must also be a compile-time term."
luca cardelli,"A concise rule for determining whether phase distinction is preserved in a language or not has been proposed by Luca Cardelli - If A is a compile-time term and B is a subterm of A, then B must also be a compile-time term."
concise rule,"A concise rule for determining whether phase distinction is preserved in a language or not has been proposed by Luca Cardelli - If A is a compile-time term and B is a subterm of A, then B must also be a compile-time term."
determining whether phase distinction,"A concise rule for determining whether phase distinction is preserved in a language or not has been proposed by Luca Cardelli - If A is a compile-time term and B is a subterm of A, then B must also be a compile-time term."
b must also,"A concise rule for determining whether phase distinction is preserved in a language or not has been proposed by Luca Cardelli - If A is a compile-time term and B is a subterm of A, then B must also be a compile-time term."
statically typed languages conform,Most statically typed languages conform to the principle of phase distinction.
separate namespaces,A language with phase distinction may have separate namespaces for types and run-time variables.
phase distinction may,A language with phase distinction may have separate namespaces for types and run-time variables.
time variables,A language with phase distinction may have separate namespaces for types and run-time variables.
phase distinction marks,"In an optimizing compiler, phase distinction marks the boundary between expressions which are safe to erase."
mathematics higher,In mathematics higher-order functions are also termed operators or functionals.
order functions,"Higher-order functions should not be confused with other uses of the word ""functor"" throughout mathematics, see Functor (disambiguation). !! In mathematics higher-order functions are also termed operators or functionals. !! Anonymous functions are often arguments being passed to higher-order functions or used for constructing the result of a higher-order function that needs to return a function."
also termed operators,In mathematics higher-order functions are also termed operators or functionals.
higher-order function,"Higher-order functions should not be confused with other uses of the word ""functor"" throughout mathematics, see Functor (disambiguation). !! In mathematics higher-order functions are also termed operators or functionals. !! In the following examples, the higher-order function twice takes a function, and applies the function to some value twice. !! map function, found in many functional programming languages, is one example of a higher-order function. !! In this Erlang example, the higher-order function or_else/2 takes a list of functions (Fs) and argument (X). !! Anonymous functions are often arguments being passed to higher-order functions or used for constructing the result of a higher-order function that needs to return a function."
throughout mathematics,"Higher-order functions should not be confused with other uses of the word ""functor"" throughout mathematics, see Functor (disambiguation)."
see functor,"Higher-order functions should not be confused with other uses of the word ""functor"" throughout mathematics, see Functor (disambiguation)."
map function,"map function, found in many functional programming languages, is one example of a higher-order function."
order function,"Anonymous functions are often arguments being passed to higher-order functions or used for constructing the result of a higher-order function that needs to return a function. !! map function, found in many functional programming languages, is one example of a higher-order function."
one example,"Mobile robots are one example of physically embodied agents; Ananova and Microsoft Agent are examples of graphically embodied agents. !! map function, found in many functional programming languages, is one example of a higher-order function."
many functional programming languages,"map function, found in many functional programming languages, is one example of a higher-order function."
value twice,"In the following examples, the higher-order function twice takes a function, and applies the function to some value twice."
order function twice takes,"In the following examples, the higher-order function twice takes a function, and applies the function to some value twice."
following examples,"In the following examples, the higher-order function twice takes a function, and applies the function to some value twice."
order function orelse,"In this Erlang example, the higher-order function or_else/2 takes a list of functions (Fs) and argument (X)."
erlang example,"In this Erlang example, the higher-order function or_else/2 takes a list of functions (Fs) and argument (X)."
parametric statistic measuring,Transfer entropy is a non-parametric statistic measuring the amount of directed (time-asymmetric) transfer of information between two random processes.
two random processes,Transfer entropy is a non-parametric statistic measuring the amount of directed (time-asymmetric) transfer of information between two random processes.
another process,"Transfer entropy from a process X to another process Y is the amount of uncertainty reduced in future values of Y by knowing the past values of X given past values of Y. !! In computer programming, DLL injection is a technique used for running code within the address space of another process by forcing it to load a dynamic-link library."
uncertainty reduced,Transfer entropy from a process X to another process Y is the amount of uncertainty reduced in future values of Y by knowing the past values of X given past values of Y.
x given past values,Transfer entropy from a process X to another process Y is the amount of uncertainty reduced in future values of Y by knowing the past values of X given past values of Y.
future values,Transfer entropy from a process X to another process Y is the amount of uncertainty reduced in future values of Y by knowing the past values of X given past values of Y.
entropy measures,The above definition of transfer entropy has been extended by other types of entropy measures such as Rnyi entropy.
rnyi entropy,The above definition of transfer entropy has been extended by other types of entropy measures such as Rnyi entropy.
regressive processes,Transfer entropy reduces to Granger causality for vector auto-regressive processes.
granger causality,Transfer entropy reduces to Granger causality for vector auto-regressive processes.
transfer entropy reduces,Transfer entropy reduces to Granger causality for vector auto-regressive processes.
vector auto,Transfer entropy reduces to Granger causality for vector auto-regressive processes.
originally defined,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
considering transfer,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
forms require,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
either conditioning,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
bivariate analysis,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
multivariate forms,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
potential source variables,"While it was originally defined for bivariate analysis, transfer entropy has been extended to multivariate forms, either conditioning on other potential source variables or considering transfer from a collection of sources, although these forms require more samples again."
interaction designs,"User experience design (UX design, UXD, UED, or XD) is the process of creating evidence-based, interaction designs between human users and products or websites."
creating evidence,"User experience design (UX design, UXD, UED, or XD) is the process of creating evidence-based, interaction designs between human users and products or websites."
human users,"User experience design (UX design, UXD, UED, or XD) is the process of creating evidence-based, interaction designs between human users and products or websites. !! The field of user experience design is a conceptual design discipline and has its roots in human factors and ergonomics, a field that, since the late 1940s, has focused on the interaction between human users, machines, and the contextual environments to design systems that address the user's experience."
design systems,"The field of user experience design is a conceptual design discipline and has its roots in human factors and ergonomics, a field that, since the late 1940s, has focused on the interaction between human users, machines, and the contextual environments to design systems that address the user's experience."
contextual environments,"The field of user experience design is a conceptual design discipline and has its roots in human factors and ergonomics, a field that, since the late 1940s, has focused on the interaction between human users, machines, and the contextual environments to design systems that address the user's experience."
user experience design draws,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
includes elements,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
user research,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
centered design,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others. !! Thus hands-on computing is a component of user-centered design, focusing on how users physically respond to virtual environments. !! The goal of user interface design is to make the user's interaction as simple and efficient as possible, in terms of accomplishing user goals (user-centered design)."
similar disciplines like interaction design,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
design approaches like human,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
user experience design evolved,"Therefore, User Experience Design evolved into a multidisciplinary design branch that involves multiple technical aspects from motion graphics design and animation to programming."
involves multiple technical aspects,"Therefore, User Experience Design evolved into a multidisciplinary design branch that involves multiple technical aspects from motion graphics design and animation to programming."
multidisciplinary design branch,"Therefore, User Experience Design evolved into a multidisciplinary design branch that involves multiple technical aspects from motion graphics design and animation to programming."
maximum weight matching,"time algorithm to find a maximum matching or a maximum weight matching in a graph that is not bipartite; it is due to Jack Edmonds, is called the paths, trees, and flowers method or simply Edmonds' algorithm, and uses bidirected edges. !! In computer science, the maximum weight matching problem is the problem of finding, in a weighted graph, a matching in which the sum of weights is maximized. !! Their work proposes an approximation algorithm for the maximum weight matching problem, which runs in linear time for any fixed error bound."
maximum weight matching problem,"Their work proposes an approximation algorithm for the maximum weight matching problem, which runs in linear time for any fixed error bound. !! In computer science, the maximum weight matching problem is the problem of finding, in a weighted graph, a matching in which the sum of weights is maximized."
time algorithm,"time algorithm to find a maximum matching or a maximum weight matching in a graph that is not bipartite; it is due to Jack Edmonds, is called the paths, trees, and flowers method or simply Edmonds' algorithm, and uses bidirected edges. !! Like the simplex algorithm of George B. Dantzig, the criss-cross algorithm is not a polynomial-time algorithm for linear programming."
uses bidirected edges,"time algorithm to find a maximum matching or a maximum weight matching in a graph that is not bipartite; it is due to Jack Edmonds, is called the paths, trees, and flowers method or simply Edmonds' algorithm, and uses bidirected edges."
maximum matching,"time algorithm to find a maximum matching or a maximum weight matching in a graph that is not bipartite; it is due to Jack Edmonds, is called the paths, trees, and flowers method or simply Edmonds' algorithm, and uses bidirected edges."
jack edmonds,"time algorithm to find a maximum matching or a maximum weight matching in a graph that is not bipartite; it is due to Jack Edmonds, is called the paths, trees, and flowers method or simply Edmonds' algorithm, and uses bidirected edges."
simply edmonds,"time algorithm to find a maximum matching or a maximum weight matching in a graph that is not bipartite; it is due to Jack Edmonds, is called the paths, trees, and flowers method or simply Edmonds' algorithm, and uses bidirected edges."
work proposes,"Their work proposes an approximation algorithm for the maximum weight matching problem, which runs in linear time for any fixed error bound."
fixed error bound,"Their work proposes an approximation algorithm for the maximum weight matching problem, which runs in linear time for any fixed error bound."
constituent parts,Some fingerprinting algorithms allow the fingerprint of a composite file to be computed from the fingerprints of its constituent parts.
composite file,Some fingerprinting algorithms allow the fingerprint of a composite file to be computed from the fingerprints of its constituent parts.
fingerprinting algorithms allow,Some fingerprinting algorithms allow the fingerprint of a composite file to be computed from the fingerprints of its constituent parts.
optimization technique,"Successive Linear Programming (SLP), also known as Sequential Linear Programming, is an optimization technique for approximately solving nonlinear optimization problems."
approximately solving nonlinear optimization problems,"Successive Linear Programming (SLP), also known as Sequential Linear Programming, is an optimization technique for approximately solving nonlinear optimization problems."
slp  also known,"Successive Linear Programming (SLP), also known as Sequential Linear Programming, is an optimization technique for approximately solving nonlinear optimization problems."
typically focus,"Older markup languages, which typically focus on typography and presentation, include troff, TeX and LaTeX."
include troff,"Older markup languages, which typically focus on typography and presentation, include troff, TeX and LaTeX."
older markup languages,"Older markup languages, which typically focus on typography and presentation, include troff, TeX and LaTeX."
particular media,"Some markup languages, such as the widely used HTML, have pre-defined presentation semantics, meaning that their specification prescribes some aspects of how to present the structured data on particular media."
specification prescribes,"Some markup languages, such as the widely used HTML, have pre-defined presentation semantics, meaning that their specification prescribes some aspects of how to present the structured data on particular media."
defined presentation semantics,"Some markup languages, such as the widely used HTML, have pre-defined presentation semantics, meaning that their specification prescribes some aspects of how to present the structured data on particular media."
widely used html,"Some markup languages, such as the widely used HTML, have pre-defined presentation semantics, meaning that their specification prescribes some aspects of how to present the structured data on particular media."
allow intermingling markup,One extremely important characteristic of most markup languages is that they allow intermingling markup with document content such as text and pictures.
document content,One extremely important characteristic of most markup languages is that they allow intermingling markup with document content such as text and pictures.
one extremely important characteristic,One extremely important characteristic of most markup languages is that they allow intermingling markup with document content such as text and pictures.
allowing authors,"In recent years, a number of markup languages have been developed with ease of use as a key goal, and without input from standards organizations, aimed at allowing authors to create formatted text via web browsers, for example in wikis and in web forums."
key goal,"In recent years, a number of markup languages have been developed with ease of use as a key goal, and without input from standards organizations, aimed at allowing authors to create formatted text via web browsers, for example in wikis and in web forums."
without input,"In recent years, a number of markup languages have been developed with ease of use as a key goal, and without input from standards organizations, aimed at allowing authors to create formatted text via web browsers, for example in wikis and in web forums."
standards organizations,"In recent years, a number of markup languages have been developed with ease of use as a key goal, and without input from standards organizations, aimed at allowing authors to create formatted text via web browsers, for example in wikis and in web forums."
web forums,"In recent years, a number of markup languages have been developed with ease of use as a key goal, and without input from standards organizations, aimed at allowing authors to create formatted text via web browsers, for example in wikis and in web forums."
sometimes called lightweight markup languages,These are sometimes called lightweight markup languages.
interpolate high dimensional functions,"Sparse grids are numerical techniques to represent, integrate or interpolate high dimensional functions."
numerical techniques,"Sparse grids are numerical techniques to represent, integrate or interpolate high dimensional functions."
dimensional dynamic models,Using Adaptive Sparse Grids to Solve High-Dimensional Dynamic Models.
solve high,Using Adaptive Sparse Grids to Solve High-Dimensional Dynamic Models.
using adaptive sparse grids,Using Adaptive Sparse Grids to Solve High-Dimensional Dynamic Models.
virtual machine component,"The Common Language Runtime (CLR), the virtual machine component of Microsoft ."
possible configurations,A state space is the set of all possible configurations of a system.
discrete finite state space,"For instance, the toy problem Vacuum World has a discrete finite state space in which there are a limited set of configurations that the vacuum and dirt can be in."
limited set,"For instance, the toy problem Vacuum World has a discrete finite state space in which there are a limited set of configurations that the vacuum and dirt can be in."
toy problem vacuum world,"For instance, the toy problem Vacuum World has a discrete finite state space in which there are a limited set of configurations that the vacuum and dirt can be in."
natural numbers starting,"A ""counter"" system, where states are the natural numbers starting at 1 and are incremented over time has an infinite discrete state space."
infinite discrete state space,"A ""counter"" system, where states are the natural numbers starting at 1 and are incremented over time has an infinite discrete state space."
angular position,The angular position of an undamped pendulum is a continuous (and therefore infinite) state space.
undamped pendulum,The angular position of an undamped pendulum is a continuous (and therefore infinite) state space.
therefore infinite,The angular position of an undamped pendulum is a continuous (and therefore infinite) state space.
dynamical system,"In the theory of dynamical systems, the state space of a discrete system defined by a function can be modeled as a directed graph where each possible state of the dynamical system is represented by a vertex with a directed edge from a to b if and only if (a) = b."
possible state,"In the theory of dynamical systems, the state space of a discrete system defined by a function can be modeled as a directed graph where each possible state of the dynamical system is represented by a vertex with a directed edge from a to b if and only if (a) = b."
discrete system defined,"In the theory of dynamical systems, the state space of a discrete system defined by a function can be modeled as a directed graph where each possible state of the dynamical system is represented by a vertex with a directed edge from a to b if and only if (a) = b."
even real human experts,"In machine learning, weighted majority algorithm (WMA) is a meta learning algorithm used to construct a compound algorithm from a pool of prediction algorithms, which could be any type of learning algorithms, classifiers, or even real human experts."
meta learning algorithm used,"In machine learning, weighted majority algorithm (WMA) is a meta learning algorithm used to construct a compound algorithm from a pool of prediction algorithms, which could be any type of learning algorithms, classifiers, or even real human experts."
handle different situations,"There are many variations of the weighted majority algorithm to handle different situations, like shifting targets, infinite pools, or randomized predictions."
like shifting targets,"There are many variations of the weighted majority algorithm to handle different situations, like shifting targets, infinite pools, or randomized predictions."
infinite pools,"There are many variations of the weighted majority algorithm to handle different situations, like shifting targets, infinite pools, or randomized predictions."
many variations,"There are many variations of the weighted majority algorithm to handle different situations, like shifting targets, infinite pools, or randomized predictions."
use random variables,Stochastic optimization (SO) methods are optimization methods that generate and use random variables.
random iterates,Stochastic optimization methods also include methods with random iterates.
solve stochastic problems,"Some stochastic optimization methods use random iterates to solve stochastic problems, combining both meanings of stochastic optimization."
deterministic problems,Stochastic optimization methods generalize deterministic methods for deterministic problems.
usually presented,"The way in which results of stochastic optimization algorithms are usually presented (e. g. , presenting only the average, or even the best, out of N runs without any mention of the spread), may also result in a positive bias towards randomness."
n runs without,"The way in which results of stochastic optimization algorithms are usually presented (e. g. , presenting only the average, or even the best, out of N runs without any mention of the spread), may also result in a positive bias towards randomness."
positive bias towards randomness,"The way in which results of stochastic optimization algorithms are usually presented (e. g. , presenting only the average, or even the best, out of N runs without any mention of the spread), may also result in a positive bias towards randomness."
spread  may also result,"The way in which results of stochastic optimization algorithms are usually presented (e. g. , presenting only the average, or even the best, out of N runs without any mention of the spread), may also result in a positive bias towards randomness."
recursive invocation made,"In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant."
type parameter changes,"In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant."
recursive parametrically polymorphic function,"In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant."
staying constant,"In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant."
also referred,"Using memory for communication inside a single program, e. g. among its multiple threads, is also referred to as shared memory. !! In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour. !! Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another"". !! DNS spoofing, also referred to as DNS cache poisoning, is a form of computer security hacking in which corrupt Domain Name System data is introduced into the DNS resolver's cache, causing the name server to return an incorrect result record, e. g. an IP address. !! A regular expression (shortened as regex or regexp; also referred to as rational expression) is a sequence of characters that specifies a search pattern in text. !! In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant. !! In formal language theory, computer science and linguistics, the Chomsky hierarchy (also referred to as the ChomskySchtzenberger hierarchy) is a containment hierarchy of classes of formal grammars."
milnermycroft typability,"In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant."
milnermycroft calculus,"In computer science, polymorphic recursion (also referred to as MilnerMycroft typability or the MilnerMycroft calculus) refers to a recursive parametrically polymorphic function where the type parameter changes with each recursive invocation made, instead of staying constant."
therefore undecidable,Type inference for polymorphic recursion is equivalent to semi-unification and therefore undecidable and requires the use of a semi-algorithm or programmer supplied type annotations.
programmer supplied type annotations,Type inference for polymorphic recursion is equivalent to semi-unification and therefore undecidable and requires the use of a semi-algorithm or programmer supplied type annotations.
gaining high precision,In type-based program analysis polymorphic recursion is often essential in gaining high precision of the analysis.
often essential,In type-based program analysis polymorphic recursion is often essential in gaining high precision of the analysis.
based program analysis polymorphic recursion,In type-based program analysis polymorphic recursion is often essential in gaining high precision of the analysis.
based memory management system,"Notable examples of systems employing polymorphic recursion include Dussart, Henglein and Mossin's binding-time analysis and the TofteTalpin region-based memory management system."
time analysis,"Notable examples of systems employing polymorphic recursion include Dussart, Henglein and Mossin's binding-time analysis and the TofteTalpin region-based memory management system. !! The methodology of run-time analysis can also be utilized for predicting other growth rates, such as consumption of memory space. !! Run-time analysis is a theoretical classification that estimates and anticipates the increase in running time (or run-time or execution time) of an algorithm as its input size (usually denoted as n) increases. !! While software profiling techniques can be used to measure an algorithm's run-time in practice, they cannot provide timing data for all infinitely many possible inputs; the latter can only be achieved by the theoretical methods of run-time analysis."
toftetalpin region,"Notable examples of systems employing polymorphic recursion include Dussart, Henglein and Mossin's binding-time analysis and the TofteTalpin region-based memory management system."
underlying type system,"As these systems assume the expressions have already been typed in an underlying type system (not necessary employing polymorphic recursion), inference can be made decidable again."
systems assume,"As these systems assume the expressions have already been typed in an underlying type system (not necessary employing polymorphic recursion), inference can be made decidable again."
necessary employing polymorphic recursion  inference,"As these systems assume the expressions have already been typed in an underlying type system (not necessary employing polymorphic recursion), inference can be made decidable again."
made decidable,"As these systems assume the expressions have already been typed in an underlying type system (not necessary employing polymorphic recursion), inference can be made decidable again."
structured svm allows training,"Whereas the SVM classifier supports binary classification, multiclass classification and regression, the structured SVM allows training of a classifier for general structured output labels."
svm classifier supports binary classification,"Whereas the SVM classifier supports binary classification, multiclass classification and regression, the structured SVM allows training of a classifier for general structured output labels."
general structured output labels,"Whereas the SVM classifier supports binary classification, multiclass classification and regression, the structured SVM allows training of a classifier for general structured output labels."
structured svm model allows one,"After training, the structured SVM model allows one to predict for new sample instances the corresponding output label; that is, given a natural language sentence, the classifier can produce the most likely parse tree."
corresponding output label,"After training, the structured SVM model allows one to predict for new sample instances the corresponding output label; that is, given a natural language sentence, the classifier can produce the most likely parse tree."
natural language sentence,"After training, the structured SVM model allows one to predict for new sample instances the corresponding output label; that is, given a natural language sentence, the classifier can produce the most likely parse tree. !! For example, the problem of translating a natural language sentence into a syntactic representation such as a parse tree can be seen as a structured prediction problem in which the structured output domain is the set of all possible parse trees."
likely parse tree,"After training, the structured SVM model allows one to predict for new sample instances the corresponding output label; that is, given a natural language sentence, the classifier can produce the most likely parse tree."
new sample instances,"After training, the structured SVM model allows one to predict for new sample instances the corresponding output label; that is, given a natural language sentence, the classifier can produce the most likely parse tree."
following regularized risk function,", the structured SVM minimizes the following regularized risk function."
structured svm minimizes,", the structured SVM minimizes the following regularized risk function."
standard structured svm primal formulation,The standard structured SVM primal formulation is given as follows.
shared resource data,"In computer architecture, cache coherence is the uniformity of shared resource data that ends up stored in multiple local caches."
cache coherence,"The above conditions satisfy the Write Propagation criteria required for cache coherence. !! One type of data occurring simultaneously in different cache memory is called cache coherence, or in some systems, global memory. !! Cache coherence is intended to manage such conflicts by maintaining a coherent view of the data values in multiple caches. !! In computer architecture, cache coherence is the uniformity of shared resource data that ends up stored in multiple local caches. !! Cache coherence is the discipline which ensures that the changes in the values of shared operands (data) are propagated throughout the system in a timely fashion."
multiple local caches,"In computer architecture, cache coherence is the uniformity of shared resource data that ends up stored in multiple local caches."
multiple caches,Cache coherence is intended to manage such conflicts by maintaining a coherent view of the data values in multiple caches.
coherent view,Cache coherence is intended to manage such conflicts by maintaining a coherent view of the data values in multiple caches.
data values,Cache coherence is intended to manage such conflicts by maintaining a coherent view of the data values in multiple caches.
propagated throughout,Cache coherence is the discipline which ensures that the changes in the values of shared operands (data) are propagated throughout the system in a timely fashion.
shared operands,Cache coherence is the discipline which ensures that the changes in the values of shared operands (data) are propagated throughout the system in a timely fashion.
timely fashion,Cache coherence is the discipline which ensures that the changes in the values of shared operands (data) are propagated throughout the system in a timely fashion.
different cache memory,"One type of data occurring simultaneously in different cache memory is called cache coherence, or in some systems, global memory."
called cache coherence,"One type of data occurring simultaneously in different cache memory is called cache coherence, or in some systems, global memory."
data occurring simultaneously,"One type of data occurring simultaneously in different cache memory is called cache coherence, or in some systems, global memory."
write propagation criteria required,The above conditions satisfy the Write Propagation criteria required for cache coherence.
conditions satisfy,The above conditions satisfy the Write Propagation criteria required for cache coherence.
partial evaluation,"If Istatic is source code designed to run inside that interpreter, then partial evaluation of the interpreter with respect to this data/program produces prog*, a version of the interpreter that only runs that source code, is written in the implementation language of the interpreter, does not require the source code to be resupplied, and runs faster than the original combination of the interpreter and the source. !! A particularly interesting example of the use of partial evaluation, first described in the 1970s by Yoshihiko Futamura, is when prog is an interpreter for a programming language. !! In computing, partial evaluation is a technique for several different types of program optimization by specialization."
several different types,"In computing, partial evaluation is a technique for several different types of program optimization by specialization."
particularly interesting example,"A particularly interesting example of the use of partial evaluation, first described in the 1970s by Yoshihiko Futamura, is when prog is an interpreter for a programming language."
yoshihiko futamura,"A particularly interesting example of the use of partial evaluation, first described in the 1970s by Yoshihiko Futamura, is when prog is an interpreter for a programming language."
original combination,"If Istatic is source code designed to run inside that interpreter, then partial evaluation of the interpreter with respect to this data/program produces prog*, a version of the interpreter that only runs that source code, is written in the implementation language of the interpreter, does not require the source code to be resupplied, and runs faster than the original combination of the interpreter and the source."
program produces prog,"If Istatic is source code designed to run inside that interpreter, then partial evaluation of the interpreter with respect to this data/program produces prog*, a version of the interpreter that only runs that source code, is written in the implementation language of the interpreter, does not require the source code to be resupplied, and runs faster than the original combination of the interpreter and the source."
run inside,"If Istatic is source code designed to run inside that interpreter, then partial evaluation of the interpreter with respect to this data/program produces prog*, a version of the interpreter that only runs that source code, is written in the implementation language of the interpreter, does not require the source code to be resupplied, and runs faster than the original combination of the interpreter and the source."
runs faster,"If Istatic is source code designed to run inside that interpreter, then partial evaluation of the interpreter with respect to this data/program produces prog*, a version of the interpreter that only runs that source code, is written in the implementation language of the interpreter, does not require the source code to be resupplied, and runs faster than the original combination of the interpreter and the source."
source code designed,"If Istatic is source code designed to run inside that interpreter, then partial evaluation of the interpreter with respect to this data/program produces prog*, a version of the interpreter that only runs that source code, is written in the implementation language of the interpreter, does not require the source code to be resupplied, and runs faster than the original combination of the interpreter and the source."
topos theory,"The category of sets is an important special case: it plays the role of a point in topos theory. !! More exotic examples, and the raison d'tre of topos theory, come from algebraic geometry. !! Topos theory is, in some sense, a generalization of classical point-set topology. !! (It's better to consider it in Ho(pro-SS); see Edwards) Using this inverse system of simplicial sets one may sometimes associate to a homotopy invariant in classical topology an inverse system of invariants in topos theory. !! As indicated in the introduction, sheaves on ordinary topological spaces motivate many of the basic definitions and results of topos theory."
ordinary topological spaces motivate many,"As indicated in the introduction, sheaves on ordinary topological spaces motivate many of the basic definitions and results of topos theory."
basic definitions,"As indicated in the introduction, sheaves on ordinary topological spaces motivate many of the basic definitions and results of topos theory."
important special case,The category of sets is an important special case: it plays the role of a point in topos theory.
exotic examples,"More exotic examples, and the raison d'tre of topos theory, come from algebraic geometry."
algebraic geometry,"More exotic examples, and the raison d'tre of topos theory, come from algebraic geometry."
set topology,"Topos theory is, in some sense, a generalization of classical point-set topology."
classical point,"Topos theory is, in some sense, a generalization of classical point-set topology."
inverse system,(It's better to consider it in Ho(pro-SS); see Edwards) Using this inverse system of simplicial sets one may sometimes associate to a homotopy invariant in classical topology an inverse system of invariants in topos theory.
classical topology,(It's better to consider it in Ho(pro-SS); see Edwards) Using this inverse system of simplicial sets one may sometimes associate to a homotopy invariant in classical topology an inverse system of invariants in topos theory.
homotopy invariant,(It's better to consider it in Ho(pro-SS); see Edwards) Using this inverse system of simplicial sets one may sometimes associate to a homotopy invariant in classical topology an inverse system of invariants in topos theory.
ss  see edwards,(It's better to consider it in Ho(pro-SS); see Edwards) Using this inverse system of simplicial sets one may sometimes associate to a homotopy invariant in classical topology an inverse system of invariants in topos theory.
based selection,"Reward-based selection is a technique used in evolutionary algorithms for selecting potentially useful solutions for recombination. !! Reward-based selection can be used within Multi-armed bandit framework for Multi-objective optimization to obtain a better approximation of the Pareto front. !! Reward-based selection can quickly identify the most fruitful directions of search by maximizing the cumulative reward of individuals. !! A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
selecting potentially useful solutions,Reward-based selection is a technique used in evolutionary algorithms for selecting potentially useful solutions for recombination.
better approximation,Reward-based selection can be used within Multi-armed bandit framework for Multi-objective optimization to obtain a better approximation of the Pareto front.
used within multi,Reward-based selection can be used within Multi-armed bandit framework for Multi-objective optimization to obtain a better approximation of the Pareto front.
armed bandit framework,Reward-based selection can be used within Multi-armed bandit framework for Multi-objective optimization to obtain a better approximation of the Pareto front.
pareto front,Reward-based selection can be used within Multi-armed bandit framework for Multi-objective optimization to obtain a better approximation of the Pareto front.
quickly identify,Reward-based selection can quickly identify the most fruitful directions of search by maximizing the cumulative reward of individuals.
fruitful directions,Reward-based selection can quickly identify the most fruitful directions of search by maximizing the cumulative reward of individuals.
algebraic properties,"In mathematics, particularly in linear algebra and applications, matrix analysis is the study of matrices and their algebraic properties."
matrix analysis,"Matrix Analysis and Applied Linear Algebra. !! In mathematics, particularly in linear algebra and applications, matrix analysis is the study of matrices and their algebraic properties. !! Matrix Analysis. !! Applied Linear Algebra and Matrix Analysis. !! Matrix Analysis and Applied Linear Algebra Book and Solutions Manual."
applied linear algebra book,Matrix Analysis and Applied Linear Algebra Book and Solutions Manual.
solutions manual,Matrix Analysis and Applied Linear Algebra Book and Solutions Manual.
applied linear algebra,Applied Linear Algebra and Matrix Analysis. !! Matrix Analysis and Applied Linear Algebra.
solve constraint satisfaction problems,"In computer science, the min-conflicts algorithm is a search algorithm or heuristic method to solve constraint satisfaction problems."
min-conflicts algorithm,"In computer science, the min-conflicts algorithm is a search algorithm or heuristic method to solve constraint satisfaction problems."
combines symbolic,"In mathematics and computer science, symbolic-numeric computation is the use of software that combines symbolic and numeric methods to solve problems."
numeric computation,"Symbolic-numeric Computation. !! The Fourth International Workshop on Symbolic-Numeric Computation (SNC2011). !! In mathematics and computer science, symbolic-numeric computation is the use of software that combines symbolic and numeric methods to solve problems."
numeric methods,"In mathematics and computer science, symbolic-numeric computation is the use of software that combines symbolic and numeric methods to solve problems."
fourth international workshop,The Fourth International Workshop on Symbolic-Numeric Computation (SNC2011).
checking whether,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! In computer science, model checking or property checking is a method for checking whether a finite-state model of a system meets a given specification (also known as correctness). !! Binary search trees support three main operations: lookup (checking whether a key is present), insertion, and deletion of an element."
possible candidates,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement."
candidate satisfies,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement."
solving technique,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! Brute-force attacks are an application of brute-force search, the general problem-solving technique of enumerating all candidates and checking each one."
general problem,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! Brute-force attacks are an application of brute-force search, the general problem-solving technique of enumerating all candidates and checking each one. !! The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959."
force search,"While a brute-force search is simple to implement and will always find a solution if it exists, implementation costs are proportional to the number of candidate solutions which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion). !! Therefore, brute-force search is typically used when the problem size is limited, or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size. !! Indeed, brute-force search can be viewed as the simplest metaheuristic. !! In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! Brute-force attacks are an application of brute-force search, the general problem-solving technique of enumerating all candidates and checking each one. !! Brute-force search is also useful as a baseline method when benchmarking other algorithms or metaheuristics."
systematically enumerating,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement."
candidate solutions,"In evolutionary computation, an initial set of candidate solutions is generated and iteratively updated. !! In a genetic algorithm, a population of candidate solutions (called individuals, creatures, organisms, or phenotypes) to an optimization problem is evolved toward better solutions. !! While a brute-force search is simple to implement and will always find a solution if it exists, implementation costs are proportional to the number of candidate solutions which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion). !! Therefore, brute-force search is typically used when the problem size is limited, or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size."
implementation costs,"While a brute-force search is simple to implement and will always find a solution if it exists, implementation costs are proportional to the number of candidate solutions which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion)."
problem increases,"While a brute-force search is simple to implement and will always find a solution if it exists, implementation costs are proportional to the number of candidate solutions which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion)."
always find,"While a brute-force search is simple to implement and will always find a solution if it exists, implementation costs are proportional to the number of candidate solutions which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion)."
many practical problems tends,"While a brute-force search is simple to implement and will always find a solution if it exists, implementation costs are proportional to the number of candidate solutions which in many practical problems tends to grow very quickly as the size of the problem increases (Combinatorial explosion)."
specific heuristics,"Therefore, brute-force search is typically used when the problem size is limited, or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size."
manageable size,"Therefore, brute-force search is typically used when the problem size is limited, or when there are problem-specific heuristics that can be used to reduce the set of candidate solutions to a manageable size."
baseline method,Brute-force search is also useful as a baseline method when benchmarking other algorithms or metaheuristics.
simplest metaheuristic,"Indeed, brute-force search can be viewed as the simplest metaheuristic."
detecting whether,"In computer programming, bounds checking is any method of detecting whether a variable is within some bounds before it is used."
always done,"Because performing bounds checking during every usage is time-consuming, it is not always done."
performing bounds checking,"Because performing bounds checking during every usage is time-consuming, it is not always done."
every usage,"Because performing bounds checking during every usage is time-consuming, it is not always done."
eliminates unneeded bounds checking,Bounds-checking elimination is a compiler optimization technique that eliminates unneeded bounds checking.
checking elimination,Bounds-checking elimination is a compiler optimization technique that eliminates unneeded bounds checking.
never perform automatic bounds checking,"Many programming languages, such as C, never perform automatic bounds checking to raise speed."
raise speed,"Many programming languages, such as C, never perform automatic bounds checking to raise speed."
run time bounds checking,The D and OCaml languages have run time bounds checking that is enabled or disabled with a compiler switch.
compressed sensing in speech signals,This article is about Compressed sensing in speech signals.
data differencing,Delta encoding is a way of storing or transmitting data in the form of differences (deltas) between sequential data rather than complete files; more generally this is known as data differencing.
transmitting data,Delta encoding is a way of storing or transmitting data in the form of differences (deltas) between sequential data rather than complete files; more generally this is known as data differencing.
complete files,Delta encoding is a way of storing or transmitting data in the form of differences (deltas) between sequential data rather than complete files; more generally this is known as data differencing.
sequential data rather,Delta encoding is a way of storing or transmitting data in the form of differences (deltas) between sequential data rather than complete files; more generally this is known as data differencing.
sometimes called delta compression,"Delta encoding is sometimes called delta compression, particularly where archival histories of changes are required (e. g. , in revision control software)."
archival histories,"Delta encoding is sometimes called delta compression, particularly where archival histories of changes are required (e. g. , in revision control software)."
large document,"In situations where differences are small for example, the change of a few words in a large document or the change of a few records in a large table delta encoding greatly reduces data redundancy."
better samples,"Unfortunately, not even all 8-bit sound samples compress better when delta encoded, and the usability of delta encoding is even smaller for 16-bit and better samples."
even smaller,"Unfortunately, not even all 8-bit sound samples compress better when delta encoded, and the usability of delta encoding is even smaller for 16-bit and better samples."
delta encoded,"Unfortunately, not even all 8-bit sound samples compress better when delta encoded, and the usability of delta encoding is even smaller for 16-bit and better samples."
bit sound samples compress better,"Unfortunately, not even all 8-bit sound samples compress better when delta encoded, and the usability of delta encoding is even smaller for 16-bit and better samples."
encodes differences,A variation of delta encoding which encodes differences between the prefixes or suffixes of strings is called incremental encoding.
called incremental encoding,A variation of delta encoding which encodes differences between the prefixes or suffixes of strings is called incremental encoding.
predicate calculus,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science. !! The notion of a database schema plays the same role as the notion of theory in predicate calculus."
formal systems used,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science."
order logicalso known,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science."
quantificational logic,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science."
order predicate calculusis,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science."
main interfaces,"The software structure, modularization, core algorithms and main interfaces do not differ from other ERPs, and ERP software suppliers manage to adapt their systems to government agencies."
government agencies,"The software structure, modularization, core algorithms and main interfaces do not differ from other ERPs, and ERP software suppliers manage to adapt their systems to government agencies. !! Evidence shows that software metrics are being widely used by government agencies, the US military, NASA, IT consultants, academic institutions, and commercial and academic development estimation software."
erp software suppliers manage,"The software structure, modularization, core algorithms and main interfaces do not differ from other ERPs, and ERP software suppliers manage to adapt their systems to government agencies."
readily codified within,This is because the procedure can be readily codified within the ERP software and replicated with confidence across multiple businesses that share that business requirement.
confidence across multiple businesses,This is because the procedure can be readily codified within the ERP software and replicated with confidence across multiple businesses that share that business requirement.
business requirement,This is because the procedure can be readily codified within the ERP software and replicated with confidence across multiple businesses that share that business requirement.
organizations thoroughly analyze processes,It is therefore crucial that organizations thoroughly analyze processes before they deploy an ERP software.
therefore crucial,It is therefore crucial that organizations thoroughly analyze processes before they deploy an ERP software.
hardware lets companies run,Two-tier ERP software and hardware lets companies run the equivalent of two ERP systems at once: one at the corporate level and one at the division or subsidiary level.
two erp systems,Two-tier ERP software and hardware lets companies run the equivalent of two ERP systems at once: one at the corporate level and one at the division or subsidiary level.
corporate level,Two-tier ERP software and hardware lets companies run the equivalent of two ERP systems at once: one at the corporate level and one at the division or subsidiary level.
subsidiary level,Two-tier ERP software and hardware lets companies run the equivalent of two ERP systems at once: one at the corporate level and one at the division or subsidiary level.
tier erp software,Two-tier ERP software and hardware lets companies run the equivalent of two ERP systems at once: one at the corporate level and one at the division or subsidiary level.
homogeneous segments according,Speaker diarisation (or diarization) is the process of partitioning an input audio stream into homogeneous segments according to the speaker identity.
input audio stream,Speaker diarisation (or diarization) is the process of partitioning an input audio stream into homogeneous segments according to the speaker identity.
speaker identity,Speaker diarisation (or diarization) is the process of partitioning an input audio stream into homogeneous segments according to the speaker identity.
speaker diarisation,"Speaker diarisation is a combination of speaker segmentation and speaker clustering. !! In speaker diarisation one of the most popular methods is to use a Gaussian mixture model to model each of the speakers, and assign the corresponding frames for each speaker with the help of a Hidden Markov Model. !! With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings. !! Speaker diarisation (or diarization) is the process of partitioning an input audio stream into homogeneous segments according to the speaker identity. !! Speaker verification (also called speaker authentication) contrasts with identification, and speaker recognition differs from speaker diarisation (recognizing when the same speaker is speaking)."
speaker clustering,Speaker diarisation is a combination of speaker segmentation and speaker clustering.
speaker segmentation,Speaker diarisation is a combination of speaker segmentation and speaker clustering.
national institute,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings. !! The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
increasing number,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
voice mail collected every year,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
specific evaluations devoted,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
received much attention,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
speech community,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
meeting recordings,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
broadcast news,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
telephone speech,"With the increasing number of broadcasts, meeting recordings and voice mail collected every year, speaker diarisation has received much attention by the speech community, as is manifested by the specific evaluations devoted to it under the auspices of the National Institute of Standards and Technology for telephone speech, broadcast news and meetings."
corresponding frames,"In speaker diarisation one of the most popular methods is to use a Gaussian mixture model to model each of the speakers, and assign the corresponding frames for each speaker with the help of a Hidden Markov Model."
popular methods,"In speaker diarisation one of the most popular methods is to use a Gaussian mixture model to model each of the speakers, and assign the corresponding frames for each speaker with the help of a Hidden Markov Model."
speaker diarisation one,"In speaker diarisation one of the most popular methods is to use a Gaussian mixture model to model each of the speakers, and assign the corresponding frames for each speaker with the help of a Hidden Markov Model."
plane sweep algorithm,"In computational geometry, a sweep line algorithm or plane sweep algorithm is an algorithmic paradigm that uses a conceptual sweep line or sweep surface to solve various problems in Euclidean space."
conceptual sweep line,"In computational geometry, a sweep line algorithm or plane sweep algorithm is an algorithmic paradigm that uses a conceptual sweep line or sweep surface to solve various problems in Euclidean space."
solve various problems,"In computational geometry, a sweep line algorithm or plane sweep algorithm is an algorithmic paradigm that uses a conceptual sweep line or sweep surface to solve various problems in Euclidean space."
processing points,"Topological sweeping is a form of the plane sweep with a relaxed ordering of processing points, which avoids the necessity of completely sorting the points; it allows some sweep line algorithms to be performed more efficiently."
completely sorting,"Topological sweeping is a form of the plane sweep with a relaxed ordering of processing points, which avoids the necessity of completely sorting the points; it allows some sweep line algorithms to be performed more efficiently."
relaxed ordering,"Topological sweeping is a form of the plane sweep with a relaxed ordering of processing points, which avoids the necessity of completely sorting the points; it allows some sweep line algorithms to be performed more efficiently."
topological sweeping,"Topological sweeping is a form of the plane sweep with a relaxed ordering of processing points, which avoids the necessity of completely sorting the points; it allows some sweep line algorithms to be performed more efficiently."
spatial verification,"The spatial verification can not be used as post-processing. !! To specify scenes or objects, is commonly used affine transformations to perform the spatial verification. !! Spatial verification is a technique in which similar locations can be identified in an automated way through a sequence of images."
automated way,An ASIC based IPS may detect and block denial-of-service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way. !! Spatial verification is a technique in which similar locations can be identified in an automated way through a sequence of images.
similar locations,Spatial verification is a technique in which similar locations can be identified in an automated way through a sequence of images.
commonly used affine transformations,"To specify scenes or objects, is commonly used affine transformations to perform the spatial verification."
specify scenes,"To specify scenes or objects, is commonly used affine transformations to perform the spatial verification."
also avoids repeated evaluations,"In programming language theory, lazy evaluation, or call-by-need, is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing)."
evaluation strategy,"In programming language theory, lazy evaluation, or call-by-need, is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing)."
strict evaluation,"The opposite of lazy evaluation is eager evaluation, sometimes known as strict evaluation. !! In programming language theory, lazy evaluation, or call-by-need, is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing)."
often combined,"Lazy evaluation is often combined with memoization, as described in Jon Bentley's Writing Efficient Programs."
writing efficient programs,"Lazy evaluation is often combined with memoization, as described in Jon Bentley's Writing Efficient Programs."
jon bentley,"Lazy evaluation is often combined with memoization, as described in Jon Bentley's Writing Efficient Programs."
operations becomes indeterminate,"Lazy evaluation is difficult to combine with imperative features such as exception handling and input/output, because the order of operations becomes indeterminate."
eager evaluation,"The opposite of lazy evaluation is eager evaluation, sometimes known as strict evaluation."
plessey system 250,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
resolution overhead,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
limited address space,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
critical part,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
christopher wadsworth,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
calculus meta,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
flow diagram,"The data-flow diagram is a tool that is part of structured analysis and data modeling. !! The refined representation of a process can be done in another data-flow diagram, which subdivides this process into sub-processes. !! A data-flow diagram is a way of representing a flow of data through a process or a system (usually an information system). !! A data-flow diagram has no control flowthere are no decision rules and no loops."
control flowthere,A data-flow diagram has no control flowthere are no decision rules and no loops.
displaying data,There are several notations for displaying data-flow diagrams.
flow diagrams,There are several notations for displaying data-flow diagrams.
several notations,There are several notations for displaying data-flow diagrams.
refined representation,"The refined representation of a process can be done in another data-flow diagram, which subdivides this process into sub-processes."
another data,"The refined representation of a process can be done in another data-flow diagram, which subdivides this process into sub-processes."
living organisms perform computations,"The concept of biological computation proposes that living organisms perform computations, and that as such, abstract ideas of information and computation may be key to understanding biology."
abstract ideas,"The concept of biological computation proposes that living organisms perform computations, and that as such, abstract ideas of information and computation may be key to understanding biology."
computation may,"The concept of biological computation proposes that living organisms perform computations, and that as such, abstract ideas of information and computation may be key to understanding biology."
biological computation proposes,"The concept of biological computation proposes that living organisms perform computations, and that as such, abstract ideas of information and computation may be key to understanding biology."
understanding biology,"The concept of biological computation proposes that living organisms perform computations, and that as such, abstract ideas of information and computation may be key to understanding biology."
biological computation,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics. !! The concept of biological computation proposes that living organisms perform computations, and that as such, abstract ideas of information and computation may be key to understanding biology."
biological data,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics."
computer methods,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics."
algorithms inspired,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics."
systems biology computations performed,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics."
elsewhere called computational biology,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics."
computational methods,"As a field, biological computation can include the study of the systems biology computations performed by biota the design of algorithms inspired by the computational methods of biota, the design and engineering of manufactured computational devices using synthetic biology components and computer methods for the analysis of biological data, elsewhere called computational biology or bioinformatics."
infinite set,"Infinite sets may be countable or uncountable. !! The power set of an infinite set is infinite. !! Any superset of an infinite set is infinite. !! The existence of any other infinite set can be proved in ZermeloFraenkel set theory (ZFC), but only by showing that it follows from the existence of the natural numbers. !! In set theory, an infinite set is a set that is not a finite set."
infinite sets may,Infinite sets may be countable or uncountable.
zermelofraenkel set theory,"In many formal set theories, such as ZermeloFraenkel set theory, set builder notation is not part of the formal syntax of the theory. !! The existence of any other infinite set can be proved in ZermeloFraenkel set theory (ZFC), but only by showing that it follows from the existence of the natural numbers."
based machine learning,"Rule-based machine learning (RBML) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves 'rules' to store, manipulate or apply. !! While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
computer science intended,"Rule-based machine learning (RBML) is a term in computer science intended to encompass any machine learning method that identifies, learns, or evolves 'rules' to store, manipulate or apply."
covering contextual knowledge,"Rule-based machine learning approaches include learning classifier systems, association rule learning, artificial immune systems, and any other method that relies on a set of rules, each covering contextual knowledge."
based decision makers,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
often hand,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
traditional rule,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
based machine learning applies,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
automatically identify useful rules,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
apply prior domain knowledge,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
human needing,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
manually construct rules,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
rule set,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
collectively make,"Therefore rule-based machine learning methods typically comprise a set of rules, or knowledge base, that collectively make up the prediction model."
therefore rule,"Therefore rule-based machine learning methods typically comprise a set of rules, or knowledge base, that collectively make up the prediction model."
graph invariant whose values,"In mathematics, a graph polynomial is a graph invariant whose values are polynomials."
standard published,"In business analysis, the Decision Model and Notation (DMN) is a standard published by the Object Management Group."
object management group,"The software modernization tasks are supported by various tools related to Model-driven architecture from the Object Management Group and processes such as ISO/IEC 14764:2006 or Service-Oriented Migration and Reuse Technique (SMART). !! The most common language used to do object-oriented modeling is the Object Management Group's Unified Modeling Language (UML). !! In business analysis, the Decision Model and Notation (DMN) is a standard published by the Object Management Group."
formal notation,"Constraint Decision Model and Notation (cDMN) is a formal notation for expressing knowledge in a tabular, intuitive format."
intuitive format,"Constraint Decision Model and Notation (cDMN) is a formal notation for expressing knowledge in a tabular, intuitive format."
constraint decision model,"Constraint Decision Model and Notation (cDMN) is a formal notation for expressing knowledge in a tabular, intuitive format."
expressing knowledge,"Constraint Decision Model and Notation (cDMN) is a formal notation for expressing knowledge in a tabular, intuitive format."
statistical model derived,The layered hidden Markov model (LHMM) is a statistical model derived from the hidden Markov model (HMM).
probability generators,"A layered hidden Markov model (LHMM) consists of N levels of HMMs, where the HMMs on level i + 1 correspond to observation symbols or probability generators at level i."
observation symbols,"A layered hidden Markov model (LHMM) consists of N levels of HMMs, where the HMMs on level i + 1 correspond to observation symbols or probability generators at level i."
multiple parties contribute,Distributed key generation (DKG) is a cryptographic process in which multiple parties contribute to the calculation of a shared public and private key set.
shared public,Distributed key generation (DKG) is a cryptographic process in which multiple parties contribute to the calculation of a shared public and private key set.
trusted third parties,"Unlike most public key encryption models, distributed key generation does not rely on Trusted Third Parties."
malicious contributions,The involvement of many parties requires Distributed key generation to ensure secrecy in the presence of malicious contributions to the key calculation.
ensure secrecy,The involvement of many parties requires Distributed key generation to ensure secrecy in the presence of malicious contributions to the key calculation.
key calculation,The involvement of many parties requires Distributed key generation to ensure secrecy in the presence of malicious contributions to the key calculation.
decrypt shared ciphertexts,Distributed Key Generation is commonly used to decrypt shared ciphertexts or create group digital signatures.
create group digital signatures,Distributed Key Generation is commonly used to decrypt shared ciphertexts or create group digital signatures.
handwritten digits,The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.
training various image processing systems,The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.
large database,The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.
modified national institute,The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.
technology database,The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems.
000 testing images,"The MNIST database contains 60,000 training images and 10,000 testing images."
000 training images,"The MNIST database contains 60,000 training images and 10,000 testing images."
mnist database contains 60,"The MNIST database contains 60,000 training images and 10,000 testing images."
special database 1,The set of images in the MNIST database was created in 1998 as a combination of two of NIST's databases: Special Database 1 and Special Database 3.
special database 3,The set of images in the MNIST database was created in 1998 as a combination of two of NIST's databases: Special Database 1 and Special Database 3.
authors achieve performance double,"Some researchers have achieved ""near-human performance"" on the MNIST database, using a committee of neural networks; in the same paper, the authors achieve performance double that of humans on other recognition tasks."
human performance,"Some researchers have achieved ""near-human performance"" on the MNIST database, using a committee of neural networks; in the same paper, the authors achieve performance double that of humans on other recognition tasks."
mnist handwritten digits,Visualization of the MNIST database groups of images of MNIST handwritten digits on GitHub
mnist database groups,Visualization of the MNIST database groups of images of MNIST handwritten digits on GitHub
possible machines,"Android epistemology is an approach to epistemology considering the space of possible machines and their capacities for knowledge, beliefs, attitudes, desires and for action in accord with their mental states."
epistemology considering,"Android epistemology is an approach to epistemology considering the space of possible machines and their capacities for knowledge, beliefs, attitudes, desires and for action in accord with their mental states."
android epistemology,"Android Epistemology, Cambridge: AAAI Press / MIT Press. !! Thinking about Android Epistemology, Cambridge: AAAI Press / MIT Press. !! Glymour, Clark ""Android Epistemology for Babies: Reflections on Words, Thoughts and Theories,"" Synthese, Vol. !! Android epistemology is an approach to epistemology considering the space of possible machines and their capacities for knowledge, beliefs, attitudes, desires and for action in accord with their mental states. !! Thus, android epistemology incorporates artificial intelligence, computational cognitive psychology, computability theory and other related disciplines."
related disciplines,"Thus, android epistemology incorporates artificial intelligence, computational cognitive psychology, computability theory and other related disciplines. !! Computer networking may be considered a branch of computer science, computer engineering, and telecommunications, since it relies on the theoretical and practical application of the related disciplines."
computational cognitive psychology,"Thus, android epistemology incorporates artificial intelligence, computational cognitive psychology, computability theory and other related disciplines."
android epistemology incorporates artificial intelligence,"Thus, android epistemology incorporates artificial intelligence, computational cognitive psychology, computability theory and other related disciplines."
aaai press,"Android Epistemology, Cambridge: AAAI Press / MIT Press. !! Thinking about Android Epistemology, Cambridge: AAAI Press / MIT Press."
theories  synthese,"Glymour, Clark ""Android Epistemology for Babies: Reflections on Words, Thoughts and Theories,"" Synthese, Vol."
called bucket sort,"For this reason, radix sort has also been called bucket sort and digital sort."
digital sort,"For this reason, radix sort has also been called bucket sort and digital sort."
sorted lexicographically,"Radix sort can be applied to data that can be sorted lexicographically, be they integers, words, punch cards, playing cards, or the mail."
punch cards,"Radix sort can be applied to data that can be sorted lexicographically, be they integers, words, punch cards, playing cards, or the mail."
playing cards,"Radix sort can be applied to data that can be sorted lexicographically, be they integers, words, punch cards, playing cards, or the mail."
radix sort dates back,Radix sort dates back as far as 1887 to the work of Herman Hollerith on tabulating machines.
tabulating machines,Radix sort dates back as far as 1887 to the work of Herman Hollerith on tabulating machines.
herman hollerith,Radix sort dates back as far as 1887 to the work of Herman Hollerith on tabulating machines.
radix sorting algorithms came,Radix sorting algorithms came into common use as a way to sort punched cards as early as 1923.
common use,"Radix sorting algorithms came into common use as a way to sort punched cards as early as 1923. !! The most common use of code signing is to provide security when deploying; in some programming languages, it can also be used to help prevent namespace conflicts."
sort punched cards,Radix sorting algorithms came into common use as a way to sort punched cards as early as 1923.
spurred work,"The development of the computer algebra systems in the second half of the 20th century is part of the discipline of ""computer algebra"" or ""symbolic computation"", which has spurred work in algorithms over mathematical objects such as polynomials."
mathematical objects,"The development of the computer algebra systems in the second half of the 20th century is part of the discipline of ""computer algebra"" or ""symbolic computation"", which has spurred work in algorithms over mathematical objects such as polynomials. !! In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects."
symbolic computation,"The development of the computer algebra systems in the second half of the 20th century is part of the discipline of ""computer algebra"" or ""symbolic computation"", which has spurred work in algorithms over mathematical objects such as polynomials. !! Some authors distinguish computer algebra from symbolic computation using the latter name to refer to kinds of symbolic computation other than the computation with mathematical formulas."
computer algebra systems may,Computer algebra systems may be divided into two classes: specialized and general-purpose.
scientific field,General-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions.
user working,General-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions.
mathematical expressions,"General-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions. !! In mathematical expressions the sign function is often represented as sgn. !! Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc. !! Deductive lambda calculus considers what happens when lambda terms are regarded as mathematical expressions. !! Symbolic Regression (SR) is a type of regression analysis that searches the space of mathematical expressions to find the model that best fits a given dataset, both in terms of accuracy and simplicity."
requires manipulation,General-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions.
purpose computer algebra systems aim,General-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions.
purpose computer algebra systems,This large amount of required computer capabilities explains the small number of general-purpose computer algebra systems.
required computer capabilities explains,This large amount of required computer capabilities explains the small number of general-purpose computer algebra systems.
two quite different sourcesthe requirements,Computer algebra systems began to appear in the 1960s and evolved out of two quite different sourcesthe requirements of theoretical physicists and research into artificial intelligence.
computer algebra systems began,Computer algebra systems began to appear in the 1960s and evolved out of two quite different sourcesthe requirements of theoretical physicists and research into artificial intelligence.
theoretical physicists,Computer algebra systems began to appear in the 1960s and evolved out of two quite different sourcesthe requirements of theoretical physicists and research into artificial intelligence.
randomness used,"For this reason, many online gambling sites provide descriptions of their shuffling algorithms and the sources of randomness used to drive these algorithms, with some gambling sites also providing auditors' reports of the performance of their systems."
gambling sites also providing auditors,"For this reason, many online gambling sites provide descriptions of their shuffling algorithms and the sources of randomness used to drive these algorithms, with some gambling sites also providing auditors' reports of the performance of their systems."
division multiplexing,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
optic communication,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
often abbreviated sm,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
mimo wireless communication,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
transmit independent channels separated,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
communications technologies used,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
strong power imbalances,An often encountered problem in open loop spatial multiplexing is to guard against instance of high channel correlation and strong power imbalances between the multiple streams.
open loop spatial multiplexing,An often encountered problem in open loop spatial multiplexing is to guard against instance of high channel correlation and strong power imbalances between the multiple streams.
multiple streams,An often encountered problem in open loop spatial multiplexing is to guard against instance of high channel correlation and strong power imbalances between the multiple streams.
high channel correlation,An often encountered problem in open loop spatial multiplexing is to guard against instance of high channel correlation and strong power imbalances between the multiple streams.
often encountered problem,An often encountered problem in open loop spatial multiplexing is to guard against instance of high channel correlation and strong power imbalances between the multiple streams.
ngh systems,One such extension which is being considered for DVB-NGH systems is the so-called enhanced Spatial Multiplexing (eSM) scheme.
called enhanced spatial multiplexing,One such extension which is being considered for DVB-NGH systems is the so-called enhanced Spatial Multiplexing (eSM) scheme.
binary tree selected,"In computer science and probability theory, a random binary tree is a binary tree selected at random from some probability distribution on binary trees."
binary trees formed,"Adding and removing nodes directly in a random binary tree will in general disrupt its random structure, but the treap and related randomized binary search tree data structures use the principle of binary trees formed from a random permutation in order to maintain a balanced binary search tree dynamically as nodes are inserted and deleted."
random structure,"Adding and removing nodes directly in a random binary tree will in general disrupt its random structure, but the treap and related randomized binary search tree data structures use the principle of binary trees formed from a random permutation in order to maintain a balanced binary search tree dynamically as nodes are inserted and deleted."
removing nodes directly,"Adding and removing nodes directly in a random binary tree will in general disrupt its random structure, but the treap and related randomized binary search tree data structures use the principle of binary trees formed from a random permutation in order to maintain a balanced binary search tree dynamically as nodes are inserted and deleted."
general disrupt,"Adding and removing nodes directly in a random binary tree will in general disrupt its random structure, but the treap and related randomized binary search tree data structures use the principle of binary trees formed from a random permutation in order to maintain a balanced binary search tree dynamically as nodes are inserted and deleted."
balanced binary search tree dynamically,"Adding and removing nodes directly in a random binary tree will in general disrupt its random structure, but the treap and related randomized binary search tree data structures use the principle of binary trees formed from a random permutation in order to maintain a balanced binary search tree dynamically as nodes are inserted and deleted."
random permutation,"Adding and removing nodes directly in a random binary tree will in general disrupt its random structure, but the treap and related randomized binary search tree data structures use the principle of binary trees formed from a random permutation in order to maintain a balanced binary search tree dynamically as nodes are inserted and deleted."
counts max records,"The searching on l's random binary tree only counts max records on (2, 1) and min records on (4, 6, 5, 1)this is why it is twice a Harmonic number."
min records,"The searching on l's random binary tree only counts max records on (2, 1) and min records on (4, 6, 5, 1)this is why it is twice a Harmonic number."
harmonic number,"The searching on l's random binary tree only counts max records on (2, 1) and min records on (4, 6, 5, 1)this is why it is twice a Harmonic number."
inserted without deletion,"In applications of binary search tree data structures, it is rare for the values in the tree to be inserted without deletion in a random order, limiting the direct applications of random binary trees."
direct applications,"In applications of binary search tree data structures, it is rare for the values in the tree to be inserted without deletion in a random order, limiting the direct applications of random binary trees."
uniform model,In some cases the analysis of random binary trees under the random permutation model can be automatically transferred to the uniform model.
automatically transferred,In some cases the analysis of random binary trees under the random permutation model can be automatically transferred to the uniform model.
accomplishing user goals,"The goal of user interface design is to make the user's interaction as simple and efficient as possible, in terms of accomplishing user goals (user-centered design)."
hand without drawing unnecessary attention,Good user interface design facilitates finishing the task at hand without drawing unnecessary attention to itself.
important function,"User interface design is a craft in which designers, perform an important function in creating the user experience."
good understanding,User interface design requires a good understanding of user needs.
user needs,"Building on UC Berkeley RISC and Sun compiler and operating system developments, SPARC architecture was highly adaptable to evolving semiconductor, software, and system technology and user needs. !! User interface design requires a good understanding of user needs."
user interface design requires,User interface design requires a good understanding of user needs.
several phases,"There are several phases and processes in the user interface design, some of which are more demanded upon than others, depending on the project."
demanded upon,"There are several phases and processes in the user interface design, some of which are more demanded upon than others, depending on the project."
fewer calculations,"In algebra, synthetic division is a method for manually performing Euclidean division of polynomials, with less writing and fewer calculations than long division."
manually performing euclidean division,"In algebra, synthetic division is a method for manually performing Euclidean division of polynomials, with less writing and fewer calculations than long division."
long division,"The advantages of synthetic division are that it allows one to calculate without writing variables, it uses few calculations, and it takes significantly less space on paper than long division. !! In algebra, synthetic division is a method for manually performing Euclidean division of polynomials, with less writing and fewer calculations than long division."
synthetic division,"The advantages of synthetic division are that it allows one to calculate without writing variables, it uses few calculations, and it takes significantly less space on paper than long division. !! ""A Generalization of Synthetic Division and A General Theorem of Division of Polynomials"" (PDF). !! The above form of synthetic division is useful in the context of the polynomial remainder theorem for evaluating univariate polynomials. !! At this point, if, after getting the third sum, we were to try and use it to fill the top rows, we would ""fall off"" the right side, thus the third sum is the first coefficient of the remainder, as in regular synthetic division. !! In algebra, synthetic division is a method for manually performing Euclidean division of polynomials, with less writing and fewer calculations than long division."
less writing,"In algebra, synthetic division is a method for manually performing Euclidean division of polynomials, with less writing and fewer calculations than long division."
allows one,"The advantages of synthetic division are that it allows one to calculate without writing variables, it uses few calculations, and it takes significantly less space on paper than long division."
takes significantly less space,"The advantages of synthetic division are that it allows one to calculate without writing variables, it uses few calculations, and it takes significantly less space on paper than long division."
calculate without writing variables,"The advantages of synthetic division are that it allows one to calculate without writing variables, it uses few calculations, and it takes significantly less space on paper than long division."
evaluating univariate polynomials,The above form of synthetic division is useful in the context of the polynomial remainder theorem for evaluating univariate polynomials.
polynomial remainder theorem,The above form of synthetic division is useful in the context of the polynomial remainder theorem for evaluating univariate polynomials.
third sum,"At this point, if, after getting the third sum, we were to try and use it to fill the top rows, we would ""fall off"" the right side, thus the third sum is the first coefficient of the remainder, as in regular synthetic division."
top rows,"At this point, if, after getting the third sum, we were to try and use it to fill the top rows, we would ""fall off"" the right side, thus the third sum is the first coefficient of the remainder, as in regular synthetic division."
first coefficient,"At this point, if, after getting the third sum, we were to try and use it to fill the top rows, we would ""fall off"" the right side, thus the third sum is the first coefficient of the remainder, as in regular synthetic division."
right side,"At this point, if, after getting the third sum, we were to try and use it to fill the top rows, we would ""fall off"" the right side, thus the third sum is the first coefficient of the remainder, as in regular synthetic division."
regular synthetic division,"At this point, if, after getting the third sum, we were to try and use it to fill the top rows, we would ""fall off"" the right side, thus the third sum is the first coefficient of the remainder, as in regular synthetic division."
general theorem,"""A Generalization of Synthetic Division and A General Theorem of Division of Polynomials"" (PDF)."
contact acoustic wave generation,Electromagnetic acoustic transducer (EMAT) is a transducer for non-contact acoustic wave generation and reception in conducting materials.
electromagnetic acoustic transducer,Electromagnetic acoustic transducer (EMAT) is a transducer for non-contact acoustic wave generation and reception in conducting materials. !! ASTM E1962-98 Standard Test Methods for Ultrasonic Surface Examinations Using Electromagnetic Acoustic Transducer (EMAT) Technology
conducting materials,Electromagnetic acoustic transducer (EMAT) is a transducer for non-contact acoustic wave generation and reception in conducting materials.
98 standard test methods,ASTM E1962-98 Standard Test Methods for Ultrasonic Surface Examinations Using Electromagnetic Acoustic Transducer (EMAT) Technology
entropy method,A Tutorial on the Cross-Entropy Method.
cross-entropy method,A Tutorial on the Cross-Entropy Method.
data becomes available,"In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once."
entire training data set,"In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once."
future data,"In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once."
best predictor,"In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once."
sequential order,"In computer science, online machine learning is a method of machine learning in which data becomes available in a sequential order and is used to update the best predictor for future data at each step, as opposed to batch learning techniques which generate the best predictor by learning on the entire training data set at once."
truth values,"However, in the untyped lambda calculus, there is no way to prevent a function from being applied to truth values, strings, or other non-number objects. !! In computational complexity theory, the maximum satisfiability problem (MAX-SAT) is the problem of determining the maximum number of clauses, of a given Boolean formula in conjunctive normal form, that can be made true by an assignment of truth values to the variables of the formula."
maximum number,"The partial maximum satisfiability problem (PMAX-SAT) asks for the maximum number of clauses which can be satisfied by any assignment of a given subset of clauses. !! In computational complexity theory, the maximum satisfiability problem (MAX-SAT) is the problem of determining the maximum number of clauses, of a given Boolean formula in conjunctive normal form, that can be made true by an assignment of truth values to the variables of the formula."
made true,"In computational complexity theory, the maximum satisfiability problem (MAX-SAT) is the problem of determining the maximum number of clauses, of a given Boolean formula in conjunctive normal form, that can be made true by an assignment of truth values to the variables of the formula."
given boolean formula,"In computational complexity theory, the maximum satisfiability problem (MAX-SAT) is the problem of determining the maximum number of clauses, of a given Boolean formula in conjunctive normal form, that can be made true by an assignment of truth values to the variables of the formula."
maximum satisfiability problem,"The partial maximum satisfiability problem (PMAX-SAT) asks for the maximum number of clauses which can be satisfied by any assignment of a given subset of clauses. !! In computational complexity theory, the maximum satisfiability problem (MAX-SAT) is the problem of determining the maximum number of clauses, of a given Boolean formula in conjunctive normal form, that can be made true by an assignment of truth values to the variables of the formula."
partial maximum satisfiability problem,The partial maximum satisfiability problem (PMAX-SAT) asks for the maximum number of clauses which can be satisfied by any assignment of a given subset of clauses.
given subset,The partial maximum satisfiability problem (PMAX-SAT) asks for the maximum number of clauses which can be satisfied by any assignment of a given subset of clauses.
car information,"Remote Touch is a vehicle interface system present in some Lexus cars for use in conjunction with in-car information, configuration, and entertainment systems."
remote touch,"Remote Touch is a vehicle interface system present in some Lexus cars for use in conjunction with in-car information, configuration, and entertainment systems. !! The Remote Touch controller, which is similar to a computer mouse or joystick, allows the driver to operate an on-screen cursor on the vehicle's GPS navigation system screen. !! Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically. !! Prior to the advent of Remote Touch, Lexus interiors were typically equipped with touchscreen interfaces. !! Remote Touch was first introduced on the 2010 Lexus RX 350 and Lexus RX 450h models, followed by the 2010 Lexus HS 250h."
entertainment systems,"Remote Touch is a vehicle interface system present in some Lexus cars for use in conjunction with in-car information, configuration, and entertainment systems."
vehicle interface system present,"Remote Touch is a vehicle interface system present in some Lexus cars for use in conjunction with in-car information, configuration, and entertainment systems."
lexus cars,"Remote Touch is a vehicle interface system present in some Lexus cars for use in conjunction with in-car information, configuration, and entertainment systems."
screen cursor,"Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically. !! The Remote Touch controller, which is similar to a computer mouse or joystick, allows the driver to operate an on-screen cursor on the vehicle's GPS navigation system screen."
remote touch controller,"The Remote Touch controller, which is similar to a computer mouse or joystick, allows the driver to operate an on-screen cursor on the vehicle's GPS navigation system screen."
computer mouse,"The Remote Touch controller, which is similar to a computer mouse or joystick, allows the driver to operate an on-screen cursor on the vehicle's GPS navigation system screen."
gps navigation system screen,"The Remote Touch controller, which is similar to a computer mouse or joystick, allows the driver to operate an on-screen cursor on the vehicle's GPS navigation system screen."
controller provides reaction force,"Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically."
force feedback,"Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically."
nearby buttons automatically,"Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically."
remote touch utilizes haptic feedback,"Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically."
2010 lexus hs 250h,"Remote Touch was first introduced on the 2010 Lexus RX 350 and Lexus RX 450h models, followed by the 2010 Lexus HS 250h."
2010 lexus rx 350,"Remote Touch was first introduced on the 2010 Lexus RX 350 and Lexus RX 450h models, followed by the 2010 Lexus HS 250h."
lexus rx 450h models,"Remote Touch was first introduced on the 2010 Lexus RX 350 and Lexus RX 450h models, followed by the 2010 Lexus HS 250h."
lexus interiors,"Prior to the advent of Remote Touch, Lexus interiors were typically equipped with touchscreen interfaces."
touchscreen interfaces,"Prior to the advent of Remote Touch, Lexus interiors were typically equipped with touchscreen interfaces."
typically equipped,"Prior to the advent of Remote Touch, Lexus interiors were typically equipped with touchscreen interfaces."
condition code register,"A status register, flag register, or condition code register (CCR) is a collection of status flag bits for a processor."
status register,"Typically, flags in the status register are modified as effects of arithmetic and bit manipulation operations. !! The status register is a hardware register that contains information about the state of the processor. !! A status register, flag register, or condition code register (CCR) is a collection of status flag bits for a processor. !! Examples of such registers include FLAGS register in the x86 architecture, flags in the program status word (PSW) register in the IBM System/360 architecture through z/Architecture, and the application program status register (APSR) in the ARM Cortex-A architecture. !! The status register lets an instruction take action contingent on the outcome of a previous instruction."
status flag bits,"A status register, flag register, or condition code register (CCR) is a collection of status flag bits for a processor."
flag register,"A status register, flag register, or condition code register (CCR) is a collection of status flag bits for a processor."
ibm system,"Examples of such registers include FLAGS register in the x86 architecture, flags in the program status word (PSW) register in the IBM System/360 architecture through z/Architecture, and the application program status register (APSR) in the ARM Cortex-A architecture."
registers include flags register,"Examples of such registers include FLAGS register in the x86 architecture, flags in the program status word (PSW) register in the IBM System/360 architecture through z/Architecture, and the application program status register (APSR) in the ARM Cortex-A architecture."
arm cortex,"Examples of such registers include FLAGS register in the x86 architecture, flags in the program status word (PSW) register in the IBM System/360 architecture through z/Architecture, and the application program status register (APSR) in the ARM Cortex-A architecture."
program status word,"Examples of such registers include FLAGS register in the x86 architecture, flags in the program status word (PSW) register in the IBM System/360 architecture through z/Architecture, and the application program status register (APSR) in the ARM Cortex-A architecture."
application program status register,"Examples of such registers include FLAGS register in the x86 architecture, flags in the program status word (PSW) register in the IBM System/360 architecture through z/Architecture, and the application program status register (APSR) in the ARM Cortex-A architecture."
hardware register,The status register is a hardware register that contains information about the state of the processor.
previous instruction,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps. !! The status register lets an instruction take action contingent on the outcome of a previous instruction."
instruction take action contingent,The status register lets an instruction take action contingent on the outcome of a previous instruction.
status register lets,The status register lets an instruction take action contingent on the outcome of a previous instruction.
bit manipulation operations,"Typically, flags in the status register are modified as effects of arithmetic and bit manipulation operations."
bilateral key exchange,Bilateral key exchange (BKE) was an encryption scheme utilized by the Society for Worldwide Interbank Financial Telecommunication (SWIFT).
encryption scheme utilized,Bilateral key exchange (BKE) was an encryption scheme utilized by the Society for Worldwide Interbank Financial Telecommunication (SWIFT).
worldwide interbank financial telecommunication,Bilateral key exchange (BKE) was an encryption scheme utilized by the Society for Worldwide Interbank Financial Telecommunication (SWIFT).
control system based,"A fuzzy control system is a control system based on fuzzy logica mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true or false, respectively)."
fuzzy logica mathematical system,"A fuzzy control system is a control system based on fuzzy logica mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true or false, respectively)."
analyzes analog input values,"A fuzzy control system is a control system based on fuzzy logica mathematical system that analyzes analog input values in terms of logical variables that take on continuous values between 0 and 1, in contrast to classical or digital logic, which operates on discrete values of either 1 or 0 (true or false, respectively)."
1985 provided simulations,"Interest in fuzzy systems was sparked by Seiji Yasunobu and Soji Miyamoto of Hitachi, who in 1985 provided simulations that demonstrated the feasibility of fuzzy control systems for the Sendai Subway."
sendai subway,"Interest in fuzzy systems was sparked by Seiji Yasunobu and Soji Miyamoto of Hitachi, who in 1985 provided simulations that demonstrated the feasibility of fuzzy control systems for the Sendai Subway."
seiji yasunobu,"Interest in fuzzy systems was sparked by Seiji Yasunobu and Soji Miyamoto of Hitachi, who in 1985 provided simulations that demonstrated the feasibility of fuzzy control systems for the Sendai Subway."
soji miyamoto,"Interest in fuzzy systems was sparked by Seiji Yasunobu and Soji Miyamoto of Hitachi, who in 1985 provided simulations that demonstrated the feasibility of fuzzy control systems for the Sendai Subway."
lens movement,The camera's fuzzy control system uses 12 inputs: 6 to obtain the current clarity data provided by the CCD and 6 to measure the rate of change of lens movement.
current clarity data provided,The camera's fuzzy control system uses 12 inputs: 6 to obtain the current clarity data provided by the CCD and 6 to measure the rate of change of lens movement.
fuzzy control system uses 12 inputs,The camera's fuzzy control system uses 12 inputs: 6 to obtain the current clarity data provided by the CCD and 6 to measure the rate of change of lens movement.
fuzzy control system uses 13 rules,The fuzzy control system uses 13 rules and requires 1.
efficient motors,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
automated space docking,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
investigated fuzzy control,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
us environmental protection agency,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
greatly reduce fuel consumption,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
simulations show,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
studied fuzzy control,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
stability model,The Stability Model has been seen and used in an array of different use-cases. !! Stability Model (SM) is a method of designing and modelling software.
modelling software,Stability Model (SM) is a method of designing and modelling software.
different use,The Stability Model has been seen and used in an array of different use-cases.
commonly encountered symmetric functions,"The most commonly encountered symmetric functions are polynomial functions, which are given by the symmetric polynomials."
symmetric functions,"1 Symmetric functions, pp 2225, Cambridge University Press, ISBN 978-0-521-73794-4. !! The most commonly encountered symmetric functions are polynomial functions, which are given by the symmetric polynomials. !! Symmetric functions should not be confused with even and odd functions, which have a different sort of symmetry."
symmetric polynomials,"Thus, the Vandermonde polynomial (together with the symmetric polynomials) generates the alternating polynomials. !! The most commonly encountered symmetric functions are polynomial functions, which are given by the symmetric polynomials."
odd functions,"Symmetric functions should not be confused with even and odd functions, which have a different sort of symmetry."
different sort,"Symmetric functions should not be confused with even and odd functions, which have a different sort of symmetry."
cambridge university press,"1 Symmetric functions, pp 2225, Cambridge University Press, ISBN 978-0-521-73794-4."
1 symmetric functions,"1 Symmetric functions, pp 2225, Cambridge University Press, ISBN 978-0-521-73794-4."
linear equations involving,"In mathematics, a system of linear equations (or linear system) is a collection of one or more linear equations involving the same variables."
system of linear equations,"In mathematics, a system of linear equations (or linear system) is a collection of one or more linear equations involving the same variables. !! A system of linear equations behave differently from the general case if the equations are linearly dependent, or if it is inconsistent and has no more equations than unknowns. !! There are several algorithms for solving a system of linear equations. !! The simplest method for solving a system of linear equations is to repeatedly eliminate variables. !! This is an example of equivalence in a system of linear equations."
linear equations behave differently,"A system of linear equations behave differently from the general case if the equations are linearly dependent, or if it is inconsistent and has no more equations than unknowns."
general case,"A system of linear equations behave differently from the general case if the equations are linearly dependent, or if it is inconsistent and has no more equations than unknowns. !! The most general case is that of symmetric bidirectional transformations."
several algorithms,There are several algorithms for solving a system of linear equations.
simplest method,The simplest method for solving a system of linear equations is to repeatedly eliminate variables.
repeatedly eliminate variables,The simplest method for solving a system of linear equations is to repeatedly eliminate variables.
random bits,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
approximated using,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
ideal true random number generator,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
mathematical guarantees,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
may depend,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
pseudorandom number generator,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
implementation may deviate,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
expected theoretical behavior,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
true source,"In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
common practice,"If an eigenvalue algorithm does not produce eigenvectors, a common practice is to use an inverse iteration based algorithm with set to a close approximation to the eigenvalue. !! It is common practice to use approximate solutions of differential equations as the basis for structural analysis. !! In common practice, randomized algorithms are approximated using a pseudorandom number generator in place of a true source of random bits; such an implementation may deviate from the expected theoretical behavior and mathematical guarantees which may depend on the existence of an ideal true random number generator."
case complexity,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
see worst,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
deliberately tries,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
bad input,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
competitive analysis,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
probabilistic turing machines,Computational complexity theory models randomized algorithms as probabilistic Turing machines.
recognizes yes,"The most basic randomized complexity class is RP, which is the class of decision problems for which there is an efficient (polynomial time) randomized algorithm (or probabilistic Turing machine) which recognizes NO-instances with absolute certainty and recognizes YES-instances with a probability of at least 1/2."
decision problems,"The most basic randomized complexity class is RP, which is the class of decision problems for which there is an efficient (polynomial time) randomized algorithm (or probabilistic Turing machine) which recognizes NO-instances with absolute certainty and recognizes YES-instances with a probability of at least 1/2."
basic randomized complexity class,"The most basic randomized complexity class is RP, which is the class of decision problems for which there is an efficient (polynomial time) randomized algorithm (or probabilistic Turing machine) which recognizes NO-instances with absolute certainty and recognizes YES-instances with a probability of at least 1/2."
absolute certainty,"The most basic randomized complexity class is RP, which is the class of decision problems for which there is an efficient (polynomial time) randomized algorithm (or probabilistic Turing machine) which recognizes NO-instances with absolute certainty and recognizes YES-instances with a probability of at least 1/2."
scalable version,"Recently, a scalable version of the Bayesian SVM was developed by Florian Wenzel, enabling the application of Bayesian SVMs to big data."
bayesian svms,"Recently, a scalable version of the Bayesian SVM was developed by Florian Wenzel, enabling the application of Bayesian SVMs to big data."
florian wenzel,"Recently, a scalable version of the Bayesian SVM was developed by Florian Wenzel, enabling the application of Bayesian SVMs to big data."
point formats,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
tapered floating point,"""On a Tapered Floating Point System"" (PDF). !! Microprogrammed significance arithmetic with tapered floating point representation. !! In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
format similar,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
length entries found,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
exponent instead,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
normal floating,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
sized entries,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
microprogrammed significance arithmetic,Microprogrammed significance arithmetic with tapered floating point representation.
tapered floating point representation,Microprogrammed significance arithmetic with tapered floating point representation.
tapered floating point system,"""On a Tapered Floating Point System"" (PDF)."
physical structures,Structural analysis is the determination of the effects of loads on physical structures and their components.
support reactions,"Structural analysis employs the fields of applied mechanics, materials science and applied mathematics to compute a structure's deformations, internal forces, stresses, support reactions, accelerations, and stability."
internal forces,"Structural analysis employs the fields of applied mechanics, materials science and applied mathematics to compute a structure's deformations, internal forces, stresses, support reactions, accelerations, and stability."
applied mechanics,"Structural analysis employs the fields of applied mechanics, materials science and applied mathematics to compute a structure's deformations, internal forces, stresses, support reactions, accelerations, and stability."
structural analysis employs,"Structural analysis employs the fields of applied mechanics, materials science and applied mathematics to compute a structure's deformations, internal forces, stresses, support reactions, accelerations, and stability."
key part,Structural analysis is thus a key part of the engineering design of structures.
engineering design,Structural analysis is thus a key part of the engineering design of structures.
linear behavior,"Advanced structural analysis may examine dynamic response, stability and non-linear behavior."
use approximate solutions,It is common practice to use approximate solutions of differential equations as the basis for structural analysis.
entire input available,"In computer science, an online algorithm is one that can process its input piece-by-piece in a serial fashion, i. e. , in the order that the input is fed to the algorithm, without having the entire input available from the start."
serial fashion,"In computer science, an online algorithm is one that can process its input piece-by-piece in a serial fashion, i. e. , in the order that the input is fed to the algorithm, without having the entire input available from the start."
input piece,"In computer science, an online algorithm is one that can process its input piece-by-piece in a serial fashion, i. e. , in the order that the input is fed to the algorithm, without having the entire input available from the start."
called online optimization,"In operations research, the area in which online algorithms are developed is called online optimization."
thus insertion sort,Thus insertion sort is an online algorithm.
many problems,"For many problems, online algorithms cannot match the performance of offline algorithms. !! The main impetus for the development of computational geometry as a discipline was progress in computer graphics and computer-aided design and manufacturing (CAD/CAM), but many problems in computational geometry are classical in nature, and may come from mathematical visualization."
online algorithms cannot match,"For many problems, online algorithms cannot match the performance of offline algorithms."
called competitive,"If the ratio between the performance of an online algorithm and an optimal offline algorithm is bounded, the online algorithm is called competitive."
optimal offline algorithm,"If the ratio between the performance of an online algorithm and an optimal offline algorithm is bounded, the online algorithm is called competitive."
optimal substructure,"As an example of a problem that is unlikely to exhibit optimal substructure, consider the problem of finding the cheapest airline ticket from Buenos Aires to Moscow. !! Typically, a greedy algorithm is used to solve a problem with optimal substructure if it can be proven by induction that this is optimal at each step. !! In computer science, a problem is said to have optimal substructure if an optimal solution can be constructed from optimal solutions of its subproblems. !! There are two key attributes that a problem must have in order for dynamic programming to be applicable: optimal substructure and overlapping sub-problems. !! This is an example of optimal substructure. !! Such an example is likely to exhibit optimal substructure."
optimal solutions,"In computer science, a problem is said to have optimal substructure if an optimal solution can be constructed from optimal solutions of its subproblems."
exhibit optimal substructure,"As an example of a problem that is unlikely to exhibit optimal substructure, consider the problem of finding the cheapest airline ticket from Buenos Aires to Moscow. !! Such an example is likely to exhibit optimal substructure."
buenos aires,"As an example of a problem that is unlikely to exhibit optimal substructure, consider the problem of finding the cheapest airline ticket from Buenos Aires to Moscow."
cheapest airline ticket,"As an example of a problem that is unlikely to exhibit optimal substructure, consider the problem of finding the cheapest airline ticket from Buenos Aires to Moscow."
one platform,"System migration involves moving a set of instructions or programs, e. g. , PLC (programmable logic controller) programs, from one platform to another, minimizing reengineering."
minimizing reengineering,"System migration involves moving a set of instructions or programs, e. g. , PLC (programmable logic controller) programs, from one platform to another, minimizing reengineering."
system migration,"System migration involves moving a set of instructions or programs, e. g. , PLC (programmable logic controller) programs, from one platform to another, minimizing reengineering."
system migration involves moving,"System migration involves moving a set of instructions or programs, e. g. , PLC (programmable logic controller) programs, from one platform to another, minimizing reengineering."
positive semi,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
definite operators,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
measure whose values,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
quantum measurement,"POVMs are a generalisation of projection-valued measures (PVMs) and, correspondingly, quantum measurements described by POVMs are a generalisation of quantum measurement described by PVMs. !! This is an oversimplification, since the physical implementation of a quantum measurement may involve a process like the absorption of a photon; after the measurement, the photon does not exist to be measured again. !! The SternGerlach experiment, proposed in 1921 and implemented in 1922, became a prototypical example of a quantum measurement having a discrete set of possible outcomes. !! In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space. !! Introductory texts on quantum theory often express this by saying that if a quantum measurement is repeated in quick succession, the same outcome will occur both times."
valued measure,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
quantum measurement theory,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
valued measures,"POVMs are a generalisation of projection-valued measures (PVMs) and, correspondingly, quantum measurements described by POVMs are a generalisation of quantum measurement described by PVMs."
quantum measurements described,"POVMs are a generalisation of projection-valued measures (PVMs) and, correspondingly, quantum measurements described by POVMs are a generalisation of quantum measurement described by PVMs."
quantum measurement described,"POVMs are a generalisation of projection-valued measures (PVMs) and, correspondingly, quantum measurements described by POVMs are a generalisation of quantum measurement described by PVMs."
quantum theory often express,"Introductory texts on quantum theory often express this by saying that if a quantum measurement is repeated in quick succession, the same outcome will occur both times."
introductory texts,"Introductory texts on quantum theory often express this by saying that if a quantum measurement is repeated in quick succession, the same outcome will occur both times."
quick succession,"Introductory texts on quantum theory often express this by saying that if a quantum measurement is repeated in quick succession, the same outcome will occur both times."
physical implementation,"This is an oversimplification, since the physical implementation of a quantum measurement may involve a process like the absorption of a photon; after the measurement, the photon does not exist to be measured again."
process like,"This is an oversimplification, since the physical implementation of a quantum measurement may involve a process like the absorption of a photon; after the measurement, the photon does not exist to be measured again."
quantum measurement may involve,"This is an oversimplification, since the physical implementation of a quantum measurement may involve a process like the absorption of a photon; after the measurement, the photon does not exist to be measured again."
sterngerlach experiment,"The SternGerlach experiment, proposed in 1921 and implemented in 1922, became a prototypical example of a quantum measurement having a discrete set of possible outcomes."
possible outcomes,"The SternGerlach experiment, proposed in 1921 and implemented in 1922, became a prototypical example of a quantum measurement having a discrete set of possible outcomes."
prototypical example,"The SternGerlach experiment, proposed in 1921 and implemented in 1922, became a prototypical example of a quantum measurement having a discrete set of possible outcomes."
analog converter,"In electronics, a digital-to-analog converter (DAC, D/A, D2A, or D-to-A) is a system that converts a digital signal into an analog signal."
digital-to-analog converter,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards. !! In electronics, a digital-to-analog converter (DAC, D/A, D2A, or D-to-A) is a system that converts a digital signal into an analog signal."
similar digital,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards."
digital speakers,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards."
sound cards,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards."
analog converters,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards."
usb speakers,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards."
evaluate data structures,"Abstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages."
purely theoretical entities,"Abstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages."
formally describe,"Abstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages."
type systems,"Type theory is closely related to, and in some cases overlaps with, type systems, which are a programming language feature used to reduce bugs and facilitate certain compiler optimizations. !! Subareas of formal verification include deductive verification (see above), abstract interpretation, automated theorem proving, type systems, and lightweight formal methods. !! Abstract data types are purely theoretical entities, used (among other things) to simplify the description of abstract algorithms, to classify and evaluate data structures, and to formally describe the type systems of programming languages."
contract methodologies,"The notion of abstract data types is related to the concept of data abstraction, important in object-oriented programming and design by contract methodologies for software development."
allow interchangeable software modules,The reason for introducing the notion of abstract data types was to allow interchangeable software modules.
modern object,"Modern object-oriented languages, such as C++ and Java, support a form of abstract data types."
oriented languages,"Note that lazy initialization can also be used in non-object-oriented languages. !! Access modifiers (or access specifiers) are keywords in object-oriented languages that set the accessibility of classes, methods, and other members. !! Modern object-oriented languages, such as C++ and Java, support a form of abstract data types. !! Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object."
inextricably intertwined,"Humanistic Intelligence [HI] is intelligence that arises because of a human being in the feedback loop of a computational process, where the human and computer are inextricably intertwined."
physiologically mediated reality,"(2002), ""Exploring Humanistic Intelligence Through Physiologically Mediated Reality"" (PDF), Proceedings of the International Symposium on Mixed and Augmented Reality (ISMAR'02) 0-7695-1781-1/02, IEEE"
international symposium,"(2002), ""Exploring Humanistic Intelligence Through Physiologically Mediated Reality"" (PDF), Proceedings of the International Symposium on Mixed and Augmented Reality (ISMAR'02) 0-7695-1781-1/02, IEEE"
pdf  proceedings,"(2002), ""Exploring Humanistic Intelligence Through Physiologically Mediated Reality"" (PDF), Proceedings of the International Symposium on Mixed and Augmented Reality (ISMAR'02) 0-7695-1781-1/02, IEEE"
exploring humanistic intelligence,"(2002), ""Exploring Humanistic Intelligence Through Physiologically Mediated Reality"" (PDF), Proceedings of the International Symposium on Mixed and Augmented Reality (ISMAR'02) 0-7695-1781-1/02, IEEE"
permit direct memory access,"A DMA attack is a type of side channel attack in computer security, in which an attacker can penetrate a computer or other device, by exploiting the presence of high-speed expansion ports that permit direct memory access (DMA)."
speed expansion ports,"A DMA attack is a type of side channel attack in computer security, in which an attacker can penetrate a computer or other device, by exploiting the presence of high-speed expansion ports that permit direct memory access (DMA)."
prevent dma attacks,Preventing physical connections to such ports will prevent DMA attacks. !! Newer operating systems may take steps to prevent DMA attacks.
preventing physical connections,Preventing physical connections to such ports will prevent DMA attacks.
external device,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
pci express,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
expansion port,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
physical rather,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
like pci,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
systems may still,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
connects attached devices directly,"Systems may still be vulnerable to a DMA attack by an external device if they have a FireWire, ExpressCard, Thunderbolt or other expansion port that, like PCI and PCI Express in general, connects attached devices directly to the physical rather than virtual memory address space."
potentially malicious devices,DMA attacks can be prevented by physical security against potentially malicious devices.
gap analysis involves,"In management literature, gap analysis involves the comparison of actual performance with potential or desired performance."
actual performance,"In management literature, gap analysis involves the comparison of actual performance with potential or desired performance."
management literature,"In management literature, gap analysis involves the comparison of actual performance with potential or desired performance."
desired performance,"In management literature, gap analysis involves the comparison of actual performance with potential or desired performance."
gap analysis,"Gap analysis involves determining, documenting and improving the difference between business requirements and current capabilities. !! This comparison becomes the gap analysis. !! Gap analysis identifies gaps between the optimized allocation and integration of the inputs (resources), and the current allocation-level. !! Gap analysis naturally flows from benchmarking and from other assessments. !! In management literature, gap analysis involves the comparison of actual performance with potential or desired performance."
optimized allocation,"Gap analysis identifies gaps between the optimized allocation and integration of the inputs (resources), and the current allocation-level."
gap analysis identifies gaps,"Gap analysis identifies gaps between the optimized allocation and integration of the inputs (resources), and the current allocation-level."
current allocation,"Gap analysis identifies gaps between the optimized allocation and integration of the inputs (resources), and the current allocation-level."
business requirements,"Gap analysis involves determining, documenting and improving the difference between business requirements and current capabilities."
gap analysis involves determining,"Gap analysis involves determining, documenting and improving the difference between business requirements and current capabilities."
current capabilities,"Gap analysis involves determining, documenting and improving the difference between business requirements and current capabilities."
comparison becomes,This comparison becomes the gap analysis.
data flows,"Weighted round robin (WRR) is a network scheduler for data flows, but also used to schedule processes. !! Quality of service is the ability to provide different priorities to different applications, users, or data flows, or to guarantee a certain level of performance to a data flow."
schedule processes,"Weighted round robin (WRR) is a network scheduler for data flows, but also used to schedule processes."
robin scheduling,"Weighted round robin is a generalisation of round-robin scheduling. !! In best-effort packet switching and other statistical multiplexing, round-robin scheduling can be used as an alternative to first-come first-served queuing. !! Round-robin scheduling is simple, easy to implement, and starvation-free. !! A multiplexer, switch, or router that provides round-robin scheduling has a separate queue for every data flow, where a data flow may be identified by its source and destination address. !! Round-robin scheduling can be applied to other scheduling problems, such as data packet scheduling in computer networks."
robin cycles,"Whereas round-robin cycles over the queues or tasks and gives one service opportunity per cycle, weighted round robin offers to each a fixed number of opportunities, as specified by the configured weight which serves to influence the portion of capacity received by each queue or task."
capacity received,"Whereas round-robin cycles over the queues or tasks and gives one service opportunity per cycle, weighted round robin offers to each a fixed number of opportunities, as specified by the configured weight which serves to influence the portion of capacity received by each queue or task."
whereas round,"Whereas round-robin cycles over the queues or tasks and gives one service opportunity per cycle, weighted round robin offers to each a fixed number of opportunities, as specified by the configured weight which serves to influence the portion of capacity received by each queue or task."
configured weight,"Whereas round-robin cycles over the queues or tasks and gives one service opportunity per cycle, weighted round robin offers to each a fixed number of opportunities, as specified by the configured weight which serves to influence the portion of capacity received by each queue or task."
weighted round robin offers,"Whereas round-robin cycles over the queues or tasks and gives one service opportunity per cycle, weighted round robin offers to each a fixed number of opportunities, as specified by the configured weight which serves to influence the portion of capacity received by each queue or task."
weighted round robin scheduling,"Like round-robin, weighted round robin scheduling is simple, easy to implement, work conserving and starvation-free."
work conserving,"Like round-robin, weighted round robin scheduling is simple, easy to implement, work conserving and starvation-free."
like round,"Like round-robin, weighted round robin scheduling is simple, easy to implement, work conserving and starvation-free."
frequent itemset mining,"Frequent pattern discovery (or FP discovery, FP mining, or Frequent itemset mining) is part of knowledge discovery in databases, Massive Online Analysis, and data mining; it describes the task of finding the most frequent and relevant patterns in large datasets."
massive online analysis,"Frequent pattern discovery (or FP discovery, FP mining, or Frequent itemset mining) is part of knowledge discovery in databases, Massive Online Analysis, and data mining; it describes the task of finding the most frequent and relevant patterns in large datasets."
relevant patterns,"Frequent pattern discovery (or FP discovery, FP mining, or Frequent itemset mining) is part of knowledge discovery in databases, Massive Online Analysis, and data mining; it describes the task of finding the most frequent and relevant patterns in large datasets."
large datasets,"Frequent pattern discovery (or FP discovery, FP mining, or Frequent itemset mining) is part of knowledge discovery in databases, Massive Online Analysis, and data mining; it describes the task of finding the most frequent and relevant patterns in large datasets."
mathematically based techniques whose purpose,"In computer science, formal specifications are mathematically based techniques whose purpose are to help with the implementation of systems and software."
formal specification,"Powerful and efficient analysisOne of the main reasons there is interest in formal specifications is that they will provide an ability to perform proofs on software implementations. !! Formal specifications describe what a system should do, not how the system should do it. !! Formal verification of software programs involves proving that a program satisfies a formal specification of its behavior. !! In computer science, formal specifications are mathematically based techniques whose purpose are to help with the implementation of systems and software. !! It is important to note that a formal specification is not an implementation, but rather it may be used to develop an implementation. !! Formal specifications are one such way to achieve this in software engineering reliability as once predicted."
formal specifications,"Formal specifications are one such way to achieve this in software engineering reliability as once predicted. !! In computer science, formal specifications are mathematically based techniques whose purpose are to help with the implementation of systems and software. !! Powerful and efficient analysisOne of the main reasons there is interest in formal specifications is that they will provide an ability to perform proofs on software implementations."
software engineering reliability,Formal specifications are one such way to achieve this in software engineering reliability as once predicted.
formal specifications describe,"Formal specifications describe what a system should do, not how the system should do it."
main reasons,The combination of good performance for sparse matrices and the ability to compute several (without computing all) eigenvalues are the main reasons for choosing to use the Lanczos algorithm. !! Powerful and efficient analysisOne of the main reasons there is interest in formal specifications is that they will provide an ability to perform proofs on software implementations.
perform proofs,Powerful and efficient analysisOne of the main reasons there is interest in formal specifications is that they will provide an ability to perform proofs on software implementations.
efficient analysisone,Powerful and efficient analysisOne of the main reasons there is interest in formal specifications is that they will provide an ability to perform proofs on software implementations.
proprietary microsoft technologies intended,"Windows Open Services Architecture (WOSA) is a set of proprietary Microsoft technologies intended to ""."
windows open services architecture,"Windows Open Services Architecture (WOSA) is a set of proprietary Microsoft technologies intended to ""."
heap data structure implemented,A skew heap (or self-adjusting heap) is a heap data structure implemented as a binary tree.
adjusting heap,A skew heap (or self-adjusting heap) is a heap data structure implemented as a binary tree.
done using,"For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm. !! The time complexity of Prim's algorithm depends on the data structures used for the graph and for ordering the edges by weight, which can be done using a priority queue. !! Every operation (add, remove_min, merge) on two skew heaps must be done using a special skew heap merge."
two skew heaps must,"Every operation (add, remove_min, merge) on two skew heaps must be done using a special skew heap merge."
every operation,"Every operation (add, remove_min, merge) on two skew heaps must be done using a special skew heap merge."
special skew heap merge,"Every operation (add, remove_min, merge) on two skew heaps must be done using a special skew heap merge."
merging two heaps,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
unconditionally swapping,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
merge path,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
maintain balance,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
leftist heap,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
adjusting form,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
horribly inefficient,"With no structural constraints, it may seem that a skew heap would be horribly inefficient."
skew heap would,"With no structural constraints, it may seem that a skew heap would be horribly inefficient."
may seem,"With no structural constraints, it may seem that a skew heap would be horribly inefficient."
structural constraints,"With no structural constraints, it may seem that a skew heap would be horribly inefficient."
computer science subfields,"The term compressed data structure arises in the computer science subfields of algorithms, data structures, and theoretical computer science."
term compressed data structure arises,"The term compressed data structure arises in the computer science subfields of algorithms, data structures, and theoretical computer science."
typically highly dependent upon,The size of the compressed data structure is typically highly dependent upon the entropy of the data being represented.
compressed data structures include,"Important examples of compressed data structures include the compressed suffix array and the FM-index, both of which can represent an arbitrary text of characters T for pattern matching."
arbitrary text,"Important examples of compressed data structures include the compressed suffix array and the FM-index, both of which can represent an arbitrary text of characters T for pattern matching."
important examples,"Important examples of compressed data structures include the compressed suffix array and the FM-index, both of which can represent an arbitrary text of characters T for pattern matching."
compressed suffix array,"Important examples of compressed data structures include the compressed suffix array and the FM-index, both of which can represent an arbitrary text of characters T for pattern matching."
compressed data structure depends upon,"In contrast, the size of a compressed data structure depends upon the particular data being represented."
particular data,"In contrast, the size of a compressed data structure depends upon the particular data being represented."
theoretic minimum,"When the data are compressible, as is often the case in practice for natural language text, the compressed data structure can occupy space very close to the information-theoretic minimum, and significantly less space than most compression schemes."
occupy space,"When the data are compressible, as is often the case in practice for natural language text, the compressed data structure can occupy space very close to the information-theoretic minimum, and significantly less space than most compression schemes."
significantly less space,"When the data are compressible, as is often the case in practice for natural language text, the compressed data structure can occupy space very close to the information-theoretic minimum, and significantly less space than most compression schemes."
also called linear optimization,"Linear programming (LP, also called linear optimization) is a method to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by linear relationships."
mathematical model whose requirements,"Linear programming (LP, also called linear optimization) is a method to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by linear relationships."
best outcome,"Linear programming (LP, also called linear optimization) is a method to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by linear relationships."
lowest cost,"Linear programming (LP, also called linear optimization) is a method to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by linear relationships."
maximum profit,"Linear programming (LP, also called linear optimization) is a method to achieve the best outcome (such as maximum profit or lowest cost) in a mathematical model whose requirements are represented by linear relationships."
linear inequality constraints,"More formally, linear programming is a technique for the optimization of a linear objective function, subject to linear equality and linear inequality constraints. !! Variants of the criss-cross algorithm also solve more general problems with linear inequality constraints and nonlinear objective functions; there are criss-cross algorithms for linear-fractional programming problems, quadratic-programming problems, and linear complementarity problems."
linear equality,"More formally, linear programming is a technique for the optimization of a linear objective function, subject to linear equality and linear inequality constraints."
linear programming algorithm finds,A linear programming algorithm finds a point in the polytope where this function has the smallest (or largest) value if such a point exists.
point exists,A linear programming algorithm finds a point in the polytope where this function has the smallest (or largest) value if such a point exists.
various fields,Linear programming can be applied to various fields of study.
acct uri scheme,"The acct URI scheme is a proposed internet standard published by the Internet Engineering Task Force, defined by RFC 7565."
internet engineering task force,"Each of the companies chose to start a common Internet Printing Protocol project in the Printer Working Group (PWG) and negotiated an IPP birds-of-a-feather (or BOF) session with the Application Area Directors in the Internet Engineering Task Force (IETF). !! Internet communication protocols are published by the Internet Engineering Task Force (IETF). !! The acct URI scheme is a proposed internet standard published by the Internet Engineering Task Force, defined by RFC 7565."
proposed internet standard published,"The acct URI scheme is a proposed internet standard published by the Internet Engineering Task Force, defined by RFC 7565."
documents using typed views,The Abstract Document Pattern allows the developer to store variables like configuration settings in an untyped tree structure and operate on the documents using typed views.
store variables like configuration settings,The Abstract Document Pattern allows the developer to store variables like configuration settings in an untyped tree structure and operate on the documents using typed views.
abstract document pattern allows,The Abstract Document Pattern allows the developer to store variables like configuration settings in an untyped tree structure and operate on the documents using typed views.
document pattern,The Abstract Document Pattern allows the developer to store variables like configuration settings in an untyped tree structure and operate on the documents using typed views. !! The full implementation of the Abstract Document pattern is available at https://java-design-patterns.
full implementation,The full implementation of the Abstract Document pattern is available at https://java-design-patterns.
https  java,The full implementation of the Abstract Document pattern is available at https://java-design-patterns.
engineering approach,Software engineering is an engineering approach on a software development of systematics application.
systematics application,Software engineering is an engineering approach on a software development of systematics application.
evaluate computer software,"A software engineer is a person who applies the principles of software engineering to design, develop, maintain, test, and evaluate computer software."
caused many problems,It was difficult to keep up with the hardware which caused many problems for software engineers.
also written,Lambda calculus (also written as -calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution.
application using variable binding,Lambda calculus (also written as -calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution.
expressing computation based,Lambda calculus (also written as -calculus) is a formal system in mathematical logic for expressing computation based on function abstraction and application using variable binding and substitution.
performing reduction operations,Lambda calculus consists of constructing lambda terms and performing reduction operations on them.
constructing lambda terms,Lambda calculus consists of constructing lambda terms and performing reduction operations on them.
lambda calculus consists,Lambda calculus consists of constructing lambda terms and performing reduction operations on them.
turing complete,"Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks. !! Lambda calculus is Turing complete, that is, it is a universal model of computation that can be used to simulate any Turing machine."
universal model,"Lambda calculus is Turing complete, that is, it is a universal model of computation that can be used to simulate any Turing machine."
lambda calculus may,Lambda calculus may be untyped or typed.
given input,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code. !! In typed lambda calculus, functions can be applied only if they are capable of accepting the given input's ""type"" of data."
fairchild semiconductor,The Clipper architecture is a 32-bit RISC-like instruction set architecture designed by Fairchild Semiconductor.
bit risc,The Clipper architecture is a 32-bit RISC-like instruction set architecture designed by Fairchild Semiconductor.
like instruction set architecture designed,The Clipper architecture is a 32-bit RISC-like instruction set architecture designed by Fairchild Semiconductor.
clipper architecture,"The Clipper architecture is a 32-bit RISC-like instruction set architecture designed by Fairchild Semiconductor. !! The Clipper architecture used a simplified instruction set compared to earlier CISC architectures, but it did incorporate some more complicated instructions than were present in other contemporary RISC processors. !! The first processors using the Clipper architecture were designed and sold by Fairchild, but the division responsible for them was subsequently sold to Intergraph in 1987; Intergraph continued work on Clipper processors for use in its own systems."
subsequently sold,"The first processors using the Clipper architecture were designed and sold by Fairchild, but the division responsible for them was subsequently sold to Intergraph in 1987; Intergraph continued work on Clipper processors for use in its own systems."
intergraph continued work,"The first processors using the Clipper architecture were designed and sold by Fairchild, but the division responsible for them was subsequently sold to Intergraph in 1987; Intergraph continued work on Clipper processors for use in its own systems."
clipper processors,"The first processors using the Clipper architecture were designed and sold by Fairchild, but the division responsible for them was subsequently sold to Intergraph in 1987; Intergraph continued work on Clipper processors for use in its own systems."
first processors using,"The first processors using the Clipper architecture were designed and sold by Fairchild, but the division responsible for them was subsequently sold to Intergraph in 1987; Intergraph continued work on Clipper processors for use in its own systems."
division responsible,"The first processors using the Clipper architecture were designed and sold by Fairchild, but the division responsible for them was subsequently sold to Intergraph in 1987; Intergraph continued work on Clipper processors for use in its own systems."
contemporary risc processors,"The Clipper architecture used a simplified instruction set compared to earlier CISC architectures, but it did incorporate some more complicated instructions than were present in other contemporary RISC processors."
clipper architecture used,"The Clipper architecture used a simplified instruction set compared to earlier CISC architectures, but it did incorporate some more complicated instructions than were present in other contemporary RISC processors."
simplified instruction set compared,"The Clipper architecture used a simplified instruction set compared to earlier CISC architectures, but it did incorporate some more complicated instructions than were present in other contemporary RISC processors."
earlier cisc architectures,"The Clipper architecture used a simplified instruction set compared to earlier CISC architectures, but it did incorporate some more complicated instructions than were present in other contemporary RISC processors."
complicated instructions,"The Clipper architecture used a simplified instruction set compared to earlier CISC architectures, but it did incorporate some more complicated instructions than were present in other contemporary RISC processors."
exists within,Virtual intelligence is the term given to artificial intelligence that exists within a virtual world.
virtual world,Virtual intelligence is the term given to artificial intelligence that exists within a virtual world.
term given,Virtual intelligence is the term given to artificial intelligence that exists within a virtual world.
demonstrate intelligence,"With today's VI bots, virtual intelligence has evolved past the constraints of past testing into a new level of the machine's ability to demonstrate intelligence."
past testing,"With today's VI bots, virtual intelligence has evolved past the constraints of past testing into a new level of the machine's ability to demonstrate intelligence."
vi bots,"With today's VI bots, virtual intelligence has evolved past the constraints of past testing into a new level of the machine's ability to demonstrate intelligence."
new level,"With today's VI bots, virtual intelligence has evolved past the constraints of past testing into a new level of the machine's ability to demonstrate intelligence."
evolved past,"With today's VI bots, virtual intelligence has evolved past the constraints of past testing into a new level of the machine's ability to demonstrate intelligence."
new distinction,Virtual Intelligence draws a new distinction as to how this application of AI is different due to the environment in which it operates.
virtual intelligence draws,Virtual Intelligence draws a new distinction as to how this application of AI is different due to the environment in which it operates.
different due,Virtual Intelligence draws a new distinction as to how this application of AI is different due to the environment in which it operates.
modsim world,"Sun Tzu Virtual Intelligence demonstration, MODSIM World, October 2009"
sun tzu virtual intelligence demonstration,"Sun Tzu Virtual Intelligence demonstration, MODSIM World, October 2009"
electrically adjustable material,A physical neural network is a type of artificial neural network in which an electrically adjustable material is used to emulate the function of a neural synapse.
sum signals,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
alex nugent describes,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
like nodes used,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
nanoconnections formed,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
signal strength input,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
numerous applications,"Numerous applications for such physical neural networks are possible. !! Matrix multiplication is thus a basic tool of linear algebra, and as such has numerous applications in many areas of mathematics, as well as in applied mathematics, statistics, physics, economics, and engineering."
specific record,"In computer science, a search data structure is any data structure that allows the efficient retrieval of specific items from a set of items, such as a specific record from a database."
efficient retrieval,"In computer science, a search data structure is any data structure that allows the efficient retrieval of specific items from a set of items, such as a specific record from a database."
specific items,"In computer science, a search data structure is any data structure that allows the efficient retrieval of specific items from a set of items, such as a specific record from a database."
specific kind,"Useful search data structures allow faster retrieval; however, they are limited to queries of some specific kind."
pigeonhole sort,Pigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number of elements (n) and the length of the range of possible key values (N) are approximately the same.
possible key values,Pigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number of elements (n) and the length of the range of possible key values (N) are approximately the same.
superconducting computing,"The primary advantage of superconducting computing is improved power efficiency over conventional CMOS technology. !! Superconducting computing research has been pursued by the U. S. National Security Agency since the mid-1950s. !! However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor. !! Superconducting computing is a form of cryogenic computing, as superconductive electronic circuits require cooling to cryogenic temperatures for operation, typically below 10 kelvin. !! Often superconducting computing is applied to quantum computing, with an important application known as superconducting quantum computing."
cryogenic computing,"Superconducting computing is a form of cryogenic computing, as superconductive electronic circuits require cooling to cryogenic temperatures for operation, typically below 10 kelvin."
superconductive electronic circuits require cooling,"Superconducting computing is a form of cryogenic computing, as superconductive electronic circuits require cooling to cryogenic temperatures for operation, typically below 10 kelvin."
cryogenic temperatures,"Superconducting computing is a form of cryogenic computing, as superconductive electronic circuits require cooling to cryogenic temperatures for operation, typically below 10 kelvin."
often superconducting computing,"Often superconducting computing is applied to quantum computing, with an important application known as superconducting quantum computing."
superconducting quantum computing,"Often superconducting computing is applied to quantum computing, with an important application known as superconducting quantum computing. !! Superconducting quantum computing is an implementation of a quantum computer in superconducting electronic circuits. !! Research in superconducting quantum computing is conducted by companies such as Google, IBM, IMEC, BBN Technologies, Rigetti, and Intel."
important application known,"Often superconducting computing is applied to quantum computing, with an important application known as superconducting quantum computing."
improved power efficiency,The primary advantage of superconducting computing is improved power efficiency over conventional CMOS technology.
primary advantage,The primary advantage of superconducting computing is improved power efficiency over conventional CMOS technology.
conventional cmos technology,The primary advantage of superconducting computing is improved power efficiency over conventional CMOS technology.
intensive tasks,"However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
still dissipate energy,"However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
data largely stays,"However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
since transferring information,"However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
large amounts,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network. !! However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
cryogenic environment,"However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
superconducting computing research,Superconducting computing research has been pursued by the U. S. National Security Agency since the mid-1950s.
national security agency since,Superconducting computing research has been pursued by the U. S. National Security Agency since the mid-1950s.
process digital images,Digital image processing is the use of a digital computer to process digital images through an algorithm.
digital computer,Digital image processing is the use of a digital computer to process digital images through an algorithm.
many advantages,"As a subcategory or field of digital signal processing, digital image processing has many advantages over analog image processing. !! The action potential pulse model has many advantages over the simpler Hodgkin Huxley version including evidence, efficiency, timing entropy measurements, and the explanation of nerve impulse flow through myelinated axons."
analog image processing,"As a subcategory or field of digital signal processing, digital image processing has many advantages over analog image processing. !! In electrical engineering and computer science, analog image processing is any image processing task conducted on two-dimensional analog signals by analog means (as opposed to digital image processing)."
multidimensional systems,Since images are defined over two dimensions (perhaps more) digital image processing may be modeled in the form of multidimensional systems.
digital image processing may,Since images are defined over two dimensions (perhaps more) digital image processing may be modeled in the form of multidimensional systems.
since images,Since images are defined over two dimensions (perhaps more) digital image processing may be modeled in the form of multidimensional systems.
two dimensions,Since images are defined over two dimensions (perhaps more) digital image processing may be modeled in the form of multidimensional systems.
three factors,"The generation and development of digital image processing are mainly affected by three factors: first, the development of computers; second, the development of mathematics (especially the creation and improvement of discrete mathematics theory); third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased."
discrete mathematics theory  third,"The generation and development of digital image processing are mainly affected by three factors: first, the development of computers; second, the development of mathematics (especially the creation and improvement of discrete mathematics theory); third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased."
medical science,"The generation and development of digital image processing are mainly affected by three factors: first, the development of computers; second, the development of mathematics (especially the creation and improvement of discrete mathematics theory); third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased."
mainly affected,"The generation and development of digital image processing are mainly affected by three factors: first, the development of computers; second, the development of mathematics (especially the creation and improvement of discrete mathematics theory); third, the demand for a wide range of applications in environment, agriculture, military, industry and medical science has increased."
jet propulsion laboratory,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
bell laboratories,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
research facilities,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
photograph enhancement,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
photo standards conversion,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
satellite imagery,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
massachusetts institute,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
particular sequence,"In object-oriented programming, sequential coupling (also known as temporal coupling) is a form of coupling where a class requires its methods to be called in a particular sequence."
sequential coupling,"In object-oriented programming, sequential coupling (also known as temporal coupling) is a form of coupling where a class requires its methods to be called in a particular sequence. !! Sequential coupling can be refactored with the template method pattern to overcome the problems posed by the usage of this anti-pattern. !! may indicate the existence of sequential coupling."
class requires,"In object-oriented programming, sequential coupling (also known as temporal coupling) is a form of coupling where a class requires its methods to be called in a particular sequence."
may indicate,may indicate the existence of sequential coupling.
problems posed,Sequential coupling can be refactored with the template method pattern to overcome the problems posed by the usage of this anti-pattern.
using support,"Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements."
assign labels,"Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements."
multiclass svm aims,"Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements."
several elements,"Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements."
various roles,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
everyday use,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
email messages,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
use information items,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
activities people perform,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
personal information management,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc. !! The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information. !! Personal information management: From Consumption to Curation. !! The characteristics of the document types, the data that can be used to describe them (meta-data), and features of the systems used to store and organize them (e. g. fielded search) are all components that may influence how users accomplish personal information management. !! Personal Information Management."
complete tasks,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
digital  web pages,"Personal information management (PIM) is the study of the activities people perform in order to acquire or create, store, organize, maintain, retrieve, and use information items such as documents (paper-based and digital), web pages, and email messages for everyday use to complete tasks (work-related or not) and fulfill a person's various roles (as parent, employee, friend, member of community, etc."
systems used,"The characteristics of the document types, the data that can be used to describe them (meta-data), and features of the systems used to store and organize them (e. g. fielded search) are all components that may influence how users accomplish personal information management."
fielded search,"The characteristics of the document types, the data that can be used to describe them (meta-data), and features of the systems used to store and organize them (e. g. fielded search) are all components that may influence how users accomplish personal information management."
may influence,"The characteristics of the document types, the data that can be used to describe them (meta-data), and features of the systems used to store and organize them (e. g. fielded search) are all components that may influence how users accomplish personal information management."
users accomplish personal information management,"The characteristics of the document types, the data that can be used to describe them (meta-data), and features of the systems used to store and organize them (e. g. fielded search) are all components that may influence how users accomplish personal information management."
document types,"The characteristics of the document types, the data that can be used to describe them (meta-data), and features of the systems used to store and organize them (e. g. fielded search) are all components that may influence how users accomplish personal information management."
apparently first used,"The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information."
manage information,"The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information."
personal computer,"The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information."
human ability,"The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information."
general excitement,"The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information."
greatly enhance,"The phrase ""Personal Information Management"" was itself apparently first used in the 1980s in the midst of general excitement over the potential of the personal computer to greatly enhance the human ability to process and manage information."
decrease calculation time,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
adder units,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
carry look,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
digital circuit design used,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
ahead adders,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
executed sequentially,"In computer science, a sequential algorithm or serial algorithm is an algorithm that is executed sequentially once through, from start to finish, without other processing executing as opposed to concurrently or in parallel. !! In simpler CPUs, the instruction cycle is executed sequentially, each instruction being processed before the next one is started."
processing executing,"In computer science, a sequential algorithm or serial algorithm is an algorithm that is executed sequentially once through, from start to finish, without other processing executing as opposed to concurrently or in parallel."
standard computer algorithms,"The term is primarily used to contrast with concurrent algorithm or parallel algorithm; most standard computer algorithms are sequential algorithms, and not specifically identified as such, as sequentialness is a background assumption."
background assumption,"The term is primarily used to contrast with concurrent algorithm or parallel algorithm; most standard computer algorithms are sequential algorithms, and not specifically identified as such, as sequentialness is a background assumption."
specifically identified,"The term is primarily used to contrast with concurrent algorithm or parallel algorithm; most standard computer algorithms are sequential algorithms, and not specifically identified as such, as sequentialness is a background assumption."
primarily used,"So in practice, shortest addition-chain exponentiation is primarily used for small fixed exponents for which a shortest chain can be precomputed and is not too large. !! The term is primarily used to contrast with concurrent algorithm or parallel algorithm; most standard computer algorithms are sequential algorithms, and not specifically identified as such, as sequentialness is a background assumption."
convolutional code,"""Sequential algorithm"" may also refer specifically to an algorithm for decoding a convolutional code."
may also refer specifically,"""Sequential algorithm"" may also refer specifically to an algorithm for decoding a convolutional code."
symmetric sparse matrix,"In numerical analysis the minimum degree algorithm is an algorithm used to permute the rows and columns of a symmetric sparse matrix before applying the Cholesky decomposition, to reduce the number of non-zeros in the Cholesky factor."
algorithm used,"Proof of authority (PoA) is an algorithm used with blockchains that delivers comparatively fast transactions through a consensus mechanism based on identity as a stake. !! In computer science, strictness analysis refers to any algorithm used to prove that a function in a non-strict functional programming language is strict in one or more of its arguments. !! In numerical analysis the minimum degree algorithm is an algorithm used to permute the rows and columns of a symmetric sparse matrix before applying the Cholesky decomposition, to reduce the number of non-zeros in the Cholesky factor."
efficiency savings,"Minimum degree algorithms are often used in the finite element method where the reordering of nodes can be carried out depending only on the topology of the mesh, rather than the coefficients in the partial differential equation, resulting in efficiency savings when the same mesh is used for a variety of coefficient values."
coefficient values,"Minimum degree algorithms are often used in the finite element method where the reordering of nodes can be carried out depending only on the topology of the mesh, rather than the coefficients in the partial differential equation, resulting in efficiency savings when the same mesh is used for a variety of coefficient values."
finite element method,"The conventional topology optimization formulation uses a finite element method (FEM) to evaluate the design performance. !! In the finite element method for the numerical solution of elliptic partial differential equations, the stiffness matrix represents the system of linear equations that must be solved in order to ascertain an approximate solution to the differential equation. !! Minimum degree algorithms are often used in the finite element method where the reordering of nodes can be carried out depending only on the topology of the mesh, rather than the coefficients in the partial differential equation, resulting in efficiency savings when the same mesh is used for a variety of coefficient values."
partial differential equation,"Minimum degree algorithms are often used in the finite element method where the reordering of nodes can be carried out depending only on the topology of the mesh, rather than the coefficients in the partial differential equation, resulting in efficiency savings when the same mesh is used for a variety of coefficient values."
method first proposed,"The minimum degree algorithm is derived from a method first proposed by Markowitz in 1959 for non-symmetric linear programming problems, which is loosely described as follows."
symmetric linear programming problems,"The minimum degree algorithm is derived from a method first proposed by Markowitz in 1959 for non-symmetric linear programming problems, which is loosely described as follows."
loosely described,"The minimum degree algorithm is derived from a method first proposed by Markowitz in 1959 for non-symmetric linear programming problems, which is loosely described as follows."
graph theoretic version,"of Markowitz method was described by Tinney and Walker in 1967 and Rose later derived a graph theoretic version of the algorithm where the factorization is only simulated, and this was named the minimum degree algorithm."
rose later derived,"of Markowitz method was described by Tinney and Walker in 1967 and Rose later derived a graph theoretic version of the algorithm where the factorization is only simulated, and this was named the minimum degree algorithm."
mmd stands,"A version of the minimum degree algorithm was implemented in the MATLAB function symmmd (where MMD stands for multiple minimum degree), but has now been superseded by a symmetric approximate multiple minimum degree function symamd, which is faster."
matlab function symmmd,"A version of the minimum degree algorithm was implemented in the MATLAB function symmmd (where MMD stands for multiple minimum degree), but has now been superseded by a symmetric approximate multiple minimum degree function symamd, which is faster."
multiple minimum degree,"A version of the minimum degree algorithm was implemented in the MATLAB function symmmd (where MMD stands for multiple minimum degree), but has now been superseded by a symmetric approximate multiple minimum degree function symamd, which is faster."
common open policy service,The Common Open Policy Service (COPS) Protocol is part of the internet protocol suite as defined by the RFC 2748.
multiple labels may,"In machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem where multiple labels may be assigned to each instance."
output classification,"In machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem where multiple labels may be assigned to each instance."
strongly related problem,"In machine learning, multi-label classification and the strongly related problem of multi-output classification are variants of the classification problem where multiple labels may be assigned to each instance."
categorizing instances,"Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to."
label problem,"Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to."
precisely one,"Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to."
maps inputs x,"Formally, multi-label classification is the problem of finding a model that maps inputs x to binary vectors y (assigning a value of 0 or 1 for each element (label) in y)."
several binary classification problems,A classifier chain is an alternative method for transforming a multi-label classification problem into several binary classification problems.
alternative method,A classifier chain is an alternative method for transforming a multi-label classification problem into several binary classification problems.
label classification problem,A classifier chain is an alternative method for transforming a multi-label classification problem into several binary classification problems.
classifier chain,A classifier chain is an alternative method for transforming a multi-label classification problem into several binary classification problems.
modification involves,5 algorithm for multi-label classification; the modification involves the entropy calculations.
finite automata,"Finite automata are often used in the frontend of programming language compilers. !! Kohavi, Z. , Switching and Finite Automata Theory. !! Word Processing in Groups is a monograph in mathematics on the theory of automatic groups; these are a type of abstract algebra whose operations are defined by the behavior of finite automata. !! Carroll, J. , Long, D. , Theory of Finite Automata with an Introduction to Formal Languages."
measure used,The spectral centroid is a measure used in digital signal processing to characterise a spectrum.
people use,"Some people use ""spectral centroid"" to refer to the median of the spectrum."
music processing,"Because the spectral centroid is a good predictor of the ""brightness"" of a sound, it is widely used in digital audio and music processing as an automatic measure of musical timbre."
good predictor,"Because the spectral centroid is a good predictor of the ""brightness"" of a sound, it is widely used in digital audio and music processing as an automatic measure of musical timbre."
automatic measure,"Because the spectral centroid is a good predictor of the ""brightness"" of a sound, it is widely used in digital audio and music processing as an automatic measure of musical timbre."
musical timbre,"Because the spectral centroid is a good predictor of the ""brightness"" of a sound, it is widely used in digital audio and music processing as an automatic measure of musical timbre."
digital audio,"Computer networks support many applications and services, such as access to the World Wide Web, digital video, digital audio, shared use of application and storage servers, printers, and fax machines, and use of email and instant messaging applications. !! Because the spectral centroid is a good predictor of the ""brightness"" of a sound, it is widely used in digital audio and music processing as an automatic measure of musical timbre."
retail prices,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
traffic congestion,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
individual based,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
location awareness,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
user schedules,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
user input,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
online sources,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
automated personal assistant,"As automated personal assistants become more popular, there are increasing legal risks involved. !! An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc. !! There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction. !! :815Both types of automated personal assistant technology are enabled by the combination of mobile computing devices, application programming interfaces (APIs), and the proliferation of mobile apps."
weather conditions,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
access information,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc. !! Internet resource locators, described in RFC 1736, convey location and access information for resources."
perform tasks,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
intelligent personal assistant,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
stock prices,"An automated personal assistant or an Intelligent Personal Assistant is a mobile software agent that can perform tasks, or services, on behalf of an individual based on a combination of user input, location awareness, and the ability to access information from a variety of online sources (such as weather conditions, traffic congestion, news, stock prices, user schedules, retail prices, etc."
handling tasks based,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
making dinner reservations,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
perform concierge,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
smart personal agents,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
events often without user initiation,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
apples siri,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
type tasks,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
provide information based,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
trontons cluzee,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
automated personal assistants,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
voice input,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
two types,"The parameters of a hidden Markov model are of two types, transition probabilities and emission probabilities (also known as output probabilities). !! There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction. !! In class-based programming languages, these are distinguished into two types: class variables (also called static member variables), where only one copy of the variable is shared with all instances of the class; and instance variables, where each instance of the class has its own independent copy of the variable."
online information,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
purchasing event tickets,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
intelligent automated assistants,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
automatically perform management,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
making travel arrangements,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
increasing legal risks involved,"As automated personal assistants become more popular, there are increasing legal risks involved."
automated personal assistants become,"As automated personal assistants become more popular, there are increasing legal risks involved."
automated personal assistant technology,":815Both types of automated personal assistant technology are enabled by the combination of mobile computing devices, application programming interfaces (APIs), and the proliferation of mobile apps."
815both types,":815Both types of automated personal assistant technology are enabled by the combination of mobile computing devices, application programming interfaces (APIs), and the proliferation of mobile apps."
functional values,"A truth table is a mathematical table used in logicspecifically in connection with Boolean algebra, boolean functions, and propositional calculuswhich sets out the functional values of logical expressions on each of their functional arguments, that is, for each combination of values taken by their logical variables."
mathematical table used,"A truth table is a mathematical table used in logicspecifically in connection with Boolean algebra, boolean functions, and propositional calculuswhich sets out the functional values of logical expressions on each of their functional arguments, that is, for each combination of values taken by their logical variables."
propositional calculuswhich sets,"A truth table is a mathematical table used in logicspecifically in connection with Boolean algebra, boolean functions, and propositional calculuswhich sets out the functional values of logical expressions on each of their functional arguments, that is, for each combination of values taken by their logical variables."
values taken,"A truth table is a mathematical table used in logicspecifically in connection with Boolean algebra, boolean functions, and propositional calculuswhich sets out the functional values of logical expressions on each of their functional arguments, that is, for each combination of values taken by their logical variables."
different order,", and the degrees of the components are the same up to linear transformations, but possibly in different order; this is Ritt's polynomial decomposition theorem."
polynomial decomposition may enable,A polynomial decomposition may enable more efficient evaluation of a polynomial.
efficient evaluation,A polynomial decomposition may enable more efficient evaluation of a polynomial.
symbolic roots using radicals,"A polynomial decomposition enables calculation of symbolic roots using radicals, even for some irreducible polynomials."
irreducible polynomials,"A polynomial decomposition enables calculation of symbolic roots using radicals, even for some irreducible polynomials."
polynomial decomposition enables calculation,"A polynomial decomposition enables calculation of symbolic roots using radicals, even for some irreducible polynomials."
maxima computer algebra system,"The first algorithm for polynomial decomposition was published in 1985, though it had been discovered in 1976, and implemented in the Macsyma/Maxima computer algebra system."
first algorithm,"The first algorithm for polynomial decomposition was published in 1985, though it had been discovered in 1976, and implemented in the Macsyma/Maxima computer algebra system."
predecessor problem,"In the static predecessor problem, the set of elements does not change, but in the dynamic predecessor problem, insertions into and deletions from the set are allowed. !! There have been a number of attempts to prove lower bounds on the predecessor problem, or find what the running time of asymptotically optimal solutions would be. !! The predecessor problem is a simple case of the nearest neighbor problem, and data structures that solve it have applications in problems like integer sorting. !! In computer science, the predecessor problem involves maintaining a set of items to, given an element, efficiently query which element precedes or succeeds that element in an order."
element precedes,"In computer science, the predecessor problem involves maintaining a set of items to, given an element, efficiently query which element precedes or succeeds that element in an order."
efficiently query,"In computer science, the predecessor problem involves maintaining a set of items to, given an element, efficiently query which element precedes or succeeds that element in an order."
predecessor problem involves maintaining,"In computer science, the predecessor problem involves maintaining a set of items to, given an element, efficiently query which element precedes or succeeds that element in an order."
static predecessor problem,"In the static predecessor problem, the set of elements does not change, but in the dynamic predecessor problem, insertions into and deletions from the set are allowed."
dynamic predecessor problem,"In the static predecessor problem, the set of elements does not change, but in the dynamic predecessor problem, insertions into and deletions from the set are allowed."
problems like integer sorting,"The predecessor problem is a simple case of the nearest neighbor problem, and data structures that solve it have applications in problems like integer sorting."
simple case,"The predecessor problem is a simple case of the nearest neighbor problem, and data structures that solve it have applications in problems like integer sorting."
prove lower bounds,"There have been a number of attempts to prove lower bounds on the predecessor problem, or find what the running time of asymptotically optimal solutions would be."
asymptotically optimal solutions would,"There have been a number of attempts to prove lower bounds on the predecessor problem, or find what the running time of asymptotically optimal solutions would be."
different computer platforms without,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
level languages,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
technical standard originally developed,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
ecma international,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
describes executable code,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
specific architectures,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
allows multiple high,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
common language infrastructure,"ISO/IEC 23271, Common Language Infrastructure. !! The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures. !! Standard ECMA-335, Common Language Infrastructure (CLI). !! ISO/IEC 23271:2012 Information technology Common Language Infrastructure (CLI) !! Ecma C# and Common Language Infrastructure Standards."
open specification,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
standard ecma,"Standard ECMA-335, Common Language Infrastructure (CLI)."
common language infrastructure standards,Ecma C# and Common Language Infrastructure Standards.
2012 information technology common language infrastructure,ISO/IEC 23271:2012 Information technology Common Language Infrastructure (CLI)
tool used,"A Markov partition in mathematics is a tool used in dynamical systems theory, allowing the methods of symbolic dynamics to be applied to the study of hyperbolic dynamics."
dynamical systems theory,"A Markov partition in mathematics is a tool used in dynamical systems theory, allowing the methods of symbolic dynamics to be applied to the study of hyperbolic dynamics."
symbolic dynamics,"The Markov partition thus allows standard techniques from symbolic dynamics to be applied, including the computation of expectation values, correlations, topological entropy, topological zeta functions, Fredholm determinants and the like. !! A Markov partition in mathematics is a tool used in dynamical systems theory, allowing the methods of symbolic dynamics to be applied to the study of hyperbolic dynamics."
hyperbolic dynamics,"A Markov partition in mathematics is a tool used in dynamical systems theory, allowing the methods of symbolic dynamics to be applied to the study of hyperbolic dynamics."
markov shift,"By using a Markov partition, the system can be made to resemble a discrete-time Markov process, with the long-term dynamical characteristics of the system represented as a Markov shift."
time markov process,"By using a Markov partition, the system can be made to resemble a discrete-time Markov process, with the long-term dynamical characteristics of the system represented as a Markov shift."
system represented,"By using a Markov partition, the system can be made to resemble a discrete-time Markov process, with the long-term dynamical characteristics of the system represented as a Markov shift."
term dynamical characteristics,"By using a Markov partition, the system can be made to resemble a discrete-time Markov process, with the long-term dynamical characteristics of the system represented as a Markov shift."
expectation values,"The Markov partition thus allows standard techniques from symbolic dynamics to be applied, including the computation of expectation values, correlations, topological entropy, topological zeta functions, Fredholm determinants and the like."
fredholm determinants,"The Markov partition thus allows standard techniques from symbolic dynamics to be applied, including the computation of expectation values, correlations, topological entropy, topological zeta functions, Fredholm determinants and the like."
topological zeta functions,"The Markov partition thus allows standard techniques from symbolic dynamics to be applied, including the computation of expectation values, correlations, topological entropy, topological zeta functions, Fredholm determinants and the like."
topological entropy,"In mathematics, the topological entropy of a topological dynamical system is a nonnegative extended real number that is a measure of the complexity of the system. !! The Markov partition thus allows standard techniques from symbolic dynamics to be applied, including the computation of expectation values, correlations, topological entropy, topological zeta functions, Fredholm determinants and the like. !! Then the topological entropy of f, denoted h(f), is defined to be the supremum of H(f,C) over all possible finite covers C of X. !! Topological entropy was first introduced in 1965 by Adler, Konheim and McAndrew. !! The second definition clarified the meaning of the topological entropy: for a system given by an iterated function, the topological entropy represents the exponential growth rate of the number of distinguishable orbits of the iterates. !! A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
markov partitions,Markov partitions have been constructed in several situations.
several situations,Markov partitions have been constructed in several situations.
heteroclinic orbits particularly easy,Markov partitions make homoclinic and heteroclinic orbits particularly easy to describe.
markov partitions make homoclinic,Markov partitions make homoclinic and heteroclinic orbits particularly easy to describe.
adding potentially non,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
free composition functions,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
free grammar,"In data compression and the theory of formal languages, the smallest grammar problem is the problem of finding the smallest context-free grammar that generates a given string of characters (but no other string). !! Syntax diagrams (or railroad diagrams) are a way to represent a context-free grammar. !! Shift-reduce parsers use a context-free grammar that deals just with local patterns of symbols. !! Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules. !! Also, neither B nor C may be the start symbol, and the third production rule can only appear if is in L(G), the language produced by the context-free grammar G. :9293,106Every grammar in Chomsky normal form is context-free, and conversely, every context-free grammar can be transformed into an equivalent one which is in Chomsky normal form and has a size no larger than the square of the original grammar's size."
rewrite rules,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
generalized context-free grammar,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
generalized context,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
grammar formalism,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
mips architecture,"The first version of the MIPS architecture was designed by MIPS Computer Systems for its R2000 microprocessor, the first MIPS implementation. !! During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation. !! The MIPS architecture has several optional extensions. !! The early MIPS architectures were 32-bit; 64-bit versions were developed later. !! Computer architecture courses in universities and technical schools often study the MIPS architecture."
developed later,"The early MIPS architectures were 32-bit; 64-bit versions were developed later. !! According to Condon, the ideas of cognitive engineering were developed later than, and independent from, the early work on the Unix operating system."
bit versions,The early MIPS architectures were 32-bit; 64-bit versions were developed later.
early mips architectures,The early MIPS architectures were 32-bit; 64-bit versions were developed later.
several optional extensions,The MIPS architecture has several optional extensions.
computer architecture courses,Computer architecture courses in universities and technical schools often study the MIPS architecture.
technical schools often study,Computer architecture courses in universities and technical schools often study the MIPS architecture.
first mips implementation,"The first version of the MIPS architecture was designed by MIPS Computer Systems for its R2000 microprocessor, the first MIPS implementation."
mips computer systems,"The first version of the MIPS architecture was designed by MIPS Computer Systems for its R2000 microprocessor, the first MIPS implementation."
first version,"The first version of the MIPS architecture was designed by MIPS Computer Systems for its R2000 microprocessor, the first MIPS implementation."
bit mips processors,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
1991 left mips ii,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
19mips computer systems,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
bit mips architecture,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
bit mips iii architecture,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
many new 32,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
mips ii implementations,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
first mips iii implementation,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
mean shift,"is called mean shift in Fukunaga and Hostetler. !! Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known. !! Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm. !! The mean shift procedure is usually credited to work by Fukunaga and Hostetler in 1975. !! Mean shift is a procedure for locating the maximathe modesof a density function given discrete data sampled from that function."
called mode,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
space mathematical analysis technique,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
parametric feature,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
seeking algorithm,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
usually credited,The mean shift procedure is usually credited to work by Fukunaga and Hostetler in 1975.
mean shift procedure,The mean shift procedure is usually credited to work by Fukunaga and Hostetler in 1975.
maximathe modesof,Mean shift is a procedure for locating the maximathe modesof a density function given discrete data sampled from that function.
called mean shift,is called mean shift in Fukunaga and Hostetler.
algorithm using,"Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known."
general kernel,"Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known."
high dimensional space,"Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known."
rigid proof,"Although the mean shift algorithm has been widely used in many applications, a rigid proof for the convergence of the algorithm using a general kernel in a high dimensional space is still not known."
every finite collection,"In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i. e. every finite linear combination of them is normally distributed."
normally distributed,"In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i. e. every finite linear combination of them is normally distributed."
every finite linear combination,"In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i. e. every finite linear combination of them is normally distributed."
random variables indexed,"In probability theory and statistics, a Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i. e. every finite linear combination of them is normally distributed."
continuous domain,"The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e. g. time or space."
infinitely many,"The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e. g. time or space."
carl friedrich gauss,The concept of Gaussian processes is named after Carl Friedrich Gauss because it is based on the notion of the Gaussian distribution (normal distribution).
dimensional generalization,Gaussian processes can be seen as an infinite-dimensional generalization of multivariate normal distributions.
properties inherited,"Gaussian processes are useful in statistical modelling, benefiting from properties inherited from the normal distribution."
valued functions,"So for positive-real-valued functions, the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors. !! Number theory (or arithmetic or higher arithmetic in older usage) is a branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions."
pure mathematics devoted primarily,Number theory (or arithmetic or higher arithmetic in older usage) is a branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions.
higher arithmetic,Number theory (or arithmetic or higher arithmetic in older usage) is a branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions.
older usage,Number theory (or arithmetic or higher arithmetic in older usage) is a branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions.
german mathematician carl friedrich gauss,"German mathematician Carl Friedrich Gauss (17771855) said, ""Mathematics is the queen of the sciencesand number theory is the queen of mathematics. """
sciencesand number theory,"German mathematician Carl Friedrich Gauss (17771855) said, ""Mathematics is the queen of the sciencesand number theory is the queen of mathematics. """
often best understood,"Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory)."
analytic number theory,"In analytic number theory, big O notation is often used to express a bound on the difference between an arithmetical function and a better understood approximation; a famous example of such a difference is the remainder term in the prime number theorem. !! Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory)."
encode properties,"Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory)."
riemann zeta function,"Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory)."
analytical objects,"Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory)."
theoretic objects,"Questions in number theory are often best understood through the study of analytical objects (for example, the Riemann zeta function) that encode properties of the integers, primes or other number-theoretic objects in some fashion (analytic number theory)."
older term,The older term for number theory is arithmetic.
early twentieth century,"By the early twentieth century, it had been superseded by ""number theory""."
euclidean division,"A division algorithm is an algorithm which, given two integers N and D, computes their quotient and/or remainder, the result of Euclidean division."
given two integers n,"A division algorithm is an algorithm which, given two integers N and D, computes their quotient and/or remainder, the result of Euclidean division."
division algorithms fall,Division algorithms fall into two main categories: slow division and fast division.
fast division,Division algorithms fall into two main categories: slow division and fast division.
slow division,Division algorithms fall into two main categories: slow division and fast division.
two main categories,"Division algorithms fall into two main categories: slow division and fast division. !! There are two main categories of texture filtering, magnification filtering and minification filtering."
final quotient per iteration,Slow division algorithms produce one digit of the final quotient per iteration.
exponentially slower,"Although very simple, it takes (Q) steps, and so is exponentially slower than even slow division algorithms like long division."
schnhagestrassen algorithm,"For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm."
karatsuba algorithm,"For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm."
large integers,"For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm."
efficient division algorithms transform,"For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm."
asymptotically efficient multiplication algorithm,"For these large integers, more efficient division algorithms transform the problem to use a small number of multiplications, which can then be done using an asymptotically efficient multiplication algorithm such as the Karatsuba algorithm, ToomCook multiplication or the SchnhageStrassen algorithm."
hava siegelmann,"The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data."
categorize unlabeled data,"The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data."
vladimir vapnik,"The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data."
vector clustering algorithm,"The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data."
shallow semantic parsing,Some methods for shallow semantic parsing are based on support vector machines.
natural class,"Seen this way, support vector machines belong to a natural class of algorithms for statistical inference, and many of its unique features are due to the behavior of the hinge loss."
unique features,"Seen this way, support vector machines belong to a natural class of algorithms for statistical inference, and many of its unique features are due to the behavior of the hinge loss."
support vector machines belong,"Seen this way, support vector machines belong to a natural class of algorithms for statistical inference, and many of its unique features are due to the behavior of the hinge loss."
based learning methods,An Introduction to Support Vector Machines and other kernel-based learning methods.
using disk encryption,"Disk encryption software is computer security software that protects the confidentiality of data stored on computer media (e. g. , a hard disk, floppy disk, or USB device) by using disk encryption."
data stored,"It can therefore be said that the purpose of database encryption is to protect the data stored in a database from being accessed by individuals with potentially ""malicious"" intentions. !! Disk encryption software is computer security software that protects the confidentiality of data stored on computer media (e. g. , a hard disk, floppy disk, or USB device) by using disk encryption. !! Data portability is a concept to protect users from having their data stored in ""silos"" or ""walled gardens"" that are incompatible with one another, i. e. closed platforms, thus subjecting them to vendor lock-in and making the creation of data backups difficult."
hard disk,"Disk encryption software is computer security software that protects the confidentiality of data stored on computer media (e. g. , a hard disk, floppy disk, or USB device) by using disk encryption. !! In computer science, storage virtualization is ""the process of presenting a logical view of the physical storage resources to"" a host computer system, ""treating all storage media (hard disk, optical disk, tape, etc. )"
computer media,"Disk encryption software is computer security software that protects the confidentiality of data stored on computer media (e. g. , a hard disk, floppy disk, or USB device) by using disk encryption."
usb device,"Disk encryption software is computer security software that protects the confidentiality of data stored on computer media (e. g. , a hard disk, floppy disk, or USB device) by using disk encryption."
floppy disk,"Disk encryption software is computer security software that protects the confidentiality of data stored on computer media (e. g. , a hard disk, floppy disk, or USB device) by using disk encryption."
file system,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
provide features,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
encrypted logical disks,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
encrypted logical,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
secretly hidden within,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
free space,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
generally cannot,"Some disk encryption software (e. g. , TrueCrypt or BestCrypt) provide features that generally cannot be accomplished with disk hardware encryption: the ability to mount ""container"" files as encrypted logical disks with their own file system; and encrypted logical ""inner"" volumes which are secretly hidden within the free space of the more obvious ""outer"" volumes."
disk encryption software include,"Well-known examples of disk encryption software include: BitLocker for Windows; FileVault for Apple OS/X; LUKS a standard free software mainly for Linux and TrueCrypt, a non-commercial freeware application, for Windows, OS/X and Linux."
commercial freeware application,"Well-known examples of disk encryption software include: BitLocker for Windows; FileVault for Apple OS/X; LUKS a standard free software mainly for Linux and TrueCrypt, a non-commercial freeware application, for Windows, OS/X and Linux."
standard free software mainly,"Well-known examples of disk encryption software include: BitLocker for Windows; FileVault for Apple OS/X; LUKS a standard free software mainly for Linux and TrueCrypt, a non-commercial freeware application, for Windows, OS/X and Linux."
known examples,"Well-known examples of disk encryption software include: BitLocker for Windows; FileVault for Apple OS/X; LUKS a standard free software mainly for Linux and TrueCrypt, a non-commercial freeware application, for Windows, OS/X and Linux."
apple os,"Well-known examples of disk encryption software include: BitLocker for Windows; FileVault for Apple OS/X; LUKS a standard free software mainly for Linux and TrueCrypt, a non-commercial freeware application, for Windows, OS/X and Linux."
brought online thorough,"When the outer container is brought online thorough the disk encryption software, whether the inner or outer volume is mounted depends on the password provided."
mounted depends,"When the outer container is brought online thorough the disk encryption software, whether the inner or outer volume is mounted depends on the password provided."
outer volume,"When the outer container is brought online thorough the disk encryption software, whether the inner or outer volume is mounted depends on the password provided."
outer container,"When the outer container is brought online thorough the disk encryption software, whether the inner or outer volume is mounted depends on the password provided."
password provided,"When the outer container is brought online thorough the disk encryption software, whether the inner or outer volume is mounted depends on the password provided."
classical economic mechanism design,Algorithmic mechanism design differs from classical economic mechanism design in several respects.
algorithmic mechanism design differs,Algorithmic mechanism design differs from classical economic mechanism design in several respects.
several respects,Algorithmic mechanism design differs from classical economic mechanism design in several respects.
research paper published,"Noam Nisan and Amir Ronen, from the Hebrew University of Jerusalem, first coined ""Algorithmic mechanism design"" in a research paper published in 1999."
noam nisan,"Noam Nisan and Amir Ronen, from the Hebrew University of Jerusalem, first coined ""Algorithmic mechanism design"" in a research paper published in 1999."
hebrew university,"Noam Nisan and Amir Ronen, from the Hebrew University of Jerusalem, first coined ""Algorithmic mechanism design"" in a research paper published in 1999."
amir ronen,"Noam Nisan and Amir Ronen, from the Hebrew University of Jerusalem, first coined ""Algorithmic mechanism design"" in a research paper published in 1999."
first coined,"Noam Nisan and Amir Ronen, from the Hebrew University of Jerusalem, first coined ""Algorithmic mechanism design"" in a research paper published in 1999."
2007  algorithmic mechanism design,"Dtting, Paul; Geiger, Andreas (May 9, 2007), Algorithmic Mechanism Design (PDF), Seminar Report, University of Karlsruhe, Fakultt fr Informatik, archived from the original (PDF) on June 13, 2015, retrieved June 11, 2015."
fakultt fr informatik,"Dtting, Paul; Geiger, Andreas (May 9, 2007), Algorithmic Mechanism Design (PDF), Seminar Report, University of Karlsruhe, Fakultt fr Informatik, archived from the original (PDF) on June 13, 2015, retrieved June 11, 2015."
retrieved june 11,"Dtting, Paul; Geiger, Andreas (May 9, 2007), Algorithmic Mechanism Design (PDF), Seminar Report, University of Karlsruhe, Fakultt fr Informatik, archived from the original (PDF) on June 13, 2015, retrieved June 11, 2015."
pdf  seminar report,"Dtting, Paul; Geiger, Andreas (May 9, 2007), Algorithmic Mechanism Design (PDF), Seminar Report, University of Karlsruhe, Fakultt fr Informatik, archived from the original (PDF) on June 13, 2015, retrieved June 11, 2015."
lexical integrity hypothesis,"Despite being widely referred to and debated in linguistics, there is no single attributable source for the Lexical Integrity Hypothesis, nor does there seem to be any single definition, which potentially poses problems for this theory's falsifiability. !! Different theories have been proposed by linguists to further refine this theory in order to account for cross-linguistic challenges to the Lexical Integrity Hypothesis. !! The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures. !! The Lexical Integrity Hypothesis (LIH) or Lexical Integrity Principle is a hypothesis in linguistics which states that syntactic transformations do not apply to subparts of words. !! Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
syntactic transformations,The Lexical Integrity Hypothesis (LIH) or Lexical Integrity Principle is a hypothesis in linguistics which states that syntactic transformations do not apply to subparts of words.
lexical integrity principle,The Lexical Integrity Hypothesis (LIH) or Lexical Integrity Principle is a hypothesis in linguistics which states that syntactic transformations do not apply to subparts of words.
linguistic challenges,Different theories have been proposed by linguists to further refine this theory in order to account for cross-linguistic challenges to the Lexical Integrity Hypothesis.
different theories,Different theories have been proposed by linguists to further refine this theory in order to account for cross-linguistic challenges to the Lexical Integrity Hypothesis.
unanalyzable units,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
theory using evidence,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
resolve clitics,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
two linguists,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
joan bresnan,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
apparent violations,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
sam mchombo,"Two linguists, Joan Bresnan of Stanford University and Sam Mchombo of the University of California, Berkeley, maintain the idea of words as unanalyzable units; Bresnan & Mchombo (1995) re-evaluate this theory using evidence from Bantu to resolve clitics' apparent violations of the Lexical Integrity Hypothesis."
lexicalist hypothesis,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures."
syntactic operations cannot access word,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures."
internal structures,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures."
widely referred,"Despite being widely referred to and debated in linguistics, there is no single attributable source for the Lexical Integrity Hypothesis, nor does there seem to be any single definition, which potentially poses problems for this theory's falsifiability."
single definition,"Rather than propose a single definition for ubiquitous computing and for these related terms, a taxonomy of properties for ubiquitous computing has been proposed, from which different kinds or flavors of ubiquitous systems and applications can be described. !! Despite being widely referred to and debated in linguistics, there is no single attributable source for the Lexical Integrity Hypothesis, nor does there seem to be any single definition, which potentially poses problems for this theory's falsifiability."
single attributable source,"Despite being widely referred to and debated in linguistics, there is no single attributable source for the Lexical Integrity Hypothesis, nor does there seem to be any single definition, which potentially poses problems for this theory's falsifiability."
potentially poses problems,"Despite being widely referred to and debated in linguistics, there is no single attributable source for the Lexical Integrity Hypothesis, nor does there seem to be any single definition, which potentially poses problems for this theory's falsifiability."
valid object,"In computing, a null pointer or null reference is a value saved for indicating that the pointer or reference does not refer to a valid object. !! A null pointer should not be confused with an uninitialized pointer: a null pointer is guaranteed to compare unequal to any pointer that points to a valid object."
value saved,"In computing, a null pointer or null reference is a value saved for indicating that the pointer or reference does not refer to a valid object."
unknown length,Programs routinely use null pointers to represent conditions such as the end of a list of unknown length or the failure to perform some action; this use of null pointers can be compared to nullable types and to the Nothing value in an option type.
represent conditions,Programs routinely use null pointers to represent conditions such as the end of a list of unknown length or the failure to perform some action; this use of null pointers can be compared to nullable types and to the Nothing value in an option type.
nothing value,Programs routinely use null pointers to represent conditions such as the end of a list of unknown length or the failure to perform some action; this use of null pointers can be compared to nullable types and to the Nothing value in an option type.
programs routinely use null pointers,Programs routinely use null pointers to represent conditions such as the end of a list of unknown length or the failure to perform some action; this use of null pointers can be compared to nullable types and to the Nothing value in an option type.
option type,Programs routinely use null pointers to represent conditions such as the end of a list of unknown length or the failure to perform some action; this use of null pointers can be compared to nullable types and to the Nothing value in an option type.
nullable types,Programs routinely use null pointers to represent conditions such as the end of a list of unknown length or the failure to perform some action; this use of null pointers can be compared to nullable types and to the Nothing value in an option type.
compare unequal,A null pointer should not be confused with an uninitialized pointer: a null pointer is guaranteed to compare unequal to any pointer that points to a valid object.
might compare equal,"It might compare equal to other, valid pointers; or it might compare equal to null pointers."
valid pointers,"It might compare equal to other, valid pointers; or it might compare equal to null pointers."
compare equal,"In C, two null pointers of any type are guaranteed to compare equal."
two null pointers,"In C, two null pointers of any type are guaranteed to compare equal."
identifying objects,Object recognition technology in the field of computer vision for finding and identifying objects in an image or video sequence.
video sequence,Object recognition technology in the field of computer vision for finding and identifying objects in an image or video sequence.
based methods,"Simplistic string metrics such as Levenshtein distance have expanded to include phonetic, token, grammatical and character-based methods of statistical comparisons. !! Roth, Peter M. and Winter, Martin ""Survey of Appearance-Based Methods for Object Recognition"", Technical Report ICG-TR-01/08, Inst. !! ""SURVEYOFAPPEARANCE-BASED METHODS FOR OBJECT RECOGNITION"" (PDF)."
index arithmetic,"sli-c-library (hosted by Google Code), ""C++ Implementation of Symmetric Level-Index Arithmetic""."
symmetric level,"sli-c-library (hosted by Google Code), ""C++ Implementation of Symmetric Level-Index Arithmetic""."
google code,"sli-c-library (hosted by Google Code), ""C++ Implementation of Symmetric Level-Index Arithmetic""."
symmetric level-index arithmetic,"sli-c-library (hosted by Google Code), ""C++ Implementation of Symmetric Level-Index Arithmetic""."
certain kinds,"In computer science, run-time algorithm specialization is a methodology for creating efficient algorithms for costly computation tasks of certain kinds. !! In psychology, genetic memory is a theorized phenomenon in which certain kinds of memories could be inherited, being present at birth in the absence of any associated sensory experience, and that such memories could be incorporated into the genome over long spans of time."
time algorithm specialization,"In computer science, run-time algorithm specialization is a methodology for creating efficient algorithms for costly computation tasks of certain kinds."
costly computation tasks,"In computer science, run-time algorithm specialization is a methodology for creating efficient algorithms for costly computation tasks of certain kinds."
run-time algorithm specialization,"In computer science, run-time algorithm specialization is a methodology for creating efficient algorithms for costly computation tasks of certain kinds."
creating efficient algorithms,"In computer science, run-time algorithm specialization is a methodology for creating efficient algorithms for costly computation tasks of certain kinds."
technology mining refers,Tech mining or technology mining refers to applying text mining methods to technical documents.
applying text mining methods,Tech mining or technology mining refers to applying text mining methods to technical documents.
technology mining,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc. !! Also, technology mining can be considered as one of technology intelligence branches. !! The number of published papers and the number of citations in technology mining area illustrates a hyperbolically progress; there is a jump in the number of publications after 2005 and a huge rise in the number of citations after 2012. !! Tech mining or technology mining refers to applying text mining methods to technical documents. !! Porter, as one of the pioneers in technology mining, defined tech mining in his book as follows: the application of text mining tools to science and technology information, informed by understanding of technological innovation processes."
technical documents,Tech mining or technology mining refers to applying text mining methods to technical documents.
tech mining,Tech mining or technology mining refers to applying text mining methods to technical documents.
text mining tools,"Porter, as one of the pioneers in technology mining, defined tech mining in his book as follows: the application of text mining tools to science and technology information, informed by understanding of technological innovation processes."
defined tech mining,"Porter, as one of the pioneers in technology mining, defined tech mining in his book as follows: the application of text mining tools to science and technology information, informed by understanding of technological innovation processes."
technology information,"Porter, as one of the pioneers in technology mining, defined tech mining in his book as follows: the application of text mining tools to science and technology information, informed by understanding of technological innovation processes."
technological innovation processes,"Porter, as one of the pioneers in technology mining, defined tech mining in his book as follows: the application of text mining tools to science and technology information, informed by understanding of technological innovation processes."
technology intelligence branches,"Also, technology mining can be considered as one of technology intelligence branches."
technology roadmapping,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc."
project initiation,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc."
portfolio selection,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc."
strategic technology planning,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc."
many applications including r,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc."
new product development,"Technology mining have many applications including R&D portfolio selection, R&D project initiation, new product development, strategic technology planning, technology roadmapping, etc."
huge rise,The number of published papers and the number of citations in technology mining area illustrates a hyperbolically progress; there is a jump in the number of publications after 2005 and a huge rise in the number of citations after 2012.
hyperbolically progress,The number of published papers and the number of citations in technology mining area illustrates a hyperbolically progress; there is a jump in the number of publications after 2005 and a huge rise in the number of citations after 2012.
technology mining area illustrates,The number of published papers and the number of citations in technology mining area illustrates a hyperbolically progress; there is a jump in the number of publications after 2005 and a huge rise in the number of citations after 2012.
published papers,The number of published papers and the number of citations in technology mining area illustrates a hyperbolically progress; there is a jump in the number of publications after 2005 and a huge rise in the number of citations after 2012.
resource management applied,Memory management is a form of resource management applied to computer memory.
essential requirement,"The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed."
dynamically allocate portions,"The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed."
longer needed,"The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed."
provide ways,"The essential requirement of memory management is to provide ways to dynamically allocate portions of memory to programs at their request, and free it for reuse when no longer needed."
several methods,"There are several methods that browser hijackers use to gain entry to an operating system. !! There are several methods for actually computing the QR decomposition, such as by means of the GramSchmidt process, Householder transformations, or Givens rotations. !! Several methods have been devised that increase the effectiveness of memory management."
memory management within,Memory management within an address space is generally categorized as either manual memory management or automatic memory management.
either manual memory management,Memory management within an address space is generally categorized as either manual memory management or automatic memory management.
generally categorized,Memory management within an address space is generally categorized as either manual memory management or automatic memory management.
set balancing,"Formally, the set balancing problem can be described as follows. !! The set balancing problem in mathematics is the problem of dividing a set to two subsets that have roughly the same characteristics."
two subsets,"The term ""validation set"" is sometimes used instead of ""test set"" in some literature (e. g. , if the original data set was partitioned into only two subsets, the test set might be referred to as the validation set). !! The set balancing problem in mathematics is the problem of dividing a set to two subsets that have roughly the same characteristics. !! However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
set balancing problem,"Formally, the set balancing problem can be described as follows. !! The set balancing problem in mathematics is the problem of dividing a set to two subsets that have roughly the same characteristics."
new observation,"Early work on statistical classification was undertaken by Fisher, in the context of two-group problems, leading to Fisher's linear discriminant function as the rule for assigning a group to a new observation."
group problems,"Early work on statistical classification was undertaken by Fisher, in the context of two-group problems, leading to Fisher's linear discriminant function as the rule for assigning a group to a new observation."
connectionist expert system,"Development of a connectionist expert system to identify foot problems based on under-foot pressure patterns. !! Connectionist expert systems are artificial neural network (ANN) based expert systems where the ANN generates inferencing rules e. g. , fuzzy-multi layer perceptron where linguistic and natural form of inputs are used. !! Connectionist expert systems. !! HYCONES: a hybrid connectionist expert system."
connectionist expert systems,"Connectionist expert systems are artificial neural network (ANN) based expert systems where the ANN generates inferencing rules e. g. , fuzzy-multi layer perceptron where linguistic and natural form of inputs are used. !! Connectionist expert systems."
natural form,"Connectionist expert systems are artificial neural network (ANN) based expert systems where the ANN generates inferencing rules e. g. , fuzzy-multi layer perceptron where linguistic and natural form of inputs are used."
based expert systems,"Connectionist expert systems are artificial neural network (ANN) based expert systems where the ANN generates inferencing rules e. g. , fuzzy-multi layer perceptron where linguistic and natural form of inputs are used."
ann generates inferencing rules e,"Connectionist expert systems are artificial neural network (ANN) based expert systems where the ANN generates inferencing rules e. g. , fuzzy-multi layer perceptron where linguistic and natural form of inputs are used."
hybrid connectionist expert system,HYCONES: a hybrid connectionist expert system.
identify foot problems based,Development of a connectionist expert system to identify foot problems based on under-foot pressure patterns.
foot pressure patterns,Development of a connectionist expert system to identify foot problems based on under-foot pressure patterns.
olap systems today,"Modern decision, and classical statistical databases are often closer to the relational model than the multidimensional model commonly used in OLAP systems today."
modern decision,"Modern decision, and classical statistical databases are often closer to the relational model than the multidimensional model commonly used in OLAP systems today."
classical statistical databases,"Modern decision, and classical statistical databases are often closer to the relational model than the multidimensional model commonly used in OLAP systems today."
multidimensional model commonly used,"Modern decision, and classical statistical databases are often closer to the relational model than the multidimensional model commonly used in OLAP systems today."
often closer,"Modern decision, and classical statistical databases are often closer to the relational model than the multidimensional model commonly used in OLAP systems today."
measured data,Statistical databases typically contain parameter data and the measured data for these parameters.
many null,Many statistical databases are sparse with many null or zero values.
many statistical databases,Many statistical databases are sparse with many null or zero values.
zero values,Many statistical databases are sparse with many null or zero values.
statistical databases often incorporate support,"Statistical databases often incorporate support for advanced statistical analysis techniques, such as correlations, which go beyond SQL."
go beyond sql,"Statistical databases often incorporate support for advanced statistical analysis techniques, such as correlations, which go beyond SQL."
advanced statistical analysis techniques,"Statistical databases often incorporate support for advanced statistical analysis techniques, such as correlations, which go beyond SQL."
almost always subject,The conclusion is that statistical databases are almost always subject to compromise.
reusable solution,"In software engineering, a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design."
commonly occurring problem within,"In software engineering, a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design."
given context,"In software engineering, a software design pattern is a general, reusable solution to a commonly occurring problem within a given context in software design."
switches connected,Bidirectional Forwarding Detection (BFD) is a network protocol that is used to detect faults between two routers or switches connected by a link.
two routers,Bidirectional Forwarding Detection (BFD) is a network protocol that is used to detect faults between two routers or switches connected by a link.
detect faults,Bidirectional Forwarding Detection (BFD) is a network protocol that is used to detect faults between two routers or switches connected by a link.
certain formal specification,"In the context of hardware and software systems, formal verification is the act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics."
intended algorithms underlying,"In the context of hardware and software systems, formal verification is the act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics."
formal verification,"Temporal logic has found an important application in formal verification, where it is used to state requirements of hardware or software systems. !! Formal verification of software programs involves proving that a program satisfies a formal specification of its behavior. !! Program repair combines techniques from formal verification and program synthesis. !! Subareas of formal verification include deductive verification (see above), abstract interpretation, automated theorem proving, type systems, and lightweight formal methods. !! In the context of hardware and software systems, formal verification is the act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics. !! Formal verification can be helpful in proving the correctness of systems such as: cryptographic protocols, combinational circuits, digital circuits with internal memory, and software expressed as source code."
using formal methods,"In the context of hardware and software systems, formal verification is the act of proving or disproving the correctness of intended algorithms underlying a system with respect to a certain formal specification or property, using formal methods of mathematics."
internal memory,"Formal verification can be helpful in proving the correctness of systems such as: cryptographic protocols, combinational circuits, digital circuits with internal memory, and software expressed as source code."
digital circuits,"Formal verification can be helpful in proving the correctness of systems such as: cryptographic protocols, combinational circuits, digital circuits with internal memory, and software expressed as source code."
software expressed,"Formal verification can be helpful in proving the correctness of systems such as: cryptographic protocols, combinational circuits, digital circuits with internal memory, and software expressed as source code."
software programs involves proving,Formal verification of software programs involves proving that a program satisfies a formal specification of its behavior.
program satisfies,"In computer science, state space enumeration are methods that consider each reachable program state to determine whether a program satisfies a given property. !! Formal verification of software programs involves proving that a program satisfies a formal specification of its behavior."
automated theorem proving,"Unit propagation (UP) or Boolean Constraint propagation (BCP) or the one-literal rule (OLR) is a procedure of automated theorem proving that can simplify a set of (usually propositional) clauses. !! Automated theorem proving (also known as ATP or automated deduction) is a subfield of automated reasoning and mathematical logic dealing with proving mathematical theorems by computer programs. !! First-order theorem proving is one of the most mature subfields of automated theorem proving. !! Commercial use of automated theorem proving is mostly concentrated in integrated circuit design and verification. !! Automated Theorem Proving: A Logical Basis. !! Subareas of formal verification include deductive verification (see above), abstract interpretation, automated theorem proving, type systems, and lightweight formal methods. !! AMD, Intel and others use automated theorem proving to verify that division and other operations are correctly implemented in their processors."
lightweight formal methods,"Subareas of formal verification include deductive verification (see above), abstract interpretation, automated theorem proving, type systems, and lightweight formal methods."
formal verification include deductive verification,"Subareas of formal verification include deductive verification (see above), abstract interpretation, automated theorem proving, type systems, and lightweight formal methods."
program repair combines techniques,Program repair combines techniques from formal verification and program synthesis.
preceding row vector,"In linear algebra, a circulant matrix is a square matrix in which all row vectors are composed of the same elements and each row vector is rotated one element to the right relative to the preceding row vector."
row vector,"In linear algebra, a circulant matrix is a square matrix in which all row vectors are composed of the same elements and each row vector is rotated one element to the right relative to the preceding row vector."
rotated one element,"In linear algebra, a circulant matrix is a square matrix in which all row vectors are composed of the same elements and each row vector is rotated one element to the right relative to the preceding row vector."
right relative,"In linear algebra, a circulant matrix is a square matrix in which all row vectors are composed of the same elements and each row vector is rotated one element to the right relative to the preceding row vector."
row vectors,"In linear algebra, a circulant matrix is a square matrix in which all row vectors are composed of the same elements and each row vector is rotated one element to the right relative to the preceding row vector."
simplifying channel equalization,"This enables the channel to be represented by a circulant matrix, simplifying channel equalization in the frequency domain."
frequency domain,"This enables the channel to be represented by a circulant matrix, simplifying channel equalization in the frequency domain."
mixcolumns step,"In cryptography, a circulant matrix is used in the MixColumns step of the Advanced Encryption Standard."
first row rather,corresponding to the first row rather than the first column of the matrix; and possibly with a different direction of shift (which is sometimes called an anti-circulant matrix).
different direction,corresponding to the first row rather than the first column of the matrix; and possibly with a different direction of shift (which is sometimes called an anti-circulant matrix). !! A different direction of development includes extensions of behavior-based robotics to multi-robot teams.
first column,"corresponding to the first row rather than the first column of the matrix; and possibly with a different direction of shift (which is sometimes called an anti-circulant matrix). !! QR decomposition is GramSchmidt orthogonalization of columns of A, started from the first column."
sometimes called,"corresponding to the first row rather than the first column of the matrix; and possibly with a different direction of shift (which is sometimes called an anti-circulant matrix). !! In computer science, a ternary search tree is a type of trie (sometimes called a prefix tree) where nodes are arranged in a manner similar to a binary search tree, but with up to three children rather than the binary tree's limit of two. !! This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution. !! In object-oriented programming, a member variable (sometimes called a member field) is a variable that is associated with a specific object, and accessible for all its methods (member functions). !! Modifying a system in a way that does not allow backward compatibility is sometimes called ""breaking"" backward compatibility."
independent management,User virtualization refers to the independent management of all aspects of the user on the desktop environment.
user virtualization refers,User virtualization refers to the independent management of all aspects of the user on the desktop environment.
centralized data share either,"User virtualization decouples a user's profile, settings and data from the operating system and stores this information into a centralized data share either in the data center or cloud."
user virtualization decouples,"User virtualization decouples a user's profile, settings and data from the operating system and stores this information into a centralized data share either in the data center or cloud."
seamless working environments across,User virtualization solutions provide consistent and seamless working environments across a range of application delivery mechanisms.
application delivery mechanisms,User virtualization solutions provide consistent and seamless working environments across a range of application delivery mechanisms.
user virtualization solutions provide consistent,User virtualization solutions provide consistent and seamless working environments across a range of application delivery mechanisms.
although user virtualization,"Although user virtualization is most closely associated with desktop virtualization, in fact, this technology can be used to manage user profiles on physical desktops as well."
manage user profiles,"Although user virtualization is most closely associated with desktop virtualization, in fact, this technology can be used to manage user profiles on physical desktops as well."
closely associated,"Although user virtualization is most closely associated with desktop virtualization, in fact, this technology can be used to manage user profiles on physical desktops as well."
physical desktops,"Although user virtualization is most closely associated with desktop virtualization, in fact, this technology can be used to manage user profiles on physical desktops as well."
single location,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
workspace without,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
currently used operating systems expands,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
single device,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
multiple devices,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
jobs escalates,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
allow access,"As the range of currently used operating systems expands, and the use of multiple devices by workers to perform their jobs escalates, user virtualization can support the creation of a ""follow-me"" identity that will allow access to a workspace without being tied into only a single device or a single location."
random subspace selection,The idea of random subspace selection from Ho was also influential in the design of random forests.
also influential,The idea of random subspace selection from Ho was also influential in the design of random forests.
bayesian information,Minimum message length (MML) is a Bayesian information-theoretic method for statistical model comparison and selection.
theoretic method,Minimum message length (MML) is a Bayesian information-theoretic method for statistical model comparison and selection.
scott problem,Resolving the Neyman-Scott Problem by Minimum Message Length.
asymmetric languages,"Chapter 11: Minimum Message Length, MDL and Generalised Bayesian Networks with Asymmetric Languages."
argument technology,"One of the challenges that argument technology faced was a lack of standardisation in the representation and underlying conception of argument in machine readable terms. !! Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019. !! Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies. !! Argument technology is a sub-field of artificial intelligence that focuses on applying computational techniques to the creation, identification, analysis, navigation, evaluation and visualisation of arguments and debates. !! A 2021 video narrated by Stephen Fry provides a summary of the societal motivations for work in argument technology."
applying computational techniques,"Argument technology is a sub-field of artificial intelligence that focuses on applying computational techniques to the creation, identification, analysis, navigation, evaluation and visualisation of arguments and debates."
underlying conception,One of the challenges that argument technology faced was a lack of standardisation in the representation and underlying conception of argument in machine readable terms.
argument technology faced,One of the challenges that argument technology faced was a lack of standardisation in the representation and underlying conception of argument in machine readable terms.
machine readable terms,One of the challenges that argument technology faced was a lack of standardisation in the representation and underlying conception of argument in machine readable terms.
nationwide research programme,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
uk nationwide deployment,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
german research funder,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
project debater,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
growing rapidly,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
robust argumentation machines,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
evidence toolkit,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
grand challenge,"Since about 2018, argument technology has been growing rapidly, with, for example, IBM's Grand Challenge, Project Debater, results for which were published in Nature in March 2021; German research funder, DFG's nationwide research programme on Robust Argumentation Machines, RATIO, begun in 2019; and UK nationwide deployment of The Evidence Toolkit by the BBC in 2019."
2021 video narrated,A 2021 video narrated by Stephen Fry provides a summary of the societal motivations for work in argument technology.
societal motivations,A 2021 video narrated by Stephen Fry provides a summary of the societal motivations for work in argument technology.
stephen fry provides,A 2021 video narrated by Stephen Fry provides a summary of the societal motivations for work in argument technology.
intelligence analysis,"Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies."
policy making,"Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies."
including education,"Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies."
risk management,"Argument technology has applications in a variety of domains, including education, healthcare, policy making, political science, intelligence analysis and risk management and has a variety of sub-fields, methodologies and technologies. !! In quantitative finance, principal component analysis can be directly applied to the risk management of interest rate derivative portfolios. !! Software diagnosis supports all branches of software engineering, in particular project management, quality management, risk management as well as implementation and test."
mean dimension,"For various topological dynamical systems with infinite topological entropy, the mean dimension can be calculated or at least bounded from below and above. !! Mean dimension is also related to the problem of embedding topological dynamical systems in shift spaces (over Euclidean cubes). !! Mean dimension was first introduced in 1999 by Gromov. !! In particular they proved the following key fact: a system with finite topological entropy has zero mean dimension. !! This allows mean dimension to be used to distinguish between systems with infinite topological entropy."
zero mean dimension,In particular they proved the following key fact: a system with finite topological entropy has zero mean dimension.
following key fact,In particular they proved the following key fact: a system with finite topological entropy has zero mean dimension.
finite topological entropy,In particular they proved the following key fact: a system with finite topological entropy has zero mean dimension.
various topological dynamical systems,"For various topological dynamical systems with infinite topological entropy, the mean dimension can be calculated or at least bounded from below and above."
least bounded,"For various topological dynamical systems with infinite topological entropy, the mean dimension can be calculated or at least bounded from below and above."
infinite topological entropy,"For various topological dynamical systems with infinite topological entropy, the mean dimension can be calculated or at least bounded from below and above. !! This allows mean dimension to be used to distinguish between systems with infinite topological entropy."
allows mean dimension,This allows mean dimension to be used to distinguish between systems with infinite topological entropy.
also related,"Mean dimension is also related to the problem of embedding topological dynamical systems in shift spaces (over Euclidean cubes). !! In Fodor's original views, the computational theory of mind is also related to the language of thought."
euclidean cubes,Mean dimension is also related to the problem of embedding topological dynamical systems in shift spaces (over Euclidean cubes).
embedding topological dynamical systems,Mean dimension is also related to the problem of embedding topological dynamical systems in shift spaces (over Euclidean cubes).
shift spaces,Mean dimension is also related to the problem of embedding topological dynamical systems in shift spaces (over Euclidean cubes).
vertices connected,"In mathematics, and more specifically in graph theory, a directed graph (or digraph) is a graph that is made up of a set of vertices connected by directed edges often called arcs."
directed edges often called arcs,"In mathematics, and more specifically in graph theory, a directed graph (or digraph) is a graph that is made up of a set of vertices connected by directed edges often called arcs."
usually called edges,"It differs from an ordinary or undirected graph, in that the latter is defined in terms of unordered pairs of vertices, which are usually called edges, links or lines."
unordered pairs,"It differs from an ordinary or undirected graph, in that the latter is defined in terms of unordered pairs of vertices, which are usually called edges, links or lines."
arc set,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
authors consider,"On the other hand, the aforementioned definition allows a directed graph to have loops (that is, arcs that directly connect nodes with themselves), but some authors consider a narrower definition that doesn't allow directed graphs to have loops. !! The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
broader definition,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
allows directed graphs,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
multiple arrows,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
target nodes,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
aforementioned definition,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
multiple arcs,"The aforementioned definition does not allow a directed graph to have multiple arrows with the same source and target nodes, but some authors consider a broader definition that allows directed graphs to have such multiple arcs (namely, they allow the arc set to be a multiset)."
directly connect nodes,"On the other hand, the aforementioned definition allows a directed graph to have loops (that is, arcs that directly connect nodes with themselves), but some authors consider a narrower definition that doesn't allow directed graphs to have loops."
allow directed graphs,"On the other hand, the aforementioned definition allows a directed graph to have loops (that is, arcs that directly connect nodes with themselves), but some authors consider a narrower definition that doesn't allow directed graphs to have loops."
narrower definition,"On the other hand, the aforementioned definition allows a directed graph to have loops (that is, arcs that directly connect nodes with themselves), but some authors consider a narrower definition that doesn't allow directed graphs to have loops."
aforementioned definition allows,"On the other hand, the aforementioned definition allows a directed graph to have loops (that is, arcs that directly connect nodes with themselves), but some authors consider a narrower definition that doesn't allow directed graphs to have loops."
see section types,"More specifically, directed graphs without loops are addressed as simple directed graphs, while directed graphs with loops are addressed as loop-digraphs (see section Types of directed graphs)."
directed graphs without loops,"More specifically, directed graphs without loops are addressed as simple directed graphs, while directed graphs with loops are addressed as loop-digraphs (see section Types of directed graphs)."
internet protocol addresses available,"In the context of the Internet addressing structure, an address pool is a set of Internet Protocol addresses available at any level in the IP address allocation hierarchy."
ip address allocation hierarchy,"In the context of the Internet addressing structure, an address pool is a set of Internet Protocol addresses available at any level in the IP address allocation hierarchy."
top level,"At the top level, the IP address pool is managed by the Internet Assigned Numbers Authority (IANA)."
internet assigned numbers authority,"At the top level, the IP address pool is managed by the Internet Assigned Numbers Authority (IANA)."
total ipv4 address pool contains 4294967296,"The total IPv4 address pool contains 4294967296 (232) addresses, while the size of the IPv6 address pool is 2128 (340282366920938463463374607431768211456) addresses."
host configurations,"In the context of application design, an address pool may be the availability of a set of addresses (IP address, MAC address) available to an application that is shared among its users, or available for allocation to users, such as in host configurations with the Dynamic Host Configuration Protocol (DHCP)."
shared among,"In the context of application design, an address pool may be the availability of a set of addresses (IP address, MAC address) available to an application that is shared among its users, or available for allocation to users, such as in host configurations with the Dynamic Host Configuration Protocol (DHCP)."
address pool may,"In the context of application design, an address pool may be the availability of a set of addresses (IP address, MAC address) available to an application that is shared among its users, or available for allocation to users, such as in host configurations with the Dynamic Host Configuration Protocol (DHCP)."
sometimes using,"Principal component analysis (PCA) is the process of computing the principal components and using them to perform a change of basis on the data, sometimes using only the first few principal components and ignoring the rest."
brooks et al,"7 of Jolliffe's Principal Component Analysis), EckartYoung theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al."
1987  empirical component analysis,"7 of Jolliffe's Principal Component Analysis), EckartYoung theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al."
empirical eigenfunction decomposition,"7 of Jolliffe's Principal Component Analysis), EckartYoung theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al."
meteorological science,"7 of Jolliffe's Principal Component Analysis), EckartYoung theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al."
principal component analysis  eckartyoung theorem,"7 of Jolliffe's Principal Component Analysis), EckartYoung theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al."
directly applied,"In quantitative finance, principal component analysis can be directly applied to the risk management of interest rate derivative portfolios."
interest rate derivative portfolios,"In quantitative finance, principal component analysis can be directly applied to the risk management of interest rate derivative portfolios."
quantitative finance,"In quantitative finance, principal component analysis can be directly applied to the risk management of interest rate derivative portfolios."
1956  quasiharmonic modes,"7 of Jolliffe's Principal Component Analysis), EckartYoung theorem (Harman, 1960), or empirical orthogonal functions (EOF) in meteorological science, empirical eigenfunction decomposition (Sirovich, 1987), empirical component analysis (Lorenz, 1956), quasiharmonic modes (Brooks et al."
one special extension,"One special extension is multiple correspondence analysis, which may be seen as the counterpart of principal component analysis for categorical data."
categorical data,"One special extension is multiple correspondence analysis, which may be seen as the counterpart of principal component analysis for categorical data."
principal component analysis creates variables,Principal component analysis creates variables that are linear combinations of the original variables.
original variables,Principal component analysis creates variables that are linear combinations of the original variables.
random experiment,"In the theory of probability and statistics, a Bernoulli trial (or binomial trial) is a random experiment with exactly two possible outcomes, ""success"" and ""failure"", in which the probability of success is the same every time the experiment is conducted."
every time,"In the theory of probability and statistics, a Bernoulli trial (or binomial trial) is a random experiment with exactly two possible outcomes, ""success"" and ""failure"", in which the probability of success is the same every time the experiment is conducted."
exactly two possible outcomes,"Independent repeated trials of an experiment with exactly two possible outcomes are called Bernoulli trials. !! In the theory of probability and statistics, a Bernoulli trial (or binomial trial) is a random experiment with exactly two possible outcomes, ""success"" and ""failure"", in which the probability of success is the same every time the experiment is conducted."
mathematical formalisation,The mathematical formalisation of the Bernoulli trial is known as the Bernoulli process.
two possible outcomes,"Since a Bernoulli trial has only two possible outcomes, it can be framed as some ""yes or no"" question."
outcomes  one,"More generally, given any probability space, for any event (set of outcomes), one can define a Bernoulli trial, corresponding to whether the event occurred or not (event or complementary event)."
event occurred,"More generally, given any probability space, for any event (set of outcomes), one can define a Bernoulli trial, corresponding to whether the event occurred or not (event or complementary event)."
called bernoulli trials,Independent repeated trials of an experiment with exactly two possible outcomes are called Bernoulli trials.
independent repeated trials,Independent repeated trials of an experiment with exactly two possible outcomes are called Bernoulli trials.
related manual procedures,"In software engineering, structured analysis (SA) and structured design (SD) are methods for analyzing business requirements and developing specifications for converting practices into computer programs, hardware configurations, and related manual procedures."
analyzing business requirements,"In software engineering, structured analysis (SA) and structured design (SD) are methods for analyzing business requirements and developing specifications for converting practices into computer programs, hardware configurations, and related manual procedures."
structured design,"In software engineering, structured analysis (SA) and structured design (SD) are methods for analyzing business requirements and developing specifications for converting practices into computer programs, hardware configurations, and related manual procedures."
developing specifications,"In software engineering, structured analysis (SA) and structured design (SD) are methods for analyzing business requirements and developing specifications for converting practices into computer programs, hardware configurations, and related manual procedures."
converting practices,"In software engineering, structured analysis (SA) and structured design (SD) are methods for analyzing business requirements and developing specifications for converting practices into computer programs, hardware configurations, and related manual procedures."
hardware configurations,"In software engineering, structured analysis (SA) and structured design (SD) are methods for analyzing business requirements and developing specifications for converting practices into computer programs, hardware configurations, and related manual procedures."
systems analysis,Structured analysis and design techniques are fundamental tools of systems analysis.
fundamental tools,Structured analysis and design techniques are fundamental tools of systems analysis.
design techniques,Structured analysis and design techniques are fundamental tools of systems analysis.
use today,Structured analysis became popular in the 1980s and is still in use today.
structured analysis became popular,Structured analysis became popular in the 1980s and is still in use today.
control terminology represented,Structured analysis consists of interpreting the system concept (or real world situations) into data and control terminology represented by data flow diagrams.
system concept,Structured analysis consists of interpreting the system concept (or real world situations) into data and control terminology represented by data flow diagrams.
structured analysis consists,Structured analysis consists of interpreting the system concept (or real world situations) into data and control terminology represented by data flow diagrams.
real world situations,Structured analysis consists of interpreting the system concept (or real world situations) into data and control terminology represented by data flow diagrams.
various published system development methodologies,"These techniques were combined in various published system development methodologies, including structured systems analysis and design method, profitable information by design (PRIDE), Nastec structured analysis & design, SDM/70 and the Spectrum structured system development methodology."
design method,"These techniques were combined in various published system development methodologies, including structured systems analysis and design method, profitable information by design (PRIDE), Nastec structured analysis & design, SDM/70 and the Spectrum structured system development methodology."
pride  nastec structured analysis,"These techniques were combined in various published system development methodologies, including structured systems analysis and design method, profitable information by design (PRIDE), Nastec structured analysis & design, SDM/70 and the Spectrum structured system development methodology."
including structured systems analysis,"These techniques were combined in various published system development methodologies, including structured systems analysis and design method, profitable information by design (PRIDE), Nastec structured analysis & design, SDM/70 and the Spectrum structured system development methodology."
spectrum structured system development methodology,"These techniques were combined in various published system development methodologies, including structured systems analysis and design method, profitable information by design (PRIDE), Nastec structured analysis & design, SDM/70 and the Spectrum structured system development methodology."
profitable information,"These techniques were combined in various published system development methodologies, including structured systems analysis and design method, profitable information by design (PRIDE), Nastec structured analysis & design, SDM/70 and the Spectrum structured system development methodology."
optimization technique employed,"Inline caching is an optimization technique employed by some language runtimes, and first developed for Smalltalk."
language runtimes,"Inline caching is an optimization technique employed by some language runtimes, and first developed for Smalltalk."
previous method lookup directly,The goal of inline caching is to speed up runtime method binding by remembering the results of a previous method lookup directly at the call site.
call site,The goal of inline caching is to speed up runtime method binding by remembering the results of a previous method lookup directly at the call site.
method binding happens,Inline caching is especially useful for dynamically typed languages where most if not all method binding happens at runtime and where virtual method tables often cannot be used.
especially useful,Inline caching is especially useful for dynamically typed languages where most if not all method binding happens at runtime and where virtual method tables often cannot be used.
virtual method tables often cannot,Inline caching is especially useful for dynamically typed languages where most if not all method binding happens at runtime and where virtual method tables often cannot be used.
many language runtimes employ,"To achieve better performance, many language runtimes employ some form of non-inline caching where the results of a limited number of method lookups are stored in an associative data structure."
achieve better performance,"To achieve better performance, many language runtimes employ some form of non-inline caching where the results of a limited number of method lookups are stored in an associative data structure."
method lookups,"To achieve better performance, many language runtimes employ some form of non-inline caching where the results of a limited number of method lookups are stored in an associative data structure."
empirical observation,The concept of inline caching is based on the empirical observation that the objects that occur at a particular call site are often of the same type.
particular call site,The concept of inline caching is based on the empirical observation that the objects that occur at a particular call site are often of the same type.
computer science covers,Logic in computer science covers the overlap between the field of logic and that of computer science.
logic in computer science,Logic in computer science covers the overlap between the field of logic and that of computer science. !! Logic in Computer Science: Modelling and Reasoning about Systems (2nd ed.
2nd ed,"Martin Davis, Ron Sigal, Elaine J. Weyuker, Computability, complexity, and languages: fundamentals of theoretical computer science, 2nd ed. !! Logic in Computer Science: Modelling and Reasoning about Systems (2nd ed. !! An Introduction to the Analysis of Algorithms (2nd ed."
form polynomial equations,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions."
elementary word problems,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions."
basic chemistry,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions."
complicated scientific problems,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions."
settings ranging,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions."
social science,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions. !! A review of recent literature on individual-based models, agent-based models, and multiagent systems shows that ABMs are used in many scientific domains including biology, ecology and social science."
define polynomial functions,"For example, they are used to form polynomial equations, which encode a wide range of problems, from elementary word problems to complicated scientific problems; they are used to define polynomial functions, which appear in settings ranging from basic chemistry and physics to economics and social science; they are used in calculus and numerical analysis to approximate other functions."
complex coefficients,"Generally, unless otherwise specified, polynomial functions have complex coefficients, arguments, and values."
unless otherwise specified,"Generally, unless otherwise specified, polynomial functions have complex coefficients, arguments, and values."
nevertheless define polynomial functions,"According to the definition of polynomial functions, there may be expressions that obviously are not polynomials but nevertheless define polynomial functions."
rational function,"While polynomial functions are defined for all values of the variables, a rational function is defined only for the values of the variables for which the denominator is not zero. !! The sum, product, or quotient (excepting division by the zero polynomial) of two rational functions is itself a rational function."
unital associative algebra,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
range equal,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
one obtains,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
every polynomial p,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
see fermat,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
one reason,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
different polynomials may give rise,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
take domain,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
integers modulo p,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
random functions,"Mathematical morphology (MM) is a theory and technique for the analysis and processing of geometrical structures, based on set theory, lattice theory, topology, and random functions."
mathematical morphology,"Mathematical Morphology was developed in 1964 by the collaborative work of Georges Matheron and Jean Serra, at the cole des Mines de Paris, France. !! Mathematical morphology (MM) is a theory and technique for the analysis and processing of geometrical structures, based on set theory, lattice theory, topology, and random functions. !! Mathematical Morphology and its Application to Signal Processing, J. Serra and Ph. !! Mathematical Morphology and Its Applications to Image Processing, J. Serra and P. Soille (Eds. !! In 1993, the first International Symposium on Mathematical Morphology (ISMM) took place in Barcelona, Spain."
geometrical structures,"Mathematical morphology (MM) is a theory and technique for the analysis and processing of geometrical structures, based on set theory, lattice theory, topology, and random functions."
jean serra,"Mathematical Morphology was developed in 1964 by the collaborative work of Georges Matheron and Jean Serra, at the cole des Mines de Paris, France."
collaborative work,"Mathematical Morphology was developed in 1964 by the collaborative work of Georges Matheron and Jean Serra, at the cole des Mines de Paris, France."
georges matheron,"Mathematical Morphology was developed in 1964 by the collaborative work of Georges Matheron and Jean Serra, at the cole des Mines de Paris, France."
cole des mines de paris,"Mathematical Morphology was developed in 1964 by the collaborative work of Georges Matheron and Jean Serra, at the cole des Mines de Paris, France."
first international symposium,"In 1993, the first International Symposium on Mathematical Morphology (ISMM) took place in Barcelona, Spain."
took place,"In 1993, the first International Symposium on Mathematical Morphology (ISMM) took place in Barcelona, Spain."
regions close,"In mathematics, a Voronoi diagram is a partition of a plane into regions close to each of a given set of objects."
peter gustav lejeune dirichlet,"The Voronoi diagram is named after Georgy Voronoy, and is also called a Voronoi tessellation, a Voronoi decomposition, a Voronoi partition, or a Dirichlet tessellation (after Peter Gustav Lejeune Dirichlet)."
georgy voronoy,"The Voronoi diagram is named after Georgy Voronoy, and is also called a Voronoi tessellation, a Voronoi decomposition, a Voronoi partition, or a Dirichlet tessellation (after Peter Gustav Lejeune Dirichlet)."
visual art,"Voronoi diagrams have practical and theoretical applications in many fields, mainly in science and technology, but also in visual art."
theoretical applications,"Voronoi diagrams have practical and theoretical applications in many fields, mainly in science and technology, but also in visual art."
two nearest sites,The line segments of the Voronoi diagram are all the points in the plane that are equidistant to the two nearest sites.
snap rounding,"There are more refined algorithms to cope with some of these issues, for example iterated snap rounding guarantees a ""large"" separation between points and non-incident edges. !! Snap rounding is a method of approximating line segment locations by creating a grid and placing each point in the centre of a cell (pixel) of the grid."
approximating line segment locations,Snap rounding is a method of approximating line segment locations by creating a grid and placing each point in the centre of a cell (pixel) of the grid.
example iterated snap rounding guarantees,"There are more refined algorithms to cope with some of these issues, for example iterated snap rounding guarantees a ""large"" separation between points and non-incident edges."
refined algorithms,"There are more refined algorithms to cope with some of these issues, for example iterated snap rounding guarantees a ""large"" separation between points and non-incident edges."
several network schedulers available,"There are several network schedulers available for the different operating systems, that implement many of the existing network scheduling algorithms."
different operating systems,"There are several network schedulers available for the different operating systems, that implement many of the existing network scheduling algorithms."
existing network scheduling algorithms,"There are several network schedulers available for the different operating systems, that implement many of the existing network scheduling algorithms."
implement many,"There are several network schedulers available for the different operating systems, that implement many of the existing network scheduling algorithms."
data obtained,Automatic target recognition (ATR) is the ability for an algorithm or device to recognize targets or other objects based on data obtained from sensors.
recognize targets,Automatic target recognition (ATR) is the ability for an algorithm or device to recognize targets or other objects based on data obtained from sensors.
objects based,Automatic target recognition (ATR) is the ability for an algorithm or device to recognize targets or other objects based on data obtained from sensors.
machine learning frameworks designed,A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014.
ian goodfellow,A generative adversarial network (GAN) is a class of machine learning frameworks designed by Ian Goodfellow and his colleagues in June 2014.
2010 blog post,An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo.
olli niemitalo,An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo.
idea involving adversarial networks,An idea involving adversarial networks was published in a 2010 blog post by Olli Niemitalo.
appealing abstract paintings,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
generate unique,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
fine arts arena,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
gan technology began,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
presence felt,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
thus dubbed,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
newly developed implementation,"Beginning in 2017, GAN technology began to make its presence felt in the fine arts arena with the appearance of a newly developed implementation which was said to have crossed the threshold of being able to generate unique and appealing abstract paintings, and thus dubbed a ""CAN"", for ""creative adversarial network""."
based generator architecture,A Style-Based Generator Architecture for Generative Adversarial Networks.
terms represent,"Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval."
including extracting,"Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval."
easy retrieval,"Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval."
corresponding domain,"Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval."
automatic creation,"Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval."
semi - automatically extract whole ontologies,Ontology learning (OL) is used to (semi-)automatically extract whole ontologies from natural language text.
every ontology learning system,"The process is usually split into the following eight tasks, which are not all necessarily applied in every ontology learning system."
necessarily applied,"The process is usually split into the following eight tasks, which are not all necessarily applied in every ontology learning system."
following eight tasks,"The process is usually split into the following eight tasks, which are not all necessarily applied in every ontology learning system."
usually split,"The process is usually split into the following eight tasks, which are not all necessarily applied in every ontology learning system."
ios press,"Ontology Learning and Population: Bridging the Gap between Text and Knowledge, Series information for Frontiers in Artificial Intelligence and Applications, IOS Press, 2008. !! Ontology Learning from Text: Methods, Evaluation and Applications, Series information for Frontiers in Artificial Intelligence and Applications, IOS Press, 2005."
series information,"Ontology Learning and Population: Bridging the Gap between Text and Knowledge, Series information for Frontiers in Artificial Intelligence and Applications, IOS Press, 2008. !! Ontology Learning from Text: Methods, Evaluation and Applications, Series information for Frontiers in Artificial Intelligence and Applications, IOS Press, 2005."
two rational functions,"The sum, product, or quotient (excepting division by the zero polynomial) of two rational functions is itself a rational function."
excepting division,"The sum, product, or quotient (excepting division by the zero polynomial) of two rational functions is itself a rational function."
equivalence classes gets around,"Using the definition of rational functions as equivalence classes gets around this, since x/x is equivalent to 1/1."
representative examples,Rational functions are representative examples of meromorphic functions.
pad approximations introduced,"Rational functions are used in numerical analysis for interpolation and approximation of functions, for example the Pad approximations introduced by Henri Pad."
henri pad,"Rational functions are used in numerical analysis for interpolation and approximation of functions, for example the Pad approximations introduced by Henri Pad."
simple random sample,"Reservoir sampling is a family of randomized algorithms for choosing a simple random sample, without replacement, of k items from a population of unknown size n in a single pass over the items."
unknown size n,"Reservoir sampling is a family of randomized algorithms for choosing a simple random sample, without replacement, of k items from a population of unknown size n in a single pass over the items."
without replacement,"Reservoir sampling is a family of randomized algorithms for choosing a simple random sample, without replacement, of k items from a population of unknown size n in a single pass over the items."
uses interpretation 1,The following algorithm was given by Efraimidis and Spirakis that uses interpretation 1:This algorithm is identical to the algorithm given in Reservoir Sampling with Random Sort except for the generation of the items' keys.
algorithm given,The following algorithm was given by Efraimidis and Spirakis that uses interpretation 1:This algorithm is identical to the algorithm given in Reservoir Sampling with Random Sort except for the generation of the items' keys.
random sort except,The following algorithm was given by Efraimidis and Spirakis that uses interpretation 1:This algorithm is identical to the algorithm given in Reservoir Sampling with Random Sort except for the generation of the items' keys.
following algorithm,The following algorithm was given by Efraimidis and Spirakis that uses interpretation 1:This algorithm is identical to the algorithm given in Reservoir Sampling with Random Sort except for the generation of the items' keys.
parse trees,Some parsing algorithms may generate a parse forest or list of parse trees for a syntactically ambiguous input.
parse forest,Some parsing algorithms may generate a parse forest or list of parse trees for a syntactically ambiguous input.
parsing algorithms may generate,Some parsing algorithms may generate a parse forest or list of parse trees for a syntactically ambiguous input.
natural language cannot rely,Parsing algorithms for natural language cannot rely on the grammar having 'nice' properties as with manually designed grammars for programming languages.
manually designed grammars,Parsing algorithms for natural language cannot rely on the grammar having 'nice' properties as with manually designed grammars for programming languages.
natural language user interfaces,"Adaptive parsing algorithms have been used to construct ""self-extending"" natural language user interfaces."
algorithms hard,"Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary."
designed around computational hardness assumptions,"Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary."
computer science practice,"Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary."
heavily based,"Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary."
actual practice,"Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around computational hardness assumptions, making such algorithms hard to break in actual practice by any adversary."
functions may,"Cryptographic Hash Functions are cryptographic algorithms that are ways to generate and utilize specific keys to encrypt data for either symmetric or asymmetric encryption, and such functions may be viewed as keys themselves."
either symmetric,"Cryptographic Hash Functions are cryptographic algorithms that are ways to generate and utilize specific keys to encrypt data for either symmetric or asymmetric encryption, and such functions may be viewed as keys themselves."
concerns cryptographic algorithms developed,Lightweight cryptography (LWC) concerns cryptographic algorithms developed for a strictly constrained environment.
1995 case bernstein v,The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.
united states ultimately resulted,The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.
united states constitution,The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.
free speech,The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.
printed source code,The 1995 case Bernstein v. United States ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as free speech by the United States Constitution.
program whose behavior,"In computer programming, undefined behavior (UB) is the result of executing a program whose behavior is prescribed to be unpredictable, in the language specification to which the computer code adheres."
undefined behavior,"In computer programming, undefined behavior (UB) is the result of executing a program whose behavior is prescribed to be unpredictable, in the language specification to which the computer code adheres. !! Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution. !! Undefined behavior is the name of a list of conditions that the program must not meet. !! c post that explained undefined behavior as allowing the compiler to do anything it chooses, even ""to make demons fly out of your nose"". !! In the C community, undefined behavior may be humorously referred to as ""nasal demons"", after a comp."
computer code adheres,"In computer programming, undefined behavior (UB) is the result of executing a program whose behavior is prescribed to be unpredictable, in the language specification to which the computer code adheres."
nasal demons,"In the C community, undefined behavior may be humorously referred to as ""nasal demons"", after a comp."
humorously referred,"In the C community, undefined behavior may be humorously referred to as ""nasal demons"", after a comp."
undefined behavior may,"In the C community, undefined behavior may be humorously referred to as ""nasal demons"", after a comp."
explained undefined behavior,"c post that explained undefined behavior as allowing the compiler to do anything it chooses, even ""to make demons fly out of your nose""."
make demons fly,"c post that explained undefined behavior as allowing the compiler to do anything it chooses, even ""to make demons fly out of your nose""."
different control flow,"Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution."
operate differently,"Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution."
programming languages allow,"Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution."
undefined behavior never happens,"Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution."
visible side effects,"Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution."
program must,Undefined behavior is the name of a list of conditions that the program must not meet.
average cost,A CPU cache is a hardware cache used by the central processing unit (CPU) of a computer to reduce the average cost (time or energy) to access data from the main memory.
hardware cache used,A CPU cache is a hardware cache used by the central processing unit (CPU) of a computer to reduce the average cost (time or energy) to access data from the main memory.
hold blocks evicted,A victim cache is a cache used to hold blocks evicted from a CPU cache upon replacement.
cpu cache upon replacement,A victim cache is a cache used to hold blocks evicted from a CPU cache upon replacement.
cache used,A victim cache is a cache used to hold blocks evicted from a CPU cache upon replacement.
currently stored,"In computer engineering, a tag RAM is used to specify which of the possible memory locations is currently stored in a CPU cache."
tag ram,"In computer engineering, a tag RAM is used to specify which of the possible memory locations is currently stored in a CPU cache."
possible memory locations,"In computer engineering, a tag RAM is used to specify which of the possible memory locations is currently stored in a CPU cache."
memory part 2,Memory part 2: CPU caches an article on lwn.
represent functions,Internal evaluation measures suffer from the problem that they represent functions that themselves can be seen as a clustering objective.
internal evaluation,"Internal evaluation measures suffer from the problem that they represent functions that themselves can be seen as a clustering objective. !! Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another. !! More than a dozen of internal evaluation measures exist, usually based on the intuition that items in the same cluster should be more similar than items in different clusters. !! When a clustering result is evaluated based on the data that was clustered itself, this is called internal evaluation."
clustering objective,Internal evaluation measures suffer from the problem that they represent functions that themselves can be seen as a clustering objective.
internal evaluation measures suffer,Internal evaluation measures suffer from the problem that they represent functions that themselves can be seen as a clustering objective.
called internal evaluation,"When a clustering result is evaluated based on the data that was clustered itself, this is called internal evaluation."
evaluated based,"When a clustering result is evaluated based on the data that was clustered itself, this is called internal evaluation."
clustering result,"When a clustering result is evaluated based on the data that was clustered itself, this is called internal evaluation."
valid results,"Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another."
one algorithm produces,"Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another."
one algorithm performs better,"Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another."
best suited,"A synchronoptic view can be used for many purposes but is best suited to the visual display of history. !! Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another."
internal evaluation measures,"Therefore, the internal evaluation measures are best suited to get some insight into situations where one algorithm performs better than another, but this shall not imply that one algorithm produces more valid results than another."
internal evaluation measures exist,"More than a dozen of internal evaluation measures exist, usually based on the intuition that items in the same cluster should be more similar than items in different clusters."
usually based,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols. !! More than a dozen of internal evaluation measures exist, usually based on the intuition that items in the same cluster should be more similar than items in different clusters."
partial permutations,"partial permutations where the final elements of each set map to each other. !! in which the ith term counts the number of partial permutations with support of size i, that is, the number of partial permutations with i non-hole entries. !! The number of partial permutations on n items, for n = 0, 1, 2, . !! , the partial permutations included in both counts 3 and 4, those permutations where the final elements of both sets are included, but do not map to each other."
ith term counts,"in which the ith term counts the number of partial permutations with support of size i, that is, the number of partial permutations with i non-hole entries."
hole entries,"in which the ith term counts the number of partial permutations with support of size i, that is, the number of partial permutations with i non-hole entries."
set map,partial permutations where the final elements of each set map to each other.
final elements,"partial permutations where the final elements of each set map to each other. !! , the partial permutations included in both counts 3 and 4, those permutations where the final elements of both sets are included, but do not map to each other."
partial permutations included,", the partial permutations included in both counts 3 and 4, those permutations where the final elements of both sets are included, but do not map to each other."
seed value  pp,"In mathematics and particularly in dynamic systems, an initial condition, in some contexts called a seed value,:pp."
contexts called,"In mathematics and particularly in dynamic systems, an initial condition, in some contexts called a seed value,:pp."
dynamic systems,"In mathematics and particularly in dynamic systems, an initial condition, in some contexts called a seed value,:pp. !! Agent-based computational economics (ACE) is the area of computational economics that studies economic processes, including whole economies, as dynamic systems of interacting agents."
initial condition,"For a system of order k (the number of time lags in discrete time, or the order of the largest derivative in continuous time) and dimension n (that is, with n different evolving variables, which together can be denoted by an n-dimensional coordinate vector), generally nk initial conditions are needed in order to trace the system's variables forward through time. !! In mathematics and particularly in dynamic systems, an initial condition, in some contexts called a seed value,:pp. !! In continuous time, the problem of finding a closed form solution for the state variables as a function of time and of the initial conditions is called the initial value problem. !! In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time. !! is called the vector of initial conditions or simply the initial condition, and contains nk pieces of information, n being the dimension of the vector X and k = 1 being the number of time lags in the system."
continuous time,"In continuous time, the problem of finding a closed form solution for the state variables as a function of time and of the initial conditions is called the initial value problem. !! In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time. !! For a system of order k (the number of time lags in discrete time, or the order of the largest derivative in continuous time) and dimension n (that is, with n different evolving variables, which together can be denoted by an n-dimensional coordinate vector), generally nk initial conditions are needed in order to trace the system's variables forward through time."
n different evolving variables,"For a system of order k (the number of time lags in discrete time, or the order of the largest derivative in continuous time) and dimension n (that is, with n different evolving variables, which together can be denoted by an n-dimensional coordinate vector), generally nk initial conditions are needed in order to trace the system's variables forward through time."
variables forward,"For a system of order k (the number of time lags in discrete time, or the order of the largest derivative in continuous time) and dimension n (that is, with n different evolving variables, which together can be denoted by an n-dimensional coordinate vector), generally nk initial conditions are needed in order to trace the system's variables forward through time."
largest derivative,"For a system of order k (the number of time lags in discrete time, or the order of the largest derivative in continuous time) and dimension n (that is, with n different evolving variables, which together can be denoted by an n-dimensional coordinate vector), generally nk initial conditions are needed in order to trace the system's variables forward through time."
time lags,"For a system of order k (the number of time lags in discrete time, or the order of the largest derivative in continuous time) and dimension n (that is, with n different evolving variables, which together can be denoted by an n-dimensional coordinate vector), generally nk initial conditions are needed in order to trace the system's variables forward through time. !! is called the vector of initial conditions or simply the initial condition, and contains nk pieces of information, n being the dimension of the vector X and k = 1 being the number of time lags in the system."
difference equations,"Certain recurrence relations can be written as difference equations by replacing iteration notation with finite differences. !! In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time."
dynamic variables,"In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time."
initial conditions affect,"In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time."
future time,"In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time."
state variables,"In continuous time, the problem of finding a closed form solution for the state variables as a function of time and of the initial conditions is called the initial value problem. !! In both differential equations in continuous time and difference equations in discrete time, initial conditions affect the value of the dynamic variables (state variables) at any future time. !! The key property that reverse computation exploits is that a majority of the operations that modify the state variables are constructive in nature."
initial value problem,"In continuous time, the problem of finding a closed form solution for the state variables as a function of time and of the initial conditions is called the initial value problem."
closed form solution,"In continuous time, the problem of finding a closed form solution for the state variables as a function of time and of the initial conditions is called the initial value problem."
contains nk pieces,"is called the vector of initial conditions or simply the initial condition, and contains nk pieces of information, n being the dimension of the vector X and k = 1 being the number of time lags in the system."
performs bidirectional transfer,A Data Mapper is a Data Access Layer that performs bidirectional transfer of data between a persistent data store (often a relational database) and an in-memory data representation (the domain layer).
persistent data store independent,The goal of the pattern is to keep the in-memory representation and the persistent data store independent of each other and the data mapper itself.
particular target,"Exploratory search is distinguished from known-item search, for which the searcher has a particular target in mind."
broader class,"Consequently, exploratory search covers a broader class of activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined conceptual area; exploratory data analysis is another example of an information exploration activity."
new information,"Consequently, exploratory search covers a broader class of activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined conceptual area; exploratory data analysis is another example of an information exploration activity."
defined conceptual area,"Consequently, exploratory search covers a broader class of activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined conceptual area; exploratory data analysis is another example of an information exploration activity."
exploratory search covers,"Consequently, exploratory search covers a broader class of activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined conceptual area; exploratory data analysis is another example of an information exploration activity."
typical information retrieval,"Consequently, exploratory search covers a broader class of activities than typical information retrieval, such as investigating, evaluating, comparing, and synthesizing, where new information is sought in a defined conceptual area; exploratory data analysis is another example of an information exploration activity."
relevant documents,Exploratory search is a topic that has grown from the fields of information retrieval and information seeking but has become more concerned with alternatives to the kind of search that has received the majority of focus (returning the most relevant documents to a Google-like keyword search).
like keyword search,Exploratory search is a topic that has grown from the fields of information retrieval and information seeking but has become more concerned with alternatives to the kind of search that has received the majority of focus (returning the most relevant documents to a Google-like keyword search).
exploratory search interfaces workshop focused,"In 2005, the Exploratory Search Interfaces workshop focused on beginning to define some of the key challenges in the field."
key challenges,"In 2005, the Exploratory Search Interfaces workshop focused on beginning to define some of the key challenges in the field."
related conferences,Since then a series of other workshops has been held at related conferences: Evaluating Exploratory Search at SIGIR06 and Exploratory Search and HCI at CHI07 (in order to meet with the experts in humancomputer interaction).
analog means,"In electrical engineering and computer science, analog image processing is any image processing task conducted on two-dimensional analog signals by analog means (as opposed to digital image processing). !! Analog signal processing is a type of signal processing conducted on continuous analog signals by some analog means (as opposed to the discrete digital signal processing where the signal processing is carried out by a digital process)."
image processing task conducted,"In electrical engineering and computer science, analog image processing is any image processing task conducted on two-dimensional analog signals by analog means (as opposed to digital image processing)."
dimensional analog signals,"In electrical engineering and computer science, analog image processing is any image processing task conducted on two-dimensional analog signals by analog means (as opposed to digital image processing)."
yet given,"In computer programming, a forward declaration is a declaration of an identifier (denoting an entity such as a type, a variable, a constant, or a function) for which the programmer has not yet given a complete definition."
complete definition,"In computer programming, a forward declaration is a declaration of an identifier (denoting an entity such as a type, a variable, a constant, or a function) for which the programmer has not yet given a complete definition."
defined first,"Forward declaration is used in languages that require declaration before use; it is necessary for mutual recursion in such languages, as it is impossible to define such functions (or data structures) without a forward reference in one definition: one of the functions (respectively, data structures) must be defined first."
require declaration,"Forward declaration is used in languages that require declaration before use; it is necessary for mutual recursion in such languages, as it is impossible to define such functions (or data structures) without a forward reference in one definition: one of the functions (respectively, data structures) must be defined first."
one definition,"One definition is that it's information visualization when the spatial representation (e. g. , the page layout of a graphic design) is chosen, whereas it's scientific visualization when the spatial representation is given. !! Forward declaration is used in languages that require declaration before use; it is necessary for mutual recursion in such languages, as it is impossible to define such functions (or data structures) without a forward reference in one definition: one of the functions (respectively, data structures) must be defined first."
languages forward declarations,"In other languages forward declarations are not necessary, which generally requires instead a multi-pass compiler and for some compilation to be deferred to link time."
generally requires instead,"In other languages forward declarations are not necessary, which generally requires instead a multi-pass compiler and for some compilation to be deferred to link time."
pass compiler,"In other languages forward declarations are not necessary, which generally requires instead a multi-pass compiler and for some compilation to be deferred to link time."
lack definition,Variables may have only forward declaration and lack definition.
variables may,Variables may have only forward declaration and lack definition. !! Fuzzy logic is a form of many-valued logic in which the truth value of variables may be any real number between 0 and 1.
computational advantage relative,"The Kaczmarz method is applicable to any linear system of equations, but its computational advantage relative to other methods depends on the system being sparse."
methods depends,"The Kaczmarz method is applicable to any linear system of equations, but its computational advantage relative to other methods depends on the system being sparse."
general rate,The general rate of the Gower-Richtarik algorithm precisely recovers the rate of the randomized Kaczmarz method in the special case when it reduced to it.
richtarik algorithm precisely recovers,The general rate of the Gower-Richtarik algorithm precisely recovers the rate of the randomized Kaczmarz method in the special case when it reduced to it.
randomized kaczmarz method  journal,"Strohmer, Thomas; Vershynin, Roman (2009b), ""Comments on the randomized Kaczmarz method"", Journal of Fourier Analysis and Applications, 15 (4): 437440,"
n edge points,"In image processing, line detection is an algorithm that takes a collection of n edge points and finds all the lines on which these edge points lie."
edge points lie,"In image processing, line detection is an algorithm that takes a collection of n edge points and finds all the lines on which these edge points lie."
expensive process,"In computer programming, lazy initialization is the tactic of delaying the creation of an object, the calculation of a value, or some other expensive process until the first time it is needed."
often used together,"In a software design pattern view, lazy initialization is often used together with a factory method pattern."
software design pattern view,"In a software design pattern view, lazy initialization is often used together with a factory method pattern."
variable using lazy initialization,"Here is an example in Smalltalk, of a typical accessor method to return the value of a variable using lazy initialization."
quality solutions,"Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection."
biologically inspired operators,"Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection."
generate high,"Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection."
air resistance,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
fitness expression,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
fitness function value,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
even impossible,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
simulation may,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
even interactive genetic algorithms,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
vehicle whose shape,"In some problems, it is hard or even impossible to define the fitness expression; in these cases, a simulation may be used to determine the fitness function value of a phenotype (e. g. computational fluid dynamics is used to determine the air resistance of a vehicle whose shape is encoded as the phenotype), or even interactive genetic algorithms are used."
main genetic operators,"Although crossover and mutation are known as the main genetic operators, it is possible to use other operators such as regrouping, colonization-extinction, or migration in genetic algorithms."
although crossover,"Although crossover and mutation are known as the main genetic operators, it is possible to use other operators such as regrouping, colonization-extinction, or migration in genetic algorithms."
low defining length,"""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks."
low order play,"""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks."
special name,"""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks."
highly fit schemata,"""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks."
building blocks,"However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudorandom number generators. !! ""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks. !! SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model."
already given,"""Because highly fit schemata of low defining length and low order play such an important role in the action of genetic algorithms, we have already given them a special name: building blocks."
queueing theory,"In queueing theory, a discipline within the mathematical theory of probability, a polling system or polling model is a system where a single server visits a set of queues in some order. !! Queueing theory has its origins in research by Agner Krarup Erlang when he created models to describe the system of Copenhagen Telephone Exchange company, a Danish company. !! In 1909, Agner Krarup Erlang, a Danish engineer who worked for the Copenhagen Telephone Exchange, published the first paper on what would now be called queueing theory. !! Queueing theory is the mathematical study of waiting lines, or queues. !! After the 1940s queueing theory became an area of research interest to mathematicians. !! Queueing theory is generally considered a branch of operations research because the results are often used when making business decisions about the resources needed to provide a service."
discipline within,"In queueing theory, a discipline within the mathematical theory of probability, a polling system or polling model is a system where a single server visits a set of queues in some order."
polling system,"The term polling system was coined at least as early as 1968 and the earliest study of such a system in 1957 where a single repairman servicing machines in the British cotton industry was modelled. !! In queueing theory, a discipline within the mathematical theory of probability, a polling system or polling model is a system where a single server visits a set of queues in some order. !! Polling systems have been used to model Token Ring networks."
single server visits,"In queueing theory, a discipline within the mathematical theory of probability, a polling system or polling model is a system where a single server visits a set of queues in some order."
british cotton industry,The term polling system was coined at least as early as 1968 and the earliest study of such a system in 1957 where a single repairman servicing machines in the British cotton industry was modelled.
term polling system,The term polling system was coined at least as early as 1968 and the earliest study of such a system in 1957 where a single repairman servicing machines in the British cotton industry was modelled.
single repairman servicing machines,The term polling system was coined at least as early as 1968 and the earliest study of such a system in 1957 where a single repairman servicing machines in the British cotton industry was modelled.
earliest study,The term polling system was coined at least as early as 1968 and the earliest study of such a system in 1957 where a single repairman servicing machines in the British cotton industry was modelled.
model token ring networks,Polling systems have been used to model Token Ring networks.
polling systems,Polling systems have been used to model Token Ring networks.
optimization technique developed,Trace scheduling is an optimization technique developed by Josh Fisher used in compilers for computer programs.
josh fisher used,Trace scheduling is an optimization technique developed by Josh Fisher used in compilers for computer programs.
trace scheduling,"Trace scheduling is one of many known techniques for doing so. !! Trace scheduling was originally developed for Very Long Instruction Word, or VLIW machines, and is a form of global code motion. !! Trace scheduling is an optimization technique developed by Josh Fisher used in compilers for computer programs. !! Trace Scheduling: A Technique for Global Microcode Compaction. !! Trace scheduling uses a basic block scheduling method to schedule the instructions in each entire trace, beginning with the trace with the highest frequency."
many known techniques,Trace scheduling is one of many known techniques for doing so.
entire trace,"Trace scheduling uses a basic block scheduling method to schedule the instructions in each entire trace, beginning with the trace with the highest frequency."
basic block scheduling method,"Trace scheduling uses a basic block scheduling method to schedule the instructions in each entire trace, beginning with the trace with the highest frequency."
trace scheduling uses,"Trace scheduling uses a basic block scheduling method to schedule the instructions in each entire trace, beginning with the trace with the highest frequency."
vliw machines,"Trace scheduling was originally developed for Very Long Instruction Word, or VLIW machines, and is a form of global code motion."
long instruction word,"Trace scheduling was originally developed for Very Long Instruction Word, or VLIW machines, and is a form of global code motion."
global code motion,"Trace scheduling was originally developed for Very Long Instruction Word, or VLIW machines, and is a form of global code motion."
global microcode compaction,Trace Scheduling: A Technique for Global Microcode Compaction.
choose several subsets,Multiple subset sum problem - a generalization off SSP in which one should choose several subsets.
solving low,Solving low-density subset sum problems.
density subset sum problems,Solving low-density subset sum problems.
classic issue,"Collision detection is a classic issue of computational geometry and has applications in various computing fields, primarily in computer graphics, computer games, computer simulations, robotics and computational physics."
various computing fields,"Collision detection is a classic issue of computational geometry and has applications in various computing fields, primarily in computer graphics, computer games, computer simulations, robotics and computational physics."
collision detection utilizes time coherence,"Collision detection utilizes time coherence to allow even finer time steps without much increasing CPU demand, such as in air traffic control."
air traffic control,"Collision detection utilizes time coherence to allow even finer time steps without much increasing CPU demand, such as in air traffic control."
priori distinction,"In addition to the a posteriori and a priori distinction, almost all modern collision detection algorithms are broken into a hierarchy of algorithms."
scientific journal,ACM Transactions on Computational Logic (ACM TOCL) is a scientific journal that aims to disseminate the latest findings of note in the field of logic in computer science. !! Michael L. Fredman and Robert E. Tarjan developed Fibonacci heaps in 1984 and published them in a scientific journal in 1987.
tarjan developed fibonacci heaps,Michael L. Fredman and Robert E. Tarjan developed Fibonacci heaps in 1984 and published them in a scientific journal in 1987.
1  amortized time,"For the Fibonacci heap, the find-minimum operation takes constant (O(1)) amortized time."
minimum operation takes constant,"For the Fibonacci heap, the find-minimum operation takes constant (O(1)) amortized time."
thus better,A Fibonacci heap is thus better than a binary or binomial heap when b is smaller than a by a non-constant factor.
constant factor,A Fibonacci heap is thus better than a binary or binomial heap when b is smaller than a by a non-constant factor.
open-system environment reference model,The development of the open-system environment reference model started early 1990s by the NIST as refinement of the POSIX (Portable Operating System Interface) standard.
textual case,"Textual case-based reasoning (TCBR) is a subtopic of case-based reasoning, in short CBR, a popular area in artificial intelligence. !! Textual Case-Based Reasoning Wiki"
based reasoning,"Model types and usage for model-based reasoning are discussed in. !! The main reason why model-based reasoning is researched since the 1990s is to create different layers for modeling and control of a system. !! In 1990, criticism was formulated on model-based reasoning. !! Textual case-based reasoning (TCBR) is a subtopic of case-based reasoning, in short CBR, a popular area in artificial intelligence."
short cbr,"Textual case-based reasoning (TCBR) is a subtopic of case-based reasoning, in short CBR, a popular area in artificial intelligence."
popular area,"Textual case-based reasoning (TCBR) is a subtopic of case-based reasoning, in short CBR, a popular area in artificial intelligence."
based reasoning wiki,Textual Case-Based Reasoning Wiki
primary data,"Raw data, also known as primary data, are data (e. g. , numbers, instrument readings, figures, etc. )"
instrument readings,"Raw data, also known as primary data, are data (e. g. , numbers, instrument readings, figures, etc. )"
raw score,"In the context of examinations, the raw data might be described as a raw score (after test scores)."
raw data might,"In the context of examinations, the raw data might be described as a raw score (after test scores)."
test scores,"In the context of examinations, the raw data might be described as a raw score (after test scores)."
every minute,"If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen are ""raw data""."
computerized thermometer,"If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen are ""raw data""."
scientist sets,"If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen are ""raw data""."
temperature readings,"If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen are ""raw data""."
chemical mixture,"If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen are ""raw data""."
test tube every minute,"If a scientist sets up a computerized thermometer which records the temperature of a chemical mixture in a test tube every minute, the list of temperature readings for every minute, as printed out on a spreadsheet or viewed on a computer screen are ""raw data""."
remove outliers,"Raw data have not been subjected to processing, ""cleaning"" by researchers to remove outliers, obvious instrument reading errors or data entry errors, or any analysis (e. g. , determining central tendency aspects such as the average or median result)."
median result,"Raw data have not been subjected to processing, ""cleaning"" by researchers to remove outliers, obvious instrument reading errors or data entry errors, or any analysis (e. g. , determining central tendency aspects such as the average or median result)."
determining central tendency aspects,"Raw data have not been subjected to processing, ""cleaning"" by researchers to remove outliers, obvious instrument reading errors or data entry errors, or any analysis (e. g. , determining central tendency aspects such as the average or median result)."
obvious instrument reading errors,"Raw data have not been subjected to processing, ""cleaning"" by researchers to remove outliers, obvious instrument reading errors or data entry errors, or any analysis (e. g. , determining central tendency aspects such as the average or median result)."
human researcher,"As well, raw data have not been subject to any other manipulation by a software program or a human researcher, analyst or technician."
appear anytime,"Ubiquitous computing (or ""ubicomp"") is a concept in software engineering, hardware engineering and computer science where computing is made to appear anytime and everywhere."
occur using,"In contrast to desktop computing, ubiquitous computing can occur using any device, in any location, and in any format."
new materials,"The underlying technologies to support ubiquitous computing include Internet, advanced middleware, operating system, mobile code, sensors, microprocessors, new I/O and user interfaces, computer networks, mobile protocols, location and positioning, and new materials."
underlying technologies,"The underlying technologies to support ubiquitous computing include Internet, advanced middleware, operating system, mobile code, sensors, microprocessors, new I/O and user interfaces, computer networks, mobile protocols, location and positioning, and new materials."
support ubiquitous computing include internet,"The underlying technologies to support ubiquitous computing include Internet, advanced middleware, operating system, mobile code, sensors, microprocessors, new I/O and user interfaces, computer networks, mobile protocols, location and positioning, and new materials."
different kinds,"Rather than propose a single definition for ubiquitous computing and for these related terms, a taxonomy of properties for ubiquitous computing has been proposed, from which different kinds or flavors of ubiquitous systems and applications can be described. !! Different types of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks. !! Another aspect of the untyped lambda calculus is that it does not distinguish between different kinds of data."
related terms,"Rather than propose a single definition for ubiquitous computing and for these related terms, a taxonomy of properties for ubiquitous computing has been proposed, from which different kinds or flavors of ubiquitous systems and applications can be described."
aware smart home technologies,"Ubiquitous computing touches on distributed computing, mobile computing, location computing, mobile networking, sensor networks, humancomputer interaction, context-aware smart home technologies, and artificial intelligence."
head benchmarks,Lossless compression algorithms and their implementations are routinely tested in head-to-head benchmarks.
routinely tested,Lossless compression algorithms and their implementations are routinely tested in head-to-head benchmarks.
easily modeled redundancy,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
thus belong,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
make shorter,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
get compressed,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
files would,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
consistently compress,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
shorter form,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
allows lossless compression algorithms,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
even get bigger,"The ""trick"" that allows lossless compression algorithms, used on the type of data they were designed for, to consistently compress such files to a shorter form is that the files the algorithms are designed to act on all have some form of easily modeled redundancy that the algorithm is designed to remove, and thus belong to the subset of files that that algorithm can make shorter, whereas other files would not get compressed or even get bigger."
improve contrast,Adaptive histogram equalization (AHE) is a computer image processing technique used to improve contrast in images.
computer image processing technique used,Adaptive histogram equalization (AHE) is a computer image processing technique used to improve contrast in images.
transformation function derived,Adaptive histogram equalization (AHE) improves on this by transforming each pixel with a transformation function derived from a neighbourhood region.
noise amplification,"Contrast Limited AHE (CLAHE) is a variant of adaptive histogram equalization in which the contrast amplification is limited, so as to reduce this problem of noise amplification."
contrast amplification,"Contrast Limited AHE (CLAHE) is a variant of adaptive histogram equalization in which the contrast amplification is limited, so as to reduce this problem of noise amplification."
without contrast limiting,"Adaptive histogram equalization in its straightforward form presented above, both with and without contrast limiting, requires the computation of a different neighbourhood histogram and transformation function for each pixel in the image."
transformation function,"Adaptive histogram equalization in its straightforward form presented above, both with and without contrast limiting, requires the computation of a different neighbourhood histogram and transformation function for each pixel in the image."
different neighbourhood histogram,"Adaptive histogram equalization in its straightforward form presented above, both with and without contrast limiting, requires the computation of a different neighbourhood histogram and transformation function for each pixel in the image."
straightforward form presented,"Adaptive histogram equalization in its straightforward form presented above, both with and without contrast limiting, requires the computation of a different neighbourhood histogram and transformation function for each pixel in the image."
exploiting quantum mechanical properties,Quantum cryptography is the science of exploiting quantum mechanical properties to perform cryptographic tasks.
perform cryptographic tasks,Quantum cryptography is the science of exploiting quantum mechanical properties to perform cryptographic tasks.
best known example,The best known example of quantum cryptography is quantum key distribution which offers an information-theoretically secure solution to the key exchange problem.
various cryptographic tasks,The advantage of quantum cryptography lies in the fact that it allows the completion of various cryptographic tasks that are proven or conjectured to be impossible using only classical (i. e. non-quantum) communication.
impossible using,The advantage of quantum cryptography lies in the fact that it allows the completion of various cryptographic tasks that are proven or conjectured to be impossible using only classical (i. e. non-quantum) communication.
quantum cryptography lies,The advantage of quantum cryptography lies in the fact that it allows the completion of various cryptographic tasks that are proven or conjectured to be impossible using only classical (i. e. non-quantum) communication.
stephen wiesner,Quantum cryptography attributes its beginning by the work of Stephen Wiesner and Gilles Brassard.
gilles brassard,Quantum cryptography attributes its beginning by the work of Stephen Wiesner and Gilles Brassard.
japan  qnu labs,"Companies that manufacture quantum cryptography systems include MagiQ Technologies, Inc. (Boston, Massachusetts, United States), ID Quantique (Geneva, Switzerland), QuintessenceLabs (Canberra, Australia), Toshiba (Tokyo, Japan), QNu Labs and SeQureNet (Paris, France)."
united states  id quantique,"Companies that manufacture quantum cryptography systems include MagiQ Technologies, Inc. (Boston, Massachusetts, United States), ID Quantique (Geneva, Switzerland), QuintessenceLabs (Canberra, Australia), Toshiba (Tokyo, Japan), QNu Labs and SeQureNet (Paris, France)."
switzerland  quintessencelabs,"Companies that manufacture quantum cryptography systems include MagiQ Technologies, Inc. (Boston, Massachusetts, United States), ID Quantique (Geneva, Switzerland), QuintessenceLabs (Canberra, Australia), Toshiba (Tokyo, Japan), QNu Labs and SeQureNet (Paris, France)."
australia  toshiba,"Companies that manufacture quantum cryptography systems include MagiQ Technologies, Inc. (Boston, Massachusetts, United States), ID Quantique (Geneva, Switzerland), QuintessenceLabs (Canberra, Australia), Toshiba (Tokyo, Japan), QNu Labs and SeQureNet (Paris, France)."
particular systems,"In mathematics, the conjugate gradient method is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is positive-definite."
whose matrix,"In mathematics, the conjugate gradient method is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is positive-definite."
often implemented,"The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition."
sparse systems,"The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition."
direct methods,"The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition."
direct implementation,"The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition."
solve unconstrained optimization problems,The conjugate gradient method can also be used to solve unconstrained optimization problems such as energy minimization.
biconjugate gradient method provides,The biconjugate gradient method provides a generalization to non-symmetric matrices.
another product,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
product engineering,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
consumer psychology,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
product setsthe vision,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
smart products poses questions relevant,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
network capable,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
smart products,"Since smart products combine a physical product with additional services, they are a form of product service system. !! Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
innovation management,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
communication science,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
media economics,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
product bundling,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
including marketing,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
various research areas,"Network capable: ability to communicate and bundle (product bundling) with another product (business) or product setsThe vision of smart products poses questions relevant to various research areas, including marketing, product engineering, computer science, artificial intelligence, economics, communication science, media economics, cognitive science, consumer psychology, innovation management and many more."
product service system,"Since smart products combine a physical product with additional services, they are a form of product service system."
additional services,"Since smart products combine a physical product with additional services, they are a form of product service system."
physical product,"Since smart products combine a physical product with additional services, they are a form of product service system."
since smart products combine,"Since smart products combine a physical product with additional services, they are a form of product service system."
stiffness matrix represents,"In the finite element method for the numerical solution of elliptic partial differential equations, the stiffness matrix represents the system of linear equations that must be solved in order to ascertain an approximate solution to the differential equation."
linear system au,", the coefficients ui are determined by the linear system Au = F. The stiffness matrix is symmetric, i. e. Aij = Aji, so all its eigenvalues are real."
coefficients ui,", the coefficients ui are determined by the linear system Au = F. The stiffness matrix is symmetric, i. e. Aij = Aji, so all its eigenvalues are real."
computational grid used,Note that the stiffness matrix will be different depending on the computational grid used for the domain and what type of finite element is used.
finite element,Note that the stiffness matrix will be different depending on the computational grid used for the domain and what type of finite element is used.
different depending,Note that the stiffness matrix will be different depending on the computational grid used for the domain and what type of finite element is used.
piecewise linear elements,"For example, the stiffness matrix when piecewise quadratic finite elements are used will have more degrees of freedom than piecewise linear elements."
piecewise quadratic finite elements,"For example, the stiffness matrix when piecewise quadratic finite elements are used will have more degrees of freedom than piecewise linear elements."
pde follows essentially,"Determining the stiffness matrix for other PDE follows essentially the same procedure, but it can be complicated by the choice of boundary conditions."
path dht,"Augmented tree-based routing (ATR) protocol, first proposed in 2007, is a multi-path DHT-based routing protocol for scalable networks."
based routing,"In order to avoid bridge loops and routing loops, many routing protocols designed for such networksincluding the Spanning Tree Protocol, Open Shortest Path First, Link-state routing protocol, Augmented tree-based routing, etc. !! Augmented tree-based routing (ATR) protocol, first proposed in 2007, is a multi-path DHT-based routing protocol for scalable networks."
augmented tree,"In order to avoid bridge loops and routing loops, many routing protocols designed for such networksincluding the Spanning Tree Protocol, Open Shortest Path First, Link-state routing protocol, Augmented tree-based routing, etc. !! Augmented Tree-based Routing Protocol for Scalable Ad Hoc Networks. !! Augmented tree-based routing (ATR) protocol, first proposed in 2007, is a multi-path DHT-based routing protocol for scalable networks."
based routing protocol,"Augmented Tree-based Routing Protocol for Scalable Ad Hoc Networks. !! Augmented tree-based routing (ATR) protocol, first proposed in 2007, is a multi-path DHT-based routing protocol for scalable networks."
tuning basic heuristic algorithms,"Metaheuristic: Methods for controlling and tuning basic heuristic algorithms, usually with usage of memory and learning."
distinguishable orbits,"The second definition clarified the meaning of the topological entropy: for a system given by an iterated function, the topological entropy represents the exponential growth rate of the number of distinguishable orbits of the iterates."
iterated function,"The second definition clarified the meaning of the topological entropy: for a system given by an iterated function, the topological entropy represents the exponential growth rate of the number of distinguishable orbits of the iterates."
second definition clarified,"The second definition clarified the meaning of the topological entropy: for a system given by an iterated function, the topological entropy represents the exponential growth rate of the number of distinguishable orbits of the iterates."
system given,"The second definition clarified the meaning of the topological entropy: for a system given by an iterated function, the topological entropy represents the exponential growth rate of the number of distinguishable orbits of the iterates."
topological entropy represents,"The second definition clarified the meaning of the topological entropy: for a system given by an iterated function, the topological entropy represents the exponential growth rate of the number of distinguishable orbits of the iterates."
usually assumed,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
topological dynamical system consists,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
hausdorff topological space x,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
various ways,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
continuous self,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
possible finite covers c,"Then the topological entropy of f, denoted h(f), is defined to be the supremum of H(f,C) over all possible finite covers C of X."
certain recurrence relation,"In mathematics, a Somos sequence is a sequence of numbers defined by a certain recurrence relation, described below."
numbers defined,"In mathematics, a Somos sequence is a sequence of numbers defined by a certain recurrence relation, described below."
nevertheless many somos sequences,"From the form of their defining recurrence (which involves division), one would expect the terms of the sequence to be fractions, but nevertheless many Somos sequences have the property that all of their members are integers."
defining recurrence,"From the form of their defining recurrence (which involves division), one would expect the terms of the sequence to be fractions, but nevertheless many Somos sequences have the property that all of their members are integers."
involves division  one would expect,"From the form of their defining recurrence (which involves division), one would expect the terms of the sequence to be fractions, but nevertheless many Somos sequences have the property that all of their members are integers."
different initial values,"While in the usual definition of the Somos sequences, the values of ai for i < k are all set equal to 1, it is also possible to define other sequences by using the same recurrences with different initial values."
also possible,"It is also possible to discover the parent of a node from a threaded binary tree, without explicit use of parent pointers or a stack, although it is slower. !! While in the usual definition of the Somos sequences, the values of ai for i < k are all set equal to 1, it is also possible to define other sequences by using the same recurrences with different initial values."
set equal,"While in the usual definition of the Somos sequences, the values of ai for i < k are all set equal to 1, it is also possible to define other sequences by using the same recurrences with different initial values."
usual definition,"While in the usual definition of the Somos sequences, the values of ai for i < k are all set equal to 1, it is also possible to define other sequences by using the same recurrences with different initial values."
somos sequences involves divisions,"The form of the recurrences describing the Somos sequences involves divisions, making it appear likely that the sequences defined by these recurrence will contain fractional values."
appear likely,"The form of the recurrences describing the Somos sequences involves divisions, making it appear likely that the sequences defined by these recurrence will contain fractional values."
recurrences describing,"The form of the recurrences describing the Somos sequences involves divisions, making it appear likely that the sequences defined by these recurrence will contain fractional values."
contain fractional values,"The form of the recurrences describing the Somos sequences involves divisions, making it appear likely that the sequences defined by these recurrence will contain fractional values."
sequences defined,"The form of the recurrences describing the Somos sequences involves divisions, making it appear likely that the sequences defined by these recurrence will contain fractional values."
somos sequences contain,"Nevertheless, for k 7 the Somos sequences contain only integer values."
integer values,"Nevertheless, for k 7 the Somos sequences contain only integer values."
determine whether,"In computer science, state space enumeration are methods that consider each reachable program state to determine whether a program satisfies a given property. !! In computer science, termination analysis is program analysis which attempts to determine whether the evaluation of a given program halts for each input."
program analysis,"Program analysis focuses on two major areas: program optimization and program correctness. !! In computer science, termination analysis is program analysis which attempts to determine whether the evaluation of a given program halts for each input. !! Program analysis can be performed without executing the program (static program analysis), during runtime (dynamic program analysis) or in a combination of both. !! Principles of Program Analysis. !! Media related to Program analysis at Wikimedia Commons !! In computer science, program analysis is the process of automatically analyzing the behavior of computer programs regarding a property such as correctness, robustness, safety and liveness. !! Abstract syntax trees are also used in program analysis and program transformation systems."
termination analysis,"Here the termination analysis must take into account all possible values of UNKNOWN and find out that in the possible case of UNKNOWN = 0 (as in the original example) the termination cannot be shown. !! Some types of termination analysis can automatically generate or imply the existence of a termination proof. !! Termination Analysis for Functional Programs. !! In computer science, termination analysis is program analysis which attempts to determine whether the evaluation of a given program halts for each input. !! In termination analysis one may also try to determine the termination behaviour of some program depending on some unknown input."
given program halts,"In computer science, termination analysis is program analysis which attempts to determine whether the evaluation of a given program halts for each input."
termination proof,Some types of termination analysis can automatically generate or imply the existence of a termination proof.
automatically generate,Some types of termination analysis can automatically generate or imply the existence of a termination proof.
unknown input,In termination analysis one may also try to determine the termination behaviour of some program depending on some unknown input.
termination behaviour,In termination analysis one may also try to determine the termination behaviour of some program depending on some unknown input.
program depending,In termination analysis one may also try to determine the termination behaviour of some program depending on some unknown input.
termination cannot,Here the termination analysis must take into account all possible values of UNKNOWN and find out that in the possible case of UNKNOWN = 0 (as in the original example) the termination cannot be shown.
original example,Here the termination analysis must take into account all possible values of UNKNOWN and find out that in the possible case of UNKNOWN = 0 (as in the original example) the termination cannot be shown.
termination analysis must take,Here the termination analysis must take into account all possible values of UNKNOWN and find out that in the possible case of UNKNOWN = 0 (as in the original example) the termination cannot be shown.
possible case,Here the termination analysis must take into account all possible values of UNKNOWN and find out that in the possible case of UNKNOWN = 0 (as in the original example) the termination cannot be shown.
possible values,"Here the termination analysis must take into account all possible values of UNKNOWN and find out that in the possible case of UNKNOWN = 0 (as in the original example) the termination cannot be shown. !! In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values. !! A ""type"" in type theory has a role similar to a ""type"" in a programming language: it dictates the operations that can be performed on a term and, for variables, the possible values it might be replaced with. !! An abstract data type is defined by its behavior (semantics) from the point of view of a user, of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations."
functional programs,Termination Analysis for Functional Programs.
city exactly,"The travelling salesman problem (also called the travelling salesperson problem or TSP) asks the following question: ""Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city"""
following question,"The travelling salesman problem (also called the travelling salesperson problem or TSP) asks the following question: ""Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city"""
shortest possible route,"The travelling salesman problem (also called the travelling salesperson problem or TSP) asks the following question: ""Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city"""
origin city,"The travelling salesman problem (also called the travelling salesperson problem or TSP) asks the following question: ""Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city"""
19th century,"The travelling salesman problem was mathematically formulated in the 19th century by the Irish mathematician W. R. Hamilton and by the British mathematician Thomas Kirkman. !! A version of depth-first search was investigated in the 19th century by French mathematician Charles Pierre Trmaux as a strategy for solving mazes. !! In contrast to the modern view, in the 19th century, biologists considered genetic memory to be a fusion of memory and heredity, and held it to be a Lamarckian mechanism. !! Abductive reasoning (also called abduction, abductive inference, or retroduction) is a form of logical inference formulated and advanced by American philosopher Charles Sanders Peirce beginning in the last third of the 19th century."
british mathematician thomas kirkman,The travelling salesman problem was mathematically formulated in the 19th century by the Irish mathematician W. R. Hamilton and by the British mathematician Thomas Kirkman.
mathematically formulated,The travelling salesman problem was mathematically formulated in the 19th century by the Irish mathematician W. R. Hamilton and by the British mathematician Thomas Kirkman.
irish mathematician w,The travelling salesman problem was mathematically formulated in the 19th century by the Irish mathematician W. R. Hamilton and by the British mathematician Thomas Kirkman.
earliest publication using,"The earliest publication using the phrase ""travelling salesman problem"" was the 1949 RAND Corporation report by Julia Robinson, ""On the Hamiltonian game (a traveling salesman problem)."
1949 rand corporation report,"The earliest publication using the phrase ""travelling salesman problem"" was the 1949 RAND Corporation report by Julia Robinson, ""On the Hamiltonian game (a traveling salesman problem)."
julia robinson,"The earliest publication using the phrase ""travelling salesman problem"" was the 1949 RAND Corporation report by Julia Robinson, ""On the Hamiltonian game (a traveling salesman problem)."
beardwoodhaltonhammersley theorem provides,The BeardwoodHaltonHammersley theorem provides a practical solution to the travelling salesman problem.
practical solution,The BeardwoodHaltonHammersley theorem provides a practical solution to the travelling salesman problem.
time traveling debugging,Time travel debugging or time traveling debugging is the process of stepping back in time through source code to understand what is happening during execution of a computer program.
stepping back,Time travel debugging or time traveling debugging is the process of stepping back in time through source code to understand what is happening during execution of a computer program.
alternating decision trees introduce structure,Alternating decision trees introduce structure to the set of hypotheses by requiring that they build off a hypothesis that was produced in an earlier iteration.
earlier iteration,Alternating decision trees introduce structure to the set of hypotheses by requiring that they build off a hypothesis that was produced in an earlier iteration.
alternating decision tree consists,An alternating decision tree consists of decision nodes and prediction nodes.
many graphical examples,An introduction to Boosting and ADTrees (Has many graphical examples of alternating decision trees in practice).
total order,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy. !! An ordered graph is a graph with a total order over its nodes."
ordering graph,"The induced graph of an ordered graph is obtained by adding some edges to an ordering graph, using the method outlined below."
method outlined,"The induced graph of an ordered graph is obtained by adding some edges to an ordering graph, using the method outlined below."
induced width,The induced width of an ordered graph is the width of its induced graph.
library science,"Document classification or document categorization is a problem in library science, information science and computer science."
document categorization,"Document classification or document categorization is a problem in library science, information science and computer science."
document classification,"Document classification or document categorization is a problem in library science, information science and computer science. !! Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism. !! The problems are overlapping, however, and there is therefore interdisciplinary research on document classification."
therefore interdisciplinary research,"The problems are overlapping, however, and there is therefore interdisciplinary research on document classification."
external mechanism,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
correct classification,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
unsupervised document classification,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
automatic document classification tasks,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
external information,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
done entirely without reference,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
classification must,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
three sorts,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
provides information,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
supervised document classification,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
human feedback,"Automatic document classification tasks can be divided into three sorts: supervised document classification where some external mechanism (such as human feedback) provides information on the correct classification for documents, unsupervised document classification (also known as document clustering), where the classification must be done entirely without reference to external information, and semi-supervised document classification, where parts of the documents are labeled by the external mechanism."
sdl family standardized,A message sequence chart (or MSC) is an interaction diagram from the SDL family standardized by the International Telecommunication Union.
international telecommunication union,A message sequence chart (or MSC) is an interaction diagram from the SDL family standardized by the International Telecommunication Union.
interaction diagram,A message sequence chart (or MSC) is an interaction diagram from the SDL family standardized by the International Telecommunication Union.
message sequence chart,"A message sequence chart (or MSC) is an interaction diagram from the SDL family standardized by the International Telecommunication Union. !! The 1996 version added references, ordering and inlining expressions concepts, and introduced HMSC (High-level Message Sequence Charts), which are the way of expressing a sequence of MSCs. !! The purpose of recommending MSC (Message Sequence Chart) is to provide a trace language for the specification and description of the communication behaviour of system components and their environment by means of message interchange. !! 120 message sequence chart (MSC)"
recommending msc,The purpose of recommending MSC (Message Sequence Chart) is to provide a trace language for the specification and description of the communication behaviour of system components and their environment by means of message interchange.
message interchange,The purpose of recommending MSC (Message Sequence Chart) is to provide a trace language for the specification and description of the communication behaviour of system components and their environment by means of message interchange.
communication behaviour,The purpose of recommending MSC (Message Sequence Chart) is to provide a trace language for the specification and description of the communication behaviour of system components and their environment by means of message interchange.
trace language,The purpose of recommending MSC (Message Sequence Chart) is to provide a trace language for the specification and description of the communication behaviour of system components and their environment by means of message interchange.
introduced hmsc,"The 1996 version added references, ordering and inlining expressions concepts, and introduced HMSC (High-level Message Sequence Charts), which are the way of expressing a sequence of MSCs."
inlining expressions concepts,"The 1996 version added references, ordering and inlining expressions concepts, and introduced HMSC (High-level Message Sequence Charts), which are the way of expressing a sequence of MSCs."
level message sequence charts,"The 1996 version added references, ordering and inlining expressions concepts, and introduced HMSC (High-level Message Sequence Charts), which are the way of expressing a sequence of MSCs."
1996 version added references,"The 1996 version added references, ordering and inlining expressions concepts, and introduced HMSC (High-level Message Sequence Charts), which are the way of expressing a sequence of MSCs."
120 message sequence chart,120 message sequence chart (MSC)
many optimization algorithms need,Many optimization algorithms need to start from a feasible point.
feasible point,Many optimization algorithms need to start from a feasible point.
control container,The Spring Framework is an application framework and inversion of control container for the Java platform.
parts database,The Suppliers and Parts database is an example relational database that is referred to extensively in the literature and described in detail in C. J.
example relational database,The Suppliers and Parts database is an example relational database that is referred to extensively in the literature and described in detail in C. J.
suppliers and parts database,The Suppliers and Parts database is an example relational database that is referred to extensively in the literature and described in detail in C. J.
latin agere,"In computer science, a software agent is a computer program that acts for a user or other program in a relationship of agency, which derives from the Latin agere (to do): an agreement to act on one's behalf."
software agents may,Software agents may be autonomous or work together with other agents or people.
robot interaction environments,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
like qualities,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
embody humanoid form,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
may possess human,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
software agents interacting,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
see asimo,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
end users,Software agents may offer various benefits to their end users by automating complex or repetitive tasks.
repetitive tasks,Software agents may offer various benefits to their end users by automating complex or repetitive tasks.
automating complex,Software agents may offer various benefits to their end users by automating complex or repetitive tasks.
cultural impacts,"However, there are organizational and cultural impacts of this technology that need to be considered prior to implementing software agents."
implementing software agents,"However, there are organizational and cultural impacts of this technology that need to be considered prior to implementing software agents."
considered prior,"However, there are organizational and cultural impacts of this technology that need to be considered prior to implementing software agents."
pessimistic decision tree pruning based,Pessimistic decision tree pruning based on tree size.
space leak,"In contrast to memory leaks, where the leaked memory is never released, the memory consumed by a space leak is released, but later than expected. !! A space leak occurs when a computer program uses more memory than necessary."
space leak occurs,A space leak occurs when a computer program uses more memory than necessary.
computer program uses,A space leak occurs when a computer program uses more memory than necessary.
never released,"In contrast to memory leaks, where the leaked memory is never released, the memory consumed by a space leak is released, but later than expected."
memory consumed,"In contrast to memory leaks, where the leaked memory is never released, the memory consumed by a space leak is released, but later than expected."
rendering algorithms,"In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images."
modeling light transport,"In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images."
generating digital images,"In 3D computer graphics, ray tracing is a technique for modeling light transport for use in a wide variety of rendering algorithms for generating digital images."
photon mapping,"recursive ray tracing, distribution ray tracing, photon mapping to path tracing are generally slower and higher fidelity than scanline rendering methods."
distribution ray tracing,"recursive ray tracing, distribution ray tracing, photon mapping to path tracing are generally slower and higher fidelity than scanline rendering methods."
higher fidelity,"recursive ray tracing, distribution ray tracing, photon mapping to path tracing are generally slower and higher fidelity than scanline rendering methods."
first deployed,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
time applications,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times. !! Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame. !! In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
less suited,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
television visual effects,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
generated images,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
still computer,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
relatively long time,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame. !! In software engineering, software durability means the solution ability of serviceability of software and to meet user's needs for a relatively long time."
based rendering,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
time ray tracing,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
new commercial graphics cards,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
become standard,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
allowing developers,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
use hybrid ray tracing,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
frame render times,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
lesser hit,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
followed suit,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
ambient occlusion,"Ray tracing is capable of simulating a variety of optical effects, such as reflection, refraction, soft shadows, scattering, depth of field, motion blur, caustics, ambient occlusion and dispersion phenomena (such as chromatic aberration)."
dispersion phenomena,"Ray tracing is capable of simulating a variety of optical effects, such as reflection, refraction, soft shadows, scattering, depth of field, motion blur, caustics, ambient occlusion and dispersion phenomena (such as chromatic aberration)."
chromatic aberration,"Ray tracing is capable of simulating a variety of optical effects, such as reflection, refraction, soft shadows, scattering, depth of field, motion blur, caustics, ambient occlusion and dispersion phenomena (such as chromatic aberration)."
motion blur,"Ray tracing is capable of simulating a variety of optical effects, such as reflection, refraction, soft shadows, scattering, depth of field, motion blur, caustics, ambient occlusion and dispersion phenomena (such as chromatic aberration)."
optical effects,"Ray tracing is capable of simulating a variety of optical effects, such as reflection, refraction, soft shadows, scattering, depth of field, motion blur, caustics, ambient occlusion and dispersion phenomena (such as chromatic aberration)."
soft shadows,"Ray tracing is capable of simulating a variety of optical effects, such as reflection, refraction, soft shadows, scattering, depth of field, motion blur, caustics, ambient occlusion and dispersion phenomena (such as chromatic aberration)."
continuous motion,"The development of kinetic data structures was motivated by computational geometry problems involving physical objects in continuous motion, such as collision or visibility detection in robotics, animation or computer graphics."
visibility detection,"The development of kinetic data structures was motivated by computational geometry problems involving physical objects in continuous motion, such as collision or visibility detection in robotics, animation or computer graphics."
known fashion,"Kinetic data structures are used on systems where there is a set of values that are changing as a function of time, in a known fashion."
social affordance,"Social affordance is most often used in the context of a social technology such as Wiki, Chat and Facebook applications and refers to sociotechnical affordances. !! Social affordances or more accurately sociotechnical affordances refer as reciprocal interactions between a technology application, its users, and its social context. !! Social affordances emerge from the coupling between the behavioral and cognitive capacities of a given organism and the objective properties of its environment. !! Social affordance is a type of affordance. !! Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
facebook applications,"Social affordance is most often used in the context of a social technology such as Wiki, Chat and Facebook applications and refers to sociotechnical affordances."
sociotechnical affordances,"Social affordance is most often used in the context of a social technology such as Wiki, Chat and Facebook applications and refers to sociotechnical affordances."
social technology,"Social affordance is most often used in the context of a social technology such as Wiki, Chat and Facebook applications and refers to sociotechnical affordances."
cognitive capacities,Social affordances emerge from the coupling between the behavioral and cognitive capacities of a given organism and the objective properties of its environment.
social affordances emerge,Social affordances emerge from the coupling between the behavioral and cognitive capacities of a given organism and the objective properties of its environment.
given organism,Social affordances emerge from the coupling between the behavioral and cognitive capacities of a given organism and the objective properties of its environment.
objective properties,Social affordances emerge from the coupling between the behavioral and cognitive capacities of a given organism and the objective properties of its environment.
social context,"In community informatics, there are several considerations which are the social context, shared values, distinct processes that are taken by members in a community, and social and technical systems. !! Social affordances or more accurately sociotechnical affordances refer as reciprocal interactions between a technology application, its users, and its social context."
social affordances,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies. !! Social affordances or more accurately sociotechnical affordances refer as reciprocal interactions between a technology application, its users, and its social context."
technology application,"Social affordances or more accurately sociotechnical affordances refer as reciprocal interactions between a technology application, its users, and its social context."
accurately sociotechnical affordances refer,"Social affordances or more accurately sociotechnical affordances refer as reciprocal interactions between a technology application, its users, and its social context."
statistical frequency,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
become normative,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
primate societies,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
primitive forms,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
social normality,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
mere factual,"Social affordances are not synonymous with mere factual, statistical frequency; on the contrary, the social normality of primitive forms of coordination can become normative, even in primate societies."
better factor,"Gap reductions can be used to demonstrate inapproximability results, as if a problem may be approximated to a better factor than the size of gap, then the approximation algorithm can be used to solve the corresponding gap problem."
problem may,"Gap reductions can be used to demonstrate inapproximability results, as if a problem may be approximated to a better factor than the size of gap, then the approximation algorithm can be used to solve the corresponding gap problem. !! The same problem may have multiple distinct neighborhoods defined on it; local optimization with neighborhoods that involve changing up to k components of the solution is often referred to as k-opt."
corresponding gap problem,"Gap reductions can be used to demonstrate inapproximability results, as if a problem may be approximated to a better factor than the size of gap, then the approximation algorithm can be used to solve the corresponding gap problem."
demonstrate inapproximability results,"Gap reductions can be used to demonstrate inapproximability results, as if a problem may be approximated to a better factor than the size of gap, then the approximation algorithm can be used to solve the corresponding gap problem."
central operation,"Because matrix multiplication is such a central operation in many numerical algorithms, much work has been invested in making matrix multiplication algorithms efficient."
much work,"Because matrix multiplication is such a central operation in many numerical algorithms, much work has been invested in making matrix multiplication algorithms efficient."
making matrix multiplication algorithms efficient,"Because matrix multiplication is such a central operation in many numerical algorithms, much work has been invested in making matrix multiplication algorithms efficient."
many numerical algorithms,"Because matrix multiplication is such a central operation in many numerical algorithms, much work has been invested in making matrix multiplication algorithms efficient."
error detection techniques allow detecting,"Error detection techniques allow detecting such errors, while error correction enables reconstruction of the original data in many cases."
error correction enables reconstruction,"Error detection techniques allow detecting such errors, while error correction enables reconstruction of the original data in many cases."
many cases,"Error detection techniques allow detecting such errors, while error correction enables reconstruction of the original data in many cases. !! In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants."
errors caused,Error detection is the detection of errors caused by noise or other impairments during transmission from the transmitter to the receiver.
received check bits,"If only error detection is required, a receiver can simply apply the same algorithm to the received data bits and compare its output with the received check bits; if the values do not match, an error has occurred at some point during the transmission."
received data bits,"If only error detection is required, a receiver can simply apply the same algorithm to the received data bits and compare its output with the received check bits; if the values do not match, an error has occurred at some point during the transmission."
simply apply,"If only error detection is required, a receiver can simply apply the same algorithm to the received data bits and compare its output with the received check bits; if the values do not match, an error has occurred at some point during the transmission."
cyclic redundancy check,"The CRCTable is a memoization of a calculation that would have to be repeated for each byte of the message (Computation of cyclic redundancy checks Multi-bit computation). !! Error detection is most commonly realized using a suitable hash function (or specifically, a checksum, cyclic redundancy check or other algorithm). !! A cyclic redundancy check (CRC) is an error-detecting code commonly used in digital networks and storage devices to detect accidental changes to raw data. !! Numerous varieties of cyclic redundancy checks have been incorporated into technical standards."
suitable hash function,"Error detection is most commonly realized using a suitable hash function (or specifically, a checksum, cyclic redundancy check or other algorithm)."
commonly realized using,"Error detection is most commonly realized using a suitable hash function (or specifically, a checksum, cyclic redundancy check or other algorithm)."
postel stated,"Postel stated, ""We are screwing up in our design of Internet protocols by violating the principle of layering. """
markov information sources,"The Viterbi algorithm is a dynamic programming algorithm for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden statescalled the Viterbi paththat results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM)."
likely sequence,"The Viterbi algorithm is a dynamic programming algorithm for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden statescalled the Viterbi paththat results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM)."
hidden statescalled,"The Viterbi algorithm is a dynamic programming algorithm for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden statescalled the Viterbi paththat results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM)."
observed events,"The Viterbi algorithm is a dynamic programming algorithm for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden statescalled the Viterbi paththat results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM)."
viterbi paththat results,"The Viterbi algorithm is a dynamic programming algorithm for obtaining the maximum a posteriori probability estimate of the most likely sequence of hidden statescalled the Viterbi paththat results in a sequence of observed events, especially in the context of Markov information sources and hidden Markov models (HMM)."
viterbi algorithm finds,The Viterbi algorithm finds the most likely string of text given the acoustic signal.
acoustic signal,The Viterbi algorithm finds the most likely string of text given the acoustic signal.
likely string,The Viterbi algorithm finds the most likely string of text given the acoustic signal.
text given,The Viterbi algorithm finds the most likely string of text given the acoustic signal.
noisy digital communication links,"The Viterbi algorithm is named after Andrew Viterbi, who proposed it in 1967 as a decoding algorithm for convolutional codes over noisy digital communication links."
andrew viterbi,"The Viterbi algorithm is named after Andrew Viterbi, who proposed it in 1967 as a decoding algorithm for convolutional codes over noisy digital communication links."
maximization problems involving probabilities,Viterbi path and Viterbi algorithm have become standard terms for the application of dynamic programming algorithms to maximization problems involving probabilities.
become standard terms,Viterbi path and Viterbi algorithm have become standard terms for the application of dynamic programming algorithms to maximization problems involving probabilities.
likely assignment,"A generalization of the Viterbi algorithm, termed the max-sum algorithm (or max-product algorithm) can be used to find the most likely assignment of all or some subset of latent variables in a large number of graphical models, e. g. Bayesian networks, Markov random fields and conditional random fields."
product algorithm,"A generalization of the Viterbi algorithm, termed the max-sum algorithm (or max-product algorithm) can be used to find the most likely assignment of all or some subset of latent variables in a large number of graphical models, e. g. Bayesian networks, Markov random fields and conditional random fields."
markov random fields,"A generalization of the Viterbi algorithm, termed the max-sum algorithm (or max-product algorithm) can be used to find the most likely assignment of all or some subset of latent variables in a large number of graphical models, e. g. Bayesian networks, Markov random fields and conditional random fields."
maintained structure,"In computing, cache algorithms (also frequently called cache replacement algorithms or cache replacement policies) are optimizing instructions, or algorithms, that a computer program or a hardware-maintained structure can utilize in order to manage a cache of information stored on the computer."
optimizing instructions,"In computing, cache algorithms (also frequently called cache replacement algorithms or cache replacement policies) are optimizing instructions, or algorithms, that a computer program or a hardware-maintained structure can utilize in order to manage a cache of information stored on the computer."
information stored,"In computing, cache algorithms (also frequently called cache replacement algorithms or cache replacement policies) are optimizing instructions, or algorithms, that a computer program or a hardware-maintained structure can utilize in order to manage a cache of information stored on the computer."
object database vendors,The Object Data Management Group (ODMG) was conceived in the summer of 1991 at a breakfast with object database vendors that was organized by Rick Cattell of Sun Microsystems.
rick cattell,The Object Data Management Group (ODMG) was conceived in the summer of 1991 at a breakfast with object database vendors that was organized by Rick Cattell of Sun Microsystems.
sun microsystems,"The Berkeley RISC design was later commercialized by Sun Microsystems as the SPARC architecture, and inspired the ARM architecture. !! The Object Data Management Group (ODMG) was conceived in the summer of 1991 at a breakfast with object database vendors that was organized by Rick Cattell of Sun Microsystems."
thomas joannes stieltjes,"In mathematics, particularly matrix theory, a Stieltjes matrix, named after Thomas Joannes Stieltjes, is a real symmetric positive definite matrix with nonpositive off-diagonal entries."
particularly matrix theory,"In mathematics, particularly matrix theory, a Stieltjes matrix, named after Thomas Joannes Stieltjes, is a real symmetric positive definite matrix with nonpositive off-diagonal entries."
every nn stieltjes matrix,"Every nn Stieltjes matrix is invertible to a nonsingular symmetric nonnegative matrix, though the converse of this statement is not true in general for n > 2."
positive real parts,"From the above definition, a Stieltjes matrix is a symmetric invertible Z-matrix whose eigenvalues have positive real parts."
matrix whose eigenvalues,"From the above definition, a Stieltjes matrix is a symmetric invertible Z-matrix whose eigenvalues have positive real parts."
symmetric invertible z,"From the above definition, a Stieltjes matrix is a symmetric invertible Z-matrix whose eigenvalues have positive real parts."
logical division,"A broadcast domain is a logical division of a computer network, in which all nodes can reach each other by broadcast at the data link layer."
computer connected,"In terms of current popular technologies, any computer connected to the same Ethernet repeater or switch is a member of the same broadcast domain. !! Further, any computer connected to the same set of inter-connected switches/repeaters is a member of the same broadcast domain."
current popular technologies,"In terms of current popular technologies, any computer connected to the same Ethernet repeater or switch is a member of the same broadcast domain."
connected switches,"Further, any computer connected to the same set of inter-connected switches/repeaters is a member of the same broadcast domain."
layer devices form boundaries,Routers and other higher-layer devices form boundaries between broadcast domains.
openvz  partitions,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
kernel allows,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
ves  virtual kernels,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
freebsd jail,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
chroot jail,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
solaris containers  virtual private servers,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
podman  zones,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
level virtualization,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
multiple isolated user space instances,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
called containers,"OS-level virtualization is an operating system (OS) paradigm in which the kernel allows the existence of multiple isolated user space instances, called containers (LXC, Solaris containers, Docker, Podman), zones (Solaris containers), virtual private servers (OpenVZ), partitions, virtual environments (VEs), virtual kernels (DragonFly BSD), or jails (FreeBSD jail or chroot jail)."
sometimes ambiguously used,"The term container, while most popularly referring to OS-level virtualization systems, is sometimes ambiguously used to refer to fuller virtual machine environments operating in varying degrees of concert with the host OS, e. g. Microsoft's Hyper-V containers."
varying degrees,"The term container, while most popularly referring to OS-level virtualization systems, is sometimes ambiguously used to refer to fuller virtual machine environments operating in varying degrees of concert with the host OS, e. g. Microsoft's Hyper-V containers."
popularly referring,"The term container, while most popularly referring to OS-level virtualization systems, is sometimes ambiguously used to refer to fuller virtual machine environments operating in varying degrees of concert with the host OS, e. g. Microsoft's Hyper-V containers."
term container,"The term container, while most popularly referring to OS-level virtualization systems, is sometimes ambiguously used to refer to fuller virtual machine environments operating in varying degrees of concert with the host OS, e. g. Microsoft's Hyper-V containers."
fuller virtual machine environments operating,"The term container, while most popularly referring to OS-level virtualization systems, is sometimes ambiguously used to refer to fuller virtual machine environments operating in varying degrees of concert with the host OS, e. g. Microsoft's Hyper-V containers."
level virtualization systems,"The term container, while most popularly referring to OS-level virtualization systems, is sometimes ambiguously used to refer to fuller virtual machine environments operating in varying degrees of concert with the host OS, e. g. Microsoft's Hyper-V containers."
scientific american column,"Spaghetti sort is a linear-time, analog algorithm for sorting a sequence of items, introduced by A. K. Dewdney in his Scientific American column."
abstract family of acceptors,An abstract family of acceptors (AFA) is a grouping of generalized acceptors.
generalized acceptors,An abstract family of acceptors (AFA) is a grouping of generalized acceptors.
intelligent agents ought,Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward.
machine learning concerned,Action model learning (sometimes abbreviated action learning) is an area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment. !! Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward.
take actions,Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward.
three basic machine learning paradigms,"Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning."
alongside supervised learning,"Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning."
needing labelled input,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
reinforcement learning differs,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
optimal actions,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
needing sub,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
explicitly corrected,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
typically stated,"The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques."
context use dynamic programming techniques,"The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques."
many reinforcement learning algorithms,"The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques."
exact mathematical model,The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.
exact methods become infeasible,The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.
target large mdps,The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.
assume knowledge,The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.
charles babbage,"The first documented computer architecture was in the correspondence between Charles Babbage and Ada Lovelace, describing the analytical engine."
ada lovelace,"The first documented computer architecture was in the correspondence between Charles Babbage and Ada Lovelace, describing the analytical engine."
first documented computer architecture,"The first documented computer architecture was in the correspondence between Charles Babbage and Ada Lovelace, describing the analytical engine."
stretch designer,"Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints."
possible within economic,"Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints."
book called planning,"Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints."
technological constraints,"Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints."
opened chapter 2,"Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints."
project stretch,"Subsequently, Brooks, a Stretch designer, opened Chapter 2 of a book called Planning a Computer System: Project Stretch by stating, Computer architecture, like other architecture, is the art of determining the needs of the user of a structure and then designing to meet those needs as effectively as possible within economic and technological constraints."
final hardware form,The earliest computer architectures were designed on paper and then directly built into the final hardware form.
directly built,The earliest computer architectures were designed on paper and then directly built into the final hardware form.
earliest computer architectures,The earliest computer architectures were designed on paper and then directly built into the final hardware form.
expected search time,"In computer science, an optimal binary search tree (Optimal BST), sometimes called a weight-balanced binary tree, is a binary search tree which provides the smallest possible search time (or expected search time) for a given sequence of accesses (or access probabilities)."
smallest possible search time,"In computer science, an optimal binary search tree (Optimal BST), sometimes called a weight-balanced binary tree, is a binary search tree which provides the smallest possible search time (or expected search time) for a given sequence of accesses (or access probabilities)."
access probabilities,"In computer science, an optimal binary search tree (Optimal BST), sometimes called a weight-balanced binary tree, is a binary search tree which provides the smallest possible search time (or expected search time) for a given sequence of accesses (or access probabilities)."
optimal bst  sometimes called,"In computer science, an optimal binary search tree (Optimal BST), sometimes called a weight-balanced binary tree, is a binary search tree which provides the smallest possible search time (or expected search time) for a given sequence of accesses (or access probabilities)."
produce nearly,"In addition to its dynamic programming algorithm, Knuth proposed two heuristics (or rules) to produce nearly (approximation of) optimal binary search trees."
major results state,Mehlhorn's major results state that only one of Knuth's heuristics (Rule II) always produces nearly optimal binary search trees.
rule ii,Mehlhorn's major results state that only one of Knuth's heuristics (Rule II) always produces nearly optimal binary search trees.
documenting complex data entities,Data structure diagrams are most useful for documenting complex data entities.
diagram type,Data Structure Diagram is a diagram type that is used to depict the structure of data elements in the data dictionary.
graphical alternative,The data structure diagram is a graphical alternative to the composition specifications within such data dictionary entries.
composition specifications within,The data structure diagram is a graphical alternative to the composition specifications within such data dictionary entries.
entityrelationship model,The data structure diagrams is a predecessor of the entityrelationship model (ER model).
input document,"A turnaround document is a document that has been output from a computer, some extra information potentially added to it, and then returned to become an input document."
extra information potentially added,"A turnaround document is a document that has been output from a computer, some extra information potentially added to it, and then returned to become an input document."
turnaround document,"A turnaround document is a document that has been output from a computer, some extra information potentially added to it, and then returned to become an input document."
first error,"The American mathematician Richard Hamming pioneered this field in the 1940s and invented the first error-correcting code in 1950: the Hamming (7,4) code."
american mathematician richard hamming pioneered,"The American mathematician Richard Hamming pioneered this field in the 1940s and invented the first error-correcting code in 1950: the Hamming (7,4) code."
correcting code,"If the number of errors within a code word exceeds the error-correcting code's capability, it fails to recover the original code word. !! The American mathematician Richard Hamming pioneered this field in the 1940s and invented the first error-correcting code in 1950: the Hamming (7,4) code."
probabilistically recovered,"Locally decodable codes are error-correcting codes for which single bits of the message can be probabilistically recovered by only looking at a small (say constant) number of positions of a codeword, even after the codeword has been corrupted at some constant fraction of positions."
single bits,"Locally decodable codes are error-correcting codes for which single bits of the message can be probabilistically recovered by only looking at a small (say constant) number of positions of a codeword, even after the codeword has been corrupted at some constant fraction of positions."
constant fraction,"Locally decodable codes are error-correcting codes for which single bits of the message can be probabilistically recovered by only looking at a small (say constant) number of positions of a codeword, even after the codeword has been corrupted at some constant fraction of positions."
say constant,"Locally decodable codes are error-correcting codes for which single bits of the message can be probabilistically recovered by only looking at a small (say constant) number of positions of a codeword, even after the codeword has been corrupted at some constant fraction of positions."
checked probabilistically whether,Locally testable codes are error-correcting codes for which it can be checked probabilistically whether a signal is close to a codeword by only looking at a small number of positions of the signal.
errors within,"If the number of errors within a code word exceeds the error-correcting code's capability, it fails to recover the original code word."
original code word,"If the number of errors within a code word exceeds the error-correcting code's capability, it fails to recover the original code word."
code word exceeds,"If the number of errors within a code word exceeds the error-correcting code's capability, it fails to recover the original code word."
bit one,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
bit error,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
correcting codeword,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
letter represents,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
media creation,Windows Media is a discontinued multimedia framework for media creation and distribution for Microsoft Windows.
discontinued multimedia framework,Windows Media is a discontinued multimedia framework for media creation and distribution for Microsoft Windows.
windows media,"The Windows Media SDK was replaced by Media Foundation when Windows Vista was released. !! WMV HD, (Windows Media Video High Definition), the branding name for high definition (HD) media content encoded using Windows Media codecs. !! Windows Media is a discontinued multimedia framework for media creation and distribution for Microsoft Windows."
windows vista,"Such bus encryption is used by Windows Vista and newer Microsoft operating systems to protect certificates, BIOS, passwords, and program authenticity. !! The Windows Media SDK was replaced by Media Foundation when Windows Vista was released."
media foundation,The Windows Media SDK was replaced by Media Foundation when Windows Vista was released.
high definition,"WMV HD, (Windows Media Video High Definition), the branding name for high definition (HD) media content encoded using Windows Media codecs."
wmv hd,"WMV HD, (Windows Media Video High Definition), the branding name for high definition (HD) media content encoded using Windows Media codecs."
branding name,"WMV HD, (Windows Media Video High Definition), the branding name for high definition (HD) media content encoded using Windows Media codecs."
windows media video high definition,"WMV HD, (Windows Media Video High Definition), the branding name for high definition (HD) media content encoded using Windows Media codecs."
ghanbarzadeh et al,"In computer science and operations research, the bees algorithm is a population-based search algorithm which was developed by Pham, Ghanbarzadeh et al."
based search algorithm,"In computer science and operations research, the bees algorithm is a population-based search algorithm which was developed by Pham, Ghanbarzadeh et al."
specific abilities,The effectiveness and specific abilities of the bees algorithm have been proven in a number of studies.
bees algorithm mimics,The bees algorithm mimics the foraging strategy of honey bees to look for the best solution to an optimisation problem.
foraging strategy,The bees algorithm mimics the foraging strategy of honey bees to look for the best solution to an optimisation problem.
honey bees,The bees algorithm mimics the foraging strategy of honey bees to look for the best solution to an optimisation problem.
best solution,The bees algorithm mimics the foraging strategy of honey bees to look for the best solution to an optimisation problem.
main search cycle,"The bees algorithm consists of an initialisation procedure and a main search cycle which is iterated for a given number T of times, or until a solution of acceptable fitness is found."
given number,"The bees algorithm consists of an initialisation procedure and a main search cycle which is iterated for a given number T of times, or until a solution of acceptable fitness is found."
initialisation procedure,"The bees algorithm consists of an initialisation procedure and a main search cycle which is iterated for a given number T of times, or until a solution of acceptable fitness is found."
acceptable fitness,"The bees algorithm consists of an initialisation procedure and a main search cycle which is iterated for a given number T of times, or until a solution of acceptable fitness is found."
bees algorithm consists,"The bees algorithm consists of an initialisation procedure and a main search cycle which is iterated for a given number T of times, or until a solution of acceptable fitness is found."
natural language needs,Any logical system which is appropriate as an instrument for the analysis of natural language needs a much richer structure than first-order predicate logic.
logical system,Any logical system which is appropriate as an instrument for the analysis of natural language needs a much richer structure than first-order predicate logic.
much richer structure,Any logical system which is appropriate as an instrument for the analysis of natural language needs a much richer structure than first-order predicate logic.
first formalized mathematically,The concept of graph edit distance was first formalized mathematically by Alberto Sanfeliu and King-Sun Fu in 1983.
sun fu,The concept of graph edit distance was first formalized mathematically by Alberto Sanfeliu and King-Sun Fu in 1983.
alberto sanfeliu,The concept of graph edit distance was first formalized mathematically by Alberto Sanfeliu and King-Sun Fu in 1983.
graph edit distance finds applications,"Graph edit distance finds applications in handwriting recognition, fingerprint recognition and cheminformatics."
graphs typically transform,Exact algorithms for computing the graph edit distance between a pair of graphs typically transform the problem into one of finding the minimum cost edit path between the two graphs.
minimum cost edit path,Exact algorithms for computing the graph edit distance between a pair of graphs typically transform the problem into one of finding the minimum cost edit path between the two graphs.
linear time despite,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
cubic computational time moreover,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
computing graph edit distance,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
available online,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
see section 2,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
algorithms sometimes working well,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
zeng et al,"Most of them have cubic computational time Moreover, there is an algorithm that deduces an approximation of the GED in linear time Despite the above algorithms sometimes working well in practice, in general the problem of computing graph edit distance is NP-hard (for a proof that's available online, see Section 2 of Zeng et al."
mainstream c  compilers like microsoft visual c,"Mainstream C++ compilers like Microsoft Visual C++ and GCC support an option that lets the compilers automatically inline any suitable function, even those not marked as inline functions."
suitable function,"Mainstream C++ compilers like Microsoft Visual C++ and GCC support an option that lets the compilers automatically inline any suitable function, even those not marked as inline functions."
compilers automatically inline,"Mainstream C++ compilers like Microsoft Visual C++ and GCC support an option that lets the compilers automatically inline any suitable function, even those not marked as inline functions."
gcc support,"Mainstream C++ compilers like Microsoft Visual C++ and GCC support an option that lets the compilers automatically inline any suitable function, even those not marked as inline functions."
line copy,"This is because inline not only gives the compiler a hint that the function should be inlined, it also has an effect on whether the compiler will generate a callable out-of-line copy of the function (see storage classes of inline functions)."
see storage classes,"This is because inline not only gives the compiler a hint that the function should be inlined, it also has an effect on whether the compiler will generate a callable out-of-line copy of the function (see storage classes of inline functions)."
storage class extern,The effect of the storage class extern when applied or not applied to inline functions differs between the C dialects and C++.
inline functions differs,The effect of the storage class extern when applied or not applied to inline functions differs between the C dialects and C++.
create one,A convenient way is to define the inline functions in header files and create one .
header files,A convenient way is to define the inline functions in header files and create one .
convenient way,A convenient way is to define the inline functions in header files and create one .
scalar prediction,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
deep neural network created,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
structured input,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
given structure,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
weights recursively,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
size input structures,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
sometimes abbreviated,"Recursive neural networks, sometimes abbreviated as RvNNs, have been successful, for instance, in learning sequence and tree structures in natural language processing, mainly phrase and sentence continuous representations based on word embedding. !! Computational archaeology is also known as ""archaeological informatics"" (Burenhult 2002, Huggett and Ross 2004) or ""archaeoinformatics"" (sometimes abbreviated as ""AI"", but not to be confused with artificial intelligence)."
learning sequence,"Recursive neural networks, sometimes abbreviated as RvNNs, have been successful, for instance, in learning sequence and tree structures in natural language processing, mainly phrase and sentence continuous representations based on word embedding."
sentence continuous representations based,"Recursive neural networks, sometimes abbreviated as RvNNs, have been successful, for instance, in learning sequence and tree structures in natural language processing, mainly phrase and sentence continuous representations based on word embedding."
mainly phrase,"Recursive neural networks, sometimes abbreviated as RvNNs, have been successful, for instance, in learning sequence and tree structures in natural language processing, mainly phrase and sentence continuous representations based on word embedding."
previous time step,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
parent representations,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
current time step,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
recurrent neural networks operate,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
combining child representations,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
linear progression,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
whereas recursive neural networks operate,"Whereas recursive neural networks operate on any hierarchical structure, combining child representations into parent representations, recurrent neural networks operate on the linear progression of time, combining the previous time step and a hidden representation into the representation for the current time step."
efficient approach,An efficient approach to implement recursive neural networks is given by the Tree Echo State Network within the reservoir computing paradigm.
tree echo state network within,An efficient approach to implement recursive neural networks is given by the Tree Echo State Network within the reservoir computing paradigm.
implement recursive neural networks,An efficient approach to implement recursive neural networks is given by the Tree Echo State Network within the reservoir computing paradigm.
combinatory logic using,Binary combinatory logic (BCL) is a computer programming language that uses binary terms 0 and 1 to create a complete formulation of combinatory logic using only the symbols 0 and 1.
complete formulation,Binary combinatory logic (BCL) is a computer programming language that uses binary terms 0 and 1 to create a complete formulation of combinatory logic using only the symbols 0 and 1.
uses binary terms 0,Binary combinatory logic (BCL) is a computer programming language that uses binary terms 0 and 1 to create a complete formulation of combinatory logic using only the symbols 0 and 1.
musical instruments,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
better understanding,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
complex sounds,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
discuss pieces,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
musical notation used,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
implicitly based,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
domain analysis gives,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
separate component frequencies,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
musical notes,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
mergeable heap data structure,"In computer science, a shadow heap is a mergeable heap data structure which supports efficient heap merging in the amortized sense."
supports efficient heap merging,"In computer science, a shadow heap is a mergeable heap data structure which supports efficient heap merging in the amortized sense."
amortized sense,"In computer science, a shadow heap is a mergeable heap data structure which supports efficient heap merging in the amortized sense."
shadow heaps make use,"More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 f(n) log log n. Throughout this article, it is assumed that A and B are binary heaps with |A| |B|."
log log n,"However, Dynamic Interpolation Search is possible in o(log log n) time using a novel data structure. !! More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 f(n) log log n. Throughout this article, it is assumed that A and B are binary heaps with |A| |B|."
shadow merge algorithm,"More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 f(n) log log n. Throughout this article, it is assumed that A and B are binary heaps with |A| |B|."
n  amortized time,"More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 f(n) log log n. Throughout this article, it is assumed that A and B are binary heaps with |A| |B|."
log n log log n  f,"More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 f(n) log log n. Throughout this article, it is assumed that A and B are binary heaps with |A| |B|."
achieve insertion,"More specifically, shadow heaps make use of the shadow merge algorithm to achieve insertion in O(f(n)) amortized time and deletion in O((log n log log n)/f(n)) amortized time, for any choice of 1 f(n) log log n. Throughout this article, it is assumed that A and B are binary heaps with |A| |B|."
sequential insertion,"Finally, the merging of shadow heaps is simply done through sequential insertion of one heap into the other using the above insertion procedure."
insertion procedure,"Finally, the merging of shadow heaps is simply done through sequential insertion of one heap into the other using the above insertion procedure."
simply done,"Finally, the merging of shadow heaps is simply done through sequential insertion of one heap into the other using the above insertion procedure."
large computation time,"passes may still require quite a large computation time, in which case other approaches such as k-fold cross validation may be more appropriate."
passes may still require quite,"passes may still require quite a large computation time, in which case other approaches such as k-fold cross validation may be more appropriate."
fold cross validation may,"passes may still require quite a large computation time, in which case other approaches such as k-fold cross validation may be more appropriate."
original sample,Non-exhaustive cross validation methods do not compute all ways of splitting the original sample.
fold cross validation,"The advantage of this method (over k-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (i. e. , the number of partitions). !! Similar to the k*l-fold cross validation, the training set is used for model fitting and the validation set is used for model evaluation for each of the hyperparameter sets."
validation split,"The advantage of this method (over k-fold cross validation) is that the proportion of the training/validation split is not dependent on the number of iterations (i. e. , the number of partitions)."
hyperparameter sets,"Similar to the k*l-fold cross validation, the training set is used for model fitting and the validation set is used for model evaluation for each of the hyperparameter sets."
model fitting,"Similar to the k*l-fold cross validation, the training set is used for model fitting and the validation set is used for model evaluation for each of the hyperparameter sets."
internet via web crawling,Distributed web crawling is a distributed computing technique whereby Internet search engines employ many computers to index the Internet via web crawling.
upload query result pages,"According to the FAQ about Nutch, an open-source search engine website, the savings in bandwidth by distributed web crawling are not significant, since ""A successful search engine requires more bandwidth to upload query result pages than its crawler needs to download pages."
crawler needs,"According to the FAQ about Nutch, an open-source search engine website, the savings in bandwidth by distributed web crawling are not significant, since ""A successful search engine requires more bandwidth to upload query result pages than its crawler needs to download pages."
successful search engine requires,"According to the FAQ about Nutch, an open-source search engine website, the savings in bandwidth by distributed web crawling are not significant, since ""A successful search engine requires more bandwidth to upload query result pages than its crawler needs to download pages."
source search engine website,"According to the FAQ about Nutch, an open-source search engine website, the savings in bandwidth by distributed web crawling are not significant, since ""A successful search engine requires more bandwidth to upload query result pages than its crawler needs to download pages."
download pages,"According to the FAQ about Nutch, an open-source search engine website, the savings in bandwidth by distributed web crawling are not significant, since ""A successful search engine requires more bandwidth to upload query result pages than its crawler needs to download pages."
dimensional vectorial input data,"Maximum Variance Unfolding (MVU), also known as Semidefinite Embedding (SDE), is an algorithm in computer science that uses semidefinite programming to perform non-linear dimensionality reduction of high-dimensional vectorial input data."
perform non,"Maximum Variance Unfolding (MVU), also known as Semidefinite Embedding (SDE), is an algorithm in computer science that uses semidefinite programming to perform non-linear dimensionality reduction of high-dimensional vectorial input data."
uses semidefinite programming,"Maximum Variance Unfolding (MVU), also known as Semidefinite Embedding (SDE), is an algorithm in computer science that uses semidefinite programming to perform non-linear dimensionality reduction of high-dimensional vectorial input data."
mvu  also known,"Maximum Variance Unfolding (MVU), also known as Semidefinite Embedding (SDE), is an algorithm in computer science that uses semidefinite programming to perform non-linear dimensionality reduction of high-dimensional vectorial input data."
garbage collection algorithm introduced,The Garbage-First Collector (G1) is a garbage collection algorithm introduced in the Oracle HotSpot Java virtual machine (JVM) 6 and supported from 7 Update 4.
first collector,The Garbage-First Collector (G1) is a garbage collection algorithm introduced in the Oracle HotSpot Java virtual machine (JVM) 6 and supported from 7 Update 4.
oracle hotspot java virtual machine,The Garbage-First Collector (G1) is a garbage collection algorithm introduced in the Oracle HotSpot Java virtual machine (JVM) 6 and supported from 7 Update 4.
borne computer,"A wearable computer, also known as a wearable or body-borne computer, is a computing device worn on the body."
computing device worn,"A wearable computer, also known as a wearable or body-borne computer, is a computing device worn on the body."
even ordinary wristwatches,"The definition of 'wearable computer' may be narrow or broad, extending to smartphones or even ordinary wristwatches."
mounted display controlled,"Under the definition of wearable computers, we also include novel user interfaces such as Google Glass, an optical head-mounted display controlled by gestures."
optical head,"Under the definition of wearable computers, we also include novel user interfaces such as Google Glass, an optical head-mounted display controlled by gestures."
also include novel user interfaces,"Under the definition of wearable computers, we also include novel user interfaces such as Google Glass, an optical head-mounted display controlled by gestures."
various technical issues common,"Wearable computers have various technical issues common to other mobile computing, such as batteries, heat dissipation, software architectures, wireless and personal area networks, and data management."
recording data continuously,"Many wearable computers are active all the time, e. g. processing or recording data continuously."
many wearable computers,"Many wearable computers are active all the time, e. g. processing or recording data continuously."
also becoming important,"With the increase in the number of periodicals that have articles online, web indexing is also becoming important for periodical websites."
articles online,"With the increase in the number of periodicals that have articles online, web indexing is also becoming important for periodical websites."
periodical websites,"With the increase in the number of periodicals that have articles online, web indexing is also becoming important for periodical websites."
web sites within,"Metadata web indexing involves assigning keywords, description or phrases to web pages or web sites within a metadata tag (or ""meta-tag"") field, so that the web page or web site can be retrieved with a list."
maximal dimension,denotes the maximal dimension of a Krylov subspace.
krylov subspaces,Krylov subspaces are used in algorithms for finding approximate solutions to high-dimensional linear algebra problems. !! can be decomposed as the direct sum of Krylov subspaces.
direct sum,can be decomposed as the direct sum of Krylov subspaces.
finding approximate solutions,Krylov subspaces are used in algorithms for finding approximate solutions to high-dimensional linear algebra problems.
dimensional linear algebra problems,Krylov subspaces are used in algorithms for finding approximate solutions to high-dimensional linear algebra problems.
involve checking,"Many linear dynamical system tests in control theory, especially those related to controllability and observability, involve checking the rank of the Krylov subspace."
many linear dynamical system tests,"Many linear dynamical system tests in control theory, especially those related to controllability and observability, involve checking the rank of the Krylov subspace."
output maps,These tests are equivalent to finding the span of the Grammians associated with the system/output maps so the uncontrollable and unobservable subspaces are simply the orthogonal complement to the Krylov subspace.
grammians associated,These tests are equivalent to finding the span of the Grammians associated with the system/output maps so the uncontrollable and unobservable subspaces are simply the orthogonal complement to the Krylov subspace.
unobservable subspaces,These tests are equivalent to finding the span of the Grammians associated with the system/output maps so the uncontrollable and unobservable subspaces are simply the orthogonal complement to the Krylov subspace.
reviewed scientific journal covering research,Computational Statistics & Data Analysis is a monthly peer-reviewed scientific journal covering research on and applications of computational statistics and data analysis.
monthly peer,Computational Statistics & Data Analysis is a monthly peer-reviewed scientific journal covering research on and applications of computational statistics and data analysis.
real values,"Structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured objects, rather than scalar discrete or real values."
involves predicting structured objects,"Structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured objects, rather than scalar discrete or real values."
umbrella term,"Structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured objects, rather than scalar discrete or real values. !! The Steiner tree problem, or minimum Steiner tree problem, named after Jakob Steiner, is an umbrella term for a class of problems in combinatorial optimization."
scalar discrete,"Structured prediction or structured (output) learning is an umbrella term for supervised machine learning techniques that involves predicting structured objects, rather than scalar discrete or real values."
structured prediction models,"Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters. !! Probabilistic graphical models form a large class of structured prediction models."
observed data,"Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters. !! In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data. !! Bayesian inference derives the posterior probability as a consequence of two antecedents: a prior probability and a ""likelihood function"" derived from a statistical model for the observed data."
true prediction value,"Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters."
adjust model parameters,"Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters."
typically trained,"Similar to commonly used supervised learning techniques, structured prediction models are typically trained by means of observed data in which the true prediction value is used to adjust model parameters."
possible parse trees,"For example, the problem of translating a natural language sentence into a syntactic representation such as a parse tree can be seen as a structured prediction problem in which the structured output domain is the set of all possible parse trees."
structured output domain,"For example, the problem of translating a natural language sentence into a syntactic representation such as a parse tree can be seen as a structured prediction problem in which the structured output domain is the set of all possible parse trees."
syntactic representation,"For example, the problem of translating a natural language sentence into a syntactic representation such as a parse tree can be seen as a structured prediction problem in which the structured output domain is the set of all possible parse trees."
application domains including bioinformatics,"Structured prediction is also used in a wide variety of application domains including bioinformatics, natural language processing, speech recognition, and computer vision."
probabilistic graphical models form,Probabilistic graphical models form a large class of structured prediction models.
large class,Probabilistic graphical models form a large class of structured prediction models.
element within,"In computer science, a linear search or sequential search is a method for finding an element within a list."
linear search runs,"A linear search runs in at worst linear time and makes at most n comparisons, where n is the length of the list."
worst linear time,"A linear search runs in at worst linear time and makes at most n comparisons, where n is the length of the list."
average case,"If each element is equally likely to be searched, then linear search has an average case of n+1/2 comparisons, but the average case can be affected if the search probabilities for each element vary."
equally likely,"If each element is equally likely to be searched, then linear search has an average case of n+1/2 comparisons, but the average case can be affected if the search probabilities for each element vary."
search probabilities,"If each element is equally likely to be searched, then linear search has an average case of n+1/2 comparisons, but the average case can be affected if the search probabilities for each element vary."
element vary,"If each element is equally likely to be searched, then linear search has an average case of n+1/2 comparisons, but the average case can be affected if the search probabilities for each element vary."
short lists,"Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, allow significantly faster searching for all but short lists."
rarely practical,"Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, allow significantly faster searching for all but short lists."
allow significantly faster searching,"Linear search is rarely practical because other search algorithms and schemes, such as the binary search algorithm and hash tables, allow significantly faster searching for all but short lists."
linear search sequentially checks,A linear search sequentially checks each element of the list until it finds an element that matches the target value.
current action based,Learning automata select their current action based on past experiences from the environment.
past experiences,Learning automata select their current action based on past experiences from the environment.
learning automata select,Learning automata select their current action based on past experiences from the environment.
learning automata,"Research in learning automata can be traced back to the work of Michael Lvovitch Tsetlin in the early 1960s in the Soviet Union. !! Learning automata select their current action based on past experiences from the environment. !! Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite. !! With respect to the field of reinforcement learning, learning automata are characterized as policy iterators. !! Learning automata were also investigated by researches in the United States in the 1960s."
michael lvovitch tsetlin,Research in learning automata can be traced back to the work of Michael Lvovitch Tsetlin in the early 1960s in the Soviet Union.
traced back,"While the basic idea behind stochastic approximation can be traced back to the RobbinsMonro algorithm of the 1950s, stochastic gradient descent has become an important optimization method in machine learning. !! Research in learning automata can be traced back to the work of Michael Lvovitch Tsetlin in the early 1960s in the Soviet Union. !! The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
united states,Learning automata were also investigated by researches in the United States in the 1960s.
also investigated,Learning automata were also investigated by researches in the United States in the 1960s.
policy iterators,"With respect to the field of reinforcement learning, learning automata are characterized as policy iterators."
finite action,"Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite."
set learning automata,"Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite."
mathematical terms,"Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite."
possible actions,"Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite."
called scalability,"A system's ability to accept higher load is called scalability, and modifying a system to handle a higher load is synonymous to performance tuning."
higher load,"A system's ability to accept higher load is called scalability, and modifying a system to handle a higher load is synonymous to performance tuning."
accept higher load,"A system's ability to accept higher load is called scalability, and modifying a system to handle a higher load is synonymous to performance tuning."
system construction,"System construction, including performance tuning."
including performance tuning,"System construction, including performance tuning."
extract knowledge,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
unstructured data,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
actionable insights,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
uses scientific methods,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
data across,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains."
apply knowledge,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. !! Learning classifier systems seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions (e. g. behavior modeling, classification, data mining, regression, function approximation, or game strategy)."
broad range,"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data, and apply knowledge and actionable insights from data across a broad range of application domains. !! Database theory encapsulates a broad range of topics related to the study and research of the theoretical realm of databases and database management systems."
unify statistics,"Data science is a ""concept to unify statistics, data analysis, informatics, and their related methods"" in order to ""understand and analyze actual phenomena"" with data."
analyze actual phenomena,"Data science is a ""concept to unify statistics, data analysis, informatics, and their related methods"" in order to ""understand and analyze actual phenomena"" with data."
related methods,"Data science is a ""concept to unify statistics, data analysis, informatics, and their related methods"" in order to ""understand and analyze actual phenomena"" with data."
fourth paradigm,"Turing Award winner Jim Gray imagined data science as a ""fourth paradigm"" of science (empirical, theoretical, computational, and now data-driven) and asserted that ""everything about science is changing because of the impact of information technology"" and the data deluge."
data deluge,"Turing Award winner Jim Gray imagined data science as a ""fourth paradigm"" of science (empirical, theoretical, computational, and now data-driven) and asserted that ""everything about science is changing because of the impact of information technology"" and the data deluge."
like structure,A hierarchical database model is a data model in which the data are organized into a tree-like structure.
hierarchical database model mandates,"The hierarchical database model mandates that each child record has only one parent, whereas each parent record can have one or more child records."
child records,"The hierarchical database model mandates that each child record has only one parent, whereas each parent record can have one or more child records."
parent record,"The hierarchical database model mandates that each child record has only one parent, whereas each parent record can have one or more child records."
one parent,"The hierarchical database model mandates that each child record has only one parent, whereas each parent record can have one or more child records."
child record,"The hierarchical database model mandates that each child record has only one parent, whereas each parent record can have one or more child records."
rapid data records,"Data Stream Mining (also known as stream learning) is the process of extracting knowledge structures from continuous, rapid data records."
extracting knowledge structures,"Data Stream Mining (also known as stream learning) is the process of extracting knowledge structures from continuous, rapid data records."
data stream,"In many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream. !! A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities."
times using limited computing,A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities.
storage capabilities,A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities.
many data stream mining applications,"In many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream."
data stream given,"In many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream."
previous instances,"In many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream."
new instances,"In many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream."
detecting concept drift,Detecting concept drift is a central issue to data stream mining.
central issue,Detecting concept drift is a central issue to data stream mining.
real data type,A real data type is a data type used in a computer program to represent an approximation of a real number.
data type used,A real data type is a data type used in a computer program to represent an approximation of a real number.
generates another program,A program transformation is any operation that takes a computer program and generates another program.
program transformation,"A program transformation is any operation that takes a computer program and generates another program. !! While the transformations can be performed manually, it is often more practical to use a program transformation system that applies specifications of the required transformations. !! may be of equal difficulty as building the program transformation system itself because of the complexity of such languages. !! Program transformations may be specified as automated procedures that modify compiler data structures (e. g. abstract syntax trees) representing the program text, or may be specified more conveniently using patterns or templates representing parameterized source code fragments. !! DMS Software Reengineering Toolkit: A Program Transformation System for DSLs and modern (C++, Java, ."
applies specifications,"While the transformations can be performed manually, it is often more practical to use a program transformation system that applies specifications of the required transformations."
required transformations,"While the transformations can be performed manually, it is often more practical to use a program transformation system that applies specifications of the required transformations."
performed manually,"While the transformations can be performed manually, it is often more practical to use a program transformation system that applies specifications of the required transformations."
program transformations may,"Program transformations may be specified as automated procedures that modify compiler data structures (e. g. abstract syntax trees) representing the program text, or may be specified more conveniently using patterns or templates representing parameterized source code fragments."
modify compiler data structures,"Program transformations may be specified as automated procedures that modify compiler data structures (e. g. abstract syntax trees) representing the program text, or may be specified more conveniently using patterns or templates representing parameterized source code fragments."
conveniently using patterns,"Program transformations may be specified as automated procedures that modify compiler data structures (e. g. abstract syntax trees) representing the program text, or may be specified more conveniently using patterns or templates representing parameterized source code fragments."
automated procedures,"Program transformations may be specified as automated procedures that modify compiler data structures (e. g. abstract syntax trees) representing the program text, or may be specified more conveniently using patterns or templates representing parameterized source code fragments."
equal difficulty,may be of equal difficulty as building the program transformation system itself because of the complexity of such languages.
static core generally refers,Static core generally refers to a microprocessor (MPU) entirely implemented in static logic.
entirely implemented,Static core generally refers to a microprocessor (MPU) entirely implemented in static logic.
static logic,Static core generally refers to a microprocessor (MPU) entirely implemented in static logic.
first implementations,"The first implementations of constraint logic programming were Prolog III, CLP(R), and CHIP."
first host languages used,"The first host languages used were logic programming languages, so the field was initially called constraint logic programming."
initially called constraint logic programming,"The first host languages used were logic programming languages, so the field was initially called constraint logic programming."
prolog implementations include one,Today most Prolog implementations include one or more libraries for constraint logic programming.
first software engineering conference,In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established.
best practices,In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established.
issues related,"Some of the issues related to end-user computing concern software architecture (iconic versus language interfaces, open versus closed, and others). !! In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established."
1968 nato held,In 1968 NATO held the first Software Engineering conference where issues related to software were addressed: guidelines and best practices for the development of software were established.
equal access,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
quality education,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
external evaluation,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish. !! In general, under the substantive session of the external evaluation, which lasted from April 22 to June 4 was written 997 000 897 tests. !! Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions. !! After the arrival of the new Minister of Education and Science Ivan Vakarchuk appropriate order number from the 1171 25 December 2008 was determined Ukrainian language as a single, which can make the external evaluation, and those who studied minority languages (Russian, Polish, Hungarian, Crimean, Moldovan/Romanian) will be given a short vocabulary of terms translated into Ukrainian. !! The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
constitutional rights,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
state standard,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
education system,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
improving public education,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
secondary education,"The purpose of external evaluation: improving public education and implementation of Ukraine's constitutional rights to equal access to quality education, monitoring of compliance with the State Standard of secondary education and the analysis of the education system, predict its development."
educational quality assessment,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
external evaluation carried,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
ukrainian center,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
postgraduate education,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
regional institute,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
local education authorities,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
educational institutions,"Provision of external evaluation carried out by the Ukrainian Center for Educational Quality Assessment in partnership with local education authorities, Regional Institute of Postgraduate Education, educational institutions."
short vocabulary,"After the arrival of the new Minister of Education and Science Ivan Vakarchuk appropriate order number from the 1171 25 December 2008 was determined Ukrainian language as a single, which can make the external evaluation, and those who studied minority languages (Russian, Polish, Hungarian, Crimean, Moldovan/Romanian) will be given a short vocabulary of terms translated into Ukrainian."
terms translated,"After the arrival of the new Minister of Education and Science Ivan Vakarchuk appropriate order number from the 1171 25 December 2008 was determined Ukrainian language as a single, which can make the external evaluation, and those who studied minority languages (Russian, Polish, Hungarian, Crimean, Moldovan/Romanian) will be given a short vocabulary of terms translated into Ukrainian."
new minister,"After the arrival of the new Minister of Education and Science Ivan Vakarchuk appropriate order number from the 1171 25 December 2008 was determined Ukrainian language as a single, which can make the external evaluation, and those who studied minority languages (Russian, Polish, Hungarian, Crimean, Moldovan/Romanian) will be given a short vocabulary of terms translated into Ukrainian."
studied minority languages,"After the arrival of the new Minister of Education and Science Ivan Vakarchuk appropriate order number from the 1171 25 December 2008 was determined Ukrainian language as a single, which can make the external evaluation, and those who studied minority languages (Russian, Polish, Hungarian, Crimean, Moldovan/Romanian) will be given a short vocabulary of terms translated into Ukrainian."
determined ukrainian language,"After the arrival of the new Minister of Education and Science Ivan Vakarchuk appropriate order number from the 1171 25 December 2008 was determined Ukrainian language as a single, which can make the external evaluation, and those who studied minority languages (Russian, Polish, Hungarian, Crimean, Moldovan/Romanian) will be given a short vocabulary of terms translated into Ukrainian."
written 997 000 897 tests,"In general, under the substantive session of the external evaluation, which lasted from April 22 to June 4 was written 997 000 897 tests."
substantive session,"In general, under the substantive session of the external evaluation, which lasted from April 22 to June 4 was written 997 000 897 tests."
russian language,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish."
optional  english,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish."
one foreign language,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish."
following subjects,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish."
ukrainian language,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish."
become university students conducted,"In 2011, an external evaluation for those wishing to become university students conducted the following subjects: Ukrainian language and literature, history of Ukraine, mathematics, biology, geography, physics, chemistry, Russian language, one foreign language (optional): English, German, French, Spanish."
tuning technique,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
dynamic behaviour,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
dependent parameters,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
essentially uses,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
gnu octave,"A detailed introduction of metaheuristic algorithms including the bat algorithm is given by Yang where a demo program in MATLAB/GNU Octave is available, while a comprehensive review is carried out by Parpinelli and Lopes."
demo program,"A detailed introduction of metaheuristic algorithms including the bat algorithm is given by Yang where a demo program in MATLAB/GNU Octave is available, while a comprehensive review is carried out by Parpinelli and Lopes."
detailed introduction,"A detailed introduction of metaheuristic algorithms including the bat algorithm is given by Yang where a demo program in MATLAB/GNU Octave is available, while a comprehensive review is carried out by Parpinelli and Lopes."
comprehensive review,"A detailed introduction of metaheuristic algorithms including the bat algorithm is given by Yang where a demo program in MATLAB/GNU Octave is available, while a comprehensive review is carried out by Parpinelli and Lopes."
metaheuristic algorithms including,"A detailed introduction of metaheuristic algorithms including the bat algorithm is given by Yang where a demo program in MATLAB/GNU Octave is available, while a comprehensive review is carried out by Parpinelli and Lopes."
evolving bat algorithm,A further improvement is the development of an evolving bat algorithm (EBA) with better efficiency.
better efficiency,A further improvement is the development of an evolving bat algorithm (EBA) with better efficiency.
block containing,"In computer science, loop inversion is a compiler optimization and loop transformation in which a while loop is replaced by an if block containing a do."
loop inversion allows safe loop,"Additionally, loop inversion allows safe loop-invariant code motion."
invariant code motion,"Additionally, loop inversion allows safe loop-invariant code motion."
book detailing,"ARM System-on-Chip Architecture is a book detailing the system on a chip ARM architecture, as a specific implementation of reduced instruction set computing."
specific implementation,"ARM System-on-Chip Architecture is a book detailing the system on a chip ARM architecture, as a specific implementation of reduced instruction set computing."
reduced instruction set computing,"ARM System-on-Chip Architecture is a book detailing the system on a chip ARM architecture, as a specific implementation of reduced instruction set computing."
arm system,"ARM System-on-Chip Architecture is a book detailing the system on a chip ARM architecture, as a specific implementation of reduced instruction set computing."
chip architecture,"ARM System-on-Chip Architecture is a book detailing the system on a chip ARM architecture, as a specific implementation of reduced instruction set computing."
chip arm architecture,"ARM System-on-Chip Architecture is a book detailing the system on a chip ARM architecture, as a specific implementation of reduced instruction set computing."
resolution attainable,Computational lithography (also known as computational scaling) is the set of mathematical and algorithmic approaches designed to improve the resolution attainable through photolithography.
computational scaling,Computational lithography (also known as computational scaling) is the set of mathematical and algorithmic approaches designed to improve the resolution attainable through photolithography.
computational lithography,"Computational lithography has come to the forefront of photolithography in 2008 as the semiconductor industry grappled with the challenges associated with the transition to 22 nanometer CMOS process technology and beyond. !! The term computational lithography was first used by Brion Technology (now a subsidiary of ASML) in 2005 to promote their hardware accelerated full chip lithography simulation platform. !! Computational lithography means the use of computers to simulate printing of micro-lithography structures. !! Computational lithography (also known as computational scaling) is the set of mathematical and algorithmic approaches designed to improve the resolution attainable through photolithography. !! While the increase in mathematical modeling has been underway for some time, the degree and expense of those calculations has justified the use of a new term to cover the changing landscape: computational lithography."
algorithmic approaches designed,Computational lithography (also known as computational scaling) is the set of mathematical and algorithmic approaches designed to improve the resolution attainable through photolithography.
semiconductor industry grappled,Computational lithography has come to the forefront of photolithography in 2008 as the semiconductor industry grappled with the challenges associated with the transition to 22 nanometer CMOS process technology and beyond.
challenges associated,Computational lithography has come to the forefront of photolithography in 2008 as the semiconductor industry grappled with the challenges associated with the transition to 22 nanometer CMOS process technology and beyond.
22 nanometer cmos process technology,Computational lithography has come to the forefront of photolithography in 2008 as the semiconductor industry grappled with the challenges associated with the transition to 22 nanometer CMOS process technology and beyond.
changing landscape,"While the increase in mathematical modeling has been underway for some time, the degree and expense of those calculations has justified the use of a new term to cover the changing landscape: computational lithography."
new term,"While the increase in mathematical modeling has been underway for some time, the degree and expense of those calculations has justified the use of a new term to cover the changing landscape: computational lithography."
mathematical modeling,"While the increase in mathematical modeling has been underway for some time, the degree and expense of those calculations has justified the use of a new term to cover the changing landscape: computational lithography."
computational lithography means,Computational lithography means the use of computers to simulate printing of micro-lithography structures.
simulate printing,Computational lithography means the use of computers to simulate printing of micro-lithography structures.
lithography structures,Computational lithography means the use of computers to simulate printing of micro-lithography structures.
first used,"Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT. !! The term computational lithography was first used by Brion Technology (now a subsidiary of ASML) in 2005 to promote their hardware accelerated full chip lithography simulation platform. !! Neither the idea nor the term are recent: Preceded by terms like algorithmizing, procedural thinking, algorithmic thinking, and computational literacy by computing pioneers like Alan Perlis and Donald Knuth, the term computational thinking was first used by Seymour Papert in 1980 and again in 1996."
brion technology,The term computational lithography was first used by Brion Technology (now a subsidiary of ASML) in 2005 to promote their hardware accelerated full chip lithography simulation platform.
term computational lithography,The term computational lithography was first used by Brion Technology (now a subsidiary of ASML) in 2005 to promote their hardware accelerated full chip lithography simulation platform.
multiple layers,"The adjective ""deep"" in deep learning refers to the use of multiple layers in the network. !! A deep Boltzmann machine (DBM) is a type of binary pairwise Markov random field (undirected probabilistic graphical model) with multiple layers of hidden random variables."
response time,"In computer architecture, the memory hierarchy separates computer storage into a hierarchy based on response time."
memory hierarchy separates computer storage,"In computer architecture, the memory hierarchy separates computer storage into a hierarchy based on response time."
memory hierarchy affects performance,"Memory hierarchy affects performance in computer architectural design, algorithm predictions, and lower level programming constructs involving locality of reference."
high performance requires considering,"Designing for high performance requires considering the restrictions of the memory hierarchy, i. e. the size and capabilities of each component."
general memory hierarchy structuring,This is a general memory hierarchy structuring.
adding complexity slows,Adding complexity slows down the memory hierarchy.
topology discovered,The Alexander horned sphere is a pathological object in topology discovered by J. W. Alexander (1924).
pathological object,The Alexander horned sphere is a pathological object in topology discovered by J. W. Alexander (1924).
alexander horned sphere,"The closure of the non-simply connected domain is called the solid Alexander horned sphere. !! The Alexander horned sphere is a pathological object in topology discovered by J. W. Alexander (1924). !! The solid Alexander horned sphere is an example of a crumpled cube; i. e. , a closed complementary domain of the embedding of a 2-sphere into the 3-sphere."
solid alexander horned sphere,"The closure of the non-simply connected domain is called the solid Alexander horned sphere. !! The solid Alexander horned sphere is an example of a crumpled cube; i. e. , a closed complementary domain of the embedding of a 2-sphere into the 3-sphere."
simply connected domain,The closure of the non-simply connected domain is called the solid Alexander horned sphere.
crumpled cube,"The solid Alexander horned sphere is an example of a crumpled cube; i. e. , a closed complementary domain of the embedding of a 2-sphere into the 3-sphere."
closed complementary domain,"The solid Alexander horned sphere is an example of a crumpled cube; i. e. , a closed complementary domain of the embedding of a 2-sphere into the 3-sphere."
scalar implementation,"Automatic vectorization, in parallel computing, is a special case of automatic parallelization, where a computer program is converted from a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once."
processes one operation,"Automatic vectorization, in parallel computing, is a special case of automatic parallelization, where a computer program is converted from a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once."
vector implementation,"Automatic vectorization, in parallel computing, is a special case of automatic parallelization, where a computer program is converted from a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once."
single pair,"Automatic vectorization, in parallel computing, is a special case of automatic parallelization, where a computer program is converted from a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once."
multiple pairs,"Automatic vectorization, in parallel computing, is a special case of automatic parallelization, where a computer program is converted from a scalar implementation, which processes a single pair of operands at a time, to a vector implementation, which processes one operation on multiple pairs of operands at once."
vector operations perform additions,"These vector operations perform additions on blocks of elements from the arrays a, b and c. Automatic vectorization is a major research topic in computer science."
major research topic,"These vector operations perform additions on blocks of elements from the arrays a, b and c. Automatic vectorization is a major research topic in computer science."
parallel operations,"So, many optimizing compilers perform automatic vectorization, where parts of sequential programs are transformed into parallel operations."
must exactly preserve program behavior,"Automatic vectorization, like any loop optimization or other compile-time optimization, must exactly preserve program behavior."
recursively cutting,Median cut is an algorithm to sort data of an arbitrary number of dimensions into series of sets by recursively cutting each set of data at the median point along the longest dimension.
longest dimension,Median cut is an algorithm to sort data of an arbitrary number of dimensions into series of sets by recursively cutting each set of data at the median point along the longest dimension.
sort data,Median cut is an algorithm to sort data of an arbitrary number of dimensions into series of sets by recursively cutting each set of data at the median point along the longest dimension.
arbitrary number,"Median cut is an algorithm to sort data of an arbitrary number of dimensions into series of sets by recursively cutting each set of data at the median point along the longest dimension. !! The Distributed Tree Search Algorithm (also known as KorfFerguson algorithm) was created to solve the following problem: ""Given a tree with non-uniform branching factor and depth, search it in parallel with an arbitrary number of processors as fast as possible. """
median point along,Median cut is an algorithm to sort data of an arbitrary number of dimensions into series of sets by recursively cutting each set of data at the median point along the longest dimension.
find 256 colours,"For example, to reduce a 64k-colour image to 256 colours, median cut is used to find 256 colours that match the original data well."
colour image,"For example, to reduce a 64k-colour image to 256 colours, median cut is used to find 256 colours that match the original data well."
original data well,"For example, to reduce a 64k-colour image to 256 colours, median cut is used to find 256 colours that match the original data well."
order markov models,Variable-order Bayesian network (VOBN) models provide an important extension of both the Bayesian network models and the variable-order Markov models.
models provide,Variable-order Bayesian network (VOBN) models provide an important extension of both the Bayesian network models and the variable-order Markov models.
important extension,Variable-order Bayesian network (VOBN) models provide an important extension of both the Bayesian network models and the variable-order Markov models.
order bayesian network,Variable-order Bayesian network (VOBN) models provide an important extension of both the Bayesian network models and the variable-order Markov models.
oldest annual international conferences,Computer Graphics International (CGI) is one of the oldest annual international conferences on computer graphics.
computer graphics international,Computer Graphics International (CGI) is one of the oldest annual international conferences on computer graphics.
categorises computer network traffic according,"Traffic classification is an automated process which categorises computer network traffic according to various parameters (for example, based on port number or protocol) into a number of traffic classes."
automated process,"Traffic classification is an automated process which categorises computer network traffic according to various parameters (for example, based on port number or protocol) into a number of traffic classes. !! The purpose of query optimization, which is an automated process, is to find the way to process a given query in minimum time."
various parameters,"Traffic classification is an automated process which categorises computer network traffic according to various parameters (for example, based on port number or protocol) into a number of traffic classes."
4 different configurations,"A comprehensive comparison of various network traffic classifiers, which depend on Deep Packet Inspection (PACE, OpenDPI, 4 different configurations of L7-filter, NDPI, Libprotoident, and Cisco NBAR), is shown in the Independent Comparison of Popular DPI Tools for Traffic Classification."
cisco nbar,"A comprehensive comparison of various network traffic classifiers, which depend on Deep Packet Inspection (PACE, OpenDPI, 4 different configurations of L7-filter, NDPI, Libprotoident, and Cisco NBAR), is shown in the Independent Comparison of Popular DPI Tools for Traffic Classification."
comprehensive comparison,"A comprehensive comparison of various network traffic classifiers, which depend on Deep Packet Inspection (PACE, OpenDPI, 4 different configurations of L7-filter, NDPI, Libprotoident, and Cisco NBAR), is shown in the Independent Comparison of Popular DPI Tools for Traffic Classification."
popular dpi tools,"A comprehensive comparison of various network traffic classifiers, which depend on Deep Packet Inspection (PACE, OpenDPI, 4 different configurations of L7-filter, NDPI, Libprotoident, and Cisco NBAR), is shown in the Independent Comparison of Popular DPI Tools for Traffic Classification."
independent comparison,"A comprehensive comparison of various network traffic classifiers, which depend on Deep Packet Inspection (PACE, OpenDPI, 4 different configurations of L7-filter, NDPI, Libprotoident, and Cisco NBAR), is shown in the Independent Comparison of Popular DPI Tools for Traffic Classification."
various network traffic classifiers,"A comprehensive comparison of various network traffic classifiers, which depend on Deep Packet Inspection (PACE, OpenDPI, 4 different configurations of L7-filter, NDPI, Libprotoident, and Cisco NBAR), is shown in the Independent Comparison of Popular DPI Tools for Traffic Classification."
also present,This same problem with traffic classification is also present in multimedia traffic.
generally proven,"It's been generally proven that using methods based on neural networks, vector support machines, statistics, and the nearest neighbors are a great way to do this traffic classification, but in some specific cases some methods are better than others, for example: neural networks work better when the whole observation set is taken into account."
great way,"It's been generally proven that using methods based on neural networks, vector support machines, statistics, and the nearest neighbors are a great way to do this traffic classification, but in some specific cases some methods are better than others, for example: neural networks work better when the whole observation set is taken into account."
neural networks work better,"It's been generally proven that using methods based on neural networks, vector support machines, statistics, and the nearest neighbors are a great way to do this traffic classification, but in some specific cases some methods are better than others, for example: neural networks work better when the whole observation set is taken into account."
whole observation set,"It's been generally proven that using methods based on neural networks, vector support machines, statistics, and the nearest neighbors are a great way to do this traffic classification, but in some specific cases some methods are better than others, for example: neural networks work better when the whole observation set is taken into account."
specific cases,"It's been generally proven that using methods based on neural networks, vector support machines, statistics, and the nearest neighbors are a great way to do this traffic classification, but in some specific cases some methods are better than others, for example: neural networks work better when the whole observation set is taken into account."
using methods based,"It's been generally proven that using methods based on neural networks, vector support machines, statistics, and the nearest neighbors are a great way to do this traffic classification, but in some specific cases some methods are better than others, for example: neural networks work better when the whole observation set is taken into account."
severely hamper,"In these cases, traffic classification mechanisms identify this traffic, allowing the network operator to either block this traffic entirely, or severely hamper its operation."
traffic entirely,"In these cases, traffic classification mechanisms identify this traffic, allowing the network operator to either block this traffic entirely, or severely hamper its operation."
either block,"In these cases, traffic classification mechanisms identify this traffic, allowing the network operator to either block this traffic entirely, or severely hamper its operation."
traffic classification mechanisms identify,"In these cases, traffic classification mechanisms identify this traffic, allowing the network operator to either block this traffic entirely, or severely hamper its operation."
given observation,"In algorithmic information theory, algorithmic probability, also known as Solomonoff probability, is a mathematical method of assigning a prior probability to a given observation."
mathematical method,"In algorithmic information theory, algorithmic probability, also known as Solomonoff probability, is a mathematical method of assigning a prior probability to a given observation. !! Topology optimization is a mathematical method that optimizes material layout within a given design space, for a given set of loads, boundary conditions and constraints with the goal of maximizing the performance of the system."
prior probability,"In algorithmic information theory, algorithmic probability, also known as Solomonoff probability, is a mathematical method of assigning a prior probability to a given observation. !! Bayesian inference derives the posterior probability as a consequence of two antecedents: a prior probability and a ""likelihood function"" derived from a statistical model for the observed data."
probable hypothesis,"Algorithmic probability deals with the following questions: Given a body of data about some phenomenon that we want to understand, how can we select the most probable hypothesis of how it was caused from among all possible hypotheses and how can we evaluate the different hypotheses"
possible hypotheses,"Algorithmic probability deals with the following questions: Given a body of data about some phenomenon that we want to understand, how can we select the most probable hypothesis of how it was caused from among all possible hypotheses and how can we evaluate the different hypotheses"
algorithmic probability deals,"Algorithmic probability deals with the following questions: Given a body of data about some phenomenon that we want to understand, how can we select the most probable hypothesis of how it was caused from among all possible hypotheses and how can we evaluate the different hypotheses"
different hypotheses,"Algorithmic probability deals with the following questions: Given a body of data about some phenomenon that we want to understand, how can we select the most probable hypothesis of how it was caused from among all possible hypotheses and how can we evaluate the different hypotheses"
following questions,"Algorithmic probability deals with the following questions: Given a body of data about some phenomenon that we want to understand, how can we select the most probable hypothesis of how it was caused from among all possible hypotheses and how can we evaluate the different hypotheses"
multiple explanations,"Four principal inspirations for Solomonoff's algorithmic probability were: Occam's razor, Epicurus' principle of multiple explanations, modern computing theory (e. g. use of a universal Turing machine) and Bayes rule for prediction."
four principal inspirations,"Four principal inspirations for Solomonoff's algorithmic probability were: Occam's razor, Epicurus' principle of multiple explanations, modern computing theory (e. g. use of a universal Turing machine) and Bayes rule for prediction."
associated invariance theorem around 1960,"Solomonoff invented the concept of algorithmic probability with its associated invariance theorem around 1960, publishing a report on it: ""A Preliminary Report on a General Theory of Inductive Inference. """
general theory,"Solomonoff invented the concept of algorithmic probability with its associated invariance theorem around 1960, publishing a report on it: ""A Preliminary Report on a General Theory of Inductive Inference. """
preliminary report,"Solomonoff invented the concept of algorithmic probability with its associated invariance theorem around 1960, publishing a report on it: ""A Preliminary Report on a General Theory of Inductive Inference. """
solomonoff invented,"Solomonoff invented the concept of algorithmic probability with its associated invariance theorem around 1960, publishing a report on it: ""A Preliminary Report on a General Theory of Inductive Inference. """
compute something starting,The algorithmic probability of any given finite output prefix q is the sum of the probabilities of the programs that compute something starting with q.
given finite output prefix q,The algorithmic probability of any given finite output prefix q is the sum of the probabilities of the programs that compute something starting with q.
prove properties,"In formal program verification, particularly the Floyd-Hoare approach, loop invariants are expressed by formal predicate logic and used to prove properties of loops and by extension algorithms that employ loops (usually correctness properties)."
employ loops,"In formal program verification, particularly the Floyd-Hoare approach, loop invariants are expressed by formal predicate logic and used to prove properties of loops and by extension algorithms that employ loops (usually correctness properties)."
usually correctness properties,"In formal program verification, particularly the Floyd-Hoare approach, loop invariants are expressed by formal predicate logic and used to prove properties of loops and by extension algorithms that employ loops (usually correctness properties)."
hoare approach,"In formal program verification, particularly the Floyd-Hoare approach, loop invariants are expressed by formal predicate logic and used to prove properties of loops and by extension algorithms that employ loops (usually correctness properties)."
deeper purpose,"From a programming methodology viewpoint, the loop invariant can be viewed as a more abstract specification of the loop, which characterizes the deeper purpose of the loop beyond the details of this implementation."
loop beyond,"From a programming methodology viewpoint, the loop invariant can be viewed as a more abstract specification of the loop, which characterizes the deeper purpose of the loop beyond the details of this implementation."
programming methodology viewpoint,"From a programming methodology viewpoint, the loop invariant can be viewed as a more abstract specification of the loop, which characterizes the deeper purpose of the loop beyond the details of this implementation."
abstract specification,"From a programming methodology viewpoint, the loop invariant can be viewed as a more abstract specification of the loop, which characterizes the deeper purpose of the loop beyond the details of this implementation."
given loop,"In fact, the loop invariant is often the same as the inductive hypothesis to be proved for a recursive program equivalent to a given loop."
artificial general intelligence,"Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence. !! In 2017 Elon Musk advocated regulation of algorithms in the context of the existential risk from artificial general intelligence."
human brain,"In general, the term cognitive computing has been used to refer to new hardware and/or software that mimics the functioning of the human brain (2004) and helps to improve human decision-making. !! Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence."
intelligence realm,"Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence."
real time,"This article describes in further detail the Geo Warping of radar video images in real time. !! Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence. !! This section explains the actual geo warping or re-projection process when applied to radar video in real time."
distributed computing project undertaken,"Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence."
term goal,"Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence."
residual network may,"In the context of residual neural networks, a non-residual network may be described as a plain network."
general task,"Cluster analysis itself is not one specific algorithm, but the general task to be solved."
one specific algorithm,"Cluster analysis itself is not one specific algorithm, but the general task to be solved."
interactive multi,"Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure."
automatic task,"Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure."
involves trial,"Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure."
joseph zubin,Cluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.
trait theory classification,Cluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.
cattell beginning,Cluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.
robert tryon,Cluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.
personality psychology,"Factor analysis is commonly used in psychometrics, personality psychology, biology, marketing, product management, operations research, finance, and machine learning. !! Cluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology."
famously used,Cluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.
theoretical foundation,"In the data mining community these methods are recognized as a theoretical foundation of cluster analysis, but often considered obsolete."
often considered obsolete,"In the data mining community these methods are recognized as a theoretical foundation of cluster analysis, but often considered obsolete."
data mining community,"In the data mining community these methods are recognized as a theoretical foundation of cluster analysis, but often considered obsolete."
systemic functional grammar,"The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts. !! Systemic functional grammar (SFG) is a form of grammatical description originated by Michael Halliday. !! Another way to understand the difference in concerns between systemic functional grammar and most variants of generative grammar is through Chomsky's claim that ""linguistics is a sub-branch of psychology"". !! Since the principal aim of systemic functional grammar is to represent the grammatical system as a resource for making meaning, it addresses different concerns. !! Systemic functional grammar deals with all of these areas of meaning equally within the grammatical system itself."
grammatical description originated,Systemic functional grammar (SFG) is a form of grammatical description originated by Michael Halliday.
systemic functional grammar deals,Systemic functional grammar deals with all of these areas of meaning equally within the grammatical system itself.
meaning equally within,Systemic functional grammar deals with all of these areas of meaning equally within the grammatical system itself.
grammatical system,"Systemic functional grammar deals with all of these areas of meaning equally within the grammatical system itself. !! Since the principal aim of systemic functional grammar is to represent the grammatical system as a resource for making meaning, it addresses different concerns."
addresses different concerns,"Since the principal aim of systemic functional grammar is to represent the grammatical system as a resource for making meaning, it addresses different concerns."
principal aim,"Since the principal aim of systemic functional grammar is to represent the grammatical system as a resource for making meaning, it addresses different concerns."
making meaning,"Since the principal aim of systemic functional grammar is to represent the grammatical system as a resource for making meaning, it addresses different concerns."
another way,"Another way to understand the difference in concerns between systemic functional grammar and most variants of generative grammar is through Chomsky's claim that ""linguistics is a sub-branch of psychology""."
generative grammar,"In linguistics, transformational grammar (TG) or transformational-generative grammar (TGG) is part of the theory of generative grammar, especially of natural languages. !! Another way to understand the difference in concerns between systemic functional grammar and most variants of generative grammar is through Chomsky's claim that ""linguistics is a sub-branch of psychology""."
grammatical accounts,The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts.
similarly orient,The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts.
encourage several,The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts.
structural accounts,The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts.
perceived weaknesses,The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts.
oriented infrastructure provides,A service-oriented infrastructure provides a foundation for IT services.
infrastructure services via,"Key aspects of service-oriented infrastructure include industrialisation and virtualisation, providing IT infrastructure services via a pool of resources (web servers, application servers, database servers, servers, storage instances) instead of through discrete instances."
oriented infrastructure include industrialisation,"Key aspects of service-oriented infrastructure include industrialisation and virtualisation, providing IT infrastructure services via a pool of resources (web servers, application servers, database servers, servers, storage instances) instead of through discrete instances."
key aspects,"Key aspects of service-oriented infrastructure include industrialisation and virtualisation, providing IT infrastructure services via a pool of resources (web servers, application servers, database servers, servers, storage instances) instead of through discrete instances."
discrete instances,"Key aspects of service-oriented infrastructure include industrialisation and virtualisation, providing IT infrastructure services via a pool of resources (web servers, application servers, database servers, servers, storage instances) instead of through discrete instances."
oriented infrastructure,"While the IT industry has widely adopted service-oriented architecture (SOA), service-oriented infrastructure or SOI has lagged in its adoption."
oriented architecture,"While the IT industry has widely adopted service-oriented architecture (SOA), service-oriented infrastructure or SOI has lagged in its adoption. !! Service-oriented modeling is the discipline of modeling business and software systems, for the purpose of designing and specifying service-oriented business systems within a variety of architectural styles and paradigms, such as application architecture, service-oriented architecture, microservices, and cloud computing."
soa  service,"While the IT industry has widely adopted service-oriented architecture (SOA), service-oriented infrastructure or SOI has lagged in its adoption."
widely adopted service,"While the IT industry has widely adopted service-oriented architecture (SOA), service-oriented infrastructure or SOI has lagged in its adoption."
simulate light,Computer graphics lighting is the collection of techniques used to simulate light in computer graphics scenes.
expression network analysis,"Weighted correlation network analysis, also known as weighted gene co-expression network analysis (WGCNA), is a widely used data mining method especially for studying biological networks based on pairwise correlations between variables."
studying biological networks based,"Weighted correlation network analysis, also known as weighted gene co-expression network analysis (WGCNA), is a widely used data mining method especially for studying biological networks based on pairwise correlations between variables."
using formalized arguments,"In artificial intelligence and related fields, an argumentation framework is a way to deal with contentious information and draw conclusions from it using formalized arguments."
argumentation framework,"There exist some extensions of the Dung's framework, like the logic-based argumentation frameworks or the value-based argumentation frameworks. !! In concrete terms, you represent an argumentation framework with a directed graph such that the nodes are the arguments, and the arrows represent the attack relation. !! There exists several criteria of equivalence between argumentation frameworks. !! In artificial intelligence and related fields, an argumentation framework is a way to deal with contentious information and draw conclusions from it using formalized arguments. !! In an abstract argumentation framework, entry-level information is a set of abstract arguments that, for instance, represent data or a proposition."
contentious information,"In artificial intelligence and related fields, an argumentation framework is a way to deal with contentious information and draw conclusions from it using formalized arguments."
draw conclusions,"In artificial intelligence and related fields, an argumentation framework is a way to deal with contentious information and draw conclusions from it using formalized arguments."
level information,"In an abstract argumentation framework, entry-level information is a set of abstract arguments that, for instance, represent data or a proposition."
represent data,"In an abstract argumentation framework, entry-level information is a set of abstract arguments that, for instance, represent data or a proposition."
arrows represent,"In concrete terms, you represent an argumentation framework with a directed graph such that the nodes are the arguments, and the arrows represent the attack relation."
concrete terms,"In concrete terms, you represent an argumentation framework with a directed graph such that the nodes are the arguments, and the arrows represent the attack relation."
attack relation,"In concrete terms, you represent an argumentation framework with a directed graph such that the nodes are the arguments, and the arrows represent the attack relation."
based argumentation frameworks,"There exist some extensions of the Dung's framework, like the logic-based argumentation frameworks or the value-based argumentation frameworks."
exists several criteria,There exists several criteria of equivalence between argumentation frameworks.
intrinsic dimension,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension."
dimensional representation retains,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension."
meaningful properties,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension."
ideally close,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension."
large numbers,"Dimensionality reduction is common in fields that deal with large numbers of observations and/or large numbers of variables, such as signal processing, speech recognition, neuroinformatics, and bioinformatics."
intermediate step,"Dimensionality reduction can be used for noise reduction, data visualization, cluster analysis, or as an intermediate step to facilitate other analyses. !! Several pathfinding algorithms, including Dijkstra's algorithm and the A* search algorithm, internally build a spanning tree as an intermediate step in solving the problem."
data transformation may,"The data transformation may be linear, as in principal component analysis (PCA), but many nonlinear dimensionality reduction techniques also exist."
user computing,"Examples of end-user computing are systems built using fourth-generation programming languages, such as MAPPER or SQL, or one of the fifth-generation programming languages, such as ICAD. !! End-user computing (EUC) refers to systems in which non-programmers can create working applications. !! End-user computing can range in complexity from users simply clicking a series of buttons, to citizen developers writing scripts in a controlled scripting language, to being able to modify and execute code directly."
create working applications,End-user computing (EUC) refers to systems in which non-programmers can create working applications.
citizen developers writing scripts,"End-user computing can range in complexity from users simply clicking a series of buttons, to citizen developers writing scripts in a controlled scripting language, to being able to modify and execute code directly."
execute code directly,"End-user computing can range in complexity from users simply clicking a series of buttons, to citizen developers writing scripts in a controlled scripting language, to being able to modify and execute code directly."
users simply clicking,"End-user computing can range in complexity from users simply clicking a series of buttons, to citizen developers writing scripts in a controlled scripting language, to being able to modify and execute code directly."
generation programming languages,"Examples of end-user computing are systems built using fourth-generation programming languages, such as MAPPER or SQL, or one of the fifth-generation programming languages, such as ICAD."
systems built using fourth,"Examples of end-user computing are systems built using fourth-generation programming languages, such as MAPPER or SQL, or one of the fifth-generation programming languages, such as ICAD."
iconic versus language interfaces,"Some of the issues related to end-user computing concern software architecture (iconic versus language interfaces, open versus closed, and others)."
user computing concern software architecture,"Some of the issues related to end-user computing concern software architecture (iconic versus language interfaces, open versus closed, and others)."
open versus closed,"Some of the issues related to end-user computing concern software architecture (iconic versus language interfaces, open versus closed, and others)."
system affairs,End-user computing allows more user-input into system affairs that can range from personalization to full-fledged ownership of a system.
user computing allows,End-user computing allows more user-input into system affairs that can range from personalization to full-fledged ownership of a system.
fledged ownership,End-user computing allows more user-input into system affairs that can range from personalization to full-fledged ownership of a system.
output quantity lies,"The specific applications of log-linear models are where the output quantity lies in the range 0 to , for values of the independent variables X, or more immediately, the transformed quantities fi(X) in the range to +."
transformed quantities fi,"The specific applications of log-linear models are where the output quantity lies in the range 0 to , for values of the independent variables X, or more immediately, the transformed quantities fi(X) in the range to +."
linear models,"The specific applications of log-linear models are where the output quantity lies in the range 0 to , for values of the independent variables X, or more immediately, the transformed quantities fi(X) in the range to +."
specific applications,"The specific applications of log-linear models are where the output quantity lies in the range 0 to , for values of the independent variables X, or more immediately, the transformed quantities fi(X) in the range to +."
independent variables x,"The specific applications of log-linear models are where the output quantity lies in the range 0 to , for values of the independent variables X, or more immediately, the transformed quantities fi(X) in the range to +."
also called synthetic imagination,"Artificial imagination, also called synthetic imagination or machine imagination, is defined as the artificial simulation of human imagination by general or special purpose computers or artificial neural networks."
human imagination,"Artificial imagination, also called synthetic imagination or machine imagination, is defined as the artificial simulation of human imagination by general or special purpose computers or artificial neural networks."
term artificial imagination,The term artificial imagination is also used to describe a property of machines or programs.
including computer science,"Artificial imagination research uses tools and insights from many fields, including computer science, rhetoric, psychology, creative arts, philosophy, neuroscience, affective computing, Artificial Intelligence, cognitive science, linguistics, operations research, creative writing, probability and logic."
creative writing,"Artificial imagination research uses tools and insights from many fields, including computer science, rhetoric, psychology, creative arts, philosophy, neuroscience, affective computing, Artificial Intelligence, cognitive science, linguistics, operations research, creative writing, probability and logic."
artificial imagination research uses tools,"Artificial imagination research uses tools and insights from many fields, including computer science, rhetoric, psychology, creative arts, philosophy, neuroscience, affective computing, Artificial Intelligence, cognitive science, linguistics, operations research, creative writing, probability and logic."
creative arts,"Artificial imagination research uses tools and insights from many fields, including computer science, rhetoric, psychology, creative arts, philosophy, neuroscience, affective computing, Artificial Intelligence, cognitive science, linguistics, operations research, creative writing, probability and logic."
artificial imagination may evolve,"Some articles on the topic speculate on how artificial imagination may evolve to create an artificial world ""people may be comfortable enough to escape from the real world""."
topic speculate,"Some articles on the topic speculate on how artificial imagination may evolve to create an artificial world ""people may be comfortable enough to escape from the real world""."
artificial world,"Some articles on the topic speculate on how artificial imagination may evolve to create an artificial world ""people may be comfortable enough to escape from the real world""."
people may,"Some articles on the topic speculate on how artificial imagination may evolve to create an artificial world ""people may be comfortable enough to escape from the real world""."
comfortable enough,"Some articles on the topic speculate on how artificial imagination may evolve to create an artificial world ""people may be comfortable enough to escape from the real world""."
using artificial neural networks,Some researchers such as G. Schleis and M. Rizki have focused on using artificial neural networks to simulate artificial imagination.
simulate artificial imagination,Some researchers such as G. Schleis and M. Rizki have focused on using artificial neural networks to simulate artificial imagination.
loosely coupling software modules,"In object-oriented design, the dependency inversion principle is a specific methodology for loosely coupling software modules."
specific methodology,"In object-oriented design, the dependency inversion principle is a specific methodology for loosely coupling software modules."
single concept,"In many projects the dependency inversion principle and pattern are considered as a single concept that should be generalized, i. e. , applied to all interfaces between software modules."
many projects,"In many projects the dependency inversion principle and pattern are considered as a single concept that should be generalized, i. e. , applied to all interfaces between software modules."
may 1996 entitled,"The dependency inversion principle was postulated by Robert C. Martin and described in several publications including the paper Object Oriented Design Quality Metrics: an analysis of dependencies, an article appearing in the C++ Report in May 1996 entitled The Dependency Inversion Principle, and the books Agile Software Development, Principles, Patterns, and Practices, and Agile Principles, Patterns, and Practices in C#."
several publications including,"The dependency inversion principle was postulated by Robert C. Martin and described in several publications including the paper Object Oriented Design Quality Metrics: an analysis of dependencies, an article appearing in the C++ Report in May 1996 entitled The Dependency Inversion Principle, and the books Agile Software Development, Principles, Patterns, and Practices, and Agile Principles, Patterns, and Practices in C#."
article appearing,"The dependency inversion principle was postulated by Robert C. Martin and described in several publications including the paper Object Oriented Design Quality Metrics: an analysis of dependencies, an article appearing in the C++ Report in May 1996 entitled The Dependency Inversion Principle, and the books Agile Software Development, Principles, Patterns, and Practices, and Agile Principles, Patterns, and Practices in C#."
books agile software development,"The dependency inversion principle was postulated by Robert C. Martin and described in several publications including the paper Object Oriented Design Quality Metrics: an analysis of dependencies, an article appearing in the C++ Report in May 1996 entitled The Dependency Inversion Principle, and the books Agile Software Development, Principles, Patterns, and Practices, and Agile Principles, Patterns, and Practices in C#."
uncle bob  jan 2016,"A Little Architecture, Robert C. Martin (Uncle Bob), Jan 2016 - a blog on significance of Dependency Inversion Principle in software architecture"
little architecture,"A Little Architecture, Robert C. Martin (Uncle Bob), Jan 2016 - a blog on significance of Dependency Inversion Principle in software architecture"
longest common subsequence problem,"The longest increasing subsequence problem is closely related to the longest common subsequence problem, which has a quadratic time dynamic programming solution: the longest increasing subsequence of a sequence S is the longest common subsequence of S and T, where T is the result of sorting S. However, for the special case in which the input is a permutation of the integers 1, 2, . !! The longest common subsequence problem is a classic computer science problem, the basis of data comparison programs such as the diff utility, and has applications in computational linguistics and bioinformatics. !! Simplified mathematical models of the longest common subsequence problem have been shown to be controlled by the TracyWidom distribution."
classic computer science problem,"The longest common subsequence problem is a classic computer science problem, the basis of data comparison programs such as the diff utility, and has applications in computational linguistics and bioinformatics."
simplified mathematical models,Simplified mathematical models of the longest common subsequence problem have been shown to be controlled by the TracyWidom distribution.
typically real numbers,Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.
take continuous values,Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.
called regression trees,Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees.
umbrella term used,"The term classification and regression tree (CART) analysis is an umbrella term used to refer to either of the above procedures, first introduced by Breiman et al."
breiman et al,"The term classification and regression tree (CART) analysis is an umbrella term used to refer to either of the above procedures, first introduced by Breiman et al."
incorrectly labeled,"Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity (named after Italian mathematician Corrado Gini) is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset."
set would,"Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity (named after Italian mathematician Corrado Gini) is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset."
randomly chosen element,"Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity (named after Italian mathematician Corrado Gini) is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset."
italian mathematician corrado gini,"Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity (named after Italian mathematician Corrado Gini) is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset."
randomly labeled according,"Used by the CART (classification and regression tree) algorithm for classification trees, Gini impurity (named after Italian mathematician Corrado Gini) is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset."
regression tree  meaning,"Introduced in CART, variance reduction is often employed in cases where the target variable is continuous (regression tree), meaning that use of many other metrics would first require discretization before being applied."
metrics would first require discretization,"Introduced in CART, variance reduction is often employed in cases where the target variable is continuous (regression tree), meaning that use of many other metrics would first require discretization before being applied."
overheads associated,"In compiler theory, loop optimization is the process of increasing execution speed and reducing the overheads associated with loops."
increasing execution speed,"In compiler theory, loop optimization is the process of increasing execution speed and reducing the overheads associated with loops."
since instructions inside loops,"Since instructions inside loops can be executed repeatedly, it is frequently not possible to give a bound on the number of instruction executions that will be impacted by a loop optimization."
instruction executions,"Since instructions inside loops can be executed repeatedly, it is frequently not possible to give a bound on the number of instruction executions that will be impacted by a loop optimization."
executed repeatedly,"Since instructions inside loops can be executed repeatedly, it is frequently not possible to give a bound on the number of instruction executions that will be impacted by a loop optimization."
presents challenges,"This presents challenges when reasoning about the correctness and benefits of a loop optimization, specifically the representations of the computation being optimized and the optimization(s) being performed."
associated test,"Loop optimization can be viewed as the application of a sequence of specific loop transformations (listed below or in Compiler transformations for high-performance computing) to the source code or intermediate representation, with each transformation having an associated test for legality."
specific loop transformations,"Loop optimization can be viewed as the application of a sequence of specific loop transformations (listed below or in Compiler transformations for high-performance computing) to the source code or intermediate representation, with each transformation having an associated test for legality."
performance computing,"Loop optimization can be viewed as the application of a sequence of specific loop transformations (listed below or in Compiler transformations for high-performance computing) to the source code or intermediate representation, with each transformation having an associated test for legality."
based approach,"The graph-based approach to Laplacian regularization is to put in relation with finite difference method. !! The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information. !! The term ""path coefficient"" derives from Wright (1921), where a particular diagram-based approach was used to consider the relations between variables in a multivariate system. !! Compared with the grid-based approach, the Monte Carlo localization is more accurate because the state represented in samples is not discretized. !! The boundaries of the polytopes, the data dependencies, and the transformations are often described using systems of constraints, and this approach is often referred to as a constraint-based approach to loop optimization. !! The typical articulated body pose estimation system involves a model-based approach, in which the pose estimation is achieved by maximizing/minimizing a similarity/dissimilarity between an observation (input) and a template model."
data dependencies,"The boundaries of the polytopes, the data dependencies, and the transformations are often described using systems of constraints, and this approach is often referred to as a constraint-based approach to loop optimization."
often described using systems,"The boundaries of the polytopes, the data dependencies, and the transformations are often described using systems of constraints, and this approach is often referred to as a constraint-based approach to loop optimization."
also allows pairs,"In computer science, a binomial heap is a data structure that acts as a priority queue but also allows pairs of heaps to be merged."
jean vuillemin,Binomial heaps were invented in 1978 by Jean Vuillemin.
conventional heaps,"This feature is central to the merge operation of a binomial heap, which is its major advantage over other conventional heaps."
major advantage,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network. !! This feature is central to the merge operation of a binomial heap, which is its major advantage over other conventional heaps."
see figure,", and thus a binomial heap with 13 nodes will consist of three binomial trees of orders 3, 2, and 0 (see figure below)."
three binomial trees,", and thus a binomial heap with 13 nodes will consist of three binomial trees of orders 3, 2, and 0 (see figure below)."
binomial heap containing 13 nodes,Example of a binomial heap containing 13 nodes with distinct keys.
distinct keys,Example of a binomial heap containing 13 nodes with distinct keys.
robotics middleware,"RoSta: a European project reaching out to the robotics community to get clearer insights into robotics middleware and architectures. !! Robotics middleware is middleware to be used in complex robot control software systems. !! A wide variety of projects for robotics middleware exist, but no one of these dominates - and in fact many robotic systems do not use any middleware."
complex robot control software systems,Robotics middleware is middleware to be used in complex robot control software systems.
robotics middleware exist,"A wide variety of projects for robotics middleware exist, but no one of these dominates - and in fact many robotic systems do not use any middleware."
fact many robotic systems,"A wide variety of projects for robotics middleware exist, but no one of these dominates - and in fact many robotic systems do not use any middleware."
robotics community,RoSta: a European project reaching out to the robotics community to get clearer insights into robotics middleware and architectures.
european project reaching,RoSta: a European project reaching out to the robotics community to get clearer insights into robotics middleware and architectures.
get clearer insights,RoSta: a European project reaching out to the robotics community to get clearer insights into robotics middleware and architectures.
propositions qualified,"In logic, temporal logic is any system of rules and symbolism for representing, and reasoning about, propositions qualified in terms of time (for example, ""I am always hungry"", ""I will eventually be hungry"", or ""I will be hungry until I eat something"")."
eat something,"In logic, temporal logic is any system of rules and symbolism for representing, and reasoning about, propositions qualified in terms of time (for example, ""I am always hungry"", ""I will eventually be hungry"", or ""I will be hungry until I eat something"")."
always hungry,"In logic, temporal logic is any system of rules and symbolism for representing, and reasoning about, propositions qualified in terms of time (for example, ""I am always hungry"", ""I will eventually be hungry"", or ""I will be hungry until I eat something"")."
tense logic,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
important contributions,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
temporal logic introduced,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
hans kamp,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
sometimes also used,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
arthur prior,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
state requirements,"Temporal logic has found an important application in formal verification, where it is used to state requirements of hardware or software systems."
important application,"Temporal logic has found an important application in formal verification, where it is used to state requirements of hardware or software systems."
timein contrast,"In a temporal logic, a statement can have a truth value that varies in timein contrast with an atemporal logic, which applies only to statements whose truth values are constant in time."
statements whose truth values,"In a temporal logic, a statement can have a truth value that varies in timein contrast with an atemporal logic, which applies only to statements whose truth values are constant in time."
atemporal logic,"In a temporal logic, a statement can have a truth value that varies in timein contrast with an atemporal logic, which applies only to statements whose truth values are constant in time."
important class,"This is an important class of pseudo-boolean functions, because they can be minimized in polynomial time."
formal language,"In philosophy, the term formal ontology is used to refer to an ontology defined by axioms in a formal language with the goal to provide an unbiased (domain- and application-independent) view on reality, which can help the modeler of domain- or application-specific ontologies (information science) to avoid possibly erroneous ontological assumptions encountered in modeling large-scale ontologies. !! Type inference refers to the automatic detection of the type of an expression in a formal language. !! In computer science, particularly in human-computer interaction, presentation semantics specify how a particular piece of a formal language is represented in a distinguished manner accessible to human senses, usually human vision. !! In computer science, an abstract syntax tree (AST), or just syntax tree, is a tree representation of the abstract syntactic structure of text (often source code) written in a formal language."
type inference refers,Type inference refers to the automatic detection of the type of an expression in a formal language.
automatic detection,Type inference refers to the automatic detection of the type of an expression in a formal language.
detect conflicting,"In such a setting, type inference cannot only become more complex, but also more helpful, as it allows to collect a complete description of everything in a composed scene, while still being able to detect conflicting or unintended uses."
type inference cannot,"In such a setting, type inference cannot only become more complex, but also more helpful, as it allows to collect a complete description of everything in a composed scene, while still being able to detect conflicting or unintended uses."
complete description,"In such a setting, type inference cannot only become more complex, but also more helpful, as it allows to collect a complete description of everything in a composed scene, while still being able to detect conflicting or unintended uses."
unintended uses,"In such a setting, type inference cannot only become more complex, but also more helpful, as it allows to collect a complete description of everything in a composed scene, while still being able to detect conflicting or unintended uses."
composed scene,"In such a setting, type inference cannot only become more complex, but also more helpful, as it allows to collect a complete description of everything in a composed scene, while still being able to detect conflicting or unintended uses."
accomplished type inference,"If there is a way to derive a type for E, then we have accomplished type inference."
include type inference include c  11,"Some languages that include type inference include C++11, C# (starting with version 3."
compiler analysis approach used,"In computer science, array access analysis is a compiler analysis approach used to decide the read and write access patterns to elements or portions of arrays."
write access patterns,"In computer science, array access analysis is a compiler analysis approach used to decide the read and write access patterns to elements or portions of arrays."
procedure level,"Array access analysis aims to obtain the knowledge of which portions or even which elements of the array are accessed by a given code segment (basic block, loop, or even at the procedure level)."
array access analysis aims,"Array access analysis aims to obtain the knowledge of which portions or even which elements of the array are accessed by a given code segment (basic block, loop, or even at the procedure level)."
given code segment,"Array access analysis aims to obtain the knowledge of which portions or even which elements of the array are accessed by a given code segment (basic block, loop, or even at the procedure level)."
largely categorized,Array access analysis can be largely categorized into exact (or reference-list-based) and summary methods for different tradeoffs of accuracy and complexity.
different tradeoffs,Array access analysis can be largely categorized into exact (or reference-list-based) and summary methods for different tradeoffs of accuracy and complexity.
summary methods,Array access analysis can be largely categorized into exact (or reference-list-based) and summary methods for different tradeoffs of accuracy and complexity.
atom images,Typical exact array access analysis include linearization and atom images.
interdisciplinary computational science,"Computational human modeling is an interdisciplinary computational science that links the diverse fields of artificial intelligence, cognitive science, and computer vision with machine learning, mathematics, and cognitive psychology."
diverse fields,"Computational human modeling is an interdisciplinary computational science that links the diverse fields of artificial intelligence, cognitive science, and computer vision with machine learning, mathematics, and cognitive psychology."
cognitive psychology,"Interruption science is a branch of human factors psychology and emerged from humancomputer interaction and cognitive psychology. !! As it relates to cognitive psychology, spreading activation is the theory of how the brain iterates through a network of associated ideas to retrieve specific information. !! Computational human modeling is an interdisciplinary computational science that links the diverse fields of artificial intelligence, cognitive science, and computer vision with machine learning, mathematics, and cognitive psychology. !! Spreading activation in semantic networks as a model were invented in cognitive psychology to model the fan out effect."
computational human modeling emphasizes descriptions,Computational human modeling emphasizes descriptions of human for A. I. research and applications.
social interactions,"Research in computational human modeling can include computer vision studies on identify (face recognition), attributes (gender, age, skin color), expressions, geometry (3D face modeling, 3D body modeling), and activity (pose, gaze, actions, and social interactions)."
skin color  expressions,"Research in computational human modeling can include computer vision studies on identify (face recognition), attributes (gender, age, skin color), expressions, geometry (3D face modeling, 3D body modeling), and activity (pose, gaze, actions, and social interactions)."
include computer vision studies,"Research in computational human modeling can include computer vision studies on identify (face recognition), attributes (gender, age, skin color), expressions, geometry (3D face modeling, 3D body modeling), and activity (pose, gaze, actions, and social interactions)."
face recognition  attributes,"Research in computational human modeling can include computer vision studies on identify (face recognition), attributes (gender, age, skin color), expressions, geometry (3D face modeling, 3D body modeling), and activity (pose, gaze, actions, and social interactions)."
algorithmsthe amount,"In computer science, the analysis of algorithms is the process of finding the computational complexity of algorithmsthe amount of time, storage, or other resources needed to execute them."
donald knuth,"The term ""analysis of algorithms"" was coined by Donald Knuth. !! Neither the idea nor the term are recent: Preceded by terms like algorithmizing, procedural thinking, algorithmic thinking, and computational literacy by computing pioneers like Alan Perlis and Donald Knuth, the term computational thinking was first used by Seymour Papert in 1980 and again in 1996."
arbitrarily large input,"In theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i. e. , to estimate the complexity function for arbitrarily large input."
complexity function,"In theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i. e. , to estimate the complexity function for arbitrarily large input."
theoretical analysis,"In theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i. e. , to estimate the complexity function for arbitrarily large input."
asymptotic sense,"In theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i. e. , to estimate the complexity function for arbitrarily large input."
algorithms typically focuses,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
practice always limited,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
practical applications constant factors,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
asymptotic performance,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
world data,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
elementary level,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
similar results,Similar results are true when using a bagged nearest neighbour classifier.
distinguished manner accessible,"In computer science, particularly in human-computer interaction, presentation semantics specify how a particular piece of a formal language is represented in a distinguished manner accessible to human senses, usually human vision."
particular piece,"In computer science, particularly in human-computer interaction, presentation semantics specify how a particular piece of a formal language is represented in a distinguished manner accessible to human senses, usually human vision."
human senses,"In computer science, particularly in human-computer interaction, presentation semantics specify how a particular piece of a formal language is represented in a distinguished manner accessible to human senses, usually human vision."
usually human vision,"In computer science, particularly in human-computer interaction, presentation semantics specify how a particular piece of a formal language is represented in a distinguished manner accessible to human senses, usually human vision."
presentation semantics specify,"In computer science, particularly in human-computer interaction, presentation semantics specify how a particular piece of a formal language is represented in a distinguished manner accessible to human senses, usually human vision."
bold typeface,</bold> must render the text between these constructs using some bold typeface is a specification of presentation semantics for that syntax.
constructs using,</bold> must render the text between these constructs using some bold typeface is a specification of presentation semantics for that syntax.
must render,</bold> must render the text between these constructs using some bold typeface is a specification of presentation semantics for that syntax.
many markup languages,"Many markup languages, including HTML, DSSSL, and XSL-FO, have presentation semantics, but others, such as XML, do not."
including html,"Many markup languages, including HTML, DSSSL, and XSL-FO, have presentation semantics, but others, such as XML, do not."
defines document content,One of the main goals of style sheet languages is to separate the syntax that defines document content from the syntax endowed with presentation semantics.
syntax endowed,One of the main goals of style sheet languages is to separate the syntax that defines document content from the syntax endowed with presentation semantics.
main goals,One of the main goals of style sheet languages is to separate the syntax that defines document content from the syntax endowed with presentation semantics.
based clustering,"In density-based clustering, clusters are defined as areas of higher density than the remainder of the data set. !! Connectivity-based clustering is a whole family of methods that differ by the way distances are computed. !! Connectivity-based clustering, also known as hierarchical clustering, is based on the core idea of objects being more related to nearby objects than to objects farther away."
higher density,"In density-based clustering, clusters are defined as areas of higher density than the remainder of the data set."
optics family,"Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC, hierarchical subspace clustering and DiSH) and correlation clustering (HiCO, hierarchical correlation clustering, 4C using ""correlation connectivity"" and ERiC exploring hierarchical density-based correlation clusters)."
correlation connectivity,"Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC, hierarchical subspace clustering and DiSH) and correlation clustering (HiCO, hierarchical correlation clustering, 4C using ""correlation connectivity"" and ERiC exploring hierarchical density-based correlation clusters)."
based correlation clusters,"Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC, hierarchical subspace clustering and DiSH) and correlation clustering (HiCO, hierarchical correlation clustering, 4C using ""correlation connectivity"" and ERiC exploring hierarchical density-based correlation clusters)."
based clustering methods,"Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC, hierarchical subspace clustering and DiSH) and correlation clustering (HiCO, hierarchical correlation clustering, 4C using ""correlation connectivity"" and ERiC exploring hierarchical density-based correlation clusters)."
subspace clustering,"This led to new clustering algorithms for high-dimensional data that focus on subspace clustering (where only some attributes are used, and cluster models include the relevant attributes for the cluster) and correlation clustering that also looks for arbitrary rotated (""correlated"") subspace clusters that can be modeled by giving a correlation of their attributes. !! Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC, hierarchical subspace clustering and DiSH) and correlation clustering (HiCO, hierarchical correlation clustering, 4C using ""correlation connectivity"" and ERiC exploring hierarchical density-based correlation clusters)."
eric exploring hierarchical density,"Ideas from density-based clustering methods (in particular the DBSCAN/OPTICS family of algorithms) have been adapted to subspace clustering (HiSC, hierarchical subspace clustering and DiSH) and correlation clustering (HiCO, hierarchical correlation clustering, 4C using ""correlation connectivity"" and ERiC exploring hierarchical density-based correlation clusters)."
executed within,Action model learning (sometimes abbreviated action learning) is an area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment.
sometimes abbreviated action learning,Action model learning (sometimes abbreviated action learning) is an area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment.
new knowledge,"Action model learning is a form of inductive reasoning, where new knowledge is generated based on agent's observations."
generated based,"Action model learning is a form of inductive reasoning, where new knowledge is generated based on agent's observations."
prone task,"Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments)."
usual motivation,"Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments)."
manual specification,"Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments)."
time consuming,"Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments)."
older paper,"In the older paper from 1992, the action model learning was studied as an extension of reinforcement learning."
despite mutual relevance,"Despite mutual relevance of the topics, action model learning is usually not addressed on planning conferences like ICAPS."
planning conferences like icaps,"Despite mutual relevance of the topics, action model learning is usually not addressed on planning conferences like ICAPS."
new dimensionthe template peacock term,Multimodal sentiment analysis is a new dimensionThe template Peacock term is being considered for merging.
complex models,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
emotion detection,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
youtube movie reviews,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
conventional text,"Similar to the conventional text-based sentiment analysis, some of the most commonly used textual features in multimodal sentiment analysis are unigrams and n-grams, which are basically a sequence of words in a given textual document. !! With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
extensive amount,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
news videos,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
social media data available online,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
emotion recognition,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
depression monitoring,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
based sentiment analysis,"Similar to the conventional text-based sentiment analysis, some of the most commonly used textual features in multimodal sentiment analysis are unigrams and n-grams, which are basically a sequence of words in a given textual document. !! With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others."
traditional sentiment analysis,"Similar to the traditional sentiment analysis, one of the most basic task in multimodal sentiment analysis is sentiment classification, which classifies different sentiments into categories such as positive, negative, or neutral."
classifies different sentiments,"Similar to the traditional sentiment analysis, one of the most basic task in multimodal sentiment analysis is sentiment classification, which classifies different sentiments into categories such as positive, negative, or neutral."
different textual,"In multimodal sentiment analysis, a combination of different textual, audio, and visual features are employed."
visual features,"In multimodal sentiment analysis, a combination of different textual, audio, and visual features are employed."
commonly used textual features,"Similar to the conventional text-based sentiment analysis, some of the most commonly used textual features in multimodal sentiment analysis are unigrams and n-grams, which are basically a sequence of words in a given textual document."
given textual document,"Similar to the conventional text-based sentiment analysis, some of the most commonly used textual features in multimodal sentiment analysis are unigrams and n-grams, which are basically a sequence of words in a given textual document."
machine code instructions required,"In computer performance, the instruction path length is the number of machine code instructions required to execute a section of a computer program."
computer performance,"In computer performance, the instruction path length is the number of machine code instructions required to execute a section of a computer program."
instruction path length,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code. !! Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length. !! The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code. !! When executing a benchmark program, most of the instruction path length is typically inside the program's inner loop. !! In computer performance, the instruction path length is the number of machine code instructions required to execute a section of a computer program."
benchmark program,"When executing a benchmark program, most of the instruction path length is typically inside the program's inner loop."
inner loop,"When executing a benchmark program, most of the instruction path length is typically inside the program's inner loop."
typically inside,"When executing a benchmark program, most of the instruction path length is typically inside the program's inner loop."
machine instructions,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code. !! The lowest-level programming paradigms are machine code, which directly represents the instructions (the contents of program memory) as a sequence of numbers, and assembly language where the machine instructions are represented by mnemonics and memory addresses can be given symbolic labels."
assembly instructions required,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code."
one relationship,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code. !! The Householder transformation was shown to have a one-to-one relationship with the canonical coset decomposition of unitary matrices defined in group theory, which can be used to parametrize unitary operators in a very efficient manner."
particular section,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code."
frequently taken,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code."
assembly instructions,"Since there is, typically, a one-to-one relationship between assembly instructions and machine instructions, the instruction path length is frequently taken as the number of assembly instructions required to perform a function or particular section of code."
good choice,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length. !! For sequential decoding to a good choice of decoding algorithm, the number of states explored wants to remain small (otherwise an algorithm which deliberately explores all states, e. g. the Viterbi algorithm, may be more suitable)."
actual instruction timings might,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length."
massive factor,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length."
secondary consideration compared,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length."
metric would,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length."
shorter path length,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length."
algorithm requiring,"Expressed in terms of instruction path length, this metric would be reduced in this instance by a massive factor of 50 a reason why actual instruction timings might be a secondary consideration compared to a good choice of algorithm requiring a shorter path length."
generally vastly different,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
assembly language program,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
instruction path length includes,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
source lines,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
particular input,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
include code,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
unreachable code,"The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
lexical elements used,"In computer science, terminal and nonterminal symbols are the lexical elements used in specifying the production rules constituting a formal grammar."
production rules constituting,"In computer science, terminal and nonterminal symbols are the lexical elements used in specifying the production rules constituting a formal grammar."
ea framework,An enterprise architecture framework (EA framework) defines how to create and use an enterprise architecture.
enterprise architecture framework,An enterprise architecture framework (EA framework) defines how to create and use an enterprise architecture.
architecture framework,"Many of the aims, principles, concepts and methods now employed in EA frameworks were established in the 1980s, and can be found in IS and IT architecture frameworks published in that decade and the next. !! In 1986, the PRISM architecture framework was developed as a result of the research project sponsored by a group of companies, including IBM, which was seemingly the first published EA framework. !! An enterprise architecture framework (EA framework) defines how to create and use an enterprise architecture. !! An architecture framework provides principles and practices for creating and using the architecture description of a system. !! The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
architecture description,An architecture framework provides principles and practices for creating and using the architecture description of a system.
architecture framework provides principles,An architecture framework provides principles and practices for creating and using the architecture description of a system.
earliest rudiments,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
open group architecture framework,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
wise planning methodology currently advocated,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
ea frameworks,"Many of the aims, principles, concepts and methods now employed in EA frameworks were established in the 1980s, and can be found in IS and IT architecture frameworks published in that decade and the next. !! The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
master plan,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
harvard business review,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
hague titled,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
architecture frameworks published,"Many of the aims, principles, concepts and methods now employed in EA frameworks were established in the 1980s, and can be found in IS and IT architecture frameworks published in that decade and the next."
including ibm,"In 1986, the PRISM architecture framework was developed as a result of the research project sponsored by a group of companies, including IBM, which was seemingly the first published EA framework."
first published ea framework,"In 1986, the PRISM architecture framework was developed as a result of the research project sponsored by a group of companies, including IBM, which was seemingly the first published EA framework."
prism architecture framework,"In 1986, the PRISM architecture framework was developed as a result of the research project sponsored by a group of companies, including IBM, which was seemingly the first published EA framework."
learning algorithms intend,What optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.
based meta,What optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.
robotics science intended,Robotic sensing is a subarea of robotics science intended to give robots sensing capabilities.
robotic sensing,"Robotic sensing is a subarea of robotics science intended to give robots sensing capabilities. !! Media related to Robotic sensing at Wikimedia Commons !! Robotic sensing mainly gives robots the ability to see, touch, hear and move and uses algorithms that require environmental feedback."
give robots sensing capabilities,Robotic sensing is a subarea of robotics science intended to give robots sensing capabilities.
robotic sensing mainly gives robots,"Robotic sensing mainly gives robots the ability to see, touch, hear and move and uses algorithms that require environmental feedback."
require environmental feedback,"Robotic sensing mainly gives robots the ability to see, touch, hear and move and uses algorithms that require environmental feedback."
uses algorithms,"Robotic sensing mainly gives robots the ability to see, touch, hear and move and uses algorithms that require environmental feedback."
wikimedia commons,Media related to Computational number theory at Wikimedia Commons !! Media related to Multidimensional signal processing at Wikimedia Commons !! Media related to Robotic sensing at Wikimedia Commons !! Media related to Program analysis at Wikimedia Commons !! Media related to Real-Time Object-Oriented Modeling at Wikimedia Commons !! Media related to Database theory at Wikimedia Commons !! Media related to Specification languages at Wikimedia Commons
media related,Media related to Computational number theory at Wikimedia Commons !! Media related to Multidimensional signal processing at Wikimedia Commons !! Media related to Robotic sensing at Wikimedia Commons !! Media related to Program analysis at Wikimedia Commons !! Media related to Real-Time Object-Oriented Modeling at Wikimedia Commons !! Media related to Database theory at Wikimedia Commons !! Media related to Specification languages at Wikimedia Commons
chain rule may also,The chain rule may also be expressed in Leibniz's notation.
substitution rule,"In integration, the counterpart to the chain rule is the substitution rule."
two rates,"Intuitively, the chain rule states that knowing the instantaneous rate of change of z relative to y and that of y relative to x allows one to calculate the instantaneous rate of change of z relative to x as the product of the two rates of change."
x allows one,"Intuitively, the chain rule states that knowing the instantaneous rate of change of z relative to y and that of y relative to x allows one to calculate the instantaneous rate of change of z relative to x as the product of the two rates of change."
chain rule states,"Intuitively, the chain rule states that knowing the instantaneous rate of change of z relative to y and that of y relative to x allows one to calculate the instantaneous rate of change of z relative to x as the product of the two rates of change."
instantaneous rate,"Intuitively, the chain rule states that knowing the instantaneous rate of change of z relative to y and that of y relative to x allows one to calculate the instantaneous rate of change of z relative to x as the product of the two rates of change."
set cover problem,"The set cover problem is a classical question in combinatorics, computer science, operations research, and complexity theory. !! If each set is assigned a cost, it becomes a weighted set cover problem. !! The minimum set cover problem can be formulated as the following integer linear program (ILP)."
classical question,"The set cover problem is a classical question in combinatorics, computer science, operations research, and complexity theory."
weighted set cover problem,"If each set is assigned a cost, it becomes a weighted set cover problem."
following integer linear program,The minimum set cover problem can be formulated as the following integer linear program (ILP).
graphical modelling language used primarily,"Behavior trees are a formal, graphical modelling language used primarily in systems and software engineering."
behavior trees employ,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
scale software,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
stakeholder needs,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
integrated system,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
natural language requirements,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
defined notation,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
even thousands,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
unambiguously represent,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
composition tree representation,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
strictly uses,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
avoid short,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
holistic representation,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
allows people,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
large sets,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
vocabulary problems,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
system needs,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
original requirements,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
behavior tree representation,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
term memory overload,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
resolves alias,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
behavior tree notation uses,"Because the behavior tree notation uses a formal semantics, for any given example, it already is, or can be made executable."
made executable,"Because the behavior tree notation uses a formal semantics, for any given example, it already is, or can be made executable."
formal semantics,"Because the behavior tree notation uses a formal semantics, for any given example, it already is, or can be made executable."
given example,"Because the behavior tree notation uses a formal semantics, for any given example, it already is, or can be made executable."
integrated behavior tree forms,Single and composite or integrated behavior tree forms are both important in the application of behavior trees in systems and software engineering.
multidimensional signal processing covers,"In signal processing, multidimensional signal processing covers all signal processing done using multidimensional signals and systems."
deals specifically,"While multidimensional signal processing is a subset of signal processing, it is unique in the sense that it deals specifically with data that can only be adequately detailed using more than one dimension. !! Web application security is a branch of information security that deals specifically with the security of websites, web applications and web services."
one dimension,"While multidimensional signal processing is a subset of signal processing, it is unique in the sense that it deals specifically with data that can only be adequately detailed using more than one dimension. !! In general, when an n-dimensional grid network is connected circularly in more than one dimension, the resulting network topology is a torus, and the network is called ""toroidal""."
adequately detailed using,"While multidimensional signal processing is a subset of signal processing, it is unique in the sense that it deals specifically with data that can only be adequately detailed using more than one dimension."
complexity warrants,"Typically, multidimensional signal processing is directly associated with digital signal processing because its complexity warrants the use of computer modelling and computation."
computer modelling,"Typically, multidimensional signal processing is directly associated with digital signal processing because its complexity warrants the use of computer modelling and computation."
directly associated,"Typically, multidimensional signal processing is directly associated with digital signal processing because its complexity warrants the use of computer modelling and computation."
statistics online computational resource,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
institutional research,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
online multi,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
education organization,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
turing degrees,"Computability theory, also known as recursion theory, is a branch of mathematical logic, computer science, and the theory of computation that originated in the 1930s with the study of computable functions and Turing degrees."
effective descriptive set theory,"In these areas, computability theory overlaps with proof theory and effective descriptive set theory."
computability theory overlaps,"In these areas, computability theory overlaps with proof theory and effective descriptive set theory."
alan turing,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post. !! Some pioneers of the theory of computation were Ramon Llull, Alonzo Church, Kurt Gdel, Alan Turing, Stephen Kleene, Rzsa Pter, John von Neumann and Claude Shannon."
stephen kleene,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post. !! Some pioneers of the theory of computation were Ramon Llull, Alonzo Church, Kurt Gdel, Alan Turing, Stephen Kleene, Rzsa Pter, John von Neumann and Claude Shannon."
rzsa pter,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post. !! Some pioneers of the theory of computation were Ramon Llull, Alonzo Church, Kurt Gdel, Alan Turing, Stephen Kleene, Rzsa Pter, John von Neumann and Claude Shannon."
computability theory originated,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post."
emil post,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post."
kurt gdel,"Computability theory originated in the 1930s, with work of Kurt Gdel, Alonzo Church, Rzsa Pter, Alan Turing, Stephen Kleene, and Emil Post. !! Some pioneers of the theory of computation were Ramon Llull, Alonzo Church, Kurt Gdel, Alan Turing, Stephen Kleene, Rzsa Pter, John von Neumann and Claude Shannon."
main form,The main form of computability studied in computability theory was introduced by Turing (1936).
computability studied,The main form of computability studied in computability theory was introduced by Turing (1936).
vector space v,"In mathematics, the symmetric algebra S(V) (also denoted Sym(V)) on a vector space V over a field K is a commutative algebra over K that contains V, and is, in some sense, minimal for this property."
commutative algebra,"In mathematics, the symmetric algebra S(V) (also denoted Sym(V)) on a vector space V over a field K is a commutative algebra over K that contains V, and is, in some sense, minimal for this property."
symmetric algebra,"The symmetric algebra S(V) can be built as the quotient of the tensor algebra T(V) by the two-sided ideal generated by the elements of the form x y y x. !! If B is a basis of V, the symmetric algebra S(V) can be identified, through a canonical isomorphism, to the polynomial ring K[B], where the elements of B are considered as indeterminates. !! The symmetric algebra S(V) can also be built from polynomial rings. !! It is possible to use the tensor algebra T(V) to describe the symmetric algebra S(V). !! In mathematics, the symmetric algebra S(V) (also denoted Sym(V)) on a vector space V over a field K is a commutative algebra over K that contains V, and is, in some sense, minimal for this property."
also denoted sym,"In mathematics, the symmetric algebra S(V) (also denoted Sym(V)) on a vector space V over a field K is a commutative algebra over K that contains V, and is, in some sense, minimal for this property."
polynomial ring k,"If B is a basis of V, the symmetric algebra S(V) can be identified, through a canonical isomorphism, to the polynomial ring K[B], where the elements of B are considered as indeterminates."
canonical isomorphism,"If B is a basis of V, the symmetric algebra S(V) can be identified, through a canonical isomorphism, to the polynomial ring K[B], where the elements of B are considered as indeterminates."
sided ideal generated,The symmetric algebra S(V) can be built as the quotient of the tensor algebra T(V) by the two-sided ideal generated by the elements of the form x y y x.
tensor algebra,The symmetric algebra S(V) can be built as the quotient of the tensor algebra T(V) by the two-sided ideal generated by the elements of the form x y y x. !! It is possible to use the tensor algebra T(V) to describe the symmetric algebra S(V).
polynomial rings,The symmetric algebra S(V) can also be built from polynomial rings.
place partitioning,"Efficient implementations of quicksort (with in-place partitioning) are typically unstable sorts and somewhat complex, but are among the fastest sorting algorithms in practice."
typically unstable sorts,"Efficient implementations of quicksort (with in-place partitioning) are typically unstable sorts and somewhat complex, but are among the fastest sorting algorithms in practice."
somewhat complex,"Efficient implementations of quicksort (with in-place partitioning) are typically unstable sorts and somewhat complex, but are among the fastest sorting algorithms in practice."
efficient implementations,"Efficient implementations of quicksort (with in-place partitioning) are typically unstable sorts and somewhat complex, but are among the fastest sorting algorithms in practice."
fastest sorting algorithms,"Efficient implementations of quicksort (with in-place partitioning) are typically unstable sorts and somewhat complex, but are among the fastest sorting algorithms in practice."
stable sorts,"Efficient implementations of quicksort (with in-place partitioning) are typically unstable sorts and somewhat complex, but are among the fastest sorting algorithms in practice."
display device,A graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device.
specialized electronic circuit designed,A graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device.
rapidly manipulate,A graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device.
frame buffer intended,A graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device.
alter memory,A graphics processing unit (GPU) is a specialized electronic circuit designed to rapidly manipulate and alter memory to accelerate the creation of images in a frame buffer intended for output to a display device.
designed sony gpu,"Later, in 1994, Sony used the term (now standing for graphics processing unit) in reference to the PlayStation console's Toshiba-designed Sony GPU in 1994."
playstation console,"Later, in 1994, Sony used the term (now standing for graphics processing unit) in reference to the PlayStation console's Toshiba-designed Sony GPU in 1994."
sony used,"Later, in 1994, Sony used the term (now standing for graphics processing unit) in reference to the PlayStation console's Toshiba-designed Sony GPU in 1994."
system ram rather,"Integrated graphics processing unit (IGPU), Integrated graphics, shared graphics solutions, integrated graphics processors (IGP) or unified memory architecture (UMA) utilize a portion of a computer's system RAM rather than dedicated graphics memory."
shared graphics solutions,"Integrated graphics processing unit (IGPU), Integrated graphics, shared graphics solutions, integrated graphics processors (IGP) or unified memory architecture (UMA) utilize a portion of a computer's system RAM rather than dedicated graphics memory."
integrated graphics processors,"Integrated graphics processing unit (IGPU), Integrated graphics, shared graphics solutions, integrated graphics processors (IGP) or unified memory architecture (UMA) utilize a portion of a computer's system RAM rather than dedicated graphics memory."
igpu  integrated graphics,"Integrated graphics processing unit (IGPU), Integrated graphics, shared graphics solutions, integrated graphics processors (IGP) or unified memory architecture (UMA) utilize a portion of a computer's system RAM rather than dedicated graphics memory."
dedicated graphics memory,"Integrated graphics processing unit (IGPU), Integrated graphics, shared graphics solutions, integrated graphics processors (IGP) or unified memory architecture (UMA) utilize a portion of a computer's system RAM rather than dedicated graphics memory."
becoming increasingly common,"It is becoming increasingly common to use a general purpose graphics processing unit (GPGPU) as a modified form of stream processor (or a vector processor), running compute kernels."
vector processor  running compute kernels,"It is becoming increasingly common to use a general purpose graphics processing unit (GPGPU) as a modified form of stream processor (or a vector processor), running compute kernels."
data hierarchy refers,"Data hierarchy refers to the systematic organization of data, often in a hierarchical form."
systematic organization,"Data hierarchy refers to the systematic organization of data, often in a hierarchical form."
data hierarchy,"The components of the data hierarchy are listed below. !! Avoiding redundancy eventually leads to proper ""Data hierarchy"" representing the relationship between data and revealing its relational structure. !! ""Data hierarchy"" is the result of proper arrangement of data without redundancy. !! Data hierarchy refers to the systematic organization of data, often in a hierarchical form. !! ""Data hierarchy"" is a basic concept in data and database theory and helps to show the relationships between smaller and larger components in a database or data file."
hierarchical form,"Data hierarchy refers to the systematic organization of data, often in a hierarchical form."
basic concept,"""Data hierarchy"" is a basic concept in data and database theory and helps to show the relationships between smaller and larger components in a database or data file."
data file,"""Data hierarchy"" is a basic concept in data and database theory and helps to show the relationships between smaller and larger components in a database or data file."
larger components,"""Data hierarchy"" is a basic concept in data and database theory and helps to show the relationships between smaller and larger components in a database or data file."
data without redundancy,"""Data hierarchy"" is the result of proper arrangement of data without redundancy."
proper arrangement,"""Data hierarchy"" is the result of proper arrangement of data without redundancy."
avoiding redundancy eventually leads,"Avoiding redundancy eventually leads to proper ""Data hierarchy"" representing the relationship between data and revealing its relational structure."
output pairings,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
used method,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
best input,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
classical widely,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
web frameworks provide,Web frameworks provide a standard way to build and deploy web applications on the World Wide Web.
standard way,Web frameworks provide a standard way to build and deploy web applications on the World Wide Web.
deploy web applications,Web frameworks provide a standard way to build and deploy web applications on the World Wide Web.
overhead associated,Web frameworks aim to automate the overhead associated with common activities performed in web development.
common activities performed,Web frameworks aim to automate the overhead associated with common activities performed in web development.
web frameworks aim,Web frameworks aim to automate the overhead associated with common activities performed in web development.
templating frameworks,"For example, many web frameworks provide libraries for database access, templating frameworks, and session management, and they often promote code reuse."
often promote code reuse,"For example, many web frameworks provide libraries for database access, templating frameworks, and session management, and they often promote code reuse."
many web frameworks provide libraries,"For example, many web frameworks provide libraries for database access, templating frameworks, and session management, and they often promote code reuse."
session management,"For example, many web frameworks provide libraries for database access, templating frameworks, and session management, and they often promote code reuse."
web frameworks must function according,"Web frameworks must function according to the architectural rules of browsers and protocols such as HTTP, which is stateless."
architectural rules,"Web frameworks must function according to the architectural rules of browsers and protocols such as HTTP, which is stateless."
given string,"In computer science, the longest palindromic substring or longest symmetric factor problem is the problem of finding a maximum-length contiguous substring of a given string that is also a palindrome. !! In data compression and the theory of formal languages, the smallest grammar problem is the problem of finding the smallest context-free grammar that generates a given string of characters (but no other string)."
longest palindromic substring,"The longest palindromic substring is not guaranteed to be unique; for example, in the string ""abracadabra"", there is no palindromic substring with length greater than three, but there are two palindromic substrings with length three, namely, ""aca"" and ""ada"". !! Therefore, it provides a linear time solution to the longest palindromic substring problem. !! The longest palindromic substring problem should not be confused with the different problem of finding the longest palindromic subsequence. !! For example, the longest palindromic substring of ""bananas"" is ""anana"". !! In computer science, the longest palindromic substring or longest symmetric factor problem is the problem of finding a maximum-length contiguous substring of a given string that is also a palindrome."
longest symmetric factor problem,"In computer science, the longest palindromic substring or longest symmetric factor problem is the problem of finding a maximum-length contiguous substring of a given string that is also a palindrome."
length contiguous substring,"In computer science, the longest palindromic substring or longest symmetric factor problem is the problem of finding a maximum-length contiguous substring of a given string that is also a palindrome."
length greater,"The longest palindromic substring is not guaranteed to be unique; for example, in the string ""abracadabra"", there is no palindromic substring with length greater than three, but there are two palindromic substrings with length three, namely, ""aca"" and ""ada""."
palindromic substring,"The longest palindromic substring is not guaranteed to be unique; for example, in the string ""abracadabra"", there is no palindromic substring with length greater than three, but there are two palindromic substrings with length three, namely, ""aca"" and ""ada""."
length three,"The longest palindromic substring is not guaranteed to be unique; for example, in the string ""abracadabra"", there is no palindromic substring with length greater than three, but there are two palindromic substrings with length three, namely, ""aca"" and ""ada""."
two palindromic substrings,"The longest palindromic substring is not guaranteed to be unique; for example, in the string ""abracadabra"", there is no palindromic substring with length greater than three, but there are two palindromic substrings with length three, namely, ""aca"" and ""ada""."
linear time solution,"Therefore, it provides a linear time solution to the longest palindromic substring problem."
longest palindromic substring problem,"The longest palindromic substring problem should not be confused with the different problem of finding the longest palindromic subsequence. !! Therefore, it provides a linear time solution to the longest palindromic substring problem."
different problem,The longest palindromic substring problem should not be confused with the different problem of finding the longest palindromic subsequence.
longest palindromic subsequence,The longest palindromic substring problem should not be confused with the different problem of finding the longest palindromic subsequence.
discover patterns,Web mining is the application of data mining techniques to discover patterns from the World Wide Web.
three main sub,There are three main sub-categories of web mining.
particular user,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
organize web,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
act autonomously,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
based information,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
sophisticated ai systems,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
web mining involves,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
structured data transmitted,"Web mining can complement the retrieval of structured data transmitted with open protocols like OAI-PMH: an example is the aggregation of works from academic publications, which are mined to identify open access versions through a mix of open source and open data methods by academic databases like Unpaywall."
identify open access versions,"Web mining can complement the retrieval of structured data transmitted with open protocols like OAI-PMH: an example is the aggregation of works from academic publications, which are mined to identify open access versions through a mix of open source and open data methods by academic databases like Unpaywall."
academic databases like unpaywall,"Web mining can complement the retrieval of structured data transmitted with open protocols like OAI-PMH: an example is the aggregation of works from academic publications, which are mined to identify open access versions through a mix of open source and open data methods by academic databases like Unpaywall."
academic publications,"Web mining can complement the retrieval of structured data transmitted with open protocols like OAI-PMH: an example is the aggregation of works from academic publications, which are mined to identify open access versions through a mix of open source and open data methods by academic databases like Unpaywall."
open protocols like oai,"Web mining can complement the retrieval of structured data transmitted with open protocols like OAI-PMH: an example is the aggregation of works from academic publications, which are mined to identify open access versions through a mix of open source and open data methods by academic databases like Unpaywall."
open data methods,"Web mining can complement the retrieval of structured data transmitted with open protocols like OAI-PMH: an example is the aggregation of works from academic publications, which are mined to identify open access versions through a mix of open source and open data methods by academic databases like Unpaywall."
increasing web performance,"Web performance optimization (WPO), or website optimization is the field of knowledge about increasing web performance."
performance optimization,"Web performance optimization improves user experience (UX) when visiting a website and therefore is highly desired by web designers and web developers. !! Web performance optimization (WPO), or website optimization is the field of knowledge about increasing web performance. !! Steve Souders coined the term ""web performance optimization"" in 2004."
steve souders coined,"Steve Souders coined the term ""web performance optimization"" in 2004."
highly desired,Web performance optimization improves user experience (UX) when visiting a website and therefore is highly desired by web designers and web developers.
file format,Simple file verification (SFV) is a file format for storing CRC32 checksums of files to verify the integrity of files.
storing crc32 checksums,Simple file verification (SFV) is a file format for storing CRC32 checksums of files to verify the integrity of files.
simple file verification,Simple file verification (SFV) is a file format for storing CRC32 checksums of files to verify the integrity of files.
nasa ames research center,"Sparse distributed memory (SDM) is a mathematical model of human long-term memory introduced by Pentti Kanerva in 1988 while he was at NASA Ames Research Center. !! The Bolshoi simulation, a computer model of the universe run in 2010 on the Pleiades supercomputer at the NASA Ames Research Center, was the most accurate cosmological simulation to that date of the evolution of the large-scale structure of the universe."
term memory introduced,Sparse distributed memory (SDM) is a mathematical model of human long-term memory introduced by Pentti Kanerva in 1988 while he was at NASA Ames Research Center.
human long,Sparse distributed memory (SDM) is a mathematical model of human long-term memory introduced by Pentti Kanerva in 1988 while he was at NASA Ames Research Center.
human neural network,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network."
mathematical representation,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network."
help model,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network."
uses high,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network."
uma ramamurthy,"At the University of Memphis, Uma Ramamurthy, Sidney K. D'Mello, and Stan Franklin created a modified version of the sparse distributed memory system that represents ""realizing forgetting. """
stan franklin created,"At the University of Memphis, Uma Ramamurthy, Sidney K. D'Mello, and Stan Franklin created a modified version of the sparse distributed memory system that represents ""realizing forgetting. """
modified version,"At the University of Memphis, Uma Ramamurthy, Sidney K. D'Mello, and Stan Franklin created a modified version of the sparse distributed memory system that represents ""realizing forgetting. """
sparse distributed memory system,"At the University of Memphis, Uma Ramamurthy, Sidney K. D'Mello, and Stan Franklin created a modified version of the sparse distributed memory system that represents ""realizing forgetting. """
realizing forgetting,"At the University of Memphis, Uma Ramamurthy, Sidney K. D'Mello, and Stan Franklin created a modified version of the sparse distributed memory system that represents ""realizing forgetting. """
sparse distributed memory system distributes,"The sparse distributed memory system distributes each pattern into approximately one hundredth of the locations, so interference can have detrimental results."
detrimental results,"The sparse distributed memory system distributes each pattern into approximately one hundredth of the locations, so interference can have detrimental results."
approximately one hundredth,"The sparse distributed memory system distributes each pattern into approximately one hundredth of the locations, so interference can have detrimental results."
genetic memory uses genetic algorithm,Genetic memory uses genetic algorithm and sparse distributed memory as a pseudo artificial neural network.
pseudo artificial neural network,Genetic memory uses genetic algorithm and sparse distributed memory as a pseudo artificial neural network.
graph may,"In the mathematical field of graph theory, a spanning tree T of an undirected graph G is a subgraph that is a tree which includes all of the vertices of G. In general, a graph may have several spanning trees, but a graph that is not connected will not contain a spanning tree (see spanning forests below)."
several spanning trees,"In the mathematical field of graph theory, a spanning tree T of an undirected graph G is a subgraph that is a tree which includes all of the vertices of G. In general, a graph may have several spanning trees, but a graph that is not connected will not contain a spanning tree (see spanning forests below)."
undirected graph g,"In the mathematical field of graph theory, a spanning tree T of an undirected graph G is a subgraph that is a tree which includes all of the vertices of G. In general, a graph may have several spanning trees, but a graph that is not connected will not contain a spanning tree (see spanning forests below)."
see spanning forests,"In the mathematical field of graph theory, a spanning tree T of an undirected graph G is a subgraph that is a tree which includes all of the vertices of G. In general, a graph may have several spanning trees, but a graph that is not connected will not contain a spanning tree (see spanning forests below)."
also edges,"If all of the edges of G are also edges of a spanning tree T of G, then G is a tree and is identical to T (that is, a tree has a unique spanning tree and it is itself)."
unique spanning tree,"If all of the edges of G are also edges of a spanning tree T of G, then G is a tree and is identical to T (that is, a tree has a unique spanning tree and it is itself)."
several pathfinding algorithms,"Several pathfinding algorithms, including Dijkstra's algorithm and the A* search algorithm, internally build a spanning tree as an intermediate step in solving the problem."
including dijkstra,"Several pathfinding algorithms, including Dijkstra's algorithm and the A* search algorithm, internally build a spanning tree as an intermediate step in solving the problem."
internally build,"Several pathfinding algorithms, including Dijkstra's algorithm and the A* search algorithm, internally build a spanning tree as an intermediate step in solving the problem."
intermediate steps,", people often use algorithms that gradually build a spanning tree (or many such trees) as intermediate steps in the process of finding the minimum spanning tree."
people often use algorithms,", people often use algorithms that gradually build a spanning tree (or many such trees) as intermediate steps in the process of finding the minimum spanning tree."
gradually build,", people often use algorithms that gradually build a spanning tree (or many such trees) as intermediate steps in the process of finding the minimum spanning tree."
state routing protocol,"In order to avoid bridge loops and routing loops, many routing protocols designed for such networksincluding the Spanning Tree Protocol, Open Shortest Path First, Link-state routing protocol, Augmented tree-based routing, etc."
many routing protocols designed,"In order to avoid bridge loops and routing loops, many routing protocols designed for such networksincluding the Spanning Tree Protocol, Open Shortest Path First, Link-state routing protocol, Augmented tree-based routing, etc."
avoid bridge loops,"In order to avoid bridge loops and routing loops, many routing protocols designed for such networksincluding the Spanning Tree Protocol, Open Shortest Path First, Link-state routing protocol, Augmented tree-based routing, etc."
open shortest path first,"In order to avoid bridge loops and routing loops, many routing protocols designed for such networksincluding the Spanning Tree Protocol, Open Shortest Path First, Link-state routing protocol, Augmented tree-based routing, etc."
conditioned even,Thus eigenvalue algorithms that work by finding the roots of the characteristic polynomial can be ill-conditioned even when the problem is not.
thus eigenvalue algorithms,Thus eigenvalue algorithms that work by finding the roots of the characteristic polynomial can be ill-conditioned even when the problem is not.
restricted matrix,The eigenvalue algorithm can then be applied to the restricted matrix.
produce eigenvectors,"If an eigenvalue algorithm does not produce eigenvectors, a common practice is to use an inverse iteration based algorithm with set to a close approximation to the eigenvalue."
close approximation,"If an eigenvalue algorithm does not produce eigenvectors, a common practice is to use an inverse iteration based algorithm with set to a close approximation to the eigenvalue."
zero entries reduce,Hessenberg and tridiagonal matrices are the starting points for many eigenvalue algorithms because the zero entries reduce the complexity of the problem.
many eigenvalue algorithms,Hessenberg and tridiagonal matrices are the starting points for many eigenvalue algorithms because the zero entries reduce the complexity of the problem.
starting points,Hessenberg and tridiagonal matrices are the starting points for many eigenvalue algorithms because the zero entries reduce the complexity of the problem.
tridiagonal matrices,Hessenberg and tridiagonal matrices are the starting points for many eigenvalue algorithms because the zero entries reduce the complexity of the problem.
instruction set architecture,"Addressing modes are an aspect of the instruction set architecture in most central processing unit (CPU) designs. !! An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set. !! In computer science, an instruction set architecture (ISA), also called computer architecture, is an abstract model of a computer."
machine language instructions,The various addressing modes that are defined in a given instruction set architecture define how the machine language instructions in that architecture identify the operand(s) of each instruction.
various addressing modes,The various addressing modes that are defined in a given instruction set architecture define how the machine language instructions in that architecture identify the operand(s) of each instruction.
architecture identify,The various addressing modes that are defined in a given instruction set architecture define how the machine language instructions in that architecture identify the operand(s) of each instruction.
given instruction set architecture define,The various addressing modes that are defined in a given instruction set architecture define how the machine language instructions in that architecture identify the operand(s) of each instruction.
addressing mode specifies,An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
constants contained within,An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
effective memory address,An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
machine instruction,An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
using information held,An addressing mode specifies how to calculate the effective memory address of an operand by using information held in registers and/or constants contained within a machine instruction or elsewhere.
compiler writers,"In computer programming, addressing modes are primarily of interest to those who write in assembly languages and to compiler writers."
one stores,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
order curve naturally iterates,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
first order,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
tree hashing,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
using oct,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
perfect hash function,"Disadvantages of perfect hash functions are that S needs to be known for the construction of the perfect hash function. !! Perfect hash functions may be used to implement a lookup table with constant worst-case access time. !! A perfect hash function can, as any hash function, be used to implement hash tables, with the advantage that no collision resolution has to be implemented. !! In computer science, a perfect hash function h for a set S is a hash function that maps distinct elements in S to a set of m integers, with no collisions. !! Non-dynamic perfect hash functions need to be re-constructed if S changes."
maps distinct elements,"In computer science, a perfect hash function h for a set S is a hash function that maps distinct elements in S to a set of m integers, with no collisions."
perfect hash function h,"In computer science, a perfect hash function h for a set S is a hash function that maps distinct elements in S to a set of m integers, with no collisions."
case access time,Perfect hash functions may be used to implement a lookup table with constant worst-case access time.
perfect hash functions may,Perfect hash functions may be used to implement a lookup table with constant worst-case access time.
constant worst,Perfect hash functions may be used to implement a lookup table with constant worst-case access time.
implement hash tables,"A perfect hash function can, as any hash function, be used to implement hash tables, with the advantage that no collision resolution has to be implemented."
collision resolution,"A perfect hash function can, as any hash function, be used to implement hash tables, with the advantage that no collision resolution has to be implemented."
perfect hash functions,Disadvantages of perfect hash functions are that S needs to be known for the construction of the perfect hash function.
dynamic perfect hash functions need,Non-dynamic perfect hash functions need to be re-constructed if S changes.
retransmits lost,Alternating bit protocol (ABP) is a simple network protocol operating at the data link layer (OSI layer 2) that retransmits lost or corrupted messages using FIFO semantics.
simple network protocol operating,Alternating bit protocol (ABP) is a simple network protocol operating at the data link layer (OSI layer 2) that retransmits lost or corrupted messages using FIFO semantics.
corrupted messages using fifo semantics,Alternating bit protocol (ABP) is a simple network protocol operating at the data link layer (OSI layer 2) that retransmits lost or corrupted messages using FIFO semantics.
european informatics network,An Alternating Bit Protocol was used by the ARPANET and the European Informatics Network.
usually propositional,Unit propagation (UP) or Boolean Constraint propagation (BCP) or the one-literal rule (OLR) is a procedure of automated theorem proving that can simplify a set of (usually propositional) clauses.
literal rule,Unit propagation (UP) or Boolean Constraint propagation (BCP) or the one-literal rule (OLR) is a procedure of automated theorem proving that can simplify a set of (usually propositional) clauses.
unit propagation,"As for resolution, unit propagation is a correct inference rule, in that it never produces a new clause that was not entailed by the old ones. !! Unit propagation (UP) or Boolean Constraint propagation (BCP) or the one-literal rule (OLR) is a procedure of automated theorem proving that can simplify a set of (usually propositional) clauses. !! The second rule of unit propagation can be seen as a restricted form of resolution, in which one of the two resolvents must always be a unit clause. !! resolution does not in general include the first rule used in unit propagation. !! The effect of unit propagation can be summarized as follows."
two resolvents must always,"The second rule of unit propagation can be seen as a restricted form of resolution, in which one of the two resolvents must always be a unit clause."
restricted form,"The second rule of unit propagation can be seen as a restricted form of resolution, in which one of the two resolvents must always be a unit clause."
second rule,"The second rule of unit propagation can be seen as a restricted form of resolution, in which one of the two resolvents must always be a unit clause."
never produces,"As for resolution, unit propagation is a correct inference rule, in that it never produces a new clause that was not entailed by the old ones."
new clause,"As for resolution, unit propagation is a correct inference rule, in that it never produces a new clause that was not entailed by the old ones."
old ones,"As for resolution, unit propagation is a correct inference rule, in that it never produces a new clause that was not entailed by the old ones."
first rule used,resolution does not in general include the first rule used in unit propagation.
general include,resolution does not in general include the first rule used in unit propagation.
suitable smoothness properties,Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e. g. differentiable or subdifferentiable).
often abbreviated sgd,Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e. g. differentiable or subdifferentiable).
important optimization method,"While the basic idea behind stochastic approximation can be traced back to the RobbinsMonro algorithm of the 1950s, stochastic gradient descent has become an important optimization method in machine learning."
basic idea behind stochastic approximation,"While the basic idea behind stochastic approximation can be traced back to the RobbinsMonro algorithm of the 1950s, stochastic gradient descent has become an important optimization method in machine learning."
stochastic gradient descent samples,"To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step."
every step,"To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step."
every iteration,"To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step."
summand functions,"To economize on the computational cost at every iteration, stochastic gradient descent samples a subset of summand functions at every step."
first shown,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
stochastic gradient descent described,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
mode back,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
propagation algorithm,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
make use,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
perform significantly better,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
vectorization libraries rather,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
step separately,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
stochastic approximation,The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation.
analyzed using,The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation.
convex minimization,The convergence of stochastic gradient descent has been analyzed using the theories of convex minimization and of stochastic approximation.
timing may need,"The code's timing may need to be predictable, rather than as fast as possible, so code caching might be disabled, along with compiler optimizations that require it."
code caching might,"The code's timing may need to be predictable, rather than as fast as possible, so code caching might be disabled, along with compiler optimizations that require it."
artificial ant,"In the ant colony optimization algorithms, an artificial ant is a simple computational agent that searches for good solutions to a given optimization problem."
simple computational agent,"In the ant colony optimization algorithms, an artificial ant is a simple computational agent that searches for good solutions to a given optimization problem."
given optimization problem,"In the ant colony optimization algorithms, an artificial ant is a simple computational agent that searches for good solutions to a given optimization problem."
good solutions,"In the ant colony optimization algorithms, an artificial ant is a simple computational agent that searches for good solutions to a given optimization problem."
ant colony optimization algorithms,"""Ant colony optimization algorithms for solving transportation problems"", Journal of Computer and Systems Sciences International, Vol. !! Chronology of ant colony optimization algorithms. !! Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations. !! In the ant colony optimization algorithms, an artificial ant is a simple computational agent that searches for good solutions to a given optimization problem."
derived methods,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
parallel implementations,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
dynamic problems,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
quadratic assignment,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
many combinatorial optimization problems,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
protein folding,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
real variables,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
solving transportation problems  journal,"""Ant colony optimization algorithms for solving transportation problems"", Journal of Computer and Systems Sciences International, Vol."
systems sciences international,"""Ant colony optimization algorithms for solving transportation problems"", Journal of Computer and Systems Sciences International, Vol."
inter-process communication,"Server Message Block (SMB) enables file sharing, printer sharing, network browsing, and inter-process communication (through named pipes) over a computer network. !! In computer science, inter-process communication or interprocess communication (IPC) refers specifically to the mechanisms an operating system provides to allow the processes to manage shared data."
interprocess communication,"In computer science, inter-process communication or interprocess communication (IPC) refers specifically to the mechanisms an operating system provides to allow the processes to manage shared data."
refers specifically,"In computer science, inter-process communication or interprocess communication (IPC) refers specifically to the mechanisms an operating system provides to allow the processes to manage shared data."
operating system provides,"In computer science, inter-process communication or interprocess communication (IPC) refers specifically to the mechanisms an operating system provides to allow the processes to manage shared data."
manage shared data,"In computer science, inter-process communication or interprocess communication (IPC) refers specifically to the mechanisms an operating system provides to allow the processes to manage shared data."
numerical weather models extends,"Even with the increasing power of supercomputers, the forecast skill of numerical weather models extends to only about six days."
increasing power,"Even with the increasing power of supercomputers, the forecast skill of numerical weather models extends to only about six days."
six days,"Even with the increasing power of supercomputers, the forecast skill of numerical weather models extends to only about six days."
forecast skill,"Even with the increasing power of supercomputers, the forecast skill of numerical weather models extends to only about six days."
parameterize cloud microphysics,"Weather models that have gridboxes with sizes between 5 and 25 kilometers (3 and 16 mi) can explicitly represent convective clouds, although they need to parameterize cloud microphysics which occur at a smaller scale."
smaller scale,"Weather models that have gridboxes with sizes between 5 and 25 kilometers (3 and 16 mi) can explicitly represent convective clouds, although they need to parameterize cloud microphysics which occur at a smaller scale."
explicitly represent convective clouds,"Weather models that have gridboxes with sizes between 5 and 25 kilometers (3 and 16 mi) can explicitly represent convective clouds, although they need to parameterize cloud microphysics which occur at a smaller scale."
specific locations,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
created based upon,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
dimensional fields produced,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
surface observations,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
numerical weather models,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
climatological conditions,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
numerical weather guidance,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
main uncertainty,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
fine computational mesh,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
urban air quality models require,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
resolution mesoscale weather models,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
air quality forecasts,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
surface winds,"Along with dissipation of energy through whitecaps and resonance between waves, surface winds from numerical weather models allow for more accurate predictions of the state of the sea surface."
accurate predictions,"Along with dissipation of energy through whitecaps and resonance between waves, surface winds from numerical weather models allow for more accurate predictions of the state of the sea surface."
numerical weather models allow,"Along with dissipation of energy through whitecaps and resonance between waves, surface winds from numerical weather models allow for more accurate predictions of the state of the sea surface."
sea surface,"Along with dissipation of energy through whitecaps and resonance between waves, surface winds from numerical weather models allow for more accurate predictions of the state of the sea surface."
several disciplines,"Architecture description languages (ADLs) are used in several disciplines: system engineering, software engineering, and enterprise modelling and engineering."
represent system architectures,The system engineering community uses an architecture description language as a language and/or a conceptual model to describe and represent system architectures.
system engineering community uses,The system engineering community uses an architecture description language as a language and/or a conceptual model to describe and represent system architectures.
software engineering community uses,The software engineering community uses an architecture description language as a computer language to create a description of a software architecture.
specifies minimum requirements,"The ISO/IEC/IEEE 42010 document, Systems and software engineeringArchitecture description, defines an architecture description language as ""any form of expression for use in architecture descriptions"" and specifies minimum requirements on ADLs."
architecture descriptions,"The ISO/IEC/IEEE 42010 document, Systems and software engineeringArchitecture description, defines an architecture description language as ""any form of expression for use in architecture descriptions"" and specifies minimum requirements on ADLs."
ieee 42010 document,"The ISO/IEC/IEEE 42010 document, Systems and software engineeringArchitecture description, defines an architecture description language as ""any form of expression for use in architecture descriptions"" and specifies minimum requirements on ADLs."
software engineeringarchitecture description,"The ISO/IEC/IEEE 42010 document, Systems and software engineeringArchitecture description, defines an architecture description language as ""any form of expression for use in architecture descriptions"" and specifies minimum requirements on ADLs."
engineering community,The enterprise modelling and engineering community have also developed architecture description languages catered for at the enterprise level.
enterprise level,The enterprise modelling and engineering community have also developed architecture description languages catered for at the enterprise level.
class acts,"This class acts as the randomized equivalent of P, i. e. BPP represents the class of efficient randomized algorithms."
randomized equivalent,"This class acts as the randomized equivalent of P, i. e. BPP represents the class of efficient randomized algorithms."
efficient randomized algorithms,"This class acts as the randomized equivalent of P, i. e. BPP represents the class of efficient randomized algorithms."
bpp represents,"This class acts as the randomized equivalent of P, i. e. BPP represents the class of efficient randomized algorithms."
volker strassen,"In linear algebra, the Strassen algorithm, named after Volker Strassen, is an algorithm for matrix multiplication. !! The study of randomized algorithms was spurred by the 1977 discovery of a randomized primality test (i. e. , determining the primality of a number) by Robert M. Solovay and Volker Strassen."
randomized primality test,"The study of randomized algorithms was spurred by the 1977 discovery of a randomized primality test (i. e. , determining the primality of a number) by Robert M. Solovay and Volker Strassen."
programming language reference,"In computing, a programming language reference or language reference manual is part of the documentation associated with most mainstream programming languages."
documentation associated,"In computing, a programming language reference or language reference manual is part of the documentation associated with most mainstream programming languages."
mainstream programming languages,"In computing, a programming language reference or language reference manual is part of the documentation associated with most mainstream programming languages."
language reference manual,"In computing, a programming language reference or language reference manual is part of the documentation associated with most mainstream programming languages."
sparc systems,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
level virtualization technology,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
first full release,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
build 51 beta,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
first released publicly,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
including solaris zones,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
solaris zone combined,By 2007 the term Solaris Containers came to mean a Solaris Zone combined with resource management controls.
resource management controls,By 2007 the term Solaris Containers came to mean a Solaris Zone combined with resource management controls.
term solaris containers came,By 2007 the term Solaris Containers came to mean a Solaris Zone combined with resource management controls.
global zones,"Later, there was a gradual move such that Solaris Containers specifically referred to non-global zones, with or without additional Resource Management."
without additional resource management,"Later, there was a gradual move such that Solaris Containers specifically referred to non-global zones, with or without additional Resource Management."
gradual move,"Later, there was a gradual move such that Solaris Containers specifically referred to non-global zones, with or without additional Resource Management."
solaris containers specifically referred,"Later, there was a gradual move such that Solaris Containers specifically referred to non-global zones, with or without additional Resource Management."
detailed documentation,The Solaris operating system provides man pages for Solaris Containers by default; more detailed documentation can be found at various on-line technical resources.
line technical resources,The Solaris operating system provides man pages for Solaris Containers by default; more detailed documentation can be found at various on-line technical resources.
release cycle,The Blastwave Solaris 8 and Solaris 9 Containers document was very early in the release cycle of the Solaris Containers technology and the actions and implementation at Blastwave resulted in a followup by Sun Microsystems marketing.
sun microsystems marketing,The Blastwave Solaris 8 and Solaris 9 Containers document was very early in the release cycle of the Solaris Containers technology and the actions and implementation at Blastwave resulted in a followup by Sun Microsystems marketing.
blastwave solaris 8,The Blastwave Solaris 8 and Solaris 9 Containers document was very early in the release cycle of the Solaris Containers technology and the actions and implementation at Blastwave resulted in a followup by Sun Microsystems marketing.
solaris 9 containers document,The Blastwave Solaris 8 and Solaris 9 Containers document was very early in the release cycle of the Solaris Containers technology and the actions and implementation at Blastwave resulted in a followup by Sun Microsystems marketing.
blastwave resulted,The Blastwave Solaris 8 and Solaris 9 Containers document was very early in the release cycle of the Solaris Containers technology and the actions and implementation at Blastwave resulted in a followup by Sun Microsystems marketing.
solaris containers technology,The Blastwave Solaris 8 and Solaris 9 Containers document was very early in the release cycle of the Solaris Containers technology and the actions and implementation at Blastwave resulted in a followup by Sun Microsystems marketing.
triangular facets,"A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets (a triangle mesh), used mainly as Discrete Global Grid in primary elevation modeling."
continuous surface consisting entirely,"A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets (a triangle mesh), used mainly as Discrete Global Grid in primary elevation modeling."
triangulated irregular network,"The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973. !! A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets (a triangle mesh), used mainly as Discrete Global Grid in primary elevation modeling. !! Some spatial databases handle more complex structures such as 3D objects, topological coverages, linear networks, and TINs (triangulated irregular network)."
triangle mesh  used mainly,"A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets (a triangle mesh), used mainly as Discrete Global Grid in primary elevation modeling."
primary elevation modeling,"A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets (a triangle mesh), used mainly as Discrete Global Grid in primary elevation modeling."
david douglas,"The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973."
simon fraser university,"The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973."
first triangulated irregular network program,"The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973."
randolph franklin,"The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973."
thomas peucker,"The first triangulated irregular network program for GIS was written by W. Randolph Franklin, under the direction of David Douglas and Thomas Peucker (Poiker), at Simon Fraser University in 1973."
complex roots,"In mathematics, the splitting circle method is a numerical algorithm for the numerical factorization of a polynomial and, ultimately, for finding its complex roots."
construct factors,"The fundamental idea of the splitting circle method is to use methods of complex analysis, more precisely the residue theorem, to construct factors of polynomials."
complex analysis,"The fundamental idea of the splitting circle method is to use methods of complex analysis, more precisely the residue theorem, to construct factors of polynomials."
use methods,"The fundamental idea of the splitting circle method is to use methods of complex analysis, more precisely the residue theorem, to construct factors of polynomials."
fundamental idea,"The fundamental idea of the splitting circle method is to use methods of complex analysis, more precisely the residue theorem, to construct factors of polynomials."
minimizes maximum error,A minimax approximation algorithm (or L approximation or uniform approximation) is a method to find an approximation of a mathematical function that minimizes maximum error.
one popular minimax approximation algorithm,One popular minimax approximation algorithm is the Remez algorithm.
remez algorithm,One popular minimax approximation algorithm is the Remez algorithm.
molecular level,Rotational correlation times are employed in the measurement of microviscosity (viscosity at the molecular level) and in protein characterization.
protein characterization,Rotational correlation times are employed in the measurement of microviscosity (viscosity at the molecular level) and in protein characterization.
rotational correlation times may,"Rotational correlation times may be measured by rotational (microwave), dielectric, and nuclear magnetic resonance (NMR) spectroscopy."
microwave  dielectric,"Rotational correlation times may be measured by rotational (microwave), dielectric, and nuclear magnetic resonance (NMR) spectroscopy."
nuclear magnetic resonance,"Rotational correlation times may be measured by rotational (microwave), dielectric, and nuclear magnetic resonance (NMR) spectroscopy."
probe molecules,"Rotational correlation times of probe molecules in media have been measured by fluorescence lifetime or for radicals, from the linewidths of electron spin resonances."
fluorescence lifetime,"Rotational correlation times of probe molecules in media have been measured by fluorescence lifetime or for radicals, from the linewidths of electron spin resonances."
electron spin resonances,"Rotational correlation times of probe molecules in media have been measured by fluorescence lifetime or for radicals, from the linewidths of electron spin resonances."
spreading activation,"As it relates to cognitive psychology, spreading activation is the theory of how the brain iterates through a network of associated ideas to retrieve specific information. !! Spreading activation in semantic networks as a model were invented in cognitive psychology to model the fan out effect. !! Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks. !! Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents. !! The spreading activation theory presents the array of concepts within our memory as cognitive units, each consisting of a node and its associated elements or characteristics, all connected together by edges."
searching associative networks,"Spreading activation is a method for searching associative networks, biological and artificial neural networks, or semantic networks."
nodes representing documents,"Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents."
terms contained,"Spreading activation can also be applied in information retrieval, by means of a network of nodes representing documents and terms contained in those documents."
brain iterates,"As it relates to cognitive psychology, spreading activation is the theory of how the brain iterates through a network of associated ideas to retrieve specific information."
retrieve specific information,"As it relates to cognitive psychology, spreading activation is the theory of how the brain iterates through a network of associated ideas to retrieve specific information."
associated ideas,"As it relates to cognitive psychology, spreading activation is the theory of how the brain iterates through a network of associated ideas to retrieve specific information."
cognitive units,"The spreading activation theory presents the array of concepts within our memory as cognitive units, each consisting of a node and its associated elements or characteristics, all connected together by edges."
spreading activation theory presents,"The spreading activation theory presents the array of concepts within our memory as cognitive units, each consisting of a node and its associated elements or characteristics, all connected together by edges."
concepts within,"The spreading activation theory presents the array of concepts within our memory as cognitive units, each consisting of a node and its associated elements or characteristics, all connected together by edges."
connected together,"The spreading activation theory presents the array of concepts within our memory as cognitive units, each consisting of a node and its associated elements or characteristics, all connected together by edges."
associated elements,"The spreading activation theory presents the array of concepts within our memory as cognitive units, each consisting of a node and its associated elements or characteristics, all connected together by edges."
also called symbolic computation,"In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects."
scientific area,"In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects."
manipulating mathematical expressions,"In mathematics and computer science, computer algebra, also called symbolic computation or algebraic computation, is a scientific area that refers to the study and development of algorithms and software for manipulating mathematical expressions and other mathematical objects."
distinct fields,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
generally considered,"Computer science is generally considered an area of academic research and distinct from computer programming. !! Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols. !! Queueing theory is generally considered a branch of operations research because the results are often used when making business decisions about the resources needed to provide a service."
given value,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
expressions containing variables,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
symbolic computation emphasizes exact computation,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
although computer algebra could,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
approximate floating point numbers,"Although computer algebra could be considered a subfield of scientific computing, they are generally considered as distinct fields because scientific computing is usually based on numerical computation with approximate floating point numbers, while symbolic computation emphasizes exact computation with expressions containing variables that have no given value and are manipulated as symbols."
main applications,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
perform symbolic calculations,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
usually different,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
large set,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
differentiation using chain rule,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
called computer algebra systems,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
user programming language,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
like simplification,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
indefinite integration,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
perform usual operations,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
language used,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
term system alluding,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
represent mathematical data,"Software applications that perform symbolic calculations are called computer algebra systems, with the term system alluding to the complexity of the main applications that include, at least, a method to represent mathematical data in a computer, a user programming language (usually different from the language used for the implementation), a dedicated memory manager, a user interface for the input/output of mathematical expressions, a large set of routines to perform usual operations, like simplification of expressions, differentiation using chain rule, polynomial factorization, indefinite integration, etc."
authors distinguish computer algebra,Some authors distinguish computer algebra from symbolic computation using the latter name to refer to kinds of symbolic computation other than the computation with mathematical formulas.
symbolic computation using,Some authors distinguish computer algebra from symbolic computation using the latter name to refer to kinds of symbolic computation other than the computation with mathematical formulas.
latter name,Some authors distinguish computer algebra from symbolic computation using the latter name to refer to kinds of symbolic computation other than the computation with mathematical formulas.
isinglenzlittle model,A Hopfield network (or Ising model of a neural network or IsingLenzLittle model) is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described earlier by Little in 1974 based on Ernst Ising's work with Wilhelm Lenz on the Ising model.
wilhelm lenz,A Hopfield network (or Ising model of a neural network or IsingLenzLittle model) is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described earlier by Little in 1974 based on Ernst Ising's work with Wilhelm Lenz on the Ising model.
described earlier,A Hopfield network (or Ising model of a neural network or IsingLenzLittle model) is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described earlier by Little in 1974 based on Ernst Ising's work with Wilhelm Lenz on the Ising model.
ernst ising,A Hopfield network (or Ising model of a neural network or IsingLenzLittle model) is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described earlier by Little in 1974 based on Ernst Ising's work with Wilhelm Lenz on the Ising model.
spin glass system popularised,A Hopfield network (or Ising model of a neural network or IsingLenzLittle model) is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described earlier by Little in 1974 based on Ernst Ising's work with Wilhelm Lenz on the Ising model.
john hopfield,A Hopfield network (or Ising model of a neural network or IsingLenzLittle model) is a form of recurrent artificial neural network and a type of spin glass system popularised by John Hopfield in 1982 as described earlier by Little in 1974 based on Ernst Ising's work with Wilhelm Lenz on the Ising model.
binary threshold nodes,"Hopfield networks serve as content-addressable (""associative"") memory systems with binary threshold nodes, or with continuous variables."
hopfield networks serve,"Hopfield networks serve as content-addressable (""associative"") memory systems with binary threshold nodes, or with continuous variables."
hopfield networks also provide,Hopfield networks also provide a model for understanding human memory.
understanding human memory,Hopfield networks also provide a model for understanding human memory.
called dense associative memories,Large memory storage capacity Hopfield Networks are now called Dense Associative Memories or modern Hopfield networks.
bruck shed light,Bruck shed light on the behavior of a neuron in the discrete Hopfield network when proving its convergence in his paper in 1990.
adobe systems,"Generic Image Library (GIL), is an open source generic programming library created by Adobe Systems for image-related programming."
related programming,"Generic Image Library (GIL), is an open source generic programming library created by Adobe Systems for image-related programming."
search engine designed,A visual search engine is a search engine designed to search for information on the World Wide Web through the input of an image or a search engine with a visual display of the search results.
search results,A visual search engine is a search engine designed to search for information on the World Wide Web through the input of an image or a search engine with a visual display of the search results.
visual search engine,"A visual search engine is a search engine designed to search for information on the World Wide Web through the input of an image or a search engine with a visual display of the search results. !! A visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique."
gives relative information based,"A visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique."
patterns based,"A visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique."
apply pattern match technique,"A visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique."
visual search engine searches images,"A visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique."
could recognize,"A visual search engine searches images, patterns based on an algorithm which it could recognize and gives relative information based on the selective or apply pattern match technique."
spiking neural network,"Neurogrid is a board that can simulate spiking neural networks directly in hardware. !! Brainchip Holdings Ltd announced on 21 October 2021 that it was taking orders for its Akida AI Processor Development Kits, making it the world's first commercially available neuromorphic processor operating on a spiking neural network. !! In a spiking neural network, a neuron's current state is defined as its membrane potential (possibly modeled as a differential equation). !! Spiking neural networks (SNNs) are artificial neural networks that more closely mimic natural neural networks. !! SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model."
closely mimic natural neural networks,Spiking neural networks (SNNs) are artificial neural networks that more closely mimic natural neural networks.
spiking neural networks,Spiking neural networks (SNNs) are artificial neural networks that more closely mimic natural neural networks. !! Neurogrid is a board that can simulate spiking neural networks directly in hardware.
taking orders,"Brainchip Holdings Ltd announced on 21 October 2021 that it was taking orders for its Akida AI Processor Development Kits, making it the world's first commercially available neuromorphic processor operating on a spiking neural network."
brainchip holdings ltd announced,"Brainchip Holdings Ltd announced on 21 October 2021 that it was taking orders for its Akida AI Processor Development Kits, making it the world's first commercially available neuromorphic processor operating on a spiking neural network."
akida ai processor development kits,"Brainchip Holdings Ltd announced on 21 October 2021 that it was taking orders for its Akida AI Processor Development Kits, making it the world's first commercially available neuromorphic processor operating on a spiking neural network."
possibly modeled,"In a spiking neural network, a neuron's current state is defined as its membrane potential (possibly modeled as a differential equation)."
membrane potential,"In a spiking neural network, a neuron's current state is defined as its membrane potential (possibly modeled as a differential equation)."
current state,"Maximal entropy random walk (MERW) is a popular type of biased random walk on a graph, in which transition probabilities are chosen accordingly to the principle of maximum entropy, which says that the probability distribution which best represents the current state of knowledge is the one with largest entropy. !! In a spiking neural network, a neuron's current state is defined as its membrane potential (possibly modeled as a differential equation)."
simulate spiking neural networks directly,Neurogrid is a board that can simulate spiking neural networks directly in hardware.
massively parallel computing platform based,SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model.
uses arm processors,SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model.
spiking neural network architecture,SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model.
layer thalamocortical model,SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model.
mobile life centre,"The Mobile Life Centre at Stockholm University in Kista, Sweden, conducts research in mobile services and ubiquitous computing. !! The Mobile Life Centre is one of the 19 VINN Excellence Centers selected by Vinnova (the Swedish Government Agency for Innovation Systems)."
mobile services,"The Mobile Life Centre at Stockholm University in Kista, Sweden, conducts research in mobile services and ubiquitous computing."
conducts research,"The Mobile Life Centre at Stockholm University in Kista, Sweden, conducts research in mobile services and ubiquitous computing."
swedish government agency,The Mobile Life Centre is one of the 19 VINN Excellence Centers selected by Vinnova (the Swedish Government Agency for Innovation Systems).
innovation systems,The Mobile Life Centre is one of the 19 VINN Excellence Centers selected by Vinnova (the Swedish Government Agency for Innovation Systems).
19 vinn excellence centers selected,The Mobile Life Centre is one of the 19 VINN Excellence Centers selected by Vinnova (the Swedish Government Agency for Innovation Systems).
synthetic media,"Though experts use the term ""synthetic media,"" individual methods such as deepfakes and text synthesis are sometimes not referred to as such by the media but instead by their respective terminology (and often use ""deepfakes"" as a euphemism, e. g. ""deepfakes for text"" for natural-language generation; ""deepfakes for voices"" for neural voice cloning, etc. ) !! Significant attention arose towards the field of synthetic media starting in 2017 when Motherboard reported on the emergence of pornographic videos altered with the use of AI algorithms to insert the faces of famous actresses. !! Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning. !! Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds. !! Synthetic media as a field has grown rapidly since the creation of generative adversarial networks, primarily through the rise of deepfakes as well as music synthesis, text generation, human image synthesis, speech synthesis, and more."
artificial intelligence algorithms,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
generative media,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
misleading people,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
generated media,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
original meaning,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
personalized media,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
automated means,"Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
artificial production,"Speech synthesis is the artificial production of human speech. !! Synthetic media (also known as AI-generated media, generative media, personalized media, and colloquially as deepfakes) is a catch-all term for the artificial production, manipulation, and modification of data and media by automated means, especially through the use of artificial intelligence algorithms, such as for the purpose of misleading people or changing an original meaning."
grown rapidly since,"Synthetic media as a field has grown rapidly since the creation of generative adversarial networks, primarily through the rise of deepfakes as well as music synthesis, text generation, human image synthesis, speech synthesis, and more."
music synthesis,"Synthetic media as a field has grown rapidly since the creation of generative adversarial networks, primarily through the rise of deepfakes as well as music synthesis, text generation, human image synthesis, speech synthesis, and more."
though experts use,"Though experts use the term ""synthetic media,"" individual methods such as deepfakes and text synthesis are sometimes not referred to as such by the media but instead by their respective terminology (and often use ""deepfakes"" as a euphemism, e. g. ""deepfakes for text"" for natural-language generation; ""deepfakes for voices"" for neural voice cloning, etc. )"
often use,"Though experts use the term ""synthetic media,"" individual methods such as deepfakes and text synthesis are sometimes not referred to as such by the media but instead by their respective terminology (and often use ""deepfakes"" as a euphemism, e. g. ""deepfakes for text"" for natural-language generation; ""deepfakes for voices"" for neural voice cloning, etc. )"
significant attention arose towards,Significant attention arose towards the field of synthetic media starting in 2017 when Motherboard reported on the emergence of pornographic videos altered with the use of AI algorithms to insert the faces of famous actresses.
pornographic videos altered,Significant attention arose towards the field of synthetic media starting in 2017 when Motherboard reported on the emergence of pornographic videos altered with the use of AI algorithms to insert the faces of famous actresses.
famous actresses,Significant attention arose towards the field of synthetic media starting in 2017 when Motherboard reported on the emergence of pornographic videos altered with the use of AI algorithms to insert the faces of famous actresses.
motherboard reported,Significant attention arose towards the field of synthetic media starting in 2017 when Motherboard reported on the emergence of pornographic videos altered with the use of AI algorithms to insert the faces of famous actresses.
supercharge fake news,"Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds."
journalistic jobs,"Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds."
complete retreat,"Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds."
generated fantasy worlds,"Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds."
synthetic media include,"Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds."
learned using,"In particular, learning in a Naive Bayes classifier is a simple matter of counting up the number of co-occurrences of features and classes, while in a maximum entropy classifier the weights, which are typically maximized using maximum a posteriori (MAP) estimation, must be learned using an iterative procedure; see #Estimating the coefficients."
simple matter,"In particular, learning in a Naive Bayes classifier is a simple matter of counting up the number of co-occurrences of features and classes, while in a maximum entropy classifier the weights, which are typically maximized using maximum a posteriori (MAP) estimation, must be learned using an iterative procedure; see #Estimating the coefficients."
typically maximized using maximum,"In particular, learning in a Naive Bayes classifier is a simple matter of counting up the number of co-occurrences of features and classes, while in a maximum entropy classifier the weights, which are typically maximized using maximum a posteriori (MAP) estimation, must be learned using an iterative procedure; see #Estimating the coefficients."
algorithm art,"Algorithmic art or algorithm art is art, mostly visual art, in which the design is generated by an algorithm."
mostly visual art,"Algorithmic art or algorithm art is art, mostly visual art, in which the design is generated by an algorithm."
algorithmic art,"Fractal art is an example of algorithmic art. !! Algorithmic artists are sometimes called algorists. !! Algorithmic art or algorithm art is art, mostly visual art, in which the design is generated by an algorithm. !! Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s. !! Algorithmic art, also known as computer-generated art, is a subset of generative art (generated by an autonomous system) and is related to systems art (influenced by systems theory)."
algorithmic artists,Algorithmic artists are sometimes called algorists.
sometimes called algorists,Algorithmic artists are sometimes called algorists.
systems art,"Algorithmic art, also known as computer-generated art, is a subset of generative art (generated by an autonomous system) and is related to systems art (influenced by systems theory)."
generative art,"Algorithmic art, also known as computer-generated art, is a subset of generative art (generated by an autonomous system) and is related to systems art (influenced by systems theory)."
generated art,"Algorithmic art, also known as computer-generated art, is a subset of generative art (generated by an autonomous system) and is related to systems art (influenced by systems theory)."
fractal art,Fractal art is an example of algorithmic art.
generated algorithmic art,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
michael noll,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
vera molnr,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
manfred mohr,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
earliest known examples,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
georg nees,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
frieder nake,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
communications technology professional,The systems architect is an information and communications technology professional.
systems architect,"The systems architect is an information and communications technology professional. !! Systems architects define the architecture of a computerized system (i. e. , a system composed of software and hardware) in order to fulfill certain requirements. !! Systems Architecture: Canaxia Brings an Architect on Board, Article"
fulfill certain requirements,"Systems architects define the architecture of a computerized system (i. e. , a system composed of software and hardware) in order to fulfill certain requirements."
computerized system,"Systems architects define the architecture of a computerized system (i. e. , a system composed of software and hardware) in order to fulfill certain requirements."
systems architects define,"Systems architects define the architecture of a computerized system (i. e. , a system composed of software and hardware) in order to fulfill certain requirements."
system composed,"Systems architects define the architecture of a computerized system (i. e. , a system composed of software and hardware) in order to fulfill certain requirements."
canaxia brings,"Systems Architecture: Canaxia Brings an Architect on Board, Article"
federal enterprise architecture,The Data Reference Model (DRM) is one of the five reference models of the Federal Enterprise Architecture.
five reference models,The Data Reference Model (DRM) is one of the five reference models of the Federal Enterprise Architecture.
data reference model,US Federal Enterprise Architecture Program Data Reference Model Version 2. !! The Data Reference Model (DRM) is one of the five reference models of the Federal Enterprise Architecture. !! The Data Reference Model version 2 released in November 2005 is a 114-page document with detailed architectural diagrams and an extensive glossary of terms.
page document,The Data Reference Model version 2 released in November 2005 is a 114-page document with detailed architectural diagrams and an extensive glossary of terms.
data reference model version 2 released,The Data Reference Model version 2 released in November 2005 is a 114-page document with detailed architectural diagrams and an extensive glossary of terms.
detailed architectural diagrams,The Data Reference Model version 2 released in November 2005 is a 114-page document with detailed architectural diagrams and an extensive glossary of terms.
extensive glossary,The Data Reference Model version 2 released in November 2005 is a 114-page document with detailed architectural diagrams and an extensive glossary of terms.
solve decision problems,Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.
called influence diagrams,Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.
bayesian sense,"Formally, Bayesian networks are directed acyclic graphs (DAGs) whose nodes represent variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses."
whose nodes represent variables,"Formally, Bayesian networks are directed acyclic graphs (DAGs) whose nodes represent variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses."
directed acyclic graphs,"Formally, Bayesian networks are directed acyclic graphs (DAGs) whose nodes represent variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses."
observable quantities,"Formally, Bayesian networks are directed acyclic graphs (DAGs) whose nodes represent variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses."
unknown parameters,"Formally, Bayesian networks are directed acyclic graphs (DAGs) whose nodes represent variables in the Bayesian sense: they may be observable quantities, latent variables, unknown parameters or hypotheses."
audio injection,"Audio injection attacks can be performed remotely. !! Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
apple siri,"Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
digital assistants,"Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
amazon echo,"Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
google home,"Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
unwanted instructions,"Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
third party,"Audio injection is the exploitation of digital assistants such as Amazon Echo, Google Home or Apple SIRI by unwanted instructions from a third party."
audio injection attacks,Audio injection attacks can be performed remotely.
performed remotely,Audio injection attacks can be performed remotely.
target value within,"In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array."
sorted array,"Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure. !! Elements in a sorted array can be looked up by their index (random access) at O(1) time, an operation taking O(log n) or O(n) time for more complex data structures. !! In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array. !! A sorted array is an array data structure in which each element is sorted in numerical, alphabetical, or some other order, and placed at equally spaced addresses in computer memory. !! The insertion and deletion of elements in a sorted array executes at O(n), due to the need to shift all the elements following the element to be inserted or deleted; in comparison a self-balancing binary search tree inserts and deletes at O(log n). !! Sorted arrays are the most space-efficient data structure with the best locality of reference for sequentially stored data. !! Block sort uses two variants: one which finds the first position to insert a value in the sorted array, and one which finds the last position."
binary search,"There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search. !! Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure. !! Binary search compares the target value to the middle element of the array. !! In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array. !! Examples of generative recursion include: gcd, quicksort, binary search, mergesort, Newton's method, fractals, and adaptive integration. !! Binary search is faster than linear search except for small arrays. !! However, the array must be sorted first to be able to apply binary search."
logarithmic search,"In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array."
binary chop,"In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array."
interval search,"In computer science, binary search, also known as half-interval search, logarithmic search, or binary chop, is a search algorithm that finds the position of a target value within a sorted array."
binary search compares,Binary search compares the target value to the middle element of the array.
small arrays,Binary search is faster than linear search except for small arrays.
linear search except,Binary search is faster than linear search except for small arrays.
sorted first,"However, the array must be sorted first to be able to apply binary search."
apply binary search,"However, the array must be sorted first to be able to apply binary search."
array must,"However, the array must be sorted first to be able to apply binary search."
fast searching,"There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search."
specialized data structures designed,"There are specialized data structures designed for fast searching, such as hash tables, that can be searched more efficiently than binary search."
bayesian statistics,"Bayesian statistics is a theory in the field of statistics based on the Bayesian interpretation of probability where probability expresses a degree of belief in an event. !! In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution. !! Properly used, abductive reasoning can be a useful source of priors in Bayesian statistics. !! Bayesian search theory is the application of Bayesian statistics to the search for lost objects. !! Although Bayes' theorem is a fundamental result of probability theory, it has a specific interpretation in Bayesian statistics. !! Bayesian statistics is named after Thomas Bayes, who formulated a specific case of Bayes' theorem in a paper published in 1763. !! The maximum a posteriori, which is the mode of the posterior and is often computed in Bayesian statistics using mathematical optimization methods, remains the same. !! Markov processes are the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in Bayesian statistics, thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory and speech processing. !! Since Bayesian statistics treats probability as a degree of belief, Bayes' theorem can directly assign a probability distribution that quantifies the belief to the parameter or set of parameters."
unknown quantity,"In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution."
maximum a posteriori probability,"In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution."
posterior distribution,"In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution."
posteriori probability,"In Bayesian statistics, a maximum a posteriori probability (MAP) estimate is an estimate of an unknown quantity, that equals the mode of the posterior distribution."
lossless jpeg,"Lossless JPEG was developed as a late addition to JPEG in 1993, using a completely different technique from the lossy JPEG standard. !! The standard Independent JPEG Group libraries cannot encode or decode it, but Ken Murchison of Oceana Matrix Ltd. wrote a patch that extends the IJG library to handle lossless JPEG. !! Lossless JPEG has some popularity in medical imaging, and is used in DNG and some digital cameras to compress raw images, but otherwise was never widely adopted. !! Adobe's DNG SDK provides a software library for encoding and decoding lossless JPEG with up to 16 bits per sample. !! Lossless JPEG is a 1993 addition to JPEG standard by the Joint Photographic Experts Group to enable lossless compression."
jpeg standard,Lossless JPEG is a 1993 addition to JPEG standard by the Joint Photographic Experts Group to enable lossless compression.
enable lossless compression,Lossless JPEG is a 1993 addition to JPEG standard by the Joint Photographic Experts Group to enable lossless compression.
joint photographic experts group,Lossless JPEG is a 1993 addition to JPEG standard by the Joint Photographic Experts Group to enable lossless compression.
completely different technique,"Lossless JPEG was developed as a late addition to JPEG in 1993, using a completely different technique from the lossy JPEG standard."
late addition,"Lossless JPEG was developed as a late addition to JPEG in 1993, using a completely different technique from the lossy JPEG standard."
ken murchison,"The standard Independent JPEG Group libraries cannot encode or decode it, but Ken Murchison of Oceana Matrix Ltd. wrote a patch that extends the IJG library to handle lossless JPEG."
oceana matrix ltd,"The standard Independent JPEG Group libraries cannot encode or decode it, but Ken Murchison of Oceana Matrix Ltd. wrote a patch that extends the IJG library to handle lossless JPEG."
ijg library,"The standard Independent JPEG Group libraries cannot encode or decode it, but Ken Murchison of Oceana Matrix Ltd. wrote a patch that extends the IJG library to handle lossless JPEG."
digital cameras,"Lossless JPEG has some popularity in medical imaging, and is used in DNG and some digital cameras to compress raw images, but otherwise was never widely adopted."
never widely adopted,"Lossless JPEG has some popularity in medical imaging, and is used in DNG and some digital cameras to compress raw images, but otherwise was never widely adopted."
dng sdk provides,Adobe's DNG SDK provides a software library for encoding and decoding lossless JPEG with up to 16 bits per sample.
16 bits per sample,Adobe's DNG SDK provides a software library for encoding and decoding lossless JPEG with up to 16 bits per sample.
includes additional features,Across Language Server is a software platform for computer-assisted translation (CAT) that includes additional features for the management of projects.
one sdl trados,"The functional principle is similar to the one SDL Trados, XTM and memoQ feature: Just like the server solutions of these two programs, Across Language Server also saves translation units or terminology entries (depending on the project's configuration) into a local or a central MSSQL database."
memoq feature,"The functional principle is similar to the one SDL Trados, XTM and memoQ feature: Just like the server solutions of these two programs, Across Language Server also saves translation units or terminology entries (depending on the project's configuration) into a local or a central MSSQL database."
central mssql database,"The functional principle is similar to the one SDL Trados, XTM and memoQ feature: Just like the server solutions of these two programs, Across Language Server also saves translation units or terminology entries (depending on the project's configuration) into a local or a central MSSQL database."
based across language server,Version 5 of the MS-SQL-database-based Across Language Server was launched in 2009.
prevent legitimate use,Denial-of-service attacks are characterized by an explicit attempt by attackers to prevent legitimate use of a service.
allow technically unsophisticated attackers access,"Marketed and promoted as stress-testing tools, they can be used to perform unauthorized denial-of-service attacks, and allow technically unsophisticated attackers access to sophisticated attack tools."
perform unauthorized denial,"Marketed and promoted as stress-testing tools, they can be used to perform unauthorized denial-of-service attacks, and allow technically unsophisticated attackers access to sophisticated attack tools."
defensive responses,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
service attacks typically involve,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
attack detection,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
response tools,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
block traffic,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
allow traffic,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
asic based ips may detect,An ASIC based IPS may detect and block denial-of-service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.
circuit breaker,An ASIC based IPS may detect and block denial-of-service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.
act like,An ASIC based IPS may detect and block denial-of-service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.
block denial,An ASIC based IPS may detect and block denial-of-service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.
many jurisdictions,Many jurisdictions have laws under which denial-of-service attacks are illegal.
model checking,"Clarke, Emerson, and Sifakis shared the 2007 Turing Award for their seminal work founding and developing the field of model checking. !! In computer science, model checking or property checking is a method for checking whether a finite-state model of a system meets a given specification (also known as correctness). !! Runtime verification avoids the complexity of traditional formal verification techniques, such as model checking and theorem proving, by analyzing only one or a few execution traces and by working directly with the actual system, thus scaling up relatively well and giving more confidence in the results of the analysis (because it avoids the tedious and error-prone step of formally modelling the system), at the expense of less coverage. !! Model checking is most often applied to hardware designs. !! Model checking began with the pioneering work of E. M. Clarke, E. A. Emerson, by J. P. Queille, and J. Sifakis. !! is finite, as it is in hardware, model checking reduces to a graph search. !! In computer science, partial order reduction is a technique for reducing the size of the state-space to be searched by a model checking or Automated planning and scheduling algorithm."
enabled transitions,"In explicit state space exploration, partial order reduction usually refers to the specific technique of expanding a representative subset of all enabled transitions."
partial order reduction usually refers,"In explicit state space exploration, partial order reduction usually refers to the specific technique of expanding a representative subset of all enabled transitions."
representative subset,"In explicit state space exploration, partial order reduction usually refers to the specific technique of expanding a representative subset of all enabled transitions."
specific technique,"In explicit state space exploration, partial order reduction usually refers to the specific technique of expanding a representative subset of all enabled transitions."
guard strengthening,"In symbolic model checking, partial order reduction can be achieved by adding more constraints (guard strengthening)."
specified distance,"In text processing, a proximity search looks for documents where two or more separately matching term occurrences are within a specified distance, where distance is the number of intermediate words or characters."
proximity search looks,"In text processing, a proximity search looks for documents where two or more separately matching term occurrences are within a specified distance, where distance is the number of intermediate words or characters."
separately matching term occurrences,"In text processing, a proximity search looks for documents where two or more separately matching term occurrences are within a specified distance, where distance is the number of intermediate words or characters."
intermediate words,"In text processing, a proximity search looks for documents where two or more separately matching term occurrences are within a specified distance, where distance is the number of intermediate words or characters."
proximity searching goes beyond,Proximity searching goes beyond the simple matching of words by adding the constraint of proximity and is generally regarded as a form of advanced search.
advanced search,Proximity searching goes beyond the simple matching of words by adding the constraint of proximity and is generally regarded as a form of advanced search.
simple matching,Proximity searching goes beyond the simple matching of words by adding the constraint of proximity and is generally regarded as a form of advanced search.
generally regarded,Proximity searching goes beyond the simple matching of words by adding the constraint of proximity and is generally regarded as a form of advanced search.
document implies,The basic linguistic assumption of proximity searching is that the proximity of the words in a document implies a relationship between the words.
one method,"Proximity searching is one method of reducing the number of pages matches, and to improve the relevance of the matched pages by using word proximity to assist in ranking."
pages matches,"Proximity searching is one method of reducing the number of pages matches, and to improve the relevance of the matched pages by using word proximity to assist in ranking."
using word proximity,"Proximity searching is one method of reducing the number of pages matches, and to improve the relevance of the matched pages by using word proximity to assist in ranking."
matched pages,"Proximity searching is one method of reducing the number of pages matches, and to improve the relevance of the matched pages by using word proximity to assist in ranking."
shotgun lists,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
added benefit,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
proximity searching helps combat spamdexing,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
avoiding webpages,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
would otherwise rank highly,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
contain dictionary lists,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
heavily biased toward word frequency,"As an added benefit, proximity searching helps combat spamdexing by avoiding webpages which contain dictionary lists or shotgun lists of thousands of words, which would otherwise rank highly if the search engine was heavily biased toward word frequency."
cyclic redundancy checks multi,The CRCTable is a memoization of a calculation that would have to be repeated for each byte of the message (Computation of cyclic redundancy checks Multi-bit computation).
cyclic redundancy checks,"The CRCTable is a memoization of a calculation that would have to be repeated for each byte of the message (Computation of cyclic redundancy checks Multi-bit computation). !! Checksum algorithms, such as CRC32 and other cyclic redundancy checks, are designed to meet much weaker requirements and are generally unsuitable as cryptographic hash functions. !! Numerous varieties of cyclic redundancy checks have been incorporated into technical standards."
bit computation,The CRCTable is a memoization of a calculation that would have to be repeated for each byte of the message (Computation of cyclic redundancy checks Multi-bit computation).
numerous varieties,Numerous varieties of cyclic redundancy checks have been incorporated into technical standards.
technical standards,"Path dependence has been used to describe institutions, technical standards, patterns of economic or social development, organizational behavior, and more. !! Numerous varieties of cyclic redundancy checks have been incorporated into technical standards."
optical method,Digital image correlation and tracking is an optical method that employs tracking and image registration techniques for accurate 2D and 3D measurements of changes in images.
employs tracking,Digital image correlation and tracking is an optical method that employs tracking and image registration techniques for accurate 2D and 3D measurements of changes in images.
increased due,"Compared to strain gages and extensometers, the amount of information gathered about the fine details of deformation during mechanical tests is increased due to the ability to provide both local and average data using digital image correlation."
fine details,"Compared to strain gages and extensometers, the amount of information gathered about the fine details of deformation during mechanical tests is increased due to the ability to provide both local and average data using digital image correlation."
strain gages,"Compared to strain gages and extensometers, the amount of information gathered about the fine details of deformation during mechanical tests is increased due to the ability to provide both local and average data using digital image correlation."
mechanical tests,"Compared to strain gages and extensometers, the amount of information gathered about the fine details of deformation during mechanical tests is increased due to the ability to provide both local and average data using digital image correlation."
information gathered,"Compared to strain gages and extensometers, the amount of information gathered about the fine details of deformation during mechanical tests is increased due to the ability to provide both local and average data using digital image correlation."
relative ease,"Digital image correlation (DIC) techniques have been increasing in popularity, especially in micro- and nano-scale mechanical testing applications due to its relative ease of implementation and use."
scale mechanical testing applications due,"Digital image correlation (DIC) techniques have been increasing in popularity, especially in micro- and nano-scale mechanical testing applications due to its relative ease of implementation and use."
dic practice,"The International Digital Image Correlation Society (iDICs) is composed of members from academia, government, and industry, and is committed to training and educating users of DIC systems and the standardization of DIC practice for general applications."
international digital image correlation society,"The International Digital Image Correlation Society (iDICs) is composed of members from academia, government, and industry, and is committed to training and educating users of DIC systems and the standardization of DIC practice for general applications."
general applications,"The International Digital Image Correlation Society (iDICs) is composed of members from academia, government, and industry, and is committed to training and educating users of DIC systems and the standardization of DIC practice for general applications."
educating users,"The International Digital Image Correlation Society (iDICs) is composed of members from academia, government, and industry, and is committed to training and educating users of DIC systems and the standardization of DIC practice for general applications."
particular target scenario,"The ambiguity function is defined by the properties of the pulse and of the filter, and not any particular target scenario."
ambiguity function exist,Many definitions of the ambiguity function exist; some are restricted to narrowband signals and others are suitable to describe the delay and Doppler relationship of wideband signals.
wideband signals,Many definitions of the ambiguity function exist; some are restricted to narrowband signals and others are suitable to describe the delay and Doppler relationship of wideband signals.
doppler relationship,Many definitions of the ambiguity function exist; some are restricted to narrowband signals and others are suitable to describe the delay and Doppler relationship of wideband signals.
narrowband signals,Many definitions of the ambiguity function exist; some are restricted to narrowband signals and others are suitable to describe the delay and Doppler relationship of wideband signals.
many definitions,Many definitions of urban informatics have been published and can be found online. !! Many definitions of the ambiguity function exist; some are restricted to narrowband signals and others are suitable to describe the delay and Doppler relationship of wideband signals.
magnitude squared,Often the definition of the ambiguity function is given as the magnitude squared of other definitions (Weiss).
ambiguity function plays,"The ambiguity function plays a key role in the field of timefrequency signal processing, as it is related to the WignerVille distribution by a 2-dimensional Fourier transform."
timefrequency signal processing,"The ambiguity function plays a key role in the field of timefrequency signal processing, as it is related to the WignerVille distribution by a 2-dimensional Fourier transform."
soft computing studying,"In computer science, evolutionary computation is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms."
global optimization inspired,"In computer science, evolutionary computation is a family of algorithms for global optimization inspired by biological evolution, and the subfield of artificial intelligence and soft computing studying these algorithms."
iteratively updated,"In evolutionary computation, an initial set of candidate solutions is generated and iteratively updated."
initial set,"In evolutionary computation, an initial set of candidate solutions is generated and iteratively updated."
problem settings,"Evolutionary computation techniques can produce highly optimized solutions in a wide range of problem settings, making them popular in computer science."
produce highly optimized solutions,"Evolutionary computation techniques can produce highly optimized solutions in a wide range of problem settings, making them popular in computer science."
evolutionary biology,Evolutionary computation is also sometimes used in evolutionary biology as an in silico experimental procedure to study common aspects of general evolutionary processes.
also sometimes used,Evolutionary computation is also sometimes used in evolutionary biology as an in silico experimental procedure to study common aspects of general evolutionary processes.
silico experimental procedure,Evolutionary computation is also sometimes used in evolutionary biology as an in silico experimental procedure to study common aspects of general evolutionary processes.
general evolutionary processes,Evolutionary computation is also sometimes used in evolutionary biology as an in silico experimental procedure to study common aspects of general evolutionary processes.
study common aspects,Evolutionary computation is also sometimes used in evolutionary biology as an in silico experimental procedure to study common aspects of general evolutionary processes.
increasingly significant part,"Since the 1990s, nature-inspired algorithms are becoming an increasingly significant part of the evolutionary computation."
inspired algorithms,"Since the 1990s, nature-inspired algorithms are becoming an increasingly significant part of the evolutionary computation."
economics analysis,"The development has resulted in the emergence of a new branch of discipline, namely econophysics, which is broadly defined as a cross-discipline that applies statistical physics methodologies which are mostly based on the complex systems theory and the chaos theory for economics analysis."
mostly based,"The development has resulted in the emergence of a new branch of discipline, namely econophysics, which is broadly defined as a cross-discipline that applies statistical physics methodologies which are mostly based on the complex systems theory and the chaos theory for economics analysis."
namely econophysics,"The development has resulted in the emergence of a new branch of discipline, namely econophysics, which is broadly defined as a cross-discipline that applies statistical physics methodologies which are mostly based on the complex systems theory and the chaos theory for economics analysis."
new branch,"The development has resulted in the emergence of a new branch of discipline, namely econophysics, which is broadly defined as a cross-discipline that applies statistical physics methodologies which are mostly based on the complex systems theory and the chaos theory for economics analysis."
broadly defined,"Persuasive technology is broadly defined as technology that is designed to change attitudes or behaviors of the users through persuasion and social influence, but not necessarily through coercion. !! The development has resulted in the emergence of a new branch of discipline, namely econophysics, which is broadly defined as a cross-discipline that applies statistical physics methodologies which are mostly based on the complex systems theory and the chaos theory for economics analysis."
applies statistical physics methodologies,"The development has resulted in the emergence of a new branch of discipline, namely econophysics, which is broadly defined as a cross-discipline that applies statistical physics methodologies which are mostly based on the complex systems theory and the chaos theory for economics analysis."
evolving rules,"In computer science, an evolving intelligent system is a fuzzy logic system which improves the own performance by evolving rules."
phrase eis,The concept of Evolving Intelligent Systems (EISs) was conceived around the turn of the century with the phrase EIS itself coined for the first time by Angelov and Kasabov in a 2006 IEEE newsletter and expanded in a 2010 text.
2006 ieee newsletter,The concept of Evolving Intelligent Systems (EISs) was conceived around the turn of the century with the phrase EIS itself coined for the first time by Angelov and Kasabov in a 2006 IEEE newsletter and expanded in a 2010 text.
conceived around,The concept of Evolving Intelligent Systems (EISs) was conceived around the turn of the century with the phrase EIS itself coined for the first time by Angelov and Kasabov in a 2006 IEEE newsletter and expanded in a 2010 text.
abstract machine used,A counter machine is an abstract machine used in a formal logic and theoretical computer science to model computation.
model computation,A counter machine is an abstract machine used in a formal logic and theoretical computer science to model computation.
counter machine comprises,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
single non,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
usually sequential,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
control instructions,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
unbounded registers,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
negative integer,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
seven instructions,For a given counter machine model the instruction set is tinyfrom just one to six or seven instructions.
given counter machine model,For a given counter machine model the instruction set is tinyfrom just one to six or seven instructions.
given computational problem,"Algorithm analysis is an important part of a broader computational complexity theory, which provides theoretical estimates for the resources needed by any algorithm which solves a given computational problem."
provides theoretical estimates,"Algorithm analysis is an important part of a broader computational complexity theory, which provides theoretical estimates for the resources needed by any algorithm which solves a given computational problem."
significantly impact system performance,Algorithm analysis is important in practice because the accidental or unintentional use of an inefficient algorithm can significantly impact system performance.
unintentional use,Algorithm analysis is important in practice because the accidental or unintentional use of an inefficient algorithm can significantly impact system performance.
informing conclusions,"Data analysis is a process of inspecting, cleansing, transforming, and modelling data with the goal of discovering useful information, informing conclusions, and supporting decision-making."
modelling data,"Data analysis is a process of inspecting, cleansing, transforming, and modelling data with the goal of discovering useful information, informing conclusions, and supporting decision-making."
discovering useful information,"Data analysis is a process of inspecting, cleansing, transforming, and modelling data with the goal of discovering useful information, informing conclusions, and supporting decision-making."
supporting decision,"Data analysis is a process of inspecting, cleansing, transforming, and modelling data with the goal of discovering useful information, informing conclusions, and supporting decision-making."
encompassing diverse techniques,"Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains."
social science domains,"Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains."
different business,"Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains."
multiple facets,"Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains."
helping businesses operate,"In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively."
data analysis plays,"In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively."
business world,"In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively."
making decisions,"In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively."
business intelligence covers data analysis,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
purely descriptive purposes,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
predictive rather,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
relies heavily,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
business information,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
focusing mainly,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
statistical applications,"In statistical applications, data analysis can be divided into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA)."
deterministic algorithm operating,"In cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks."
length groups,"In cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks."
called blocks,"In cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks."
single block,"Even a secure block cipher is suitable for the encryption of only a single block of data at a time, using a fixed key."
fixed key,"Even a secure block cipher is suitable for the encryption of only a single block of data at a time, using a fixed key."
block ciphers may also feature,"However, block ciphers may also feature as building blocks in other cryptographic protocols, such as universal hash functions and pseudorandom number generators."
block cipher consists,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
algorithms accept two inputs,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
size k bits,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
function properly,"In software engineering, a circular dependency is a relation between two or more modules which either directly or indirectly depend on each other to function properly."
indirectly depend,"In software engineering, a circular dependency is a relation between two or more modules which either directly or indirectly depend on each other to function properly."
based texture compression algorithm developed,Adaptive scalable texture compression (ASTC) is a lossy block-based texture compression algorithm developed by Jrn Nystad et al.
jrn nystad et al,Adaptive scalable texture compression (ASTC) is a lossy block-based texture compression algorithm developed by Jrn Nystad et al.
bottom rung,"Mathematical induction proves that we can climb as high as we like on a ladder, by proving that we can climb onto the bottom rung (the basis) and that from each rung we can climb up to the next one (the step)."
climb onto,"Mathematical induction proves that we can climb as high as we like on a ladder, by proving that we can climb onto the bottom rung (the basis) and that from each rung we can climb up to the next one (the step)."
next one,"Mathematical induction proves that we can climb as high as we like on a ladder, by proving that we can climb onto the bottom rung (the basis) and that from each rung we can climb up to the next one (the step). !! In simpler CPUs, the instruction cycle is executed sequentially, each instruction being processed before the next one is started."
mathematical induction proves,"Mathematical induction proves that we can climb as high as we like on a ladder, by proving that we can climb onto the bottom rung (the basis) and that from each rung we can climb up to the next one (the step)."
extended sense,Mathematical induction in this extended sense is closely related to recursion.
formal proofs,"Mathematical induction is an inference rule used in formal proofs, and is the foundation of most correctness proofs for computer programs."
inference rule used,"Mathematical induction is an inference rule used in formal proofs, and is the foundation of most correctness proofs for computer programs."
name may suggest otherwise,"Although its name may suggest otherwise, mathematical induction should not be confused with inductive reasoning as used in philosophy (see Problem of induction)."
see problem,"Although its name may suggest otherwise, mathematical induction should not be confused with inductive reasoning as used in philosophy (see Problem of induction)."
dynamic programming usually refers,"In terms of mathematical optimization, dynamic programming usually refers to simplifying a decision by breaking it down into a sequence of decision steps over time."
problem involves breaking,The dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions.
smaller decisions,The dynamic programming approach to solve this problem involves breaking it apart into a sequence of smaller decisions.
two key attributes,There are two key attributes that a problem must have in order for dynamic programming to be applicable: optimal substructure and overlapping sub-problems.
overlapping sub,There are two key attributes that a problem must have in order for dynamic programming to be applicable: optimal substructure and overlapping sub-problems.
problem must,There are two key attributes that a problem must have in order for dynamic programming to be applicable: optimal substructure and overlapping sub-problems.
geographic location,Automatic vehicle location (AVL or ~locating; telelocating in EU) is a means for automatically determining and transmitting the geographic location of a vehicle.
automatic vehicle location,Automatic vehicle location (AVL or ~locating; telelocating in EU) is a means for automatically determining and transmitting the geographic location of a vehicle. !! The use of Automatic Vehicle Location is given in the following scenario; A car breaks down by the side of the road and the occupant calls a vehicle recovery company.
automatically determining,Automatic vehicle location (AVL or ~locating; telelocating in EU) is a means for automatically determining and transmitting the geographic location of a vehicle.
following scenario,The use of Automatic Vehicle Location is given in the following scenario; A car breaks down by the side of the road and the occupant calls a vehicle recovery company.
car breaks,The use of Automatic Vehicle Location is given in the following scenario; A car breaks down by the side of the road and the occupant calls a vehicle recovery company.
occupant calls,The use of Automatic Vehicle Location is given in the following scenario; A car breaks down by the side of the road and the occupant calls a vehicle recovery company.
vehicle recovery company,The use of Automatic Vehicle Location is given in the following scenario; A car breaks down by the side of the road and the occupant calls a vehicle recovery company.
interaction design,"While interaction design has an interest in form (similar to other design fields), its main area of focus rests on behavior. !! "":xxvii,30 Beyond the digital aspect, interaction design is also useful when creating physical (non-digital) products, exploring how a user might interact with it. !! The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden. !! Interaction design, often abbreviated as IxD, is ""the practice of designing interactive digital products, environments, systems, and services. !! Common topics of interaction design include design, humancomputer interaction, and software development. !! :xxvii,30 Rather than analyzing how things are, interaction design synthesizes and imagines things as they could be."
interactive institute,"The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden. !! The Interactive Institute was founded in 1998 by the Swedish Foundation for Strategic Research, and is owned by Research Institutes of Sweden (RISE) through the Swedish ICT group."
experimental research institute,"The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden."
the interactive institute,"The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden. !! The Interactive Institute website !! The Interactive Institute was founded in 1998 by the Swedish Foundation for Strategic Research, and is owned by Research Institutes of Sweden (RISE) through the Swedish ICT group."
interactive institute swedish ict,"The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden."
communications technology,"The Interactive Institute (also known as Interactive Institute Swedish ICT) is an experimental research institute in the fields of information and communications technology, interaction design, and visualization, operating in Sweden."
swedish foundation,"The Interactive Institute was founded in 1998 by the Swedish Foundation for Strategic Research, and is owned by Research Institutes of Sweden (RISE) through the Swedish ICT group."
research institutes,"The Interactive Institute was founded in 1998 by the Swedish Foundation for Strategic Research, and is owned by Research Institutes of Sweden (RISE) through the Swedish ICT group."
strategic research,"The Interactive Institute was founded in 1998 by the Swedish Foundation for Strategic Research, and is owned by Research Institutes of Sweden (RISE) through the Swedish ICT group."
swedish ict group,"The Interactive Institute was founded in 1998 by the Swedish Foundation for Strategic Research, and is owned by Research Institutes of Sweden (RISE) through the Swedish ICT group."
interactive institute website,The Interactive Institute website
physical experiences,"A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
combines playing,"A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
sometimes written,"A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
transreality game,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space. !! A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
video game,"A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
reality game,"A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
may also integrate,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
liping xie,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
world optimum,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
data feeds,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
sample individuals search,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
real world forces,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
virtual problem space,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
entire information associated,"Random-fuzzy variable (RFV) is a type 2 fuzzy variable, defined using the mathematical possibility theory, used to represent the entire information associated to a measurement result."
measurement result,"Random-fuzzy variable (RFV) is a type 2 fuzzy variable, defined using the mathematical possibility theory, used to represent the entire information associated to a measurement result."
constructed using,A Random-fuzzy variable can be constructed using an Internal possibility distribution(rinternal) and a random possibility distribution(rrandom).
confidence level,A Random-Fuzzy variable is capable of giving a complete picture of the random and systematic contributions to the total uncertainty from the -cuts for any confidence level as the confidence level is nothing but 1-.
systematic contributions,A Random-Fuzzy variable is capable of giving a complete picture of the random and systematic contributions to the total uncertainty from the -cuts for any confidence level as the confidence level is nothing but 1-.
total uncertainty,A Random-Fuzzy variable is capable of giving a complete picture of the random and systematic contributions to the total uncertainty from the -cuts for any confidence level as the confidence level is nothing but 1-.
complete picture,A Random-Fuzzy variable is capable of giving a complete picture of the random and systematic contributions to the total uncertainty from the -cuts for any confidence level as the confidence level is nothing but 1-.
provide guidelines,The service autonomy principle attempts to provide guidelines for designing autonomous services so that the resulting services are more predictable and reliable.
resulting services,The service autonomy principle attempts to provide guidelines for designing autonomous services so that the resulting services are more predictable and reliable.
service autonomy principle attempts,The service autonomy principle attempts to provide guidelines for designing autonomous services so that the resulting services are more predictable and reliable.
provide communication among,"In computer science, shared memory is memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies."
avoid redundant copies,"In computer science, shared memory is memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies."
simultaneously accessed,"In computer science, shared memory is memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies."
passing data,Shared memory is an efficient means of passing data between programs.
efficient means,Shared memory is an efficient means of passing data between programs.
communication inside,"Using memory for communication inside a single program, e. g. among its multiple threads, is also referred to as shared memory."
single program,"Using memory for communication inside a single program, e. g. among its multiple threads, is also referred to as shared memory."
using memory,"Using memory for communication inside a single program, e. g. among its multiple threads, is also referred to as shared memory."
multiple threads,"Using memory for communication inside a single program, e. g. among its multiple threads, is also referred to as shared memory."
shared memory,"Using memory for communication inside a single program, e. g. among its multiple threads, is also referred to as shared memory. !! A shared memory system is relatively easy to program since all processors share a single view of data and the communication between processors can be as fast as memory accesses to a same location. !! Shared memory is an efficient means of passing data between programs. !! In computer science, shared memory is memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies. !! In computer hardware, shared memory refers to a (typically large) block of random access memory (RAM) that can be accessed by several different central processing units (CPUs) in a multiprocessor computer system."
shared memory refers,"In computer hardware, shared memory refers to a (typically large) block of random access memory (RAM) that can be accessed by several different central processing units (CPUs) in a multiprocessor computer system."
typically large,"In computer hardware, shared memory refers to a (typically large) block of random access memory (RAM) that can be accessed by several different central processing units (CPUs) in a multiprocessor computer system."
program since,A shared memory system is relatively easy to program since all processors share a single view of data and the communication between processors can be as fast as memory accesses to a same location.
single view,A shared memory system is relatively easy to program since all processors share a single view of data and the communication between processors can be as fast as memory accesses to a same location.
relatively easy,A shared memory system is relatively easy to program since all processors share a single view of data and the communication between processors can be as fast as memory accesses to a same location.
processors share,A shared memory system is relatively easy to program since all processors share a single view of data and the communication between processors can be as fast as memory accesses to a same location.
transform data stored,"Database encryption can generally be defined as a process that uses an algorithm to transform data stored in a database into ""cipher text"" that is incomprehensible without first being decrypted."
incomprehensible without first,"Database encryption can generally be defined as a process that uses an algorithm to transform data stored in a database into ""cipher text"" that is incomprehensible without first being decrypted."
technologies available,"There are multiple techniques and technologies available for database encryption, the most important of which will be detailed in this article."
multiple techniques,"There are multiple techniques and technologies available for database encryption, the most important of which will be detailed in this article."
symmetric key,"The contents of the database are encrypted using a symmetric key that is often referred to as a ""database encryption key""."
encrypted using,"The contents of the database are encrypted using a symmetric key that is often referred to as a ""database encryption key""."
loss thereof,"The main disadvantage associated with column-level database encryption is speed, or a loss thereof."
main disadvantage associated,"The main disadvantage associated with column-level database encryption is speed, or a loss thereof."
margin support vector machine described,The soft-margin support vector machine described above is an example of an empirical risk minimization (ERM) algorithm for the hinge loss.
learn nonlinear dimension reduction functions,Autoencoders can be used to learn nonlinear dimension reduction functions and codings together with an inverse function from the coding to the original representation.
codings together,Autoencoders can be used to learn nonlinear dimension reduction functions and codings together with an inverse function from the coding to the original representation.
usually performed prior,"For high-dimensional datasets (i. e. with number of dimensions more than 10), dimension reduction is usually performed prior to applying a K-nearest neighbors algorithm (k-NN) in order to avoid the effects of the curse of dimensionality. !! For high-dimensional data (e. g. , with number of dimensions more than 10) dimension reduction is usually performed prior to applying the k-NN algorithm in order to avoid the effects of the curse of dimensionality."
10  dimension reduction,"For high-dimensional datasets (i. e. with number of dimensions more than 10), dimension reduction is usually performed prior to applying a K-nearest neighbors algorithm (k-NN) in order to avoid the effects of the curse of dimensionality."
dimensional datasets,"For high-dimensional datasets (i. e. with number of dimensions more than 10), dimension reduction is usually performed prior to applying a K-nearest neighbors algorithm (k-NN) in order to avoid the effects of the curse of dimensionality. !! Parallel coordinates are a common way of visualizing and analyzing high-dimensional datasets."
processing step followed,"Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space."
abstraction higher,"An algorithmic paradigm is an abstraction higher than the notion of an algorithm, just as an algorithm is an abstraction higher than a computer program."
special kind,"In order theory, a branch of mathematics, an order embedding is a special kind of monotone function, which provides a way to include one partially ordered set into another. !! In the mathematical discipline of linear algebra, a triangular matrix is a special kind of square matrix."
lower triangular matrix l,"By the LU decomposition algorithm, an invertible matrix may be written as the product of a lower triangular matrix L and an upper triangular matrix U if and only if all its leading principal minors are non-zero."
upper triangular matrix u,"A matrix equation with an upper triangular matrix U can be solved in an analogous way, only working backwards. !! By the LU decomposition algorithm, an invertible matrix may be written as the product of a lower triangular matrix L and an upper triangular matrix U if and only if all its leading principal minors are non-zero."
invertible matrix may,"By the LU decomposition algorithm, an invertible matrix may be written as the product of a lower triangular matrix L and an upper triangular matrix U if and only if all its leading principal minors are non-zero."
working backwards,"A matrix equation with an upper triangular matrix U can be solved in an analogous way, only working backwards."
analogous way,"A matrix equation with an upper triangular matrix U can be solved in an analogous way, only working backwards."
condensed matter physics,"Lattice models originally occurred in the context of condensed matter physics, where the atoms of a crystal automatically form a lattice."
crystal automatically form,"Lattice models originally occurred in the context of condensed matter physics, where the atoms of a crystal automatically form a lattice."
lattice models originally occurred,"Lattice models originally occurred in the context of condensed matter physics, where the atoms of a crystal automatically form a lattice."
many reasons,"Currently, lattice models are quite popular in theoretical physics, for many reasons."
quite popular,"Currently, lattice models are quite popular in theoretical physics, for many reasons."
theoretical physics,"Currently, lattice models are quite popular in theoretical physics, for many reasons."
lattice model,"Lattice models are also ideal for study by the methods of computational physics, as the discretization of any continuum model automatically turns it into a lattice model."
also ideal,"Lattice models are also ideal for study by the methods of computational physics, as the discretization of any continuum model automatically turns it into a lattice model."
continuum model automatically turns,"Lattice models are also ideal for study by the methods of computational physics, as the discretization of any continuum model automatically turns it into a lattice model."
potts model,"Examples of lattice models in condensed matter physics include the Ising model, the Potts model, the XY model, the Toda lattice."
toda lattice,"Examples of lattice models in condensed matter physics include the Ising model, the Potts model, the XY model, the Toda lattice."
condensed matter physics include,"Examples of lattice models in condensed matter physics include the Ising model, the Potts model, the XY model, the Toda lattice."
xy model,"Examples of lattice models in condensed matter physics include the Ising model, the Potts model, the XY model, the Toda lattice."
continuum theory,"Physical lattice models frequently occur as an approximation to a continuum theory, either to give an ultraviolet cutoff to the theory to prevent divergences or to perform numerical computations."
ultraviolet cutoff,"Physical lattice models frequently occur as an approximation to a continuum theory, either to give an ultraviolet cutoff to the theory to prevent divergences or to perform numerical computations."
perform numerical computations,"Physical lattice models frequently occur as an approximation to a continuum theory, either to give an ultraviolet cutoff to the theory to prevent divergences or to perform numerical computations."
physical lattice models frequently occur,"Physical lattice models frequently occur as an approximation to a continuum theory, either to give an ultraviolet cutoff to the theory to prevent divergences or to perform numerical computations."
prevent divergences,"Physical lattice models frequently occur as an approximation to a continuum theory, either to give an ultraviolet cutoff to the theory to prevent divergences or to perform numerical computations."
identities involving,Some identities involving the Fibonacci Polynomials.
search upon,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
cbir system,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
involves providing,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
sample image,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
based image retrieval,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
discover content,"Reverse image search also allows users to discover content that is related to a specific sample image, popularity of an image, and discover manipulated versions and derivative works."
derivative works,"Reverse image search also allows users to discover content that is related to a specific sample image, popularity of an image, and discover manipulated versions and derivative works."
specific sample image,"Reverse image search also allows users to discover content that is related to a specific sample image, popularity of an image, and discover manipulated versions and derivative works."
discover manipulated versions,"Reverse image search also allows users to discover content that is related to a specific sample image, popularity of an image, and discover manipulated versions and derivative works."
image url,Google's Search by Image is a feature that uses reverse image search and allows users to search for related images just by uploading an image or image URL.
related images,Google's Search by Image is a feature that uses reverse image search and allows users to search for related images just by uploading an image or image URL.
uses reverse image search,Google's Search by Image is a feature that uses reverse image search and allows users to search for related images just by uploading an image or image URL.
search engine specialized,TinEye is a search engine specialized for reverse image search.
concrete mathematical underpinning,"In mathematics and computer science, trace theory aims to provide a concrete mathematical underpinning for the study of concurrent computation and process calculi."
process calculi,"In mathematics and computer science, trace theory aims to provide a concrete mathematical underpinning for the study of concurrent computation and process calculi. !! While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
trace theory aims,"In mathematics and computer science, trace theory aims to provide a concrete mathematical underpinning for the study of concurrent computation and process calculi."
trace theory stems,"The power of trace theory stems from the fact that the algebra of dependency graphs (such as Petri nets) is isomorphic to that of trace monoids, and thus, one can apply both algebraic formal language tools, as well as tools from graph theory."
antoni mazurkiewicz,"While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
first formulated,"While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
pierre cartier,"While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
deterministic choice,"While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
dominique foata,"While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
mediated reality system,"A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment."
intuitive means,"A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment."
flying environment,"A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment."
synthetic vision system,"Minimum aviation system performance standards for Enhanced Vision Systems, Synthetic Vision Systems, Combined Vision Systems and Enhanced Flight Vision Systems. !! ED-179B - MASP for Enhanced Vision Systems and Synthetic Vision Systems and Combined Vision Systems and Enhanced Flight Vision Systems. !! A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment. !! In 2005 a synthetic vision system was installed on a Gulfstream V test aircraft as part of NASA's ""Turning Goals Into Reality"" program."
provide pilots,"A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment."
aerial vehicles,"A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment."
turning goals,"In 2005 a synthetic vision system was installed on a Gulfstream V test aircraft as part of NASA's ""Turning Goals Into Reality"" program."
gulfstream v test aircraft,"In 2005 a synthetic vision system was installed on a Gulfstream V test aircraft as part of NASA's ""Turning Goals Into Reality"" program."
combined vision systems,"ED-179B - MASP for Enhanced Vision Systems and Synthetic Vision Systems and Combined Vision Systems and Enhanced Flight Vision Systems. !! Minimum aviation system performance standards for Enhanced Vision Systems, Synthetic Vision Systems, Combined Vision Systems and Enhanced Flight Vision Systems."
minimum aviation system performance standards,"Minimum aviation system performance standards for Enhanced Vision Systems, Synthetic Vision Systems, Combined Vision Systems and Enhanced Flight Vision Systems."
enhanced vision systems,"ED-179B - MASP for Enhanced Vision Systems and Synthetic Vision Systems and Combined Vision Systems and Enhanced Flight Vision Systems. !! Minimum aviation system performance standards for Enhanced Vision Systems, Synthetic Vision Systems, Combined Vision Systems and Enhanced Flight Vision Systems."
enhanced flight vision systems,"ED-179B - MASP for Enhanced Vision Systems and Synthetic Vision Systems and Combined Vision Systems and Enhanced Flight Vision Systems. !! Minimum aviation system performance standards for Enhanced Vision Systems, Synthetic Vision Systems, Combined Vision Systems and Enhanced Flight Vision Systems."
synthetic vision systems,"ED-179B - MASP for Enhanced Vision Systems and Synthetic Vision Systems and Combined Vision Systems and Enhanced Flight Vision Systems. !! Minimum aviation system performance standards for Enhanced Vision Systems, Synthetic Vision Systems, Combined Vision Systems and Enhanced Flight Vision Systems."
still diagonalizable,"is not positive-semidefinite and Hermitian but still diagonalizable, its eigendecomposition and singular value decomposition are distinct."
corresponding column,"Consequently, if all singular values of a square matrix M are non-degenerate and non-zero, then its singular value decomposition is unique, up to multiplication of a column of U by a unit-phase factor and simultaneous multiplication of the corresponding column of V by the same unit-phase factor."
numerical method used,"In computational electromagnetics, the scattering-matrix method (SMM) is a numerical method used to solve Maxwell's equations."
solve maxwell,"In computational electromagnetics, the scattering-matrix method (SMM) is a numerical method used to solve Maxwell's equations."
computational electromagnetics,"This makes computational electromagnetics (CEM) important to the design, and modeling of antenna, radar, satellite and other communication systems, nanophotonic devices and high speed silicon electronics, medical imaging, cell-phone antenna design, among other applications. !! The first application of the FMM in computational electromagnetics was by Engheta et al. !! Computational electromagnetics (CEM), computational electrodynamics or electromagnetic modeling is the process of modeling the interaction of electromagnetic fields with physical objects and the environment. !! Fast and Efficient Algorithms in Computational Electromagnetics. !! In computational electromagnetics, the scattering-matrix method (SMM) is a numerical method used to solve Maxwell's equations. !! Computational electromagnetics: a review Archived 2016-03-15 at the Wayback Machine"
first implemented,"The Cache Discovery Protocol was originally developed jointly by BitTorrent, Inc. and CacheLogic and first implemented in version 4."
originally developed jointly,"The Cache Discovery Protocol was originally developed jointly by BitTorrent, Inc. and CacheLogic and first implemented in version 4."
image pixel,This geographical re-projection is also called geographical warping or Geo Warping where each image pixel has to be transformed from one projection into another.
geo warping,This article describes in further detail the Geo Warping of radar video images in real time. !! It will also show that radar video Geo Warping is done most efficiently when it is integrated with the radar scan conversion process. !! This section explains the actual geo warping or re-projection process when applied to radar video in real time. !! The Figure Geo Warping Radar to CIB Projection shows dashed the maximal range circle for a range of 111 km or 60 miles using the radar projection. !! This geographical re-projection is also called geographical warping or Geo Warping where each image pixel has to be transformed from one projection into another.
one projection,This geographical re-projection is also called geographical warping or Geo Warping where each image pixel has to be transformed from one projection into another.
also called geographical warping,This geographical re-projection is also called geographical warping or Geo Warping where each image pixel has to be transformed from one projection into another.
article describes,This article describes in further detail the Geo Warping of radar video images in real time.
radar video images,This article describes in further detail the Geo Warping of radar video images in real time.
radar scan conversion process,It will also show that radar video Geo Warping is done most efficiently when it is integrated with the radar scan conversion process.
radar video geo warping,It will also show that radar video Geo Warping is done most efficiently when it is integrated with the radar scan conversion process.
also show,It will also show that radar video Geo Warping is done most efficiently when it is integrated with the radar scan conversion process.
radar video,This section explains the actual geo warping or re-projection process when applied to radar video in real time.
section explains,This section explains the actual geo warping or re-projection process when applied to radar video in real time.
actual geo warping,This section explains the actual geo warping or re-projection process when applied to radar video in real time.
60 miles using,The Figure Geo Warping Radar to CIB Projection shows dashed the maximal range circle for a range of 111 km or 60 miles using the radar projection.
figure geo warping radar,The Figure Geo Warping Radar to CIB Projection shows dashed the maximal range circle for a range of 111 km or 60 miles using the radar projection.
maximal range circle,The Figure Geo Warping Radar to CIB Projection shows dashed the maximal range circle for a range of 111 km or 60 miles using the radar projection.
cib projection shows dashed,The Figure Geo Warping Radar to CIB Projection shows dashed the maximal range circle for a range of 111 km or 60 miles using the radar projection.
software tool,Deep Learning Studio is a software tool that aims to simplify the creation of deep learning models used in artificial intelligence.
deep learning models used,Deep Learning Studio is a software tool that aims to simplify the creation of deep learning models used in artificial intelligence.
developing effective deep learning models,"Prior to the release of Deep Learning Studio in January 2017, proficiency in Python, among other programming languages, was essential in developing effective deep learning models."
available data,"Deep Learning Studio sought to simplify the model creation process through a visual, drag-and-drop interface and the application of pre-trained learning models on available data."
model creation process,"Deep Learning Studio sought to simplify the model creation process through a visual, drag-and-drop interface and the application of pre-trained learning models on available data."
deep learning studio sought,"Deep Learning Studio sought to simplify the model creation process through a visual, drag-and-drop interface and the application of pre-trained learning models on available data."
drop interface,"Deep Learning Studio sought to simplify the model creation process through a visual, drag-and-drop interface and the application of pre-trained learning models on available data."
developer behind deep learning studio,"Irving, TX-based Deep Cognition Inc. is the developer behind Deep Learning Studio."
based deep cognition inc,"Irving, TX-based Deep Cognition Inc. is the developer behind Deep Learning Studio."
san jose,"0 of Deep Learning Studio at NVIDIA's GTC 2018 Conference in San Jose, CA."
gtc 2018 conference,"0 of Deep Learning Studio at NVIDIA's GTC 2018 Conference in San Jose, CA."
designing interactive digital products,"Interaction design, often abbreviated as IxD, is ""the practice of designing interactive digital products, environments, systems, and services."
creating physical,""":xxvii,30 Beyond the digital aspect, interaction design is also useful when creating physical (non-digital) products, exploring how a user might interact with it."
user might interact,""":xxvii,30 Beyond the digital aspect, interaction design is also useful when creating physical (non-digital) products, exploring how a user might interact with it."
interaction design include design,"Common topics of interaction design include design, humancomputer interaction, and software development."
common topics,"Common topics of interaction design include design, humancomputer interaction, and software development."
main area,"While interaction design has an interest in form (similar to other design fields), its main area of focus rests on behavior."
focus rests,"While interaction design has an interest in form (similar to other design fields), its main area of focus rests on behavior."
design fields,"While interaction design has an interest in form (similar to other design fields), its main area of focus rests on behavior."
interaction design synthesizes,":xxvii,30 Rather than analyzing how things are, interaction design synthesizes and imagines things as they could be."
imagines things,":xxvii,30 Rather than analyzing how things are, interaction design synthesizes and imagines things as they could be."
often simpler,Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms.
flat display,"In humancomputer interaction, an organic user interface (OUI) is defined as a user interface with a non-flat display."
special issue,Organic user interfaces were first introduced in a special issue of the Communications of the ACM in 2008. !! Organic User Interfaces: Special Issue of CACM
organic user interfaces took place,"The first International Workshop on Organic User Interfaces took place at CHI 2009 in Boston, Massachusetts."
first international workshop,"The first International Workshop on Organic User Interfaces took place at CHI 2009 in Boston, Massachusetts."
actual colors,The memory color effect is the phenomenon that memory colors directly modulate the appearance of the actual colors of objects.
memory colors directly modulate,The memory color effect is the phenomenon that memory colors directly modulate the appearance of the actual colors of objects.
german mailboxes,"Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
made objects,"Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
especially pronounced,"Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
subsequent empirical studies,"Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
also shown,"Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
yellow objects,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect. !! Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
visual system,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
short wavelengths,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
towards light,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
orange hues,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
longer wavelengths,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
bluish hues,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
natural daylight shifts,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
thereby providing,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect. !! The basic idea of enterprise modelling according to Ulrich Frank is ""to offer different views on an enterprise, thereby providing a medium to foster dialogues between various stakeholders - both in academia and in practice."
higher degree,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
memorize objects better,Memory color effect can be derived from the human instinct to memorize objects better.
human instinct,Memory color effect can be derived from the human instinct to memorize objects better.
trichromacy evolved,This suggests that the memory color effect is related to the emergence of trichromacy because it has been argued that trichromacy evolved to optimize the ability to detect ripe fruitsobjects that appear in canonical hues.
detect ripe fruitsobjects,This suggests that the memory color effect is related to the emergence of trichromacy because it has been argued that trichromacy evolved to optimize the ability to detect ripe fruitsobjects that appear in canonical hues.
solving one problem using another,"In computational complexity theory, a polynomial-time reduction is a method for solving one problem using another."
second problem,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well."
time reduction proves,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well."
first problem,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well."
efficient algorithm exists,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well."
one exists,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well. !! Implicit trees (such as game trees or other problem-solving trees) may be of infinite size; breadth-first search is guaranteed to find a solution node if one exists."
second one,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well."
complexity classes,Polynomial-time reductions are frequently used in complexity theory for defining both complexity classes and complete problems for those classes.
complete problems,"Polynomial-time reductions are frequently used in complexity theory for defining both complexity classes and complete problems for those classes. !! If real computation were physically realizable, one could use it to solve NP-complete problems, and even #P-complete problems, in polynomial time."
table reductions,"The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
time many,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
least restrictive,"The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
common types,"The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
one reduction,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction."
conquer algorithm recursively breaks,"A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly."
become simple enough,"A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly."
related type,"A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly."
designing efficient divide,Designing efficient divide-and-conquer algorithms can be difficult.
often determined,"The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations."
solving recurrence relations,"The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations."
usually proved,"The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations."
general divide,"These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops."
simple loops,"These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops."
use tail recursion,"These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops."
broad definition,"Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm""."
loops could,"Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm""."
uses recursion,"Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm""."
every algorithm,"Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a ""divide-and-conquer algorithm""."
given signature,"In universal algebra and mathematical logic, a term algebra is a freely generated algebraic structure over a given signature."
freely generated algebraic structure,"In universal algebra and mathematical logic, a term algebra is a freely generated algebraic structure over a given signature."
signature consisting,"For example, in a signature consisting of a single binary operation, the term algebra over a set X of variables is exactly the free magma generated by X."
free magma generated,"For example, in a signature consisting of a single binary operation, the term algebra over a set X of variables is exactly the free magma generated by X."
category theory perspective,"From a category theory perspective, a term algebra is the initial object for the category of all X-generated algebras of the same signature, and this object, unique up to isomorphism, is called an initial algebra; it generates by homomorphic projection all algebras in the category."
initial algebra,"From a category theory perspective, a term algebra is the initial object for the category of all X-generated algebras of the same signature, and this object, unique up to isomorphism, is called an initial algebra; it generates by homomorphic projection all algebras in the category."
initial object,"From a category theory perspective, a term algebra is the initial object for the category of all X-generated algebras of the same signature, and this object, unique up to isomorphism, is called an initial algebra; it generates by homomorphic projection all algebras in the category."
term algebras also play,"Term algebras also play a role in the semantics of abstract data types, where an abstract data type declaration provides the signature of a multi-sorted algebraic structure and the term algebra is a concrete model of the abstract declaration."
abstract data type declaration provides,"Term algebras also play a role in the semantics of abstract data types, where an abstract data type declaration provides the signature of a multi-sorted algebraic structure and the term algebra is a concrete model of the abstract declaration."
abstract declaration,"Term algebras also play a role in the semantics of abstract data types, where an abstract data type declaration provides the signature of a multi-sorted algebraic structure and the term algebra is a concrete model of the abstract declaration."
shown decidable using quantifier elimination,Term algebras can be shown decidable using quantifier elimination.
require high security,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
electronic systems,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
top boxes,"Unlike graphics processing units (GPUs), which are used for computer displays, media processors are targeted at digital televisions and set-top boxes. !! Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
tv set,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
automated teller machines,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
way digital radios,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
secure data communication devices,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
used primarily,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
another processor,Bus encryption can also mean encrypted data transmission on a data bus from one processor to another processor.
also mean encrypted data transmission,Bus encryption can also mean encrypted data transmission on a data bus from one processor to another processor.
one processor,Bus encryption can also mean encrypted data transmission on a data bus from one processor to another processor.
protect certificates,"Such bus encryption is used by Windows Vista and newer Microsoft operating systems to protect certificates, BIOS, passwords, and program authenticity."
program authenticity,"Such bus encryption is used by Windows Vista and newer Microsoft operating systems to protect certificates, BIOS, passwords, and program authenticity."
newer microsoft operating systems,"Such bus encryption is used by Windows Vista and newer Microsoft operating systems to protect certificates, BIOS, passwords, and program authenticity."
protected video path,PVP-UAB (Protected Video Path) provides bus encryption of premium video content in PCs as it passes over the PCIe bus to graphics cards to enforce digital rights management.
enforce digital rights management,PVP-UAB (Protected Video Path) provides bus encryption of premium video content in PCs as it passes over the PCIe bus to graphics cards to enforce digital rights management.
premium video content,PVP-UAB (Protected Video Path) provides bus encryption of premium video content in PCs as it passes over the PCIe bus to graphics cards to enforce digital rights management.
provides bus encryption,PVP-UAB (Protected Video Path) provides bus encryption of premium video content in PCs as it passes over the PCIe bus to graphics cards to enforce digital rights management.
matching pattern,"Uses of pattern matching include outputting the locations (if any) of a pattern within a token sequence, to output some component of the matched pattern, and to substitute the matching pattern with some other token sequence (i. e. , search and replace)."
matched pattern,"Uses of pattern matching include outputting the locations (if any) of a pattern within a token sequence, to output some component of the matched pattern, and to substitute the matching pattern with some other token sequence (i. e. , search and replace)."
pattern within,"Uses of pattern matching include outputting the locations (if any) of a pattern within a token sequence, to output some component of the matched pattern, and to substitute the matching pattern with some other token sequence (i. e. , search and replace)."
pattern matching include outputting,"Uses of pattern matching include outputting the locations (if any) of a pattern within a token sequence, to output some component of the matched pattern, and to substitute the matching pattern with some other token sequence (i. e. , search and replace)."
pattern matching sometimes includes support,Pattern matching sometimes includes support for guards.
parsing algorithms often rely,Parsing algorithms often rely on pattern matching to transform strings into syntax trees.
transform strings,Parsing algorithms often rely on pattern matching to transform strings into syntax trees.
early programming languages,"Early programming languages with pattern matching constructs include COMIT (1957), SNOBOL (1962), Refal (1968) with tree-based pattern matching, Prolog (1972), SASL (1976), NPL (1977), and KRC (1981)."
based pattern matching,"Early programming languages with pattern matching constructs include COMIT (1957), SNOBOL (1962), Refal (1968) with tree-based pattern matching, Prolog (1972), SASL (1976), NPL (1977), and KRC (1981)."
pattern matching constructs include comit,"Early programming languages with pattern matching constructs include COMIT (1957), SNOBOL (1962), Refal (1968) with tree-based pattern matching, Prolog (1972), SASL (1976), NPL (1977), and KRC (1981)."
reduce data redundancy,"Database normalization is the process of structuring a database, usually a relational database, in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity."
called normal forms,"Database normalization is the process of structuring a database, usually a relational database, in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity."
improve data integrity,"Database normalization is the process of structuring a database, usually a relational database, in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity."
achieved unless,"The process is progressive, and a higher level of database normalization cannot be achieved unless the previous levels have been satisfied."
previous levels,"The process is progressive, and a higher level of database normalization cannot be achieved unless the previous levels have been satisfied."
database normalization cannot,"The process is progressive, and a higher level of database normalization cannot be achieved unless the previous levels have been satisfied."
mike chapple,Database Normalization Basics by Mike Chapple (About.
database normalization basics,Database Normalization Basics by Mike Chapple (About.
mike hillyer,An Introduction to Database Normalization by Mike Hillyer.
based metaheuristics,"This is a chronologically ordered list of metaphor-based metaheuristics and swarm intelligence algorithms. !! As a general rule, publication of papers on metaphor-based metaheuristics has been limited to second-tier journals and conferences, but some recent exceptions to this rule can be found."
chronologically ordered list,This is a chronologically ordered list of metaphor-based metaheuristics and swarm intelligence algorithms.
metaphor-based metaheuristics,"This is a chronologically ordered list of metaphor-based metaheuristics and swarm intelligence algorithms. !! As a general rule, publication of papers on metaphor-based metaheuristics has been limited to second-tier journals and conferences, but some recent exceptions to this rule can be found."
tier journals,"As a general rule, publication of papers on metaphor-based metaheuristics has been limited to second-tier journals and conferences, but some recent exceptions to this rule can be found."
recent exceptions,"As a general rule, publication of papers on metaphor-based metaheuristics has been limited to second-tier journals and conferences, but some recent exceptions to this rule can be found."
general rule,"As a general rule, publication of papers on metaphor-based metaheuristics has been limited to second-tier journals and conferences, but some recent exceptions to this rule can be found."
protocol whose full specification,A free protocol is a protocol whose full specification is freely available and for which there are no restrictions (e. g. legal or technical) on its use.
free protocol,Free protocol are important for interoperability and choice of software. !! XMPP is a free protocol. !! A free protocol is a protocol whose full specification is freely available and for which there are no restrictions (e. g. legal or technical) on its use.
freely available,A free protocol is a protocol whose full specification is freely available and for which there are no restrictions (e. g. legal or technical) on its use.
service quality,Synthetic measure (indicator) of service quality in each hotel is calculated with the help of the aggregation operator. !! Network performance refers to measures of service quality of a network as seen by the customer.
network performance refers,Network performance refers to measures of service quality of a network as seen by the customer.
interactive computing refers,"In computer science, interactive computing refers to software which accepts input from the user as it runs."
accepts input,"In computer science, interactive computing refers to software which accepts input from the user as it runs."
time interaction  dialog,"Interactive computing focuses on real-time interaction (""dialog"") between the computer and the operator, and the technologies that enable them."
interactive computing focuses,"Interactive computing focuses on real-time interaction (""dialog"") between the computer and the operator, and the technologies that enable them."
studied extensively,"The nature of interactive computing as well as its impact on users, are studied extensively in the field of computer interaction."
interactive display graphics program,"Ivan Sutherland is considered the father of interactive computing for his work on Sketchpad, the interactive display graphics program he developed in 1963."
ivan sutherland,"Ivan Sutherland is considered the father of interactive computing for his work on Sketchpad, the interactive display graphics program he developed in 1963. !! In 1967, flight-simulation work by Danny Cohen led to the development of the CohenSutherland computer graphics two- and three-dimensional line clipping algorithms, created with Ivan Sutherland."
visionary manifesto published,"There he facilitated ARPA's research grant to Douglas Engelbart for developing the NLS system at SRI, based on his visionary manifesto published in a 1962 report, in which Engelbart envisioned interactive computing as a vehicle for user interaction with computers, with each other, and with their knowledge, all in a vast virtual information space."
research grant,"There he facilitated ARPA's research grant to Douglas Engelbart for developing the NLS system at SRI, based on his visionary manifesto published in a 1962 report, in which Engelbart envisioned interactive computing as a vehicle for user interaction with computers, with each other, and with their knowledge, all in a vast virtual information space."
facilitated arpa,"There he facilitated ARPA's research grant to Douglas Engelbart for developing the NLS system at SRI, based on his visionary manifesto published in a 1962 report, in which Engelbart envisioned interactive computing as a vehicle for user interaction with computers, with each other, and with their knowledge, all in a vast virtual information space."
engelbart envisioned interactive computing,"There he facilitated ARPA's research grant to Douglas Engelbart for developing the NLS system at SRI, based on his visionary manifesto published in a 1962 report, in which Engelbart envisioned interactive computing as a vehicle for user interaction with computers, with each other, and with their knowledge, all in a vast virtual information space."
douglas engelbart,"There he facilitated ARPA's research grant to Douglas Engelbart for developing the NLS system at SRI, based on his visionary manifesto published in a 1962 report, in which Engelbart envisioned interactive computing as a vehicle for user interaction with computers, with each other, and with their knowledge, all in a vast virtual information space."
user interaction,"There he facilitated ARPA's research grant to Douglas Engelbart for developing the NLS system at SRI, based on his visionary manifesto published in a 1962 report, in which Engelbart envisioned interactive computing as a vehicle for user interaction with computers, with each other, and with their knowledge, all in a vast virtual information space."
w3c emotion incubator group,"An Emotion Markup Language (EML or EmotionML) has first been defined by the W3C Emotion Incubator Group (EmoXG) as a general-purpose emotion annotation and representation language, which should be usable in a large variety of technological contexts where emotions need to be represented."
technological contexts,"An Emotion Markup Language (EML or EmotionML) has first been defined by the W3C Emotion Incubator Group (EmoXG) as a general-purpose emotion annotation and representation language, which should be usable in a large variety of technological contexts where emotions need to be represented."
large variety,"An Emotion Markup Language (EML or EmotionML) has first been defined by the W3C Emotion Incubator Group (EmoXG) as a general-purpose emotion annotation and representation language, which should be usable in a large variety of technological contexts where emotions need to be represented."
emotions need,"An Emotion Markup Language (EML or EmotionML) has first been defined by the W3C Emotion Incubator Group (EmoXG) as a general-purpose emotion annotation and representation language, which should be usable in a large variety of technological contexts where emotions need to be represented."
purpose emotion annotation,"An Emotion Markup Language (EML or EmotionML) has first been defined by the W3C Emotion Incubator Group (EmoXG) as a general-purpose emotion annotation and representation language, which should be usable in a large variety of technological contexts where emotions need to be represented."
way accessible,"In 2007, the Emotion Markup Language Incubator Group (EmotionML XG) was set up as a follow-up to the Emotion Incubator Group, ""to propose a specification draft for an Emotion Markup Language, to document it in a way accessible to non-experts, and to illustrate its use in conjunction with a number of existing markups. """
emotion incubator group,"In 2007, the Emotion Markup Language Incubator Group (EmotionML XG) was set up as a follow-up to the Emotion Incubator Group, ""to propose a specification draft for an Emotion Markup Language, to document it in a way accessible to non-experts, and to illustrate its use in conjunction with a number of existing markups. """
specification draft,"In 2007, the Emotion Markup Language Incubator Group (EmotionML XG) was set up as a follow-up to the Emotion Incubator Group, ""to propose a specification draft for an Emotion Markup Language, to document it in a way accessible to non-experts, and to illustrate its use in conjunction with a number of existing markups. """
existing markups,"In 2007, the Emotion Markup Language Incubator Group (EmotionML XG) was set up as a follow-up to the Emotion Incubator Group, ""to propose a specification draft for an Emotion Markup Language, to document it in a way accessible to non-experts, and to illustrate its use in conjunction with a number of existing markups. """
emotionml xg,"In 2007, the Emotion Markup Language Incubator Group (EmotionML XG) was set up as a follow-up to the Emotion Incubator Group, ""to propose a specification draft for an Emotion Markup Language, to document it in a way accessible to non-experts, and to illustrate its use in conjunction with a number of existing markups. """
final report,"The final report of the Emotion Markup Language Incubator Group, Elements of an EmotionML 1."
first public working draft,"The work then was continued in 2009 in the frame of the W3C's Multimodal Interaction Activity, with the First Public Working Draft of ""Emotion Markup Language (EmotionML) 1."
multimodal interaction activity,"W3C's Multimodal Interaction Activity an initiative from W3C aiming to provide means (mostly XML) to support Multimodal Interaction scenarios on the Web. !! The work then was continued in 2009 in the frame of the W3C's Multimodal Interaction Activity, with the First Public Working Draft of ""Emotion Markup Language (EmotionML) 1."
last call working draft,"The Last Call Working Draft of ""Emotion Markup Language 1."
emotion markup language 1,"The Last Call Working Draft of ""Emotion Markup Language 1."
equally spaced addresses,"A sorted array is an array data structure in which each element is sorted in numerical, alphabetical, or some other order, and placed at equally spaced addresses in computer memory."
best locality,Sorted arrays are the most space-efficient data structure with the best locality of reference for sequentially stored data.
one needs,"Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure."
log n  thus sorted arrays,"Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure."
found using,"Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure."
elements within,"Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure."
elements quickly,"Elements within a sorted array are found using a binary search, in O(log n); thus sorted arrays are suited for cases when one needs to be able to look up elements quickly, e. g. as a set or multiset data structure."
balancing binary search tree inserts,"The insertion and deletion of elements in a sorted array executes at O(n), due to the need to shift all the elements following the element to be inserted or deleted; in comparison a self-balancing binary search tree inserts and deletes at O(log n)."
sorted array executes,"The insertion and deletion of elements in a sorted array executes at O(n), due to the need to shift all the elements following the element to be inserted or deleted; in comparison a self-balancing binary search tree inserts and deletes at O(log n)."
elements following,"The insertion and deletion of elements in a sorted array executes at O(n), due to the need to shift all the elements following the element to be inserted or deleted; in comparison a self-balancing binary search tree inserts and deletes at O(log n)."
operation taking,"Elements in a sorted array can be looked up by their index (random access) at O(1) time, an operation taking O(log n) or O(n) time for more complex data structures."
collective properties,"Quantum computing is a type of computation that harnesses the collective properties of quantum states, such as superposition, interference, and entanglement, to perform calculations."
quantum states,"Quantum computing is a type of computation that harnesses the collective properties of quantum states, such as superposition, interference, and entanglement, to perform calculations."
perform calculations,"Quantum computing is a type of computation that harnesses the collective properties of quantum states, such as superposition, interference, and entanglement, to perform calculations."
quantum computing began,Quantum computing began in 1980 when physicist Paul Benioff proposed a quantum mechanical model of the Turing machine.
physicist paul benioff proposed,Quantum computing began in 1980 when physicist Paul Benioff proposed a quantum mechanical model of the Turing machine.
quantum mechanical model,Quantum computing began in 1980 when physicist Paul Benioff proposed a quantum mechanical model of the Turing machine.
tolerant quantum computing,"Despite ongoing experimental progress since the late 1990s, most researchers believe that ""fault-tolerant quantum computing [is] still a rather distant dream. """
researchers believe,"Despite ongoing experimental progress since the late 1990s, most researchers believe that ""fault-tolerant quantum computing [is] still a rather distant dream. """
rather distant dream,"Despite ongoing experimental progress since the late 1990s, most researchers believe that ""fault-tolerant quantum computing [is] still a rather distant dream. """
despite ongoing experimental progress since,"Despite ongoing experimental progress since the late 1990s, most researchers believe that ""fault-tolerant quantum computing [is] still a rather distant dream. """
private sectors,"In recent years, investment in quantum computing research has increased in the public and private sectors."
possible operations,"An abstract data type is defined by its behavior (semantics) from the point of view of a user, of the data, specifically in terms of possible values, possible operations on data of this type, and the behavior of these operations."
generalized approach,"The term abstract data type can also be regarded as a generalized approach of a number of algebraic structures, such as lattices, groups, and rings."
term abstract data type,"The term abstract data type can also be regarded as a generalized approach of a number of algebraic structures, such as lattices, groups, and rings."
maximum common edge subgraph,"to the maximum common edge subgraph problem are required to have the same number of vertices, the problem is APX-hard."
mostly used,"A media processor, mostly used as an image/video processor, is a microprocessor-based system-on-a-chip which is designed to deal with digital streaming data in real-time (e. g. display refresh) rates."
display refresh,"A media processor, mostly used as an image/video processor, is a microprocessor-based system-on-a-chip which is designed to deal with digital streaming data in real-time (e. g. display refresh) rates."
unlike graphics processing units,"Unlike graphics processing units (GPUs), which are used for computer displays, media processors are targeted at digital televisions and set-top boxes."
digital televisions,"Unlike graphics processing units (GPUs), which are used for computer displays, media processors are targeted at digital televisions and set-top boxes."
computer displays,"Today, computer graphics is a core technology in digital photography, film, video games, cell phone and computer displays, and many specialized applications. !! Unlike graphics processing units (GPUs), which are used for computer displays, media processors are targeted at digital televisions and set-top boxes."
like featuresprevious,"DSP-like featuresPrevious to media processors, these streaming media datatypes were processed using fixed-function, hardwired ASICs, which could not be updated in the field."
hardwired asics,"DSP-like featuresPrevious to media processors, these streaming media datatypes were processed using fixed-function, hardwired ASICs, which could not be updated in the field."
processed using fixed,"DSP-like featuresPrevious to media processors, these streaming media datatypes were processed using fixed-function, hardwired ASICs, which could not be updated in the field."
philips semiconductors split,"consumer electronics, Philips Semiconductors split off from Philips and became NXP Semiconductors in 2006Consumer electronics companies have successfully dominated this market by designing their own media processors and integrating them into their video products."
became nxp semiconductors,"consumer electronics, Philips Semiconductors split off from Philips and became NXP Semiconductors in 2006Consumer electronics companies have successfully dominated this market by designing their own media processors and integrating them into their video products."
video products,"consumer electronics, Philips Semiconductors split off from Philips and became NXP Semiconductors in 2006Consumer electronics companies have successfully dominated this market by designing their own media processors and integrating them into their video products."
2006consumer electronics companies,"consumer electronics, Philips Semiconductors split off from Philips and became NXP Semiconductors in 2006Consumer electronics companies have successfully dominated this market by designing their own media processors and integrating them into their video products."
successfully dominated,"consumer electronics, Philips Semiconductors split off from Philips and became NXP Semiconductors in 2006Consumer electronics companies have successfully dominated this market by designing their own media processors and integrating them into their video products."
house media processor devices,"Companies such as Philips, Samsung, Matsushita, Fujitsu, Mitsubishi have their own in-house media processor devices."
two preceding ones,"In mathematics, the Fibonacci numbers, commonly denoted Fn, form a sequence, the Fibonacci sequence, in which each number is the sum of the two preceding ones."
commonly denoted fn,"In mathematics, the Fibonacci numbers, commonly denoted Fn, form a sequence, the Fibonacci sequence, in which each number is the sum of the two preceding ones."
two lengths,"The Fibonacci numbers were first described in Indian mathematics, as early as 200 BC in work by Pingala on enumerating possible patterns of Sanskrit poetry formed from syllables of two lengths."
indian mathematics,"The Fibonacci numbers were first described in Indian mathematics, as early as 200 BC in work by Pingala on enumerating possible patterns of Sanskrit poetry formed from syllables of two lengths."
sanskrit poetry formed,"The Fibonacci numbers were first described in Indian mathematics, as early as 200 BC in work by Pingala on enumerating possible patterns of Sanskrit poetry formed from syllables of two lengths."
fibonacci numbers appear unexpectedly often,"Fibonacci numbers appear unexpectedly often in mathematics, so much so that there is an entire journal dedicated to their study, the Fibonacci Quarterly."
entire journal dedicated,"Fibonacci numbers appear unexpectedly often in mathematics, so much so that there is an entire journal dedicated to their study, the Fibonacci Quarterly."
interconnecting parallel,"Applications of Fibonacci numbers include computer algorithms such as the Fibonacci search technique and the Fibonacci heap data structure, and graphs called Fibonacci cubes used for interconnecting parallel and distributed systems."
graphs called fibonacci cubes used,"Applications of Fibonacci numbers include computer algorithms such as the Fibonacci search technique and the Fibonacci heap data structure, and graphs called Fibonacci cubes used for interconnecting parallel and distributed systems."
strongly related,"Fibonacci numbers are strongly related to the golden ratio: Binet's formula expresses the nth Fibonacci number in terms of n and the golden ratio, and implies that the ratio of two consecutive Fibonacci numbers tends to the golden ratio as n increases."
formula expresses,"Fibonacci numbers are strongly related to the golden ratio: Binet's formula expresses the nth Fibonacci number in terms of n and the golden ratio, and implies that the ratio of two consecutive Fibonacci numbers tends to the golden ratio as n increases."
two consecutive fibonacci numbers tends,"Fibonacci numbers are strongly related to the golden ratio: Binet's formula expresses the nth Fibonacci number in terms of n and the golden ratio, and implies that the ratio of two consecutive Fibonacci numbers tends to the golden ratio as n increases."
golden ratio,"Fibonacci numbers are strongly related to the golden ratio: Binet's formula expresses the nth Fibonacci number in terms of n and the golden ratio, and implies that the ratio of two consecutive Fibonacci numbers tends to the golden ratio as n increases."
particular characteristic,The particular characteristic of a cache language model is that it contains a cache component and assigns relatively high probabilities to words or word sequences that occur elsewhere in a given text.
assigns relatively high probabilities,The particular characteristic of a cache language model is that it contains a cache component and assigns relatively high probabilities to words or word sequences that occur elsewhere in a given text.
occur elsewhere,The particular characteristic of a cache language model is that it contains a cache component and assigns relatively high probabilities to words or word sequences that occur elsewhere in a given text.
means sole,"The primary, but by no means sole, use of cache language models is in speech recognition systems."
still probably,"If the system has a cache language model, ""elephant"" will still probably be misrecognized the first time it is spoken and will have to be entered into the text manually; however, from this point on the system is aware that ""elephant"" is likely to occur again the estimated probability of occurrence of ""elephant"" has been increased, making it more likely that if it is spoken it will be recognized correctly."
recognized correctly,"If the system has a cache language model, ""elephant"" will still probably be misrecognized the first time it is spoken and will have to be entered into the text manually; however, from this point on the system is aware that ""elephant"" is likely to occur again the estimated probability of occurrence of ""elephant"" has been increased, making it more likely that if it is spoken it will be recognized correctly."
estimated probability,"If the system has a cache language model, ""elephant"" will still probably be misrecognized the first time it is spoken and will have to be entered into the text manually; however, from this point on the system is aware that ""elephant"" is likely to occur again the estimated probability of occurrence of ""elephant"" has been increased, making it more likely that if it is spoken it will be recognized correctly."
text manually,"If the system has a cache language model, ""elephant"" will still probably be misrecognized the first time it is spoken and will have to be entered into the text manually; however, from this point on the system is aware that ""elephant"" is likely to occur again the estimated probability of occurrence of ""elephant"" has been increased, making it more likely that if it is spoken it will be recognized correctly."
occurred near,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
text subsequent instances,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
single words,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
assigned higher probabilities,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
higher probability,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
occurred previously,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
also multi,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
exist variants,"In machine learning, one-class classification (OCC), also known as unary classification or class-modelling, tries to identify objects of a specific class amongst all objects, by primarily learning from a training set containing only the objects of that class, although there exist variants of one-class classifiers where counter-examples are used to further refine the classification boundary. !! There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
san francisco,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
porting unix,"MKS Toolkit is a software package produced and maintained by PTC that provides a Unix-like environment for scripting, connectivity and porting Unix and Linux software to Microsoft Windows."
software package produced,"MKS Toolkit is a software package produced and maintained by PTC that provides a Unix-like environment for scripting, connectivity and porting Unix and Linux software to Microsoft Windows."
mks toolkit,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company. !! MKS Toolkit is a software package produced and maintained by PTC that provides a Unix-like environment for scripting, connectivity and porting Unix and Linux software to Microsoft Windows. !! Several editions of each version, such as MKS Toolkit for developers, power users, enterprise developers and interoperability are available, with the enterprise developer edition being the most complete. !! The Datafocus product NuTCRACKER had included the MKS Toolkit since 1994 as part of its Unix compatibility technology. !! Before PTC, MKS Toolkit was owned by MKS Inc."
power users,"Several editions of each version, such as MKS Toolkit for developers, power users, enterprise developers and interoperability are available, with the enterprise developer edition being the most complete."
enterprise developer edition,"Several editions of each version, such as MKS Toolkit for developers, power users, enterprise developers and interoperability are available, with the enterprise developer edition being the most complete."
enterprise developers,"Several editions of each version, such as MKS Toolkit for developers, power users, enterprise developers and interoperability are available, with the enterprise developer edition being the most complete."
several editions,"Several editions of each version, such as MKS Toolkit for developers, power users, enterprise developers and interoperability are available, with the enterprise developer edition being the most complete."
mks inc,"Before PTC, MKS Toolkit was owned by MKS Inc."
unix compatibility technology,The Datafocus product NuTCRACKER had included the MKS Toolkit since 1994 as part of its Unix compatibility technology.
mks toolkit since 1994,The Datafocus product NuTCRACKER had included the MKS Toolkit since 1994 as part of its Unix compatibility technology.
datafocus product nutcracker,The Datafocus product NuTCRACKER had included the MKS Toolkit since 1994 as part of its Unix compatibility technology.
also licensed,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company."
latter company,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company."
windows services,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company."
first two versions,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company."
later dropped,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company."
microsoft purchased,"The MKS Toolkit was also licensed by Microsoft for the first two versions of their Windows Services for Unix, but later dropped in favor of Interix after Microsoft purchased the latter company."
instruction cycle,"The instruction cycle (also known as the fetchdecodeexecute cycle, or simply the fetch-execute cycle) is the cycle that the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions. !! This is the only stage of the instruction cycle that is useful from the perspective of the end-user. !! In simpler CPUs, the instruction cycle is executed sequentially, each instruction being processed before the next one is started. !! In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
fetchdecodeexecute cycle,"The instruction cycle (also known as the fetchdecodeexecute cycle, or simply the fetch-execute cycle) is the cycle that the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions."
process instructions,"The instruction cycle (also known as the fetchdecodeexecute cycle, or simply the fetch-execute cycle) is the cycle that the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions."
execute cycle,"The instruction cycle (also known as the fetchdecodeexecute cycle, or simply the fetch-execute cycle) is the cycle that the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions."
simpler cpus,"In simpler CPUs, the instruction cycle is executed sequentially, each instruction being processed before the next one is started."
instead executed concurrently,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
instruction cycles,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
separate steps,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
instruction pipeline,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
next instruction starts,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
modern cpus,"In most modern CPUs, the instruction cycles are instead executed concurrently, and often in parallel, through an instruction pipeline: the next instruction starts being processed before the previous instruction has finished, which is possible because the cycle is broken up into separate steps."
i39l short,"In computing, the Inter-Client Communication Conventions Manual (ICCCM or I39L short for ""I"", 39 letters and ""L"") is a standard protocol for the X Window System."
standard protocol,"In computing, the Inter-Client Communication Conventions Manual (ICCCM or I39L short for ""I"", 39 letters and ""L"") is a standard protocol for the X Window System."
inter-client communication conventions manual,"Inter-Client Communication Conventions Manual, Version 2. !! Inter-Client Communication Conventions Manual Version 2. !! In computing, the Inter-Client Communication Conventions Manual (ICCCM or I39L short for ""I"", 39 letters and ""L"") is a standard protocol for the X Window System."
x window system,"In computing, the Inter-Client Communication Conventions Manual (ICCCM or I39L short for ""I"", 39 letters and ""L"") is a standard protocol for the X Window System."
client communication conventions manual,"Inter-Client Communication Conventions Manual, Version 2. !! In computing, the Inter-Client Communication Conventions Manual (ICCCM or I39L short for ""I"", 39 letters and ""L"") is a standard protocol for the X Window System."
client communication conventions manual version 2,Inter-Client Communication Conventions Manual Version 2.
simply iop,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
ugv iop  robotics,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
united states department,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
autonomous systems ground iop,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
unmanned ground vehicles,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
maintain open architecture interoperability standards,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
ugv interoperability profile,"UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
absolute rule,These prerequisites are known as (computer) system requirements and are often used as a guideline as opposed to an absolute rule.
software defines two sets,Most software defines two sets of system requirements: minimum and recommended.
increasing demand,"With increasing demand for higher processing power and resources in newer versions of software, system requirements tend to increase over time."
higher processing power,"With increasing demand for higher processing power and resources in newer versions of software, system requirements tend to increase over time."
newer versions,"With increasing demand for higher processing power and resources in newer versions of software, system requirements tend to increase over time."
system requirements tend,"With increasing demand for higher processing power and resources in newer versions of software, system requirements tend to increase over time."
first definition,"The first definition of the cognitive network was provided by Theo Kanter in his doctoral research at KTH, The Royal Institute of Technology, Stockholm, including a presentation in June 1998 of the cognitive network as the network with memory. !! A second meaning of the term of system requirements, is a generalisation of this first definition, giving the requirements to be met in the design of a system or sub-system."
second meaning,"A second meaning of the term of system requirements, is a generalisation of this first definition, giving the requirements to be met in the design of a system or sub-system."
fully usable,"Generally speaking, this is a better guideline than minimum system requirements in order to have a fully usable and enjoyable experience with that software."
better guideline,"Generally speaking, this is a better guideline than minimum system requirements in order to have a fully usable and enjoyable experience with that software."
generally speaking,"Generally speaking, trajectory optimization is a technique for computing an open-loop solution to an optimal control problem. !! Generally speaking, this is a better guideline than minimum system requirements in order to have a fully usable and enjoyable experience with that software."
enjoyable experience,"Generally speaking, this is a better guideline than minimum system requirements in order to have a fully usable and enjoyable experience with that software."
equivalent state,"The concept of reverse computation is somewhat simpler than reversible computing in that reverse computation is only required to restore the equivalent state of a software application, rather than support the reversibility of the set of all possible instructions."
somewhat simpler,"The concept of reverse computation is somewhat simpler than reversible computing in that reverse computation is only required to restore the equivalent state of a software application, rather than support the reversibility of the set of all possible instructions."
possible instructions,"The concept of reverse computation is somewhat simpler than reversible computing in that reverse computation is only required to restore the equivalent state of a software application, rather than support the reversibility of the set of all possible instructions."
software application areas,"Reversible computing concepts have been successfully applied as reverse computation in software application areas such as database design, checkpointing and debugging, and code differentiation."
successfully applied,"Sparse dictionary learning has been successfully applied to various image, video and audio processing tasks as well as to texture synthesis and unsupervised clustering. !! Reversible computing concepts have been successfully applied as reverse computation in software application areas such as database design, checkpointing and debugging, and code differentiation."
reversible computing concepts,"Reversible computing concepts have been successfully applied as reverse computation in software application areas such as database design, checkpointing and debugging, and code differentiation."
code differentiation,"Reversible computing concepts have been successfully applied as reverse computation in software application areas such as database design, checkpointing and debugging, and code differentiation."
reverse computation exploits,The key property that reverse computation exploits is that a majority of the operations that modify the state variables are constructive in nature.
key property,The key property that reverse computation exploits is that a majority of the operations that modify the state variables are constructive in nature.
multiple distinct neighborhoods defined,The same problem may have multiple distinct neighborhoods defined on it; local optimization with neighborhoods that involve changing up to k components of the solution is often referred to as k-opt.
involve changing,The same problem may have multiple distinct neighborhoods defined on it; local optimization with neighborhoods that involve changing up to k components of the solution is often referred to as k-opt.
jakarta charter,"The Byte Code Engineering Library (BCEL) is a project sponsored by the Apache Foundation previously under their Jakarta charter to provide a simple API for decomposing, modifying, and recomposing binary Java classes (I. e. bytecode)."
project sponsored,"The Byte Code Engineering Library (BCEL) is a project sponsored by the Apache Foundation previously under their Jakarta charter to provide a simple API for decomposing, modifying, and recomposing binary Java classes (I. e. bytecode)."
apache foundation previously,"The Byte Code Engineering Library (BCEL) is a project sponsored by the Apache Foundation previously under their Jakarta charter to provide a simple API for decomposing, modifying, and recomposing binary Java classes (I. e. bytecode)."
maintaining distributed directory information services,"The Lightweight Directory Access Protocol (LDAP ) is an open, vendor-neutral, industry standard application protocol for accessing and maintaining distributed directory information services over an Internet Protocol (IP) network."
500 directory access protocol,"500 Directory Access Protocol (DAP), which required the Open Systems Interconnection (OSI) protocol stack."
burroughs b5000 instruction set includes,"The Burroughs B5000 instruction set includes the set of valid operations for the B5000, B5500 and B5700."
valid operations,"The Burroughs B5000 instruction set includes the set of valid operations for the B5000, B5500 and B5700. !! Most programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type."
natural intelligence displayed,"Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans."
animals including humans,"Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans."
intelligence demonstrated,"Artificial intelligence (AI) is intelligence demonstrated by machines, as opposed to natural intelligence displayed by animals including humans."
popular accounts use,"Some popular accounts use the term ""artificial intelligence"" to describe machines that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"", however, this definition is rejected by major AI researchers."
describe machines,"Some popular accounts use the term ""artificial intelligence"" to describe machines that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"", however, this definition is rejected by major AI researchers."
problem solving  however,"Some popular accounts use the term ""artificial intelligence"" to describe machines that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"", however, this definition is rejected by major AI researchers."
humans associate,"Some popular accounts use the term ""artificial intelligence"" to describe machines that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"", however, this definition is rejected by major AI researchers."
major ai researchers,"Some popular accounts use the term ""artificial intelligence"" to describe machines that mimic ""cognitive"" functions that humans associate with the human mind, such as ""learning"" and ""problem solving"", however, this definition is rejected by major AI researchers."
experienced several waves,"Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an ""AI winter""), followed by new approaches, success and renewed funding."
new approaches,"Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an ""AI winter""), followed by new approaches, success and renewed funding."
academic discipline,"Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an ""AI winter""), followed by new approaches, success and renewed funding."
ai winter  followed,"Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an ""AI winter""), followed by new approaches, success and renewed funding."
renewed funding,"Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an ""AI winter""), followed by new approaches, success and renewed funding."
years since,"Artificial intelligence was founded as an academic discipline in 1956, and in the years since has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an ""AI winter""), followed by new approaches, success and renewed funding."
mary shelley,"and have been common in fiction, as in Mary Shelley's Frankenstein or Karel apek's R. U. R. These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence."
fates raised many,"and have been common in fiction, as in Mary Shelley's Frankenstein or Karel apek's R. U. R. These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence."
karel apek,"and have been common in fiction, as in Mary Shelley's Frankenstein or Karel apek's R. U. R. These characters and their fates raised many of the same issues now discussed in the ethics of artificial intelligence."
basic objects,Computable functions are the basic objects of study in computability theory.
corresponding output,"Computable functions are the formalized analogue of the intuitive notion of algorithms, in the sense that a function is computable if there exists an algorithm that can do the job of the function, i. e. given an input of the function domain it can return the corresponding output."
function domain,"Computable functions are the formalized analogue of the intuitive notion of algorithms, in the sense that a function is computable if there exists an algorithm that can do the job of the function, i. e. given an input of the function domain it can return the corresponding output."
formalized analogue,"Computable functions are the formalized analogue of the intuitive notion of algorithms, in the sense that a function is computable if there exists an algorithm that can do the job of the function, i. e. given an input of the function domain it can return the corresponding output."
discuss computability without referring,Computable functions are used to discuss computability without referring to any concrete model of computation such as Turing machines or register machines.
register machines,Computable functions are used to discuss computability without referring to any concrete model of computation such as Turing machines or register machines.
give rise,"Particular models of computability that give rise to the set of computable functions are the Turing-computable functions and the general recursive functions. !! While cognitive grammar emphasizes the study of the cognitive principles that give rise to linguistic organization, construction grammar aims to provide a more descriptively and formally detailed account of the linguistic units that comprise a particular language."
particular models,Particular models of computability that give rise to the set of computable functions are the Turing-computable functions and the general recursive functions.
precise definition,"Before the precise definition of computable function, mathematicians often used the informal term effectively calculable."
informal term effectively calculable,"Before the precise definition of computable function, mathematicians often used the informal term effectively calculable."
mathematicians often used,"Before the precise definition of computable function, mathematicians often used the informal term effectively calculable."
open addressing based hash tables,"In computer programming, primary clustering is one of two major failure modes of open addressing based hash tables, especially those using linear probing."
using linear probing,"In computer programming, primary clustering is one of two major failure modes of open addressing based hash tables, especially those using linear probing."
complexity class sc,"Deterministic context-free languages can be recognized by a deterministic Turing machine in polynomial time and O(log2 n) space; as a corollary, DCFL is a subset of the complexity class SC."
great practical importance,The languages of this class have great practical importance in computer science as they can be parsed much more efficiently than nondeterministic context-free languages.
parsed much,The languages of this class have great practical importance in computer science as they can be parsed much more efficiently than nondeterministic context-free languages.
perform optimal actions based,A rational agent or rational being is a person or entity that always aims to perform optimal actions based on given premises and information.
always aims,A rational agent or rational being is a person or entity that always aims to perform optimal actions based on given premises and information.
given premises,A rational agent or rational being is a person or entity that always aims to perform optimal actions based on given premises and information.
rational agent,"The idea of a rational agent is important to the philosophy of utilitarianism, as detailed by philosopher Jeremy Bentham's theory of the felicific calculus, also known as the hedonistic calculus. !! The concept of rational agents can be found in various disciplines such as artificial intelligence, cognitive science, decision theory, economics, ethics, game theory, and the study of practical reason. !! A rational agent or rational being is a person or entity that always aims to perform optimal actions based on given premises and information. !! A rational agent can be anything that makes decisions, typically a person, firm, machine, or software. !! In reference to economics, rational agent refers to hypothetical consumers and how they make decisions in a free market."
makes decisions,"A rational agent can be anything that makes decisions, typically a person, firm, machine, or software."
various disciplines,"The concept of rational agents can be found in various disciplines such as artificial intelligence, cognitive science, decision theory, economics, ethics, game theory, and the study of practical reason."
free market,"In reference to economics, rational agent refers to hypothetical consumers and how they make decisions in a free market."
hypothetical consumers,"In reference to economics, rational agent refers to hypothetical consumers and how they make decisions in a free market."
make decisions,"Because it does not know the whole input, an online algorithm is forced to make decisions that may later turn out not to be optimal, and the study of online algorithms has focused on the quality of decision-making that is possible in this setting. !! In reference to economics, rational agent refers to hypothetical consumers and how they make decisions in a free market."
rational agent refers,"In reference to economics, rational agent refers to hypothetical consumers and how they make decisions in a free market."
hedonistic calculus,"The idea of a rational agent is important to the philosophy of utilitarianism, as detailed by philosopher Jeremy Bentham's theory of the felicific calculus, also known as the hedonistic calculus."
philosopher jeremy bentham,"The idea of a rational agent is important to the philosophy of utilitarianism, as detailed by philosopher Jeremy Bentham's theory of the felicific calculus, also known as the hedonistic calculus."
better cache locality compared,Arrays have better cache locality compared to linked lists.
link previous,"Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal."
constant number,"Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal."
list traversal,"Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal."
linked lists allow insertion,"Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal."
last node,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
since simple linked lists,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
efficient indexing,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
new node,"XOR linked lists do not provide some of the important advantages of doubly linked lists, such as the ability to delete a node from the list knowing only its address or the ability to insert a new node before or after an existing node when knowing only the address of the existing node. !! On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
allow random access,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
many basic operationssuch,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
given datum,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
insertedmay require iterating,"On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operationssuch as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be insertedmay require iterating through most or all of the list elements."
programmable fashion,Quantum simulators permit the study of quantum system in a programmable fashion.
quantum simulators permit,Quantum simulators permit the study of quantum system in a programmable fashion.
quantum simulators may,"Quantum simulators may be contrasted with generally programmable ""digital"" quantum computers, which would be capable of solving a wider class of quantum problems."
generally programmable,"Quantum simulators may be contrasted with generally programmable ""digital"" quantum computers, which would be capable of solving a wider class of quantum problems."
wider class,"Quantum simulators may be contrasted with generally programmable ""digital"" quantum computers, which would be capable of solving a wider class of quantum problems."
yuri manin,A universal quantum simulator is a quantum computer proposed by Yuri Manin in 1980 and Richard Feynman in 1982.
quantum computer proposed,A universal quantum simulator is a quantum computer proposed by Yuri Manin in 1980 and Richard Feynman in 1982.
richard feynman,A universal quantum simulator is a quantum computer proposed by Yuri Manin in 1980 and Richard Feynman in 1982.
polar molecules,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
superconducting circuits,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
quantum dots,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
experimental platforms,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
including systems,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
photonic systems,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
trapped ions,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
ultracold quantum gases,"Quantum simulators have been realized on a number of experimental platforms, including systems of ultracold quantum gases, polar molecules, trapped ions, photonic systems, quantum dots, and superconducting circuits."
quantum simulators provide,Quantum simulators provide an alternative route to understanding the properties of these systems.
also sometimes referred,"Scripting languages are also sometimes referred to as very high-level programming languages, as they sometimes operate at a high level of abstraction, or as control languages, particularly for job control languages on mainframes. !! In artificial intelligence, an embodied agent, also sometimes referred to as an interface agent, is an intelligent agent that interacts with the environment through a physical body within that environment."
physical body within,"In artificial intelligence, an embodied agent, also sometimes referred to as an interface agent, is an intelligent agent that interacts with the environment through a physical body within that environment."
embodied agent,"In artificial intelligence, an embodied agent, also sometimes referred to as an interface agent, is an intelligent agent that interacts with the environment through a physical body within that environment. !! Agents that are represented graphically with a body, for example a human or a cartoon animal, are also called embodied agents, although they have only virtual, not physical, embodiment. !! Embodied conversational agents are embodied agents (usually with a graphical front-end as opposed to a robotic body) that are capable of engaging in conversation with one another and with humans employing the same verbal and nonverbal means that humans do (such as gesture, facial expression, and so forth). !! Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction. !! Mobile robots are one example of physically embodied agents; Ananova and Microsoft Agent are examples of graphically embodied agents."
also called embodied agents,"Agents that are represented graphically with a body, for example a human or a cartoon animal, are also called embodied agents, although they have only virtual, not physical, embodiment."
cartoon animal,"Agents that are represented graphically with a body, for example a human or a cartoon animal, are also called embodied agents, although they have only virtual, not physical, embodiment."
represented graphically,"Agents that are represented graphically with a body, for example a human or a cartoon animal, are also called embodied agents, although they have only virtual, not physical, embodiment."
graphically embodied agents,Mobile robots are one example of physically embodied agents; Ananova and Microsoft Agent are examples of graphically embodied agents.
microsoft agent,"Furthermore, the Office Assistant could use the Lernout & Hauspie TruVoice Text-to-Speech Engine to provide output speech capabilities to Microsoft Agent, but it required SAPI 4. !! Mobile robots are one example of physically embodied agents; Ananova and Microsoft Agent are examples of graphically embodied agents."
physically embodied agents,Mobile robots are one example of physically embodied agents; Ananova and Microsoft Agent are examples of graphically embodied agents.
mobile robots,Mobile robots are one example of physically embodied agents; Ananova and Microsoft Agent are examples of graphically embodied agents.
nonverbal means,"Embodied conversational agents are embodied agents (usually with a graphical front-end as opposed to a robotic body) that are capable of engaging in conversation with one another and with humans employing the same verbal and nonverbal means that humans do (such as gesture, facial expression, and so forth)."
graphical front,"Embodied conversational agents are embodied agents (usually with a graphical front-end as opposed to a robotic body) that are capable of engaging in conversation with one another and with humans employing the same verbal and nonverbal means that humans do (such as gesture, facial expression, and so forth)."
humans employing,"Embodied conversational agents are embodied agents (usually with a graphical front-end as opposed to a robotic body) that are capable of engaging in conversation with one another and with humans employing the same verbal and nonverbal means that humans do (such as gesture, facial expression, and so forth)."
robotic body,"Embodied conversational agents are embodied agents (usually with a graphical front-end as opposed to a robotic body) that are capable of engaging in conversation with one another and with humans employing the same verbal and nonverbal means that humans do (such as gesture, facial expression, and so forth)."
unite gesture,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
powerful means,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
graphically embodied agents aim,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
face communication,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
enable face,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
connects automotive suppliers,"The Automotive Network Exchange (ANX), a large private extranet that connects automotive suppliers to automotive manufacturers."
automotive manufacturers,"The Automotive Network Exchange (ANX), a large private extranet that connects automotive suppliers to automotive manufacturers."
automotive industry action group,"The Automotive Network Exchange is the private extranet initially set up and maintained by the Automotive Industry Action Group, Telcordia, General Motors, Ford, and Chrysler."
general motors,"The Automotive Network Exchange is the private extranet initially set up and maintained by the Automotive Industry Action Group, Telcordia, General Motors, Ford, and Chrysler."
private extranet initially set,"The Automotive Network Exchange is the private extranet initially set up and maintained by the Automotive Industry Action Group, Telcordia, General Motors, Ford, and Chrysler."
development time,"Structured programming is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by making extensive use of the structured control flow constructs of selection (if/then/else) and repetition (while and for), block structures, and subroutines. !! Structured concurrency is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by using a structured approach to concurrent programming."
structured approach,"Structured concurrency is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by using a structured approach to concurrent programming."
programming paradigm aimed,"Structured programming is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by making extensive use of the structured control flow constructs of selection (if/then/else) and repetition (while and for), block structures, and subroutines. !! Structured concurrency is a programming paradigm aimed at improving the clarity, quality, and development time of a computer program by using a structured approach to concurrent programming."
introduced control flow constructs,"Structured concurrency is analogous to structured programming, which introduced control flow constructs that encapsulated sequential statements and subroutines."
smith argues,"However, Smith argues that this model is not true structured concurrency as the programming language is unaware of the joining behavior, and is thus unable to enforce safety."
true structured concurrency,"However, Smith argues that this model is not true structured concurrency as the programming language is unaware of the joining behavior, and is thus unable to enforce safety."
enforce safety,"However, Smith argues that this model is not true structured concurrency as the programming language is unaware of the joining behavior, and is thus unable to enforce safety."
joining behavior,"However, Smith argues that this model is not true structured concurrency as the programming language is unaware of the joining behavior, and is thus unable to enforce safety."
thus unable,"However, Smith argues that this model is not true structured concurrency as the programming language is unaware of the joining behavior, and is thus unable to enforce safety."
swift adopted structured concurrency,"In 2021, Swift adopted structured concurrency."
add structured concurrency,"Later that year, a draft proposal was published to add structured concurrency to Java."
draft proposal,"Later that year, a draft proposal was published to add structured concurrency to Java."
otherwise affected without,"In physics, action at a distance is the concept that an object can be moved, changed, or otherwise affected without being physically touched (as in mechanical contact) by another object."
action at a distance,"More generally ""action at a distance"" describes the failure of early atomistic and mechanistic theories which sought to reduce all physical interaction to collision. !! In physics, action at a distance is the concept that an object can be moved, changed, or otherwise affected without being physically touched (as in mechanical contact) by another object. !! On page 437 he indicates the physicists' disgust with action at a distance. !! Philosopher William of Ockham discussed action at a distance to explain magnetism and the ability of the Sun to heat the Earth's atmosphere without affecting the intervening space. !! Efforts to account for action at a distance in the theory of electromagnetism led to the development of the concept of a field which mediated interactions between currents and charges across empty space."
another object,"In physics, action at a distance is the concept that an object can be moved, changed, or otherwise affected without being physically touched (as in mechanical contact) by another object."
mechanical contact,"In physics, action at a distance is the concept that an object can be moved, changed, or otherwise affected without being physically touched (as in mechanical contact) by another object."
physically touched,"In physics, action at a distance is the concept that an object can be moved, changed, or otherwise affected without being physically touched (as in mechanical contact) by another object."
physical interaction,"More generally ""action at a distance"" describes the failure of early atomistic and mechanistic theories which sought to reduce all physical interaction to collision."
early atomistic,"More generally ""action at a distance"" describes the failure of early atomistic and mechanistic theories which sought to reduce all physical interaction to collision."
mechanistic theories,"More generally ""action at a distance"" describes the failure of early atomistic and mechanistic theories which sought to reduce all physical interaction to collision."
philosopher william,Philosopher William of Ockham discussed action at a distance to explain magnetism and the ability of the Sun to heat the Earth's atmosphere without affecting the intervening space.
ockham discussed action,Philosopher William of Ockham discussed action at a distance to explain magnetism and the ability of the Sun to heat the Earth's atmosphere without affecting the intervening space.
explain magnetism,Philosopher William of Ockham discussed action at a distance to explain magnetism and the ability of the Sun to heat the Earth's atmosphere without affecting the intervening space.
atmosphere without affecting,Philosopher William of Ockham discussed action at a distance to explain magnetism and the ability of the Sun to heat the Earth's atmosphere without affecting the intervening space.
intervening space,Philosopher William of Ockham discussed action at a distance to explain magnetism and the ability of the Sun to heat the Earth's atmosphere without affecting the intervening space.
mediated interactions,Efforts to account for action at a distance in the theory of electromagnetism led to the development of the concept of a field which mediated interactions between currents and charges across empty space.
electromagnetism led,Efforts to account for action at a distance in the theory of electromagnetism led to the development of the concept of a field which mediated interactions between currents and charges across empty space.
charges across empty space,Efforts to account for action at a distance in the theory of electromagnetism led to the development of the concept of a field which mediated interactions between currents and charges across empty space.
virtual start,"The Worst-case Fair Weighted Fair Queueing (WF2Q) fixes it by adding a virtual start of service to each packet, and selects a packet only if its virtual start of service is not less than the current time."
case fair weighted fair queueing,"The Worst-case Fair Weighted Fair Queueing (WF2Q) fixes it by adding a virtual start of service to each packet, and selects a packet only if its virtual start of service is not less than the current time."
topological structure,"Bifurcation theory is the mathematical study of changes in the qualitative or topological structure of a given family of curves, such as the integral curves of a family of vector fields, and the solutions of a family of differential equations. !! A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data."
unsupervised machine learning technique used,A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data.
organizing feature map,A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data.
typically two,A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data.
cause different parts,The goal of learning in the self-organizing map is to cause different parts of the network to respond similarly to certain input patterns.
certain input patterns,The goal of learning in the self-organizing map is to cause different parts of the network to respond similarly to certain input patterns.
respond similarly,The goal of learning in the self-organizing map is to cause different parts of the network to respond similarly to certain input patterns.
representing input data,"While representing input data as vectors has been emphasized in this article, any kind of object which can be represented digitally, which has an appropriate distance measure associated with it, and in which the necessary operations for training are possible can be used to construct a self-organizing map."
represented digitally,"While representing input data as vectors has been emphasized in this article, any kind of object which can be represented digitally, which has an appropriate distance measure associated with it, and in which the necessary operations for training are possible can be used to construct a self-organizing map."
necessary operations,"While representing input data as vectors has been emphasized in this article, any kind of object which can be represented digitally, which has an appropriate distance measure associated with it, and in which the necessary operations for training are possible can be used to construct a self-organizing map."
appropriate distance measure associated,"While representing input data as vectors has been emphasized in this article, any kind of object which can be represented digitally, which has an appropriate distance measure associated with it, and in which the necessary operations for training are possible can be used to construct a self-organizing map."
includes matrices,"This includes matrices, continuous functions or even other self-organizing maps."
continuous functions,"This includes matrices, continuous functions or even other self-organizing maps."
mac  sometimes known,"In cryptography, a message authentication code (MAC), sometimes known as a tag, is a short piece of information used for authenticating a message."
information used,"In cryptography, a message authentication code (MAC), sometimes known as a tag, is a short piece of information used for authenticating a message."
instead using checksum,"RFC 4949 recommends avoiding the term message integrity code (MIC), and instead using checksum, error detection code, hash, keyed hash, message authentication code, or protected checksum."
rfc 4949 recommends avoiding,"RFC 4949 recommends avoiding the term message integrity code (MIC), and instead using checksum, error detection code, hash, keyed hash, message authentication code, or protected checksum."
term message integrity code,"RFC 4949 recommends avoiding the term message integrity code (MIC), and instead using checksum, error detection code, hash, keyed hash, message authentication code, or protected checksum."
forge tags,"A secure message authentication code must resist attempts by an adversary to forge tags, for arbitrary, select, or all messages, including under conditions of known- or chosen-message."
independent hashing functions provide,"More generally, k-independent hashing functions provide a secure message authentication code as long as the key is used less than k times for k-ways independent hashing functions."
ways independent hashing functions,"More generally, k-independent hashing functions provide a secure message authentication code as long as the key is used less than k times for k-ways independent hashing functions."
used less,"More generally, k-independent hashing functions provide a secure message authentication code as long as the key is used less than k times for k-ways independent hashing functions."
mostly gradually correcting,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
behavioral robotics,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
based robotics,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links. !! A different direction of development includes extensions of behavior-based robotics to multi-robot teams. !! This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering. !! Subsumption architecture is a reactive robotic architecture heavily associated with behavior-based robotics which was very popular in the 1980s and 90s."
exhibit complex,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
behavior-based robotics,"A different direction of development includes extensions of behavior-based robotics to multi-robot teams. !! Subsumption architecture is a reactive robotic architecture heavily associated with behavior-based robotics which was very popular in the 1980s and 90s. !! Rather than use preset calculations to tackle a situation, behavior-based robotics relies on adaptability. !! Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links. !! This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering. !! Behavior-based robotics sets itself apart from traditional artificial intelligence by using biological systems as a model."
immediate environment,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
motor links,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
actions via sensory,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
using biological systems,Behavior-based robotics sets itself apart from traditional artificial intelligence by using biological systems as a model.
based robotics sets,Behavior-based robotics sets itself apart from traditional artificial intelligence by using biological systems as a model.
based robotics relies,"Rather than use preset calculations to tackle a situation, behavior-based robotics relies on adaptability."
use preset calculations,"Rather than use preset calculations to tackle a situation, behavior-based robotics relies on adaptability."
allowed behavior,This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering.
data gathering,This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering.
become commonplace,This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering.
development includes extensions,A different direction of development includes extensions of behavior-based robotics to multi-robot teams.
robot teams,A different direction of development includes extensions of behavior-based robotics to multi-robot teams.
existing ai systems,"Applied Artificial Intelligence is a peer-reviewed scientific journal covering applications of artificial intelligence in management, industry, engineering, administration, and education, as well as evaluations of existing AI systems and tools and their economic, social, and cultural impact."
reviewed scientific journal covering applications,"Applied Artificial Intelligence is a peer-reviewed scientific journal covering applications of artificial intelligence in management, industry, engineering, administration, and education, as well as evaluations of existing AI systems and tools and their economic, social, and cultural impact."
cultural impact,"Applied Artificial Intelligence is a peer-reviewed scientific journal covering applications of artificial intelligence in management, industry, engineering, administration, and education, as well as evaluations of existing AI systems and tools and their economic, social, and cultural impact."
limit values,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
desirable properties,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
certain known functions,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
inexpensive computation,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
target functions,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
specific class,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
known target functions approximation theory,"First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
whose impact,"The motivation for regulation of algorithms is the apprehension of losing control over the algorithms, whose impact on human life increases."
human life increases,"The motivation for regulation of algorithms is the apprehension of losing control over the algorithms, whose impact on human life increases."
losing control,"The motivation for regulation of algorithms is the apprehension of losing control over the algorithms, whose impact on human life increases."
2017 elon musk advocated regulation,In 2017 Elon Musk advocated regulation of algorithms in the context of the existential risk from artificial general intelligence.
existential risk,In 2017 Elon Musk advocated regulation of algorithms in the context of the existential risk from artificial general intelligence.
extra element theorem,The asymptotic gain model is a special case of the extra element theorem.
asymptotic gain model,"The asymptotic gain model is a special case of the extra element theorem. !! To implement the asymptotic gain model, the dependent source associated with either transistor can be used. !! The aim is to find the low-frequency, open-circuit, transresistance gain of this circuit G = vout / iin using the asymptotic gain model. !! The above expressions can be substituted into the asymptotic gain model equation to find the overall gain G. The resulting gain is the current gain of the amplifier with a short-circuit load. !! Lecture notes on the asymptotic gain model"
iin using,"The aim is to find the low-frequency, open-circuit, transresistance gain of this circuit G = vout / iin using the asymptotic gain model."
transresistance gain,"The aim is to find the low-frequency, open-circuit, transresistance gain of this circuit G = vout / iin using the asymptotic gain model."
dependent source associated,"To implement the asymptotic gain model, the dependent source associated with either transistor can be used."
either transistor,"To implement the asymptotic gain model, the dependent source associated with either transistor can be used."
overall gain g,The above expressions can be substituted into the asymptotic gain model equation to find the overall gain G. The resulting gain is the current gain of the amplifier with a short-circuit load.
circuit load,The above expressions can be substituted into the asymptotic gain model equation to find the overall gain G. The resulting gain is the current gain of the amplifier with a short-circuit load.
current gain,The above expressions can be substituted into the asymptotic gain model equation to find the overall gain G. The resulting gain is the current gain of the amplifier with a short-circuit load.
resulting gain,The above expressions can be substituted into the asymptotic gain model equation to find the overall gain G. The resulting gain is the current gain of the amplifier with a short-circuit load.
data according,Database design is the organization of data according to a database model.
identifying interrelationships,Database design involves classifying data and identifying interrelationships.
database design involves classifying data,Database design involves classifying data and identifying interrelationships.
financial information,"In a majority of cases, a person who is doing the design of a database is a person with expertise in the area of database design, rather than expertise in the domain from which the data to be stored is drawn e. g. financial information, biological information etc."
biological information etc,"In a majority of cases, a person who is doing the design of a database is a person with expertise in the area of database design, rather than expertise in the domain from which the data to be stored is drawn e. g. financial information, biological information etc."
needed information,"This process is one which is generally considered part of requirements analysis, and requires skill on the part of the database designer to elicit the needed information from those with the domain knowledge."
database designer,"Once a database designer is aware of the data which is to be stored within the database, they must then determine where dependency is within the data. !! This process is one which is generally considered part of requirements analysis, and requires skill on the part of the database designer to elicit the needed information from those with the domain knowledge."
requires skill,"This process is one which is generally considered part of requirements analysis, and requires skill on the part of the database designer to elicit the needed information from those with the domain knowledge."
generally considered part,"This process is one which is generally considered part of requirements analysis, and requires skill on the part of the database designer to elicit the needed information from those with the domain knowledge."
domain knowledge,"By not requiring a priori specification of a model, symbolic regression isn't affected by human bias, or unknown gaps in domain knowledge. !! This process is one which is generally considered part of requirements analysis, and requires skill on the part of the database designer to elicit the needed information from those with the domain knowledge."
stored within,"Once a database designer is aware of the data which is to be stored within the database, they must then determine where dependency is within the data."
framework-specific modeling language,A framework-specific modeling language (FSML) is a kind of domain-specific modeling language which is designed for an object-oriented application framework.
specific modeling language,A framework-specific modeling language (FSML) is a kind of domain-specific modeling language which is designed for an object-oriented application framework.
oriented application framework,A framework-specific modeling language (FSML) is a kind of domain-specific modeling language which is designed for an object-oriented application framework.
solve visual tasks,Geometric feature learning is a technique combining machine learning and computer vision to solve visual tasks.
technique combining machine learning,Geometric feature learning is a technique combining machine learning and computer vision to solve visual tasks.
solve recognition problems,"Geometric feature learning methods can not only solve recognition problems but also predict subsequent actions by analyzing a set of sequential input sensory images, usually some extracting features of images."
also predict subsequent actions,"Geometric feature learning methods can not only solve recognition problems but also predict subsequent actions by analyzing a set of sequential input sensory images, usually some extracting features of images."
extracting features,"Geometric feature learning methods can not only solve recognition problems but also predict subsequent actions by analyzing a set of sequential input sensory images, usually some extracting features of images."
sequential input sensory images,"Geometric feature learning methods can not only solve recognition problems but also predict subsequent actions by analyzing a set of sequential input sensory images, usually some extracting features of images."
gradient method,"The conjugate gradient method can also be used to solve unconstrained optimization problems such as energy minimization. !! The conjugate gradient method is often implemented as an iterative algorithm, applicable to sparse systems that are too large to be handled by a direct implementation or other direct methods such as the Cholesky decomposition. !! The biconjugate gradient method provides a generalization to non-symmetric matrices. !! Various nonlinear conjugate gradient methods seek minima of nonlinear optimization problems. !! In mathematics, the conjugate gradient method is an algorithm for the numerical solution of particular systems of linear equations, namely those whose matrix is positive-definite."
also called adaptive simpson,"Adaptive Simpson's method, also called adaptive Simpson's rule, is a method of numerical integration proposed by G. F. Kuncir in 1962."
adaptive simpson,"Adaptive Simpson's method, also called adaptive Simpson's rule, is a method of numerical integration proposed by G. F. Kuncir in 1962. !! Some inputs will fail to converge in adaptive Simpson's method quickly, resulting in the tolerance underflowing and producing an infinite loop. !! Adaptive Simpson's method uses an estimate of the error we get from calculating a definite integral using Simpson's rule. !! Here is an implementation of adaptive Simpson's method in Python."
numerical integration proposed,"Adaptive Simpson's method, also called adaptive Simpson's rule, is a method of numerical integration proposed by G. F. Kuncir in 1962."
method uses,Adaptive Simpson's method uses an estimate of the error we get from calculating a definite integral using Simpson's rule.
definite integral using simpson,Adaptive Simpson's method uses an estimate of the error we get from calculating a definite integral using Simpson's rule.
recursive manner,"If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying adaptive Simpson's method to each subinterval in a recursive manner."
applying adaptive simpson,"If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying adaptive Simpson's method to each subinterval in a recursive manner."
algorithm calls,"If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying adaptive Simpson's method to each subinterval in a recursive manner."
error exceeds,"If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying adaptive Simpson's method to each subinterval in a recursive manner."
specified tolerance,"If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying adaptive Simpson's method to each subinterval in a recursive manner."
method quickly,"Some inputs will fail to converge in adaptive Simpson's method quickly, resulting in the tolerance underflowing and producing an infinite loop."
tolerance underflowing,"Some inputs will fail to converge in adaptive Simpson's method quickly, resulting in the tolerance underflowing and producing an infinite loop."
maximum entropy thermodynamics,"In principle, maximum entropy thermodynamics does not refer narrowly and only to classical thermodynamic entropy. !! In physics, maximum entropy thermodynamics (colloquially, MaxEnt thermodynamics) views equilibrium thermodynamics and statistical mechanics as inference processes. !! The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
maxent thermodynamics,"In physics, maximum entropy thermodynamics (colloquially, MaxEnt thermodynamics) views equilibrium thermodynamics and statistical mechanics as inference processes."
inference processes,"In physics, maximum entropy thermodynamics (colloquially, MaxEnt thermodynamics) views equilibrium thermodynamics and statistical mechanics as inference processes."
views equilibrium thermodynamics,"In physics, maximum entropy thermodynamics (colloquially, MaxEnt thermodynamics) views equilibrium thermodynamics and statistical mechanics as inference processes."
important opposition,"The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
published results,"The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
relative paucity,"The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
maxent school,"The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
new testable predictions far,"The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
classical thermodynamic entropy,"In principle, maximum entropy thermodynamics does not refer narrowly and only to classical thermodynamic entropy."
refer narrowly,"In principle, maximum entropy thermodynamics does not refer narrowly and only to classical thermodynamic entropy."
shadow paging,"Shadow paging is a copy-on-write technique for avoiding in-place updates of pages. !! In computer science, shadow paging is a technique for providing atomicity and durability (two of the ACID properties) in database systems. !! Shadow paging is similar to the old masternew master batch processing technique used in mainframe database systems. !! Shadow paging is also similar to purely functional data structures, in that in-place updates are avoided. !! If the referring pages must also be updated via shadow paging, this procedure may recurse many times, becoming quite costly."
acid properties,"In computer science, shadow paging is a technique for providing atomicity and durability (two of the ACID properties) in database systems."
providing atomicity,"In computer science, shadow paging is a technique for providing atomicity and durability (two of the ACID properties) in database systems."
place updates,"Shadow paging is also similar to purely functional data structures, in that in-place updates are avoided. !! Shadow paging is a copy-on-write technique for avoiding in-place updates of pages."
write technique,Shadow paging is a copy-on-write technique for avoiding in-place updates of pages.
becoming quite costly,"If the referring pages must also be updated via shadow paging, this procedure may recurse many times, becoming quite costly."
updated via shadow paging,"If the referring pages must also be updated via shadow paging, this procedure may recurse many times, becoming quite costly."
referring pages must also,"If the referring pages must also be updated via shadow paging, this procedure may recurse many times, becoming quite costly."
procedure may recurse many times,"If the referring pages must also be updated via shadow paging, this procedure may recurse many times, becoming quite costly."
mainframe database systems,Shadow paging is similar to the old masternew master batch processing technique used in mainframe database systems.
purely functional data structures,"Shadow paging is also similar to purely functional data structures, in that in-place updates are avoided. !! Therefore, lazy evaluation naturally becomes an important part of the construction of purely functional data structures. !! One of the key tools in building efficient, purely functional data structures is memoization."
also similar,"Shadow paging is also similar to purely functional data structures, in that in-place updates are avoided."
representing f0 contour,The Fujisaki model is a superpositional model for representing F0 contour of speech.
superpositional model,The Fujisaki model is a superpositional model for representing F0 contour of speech.
fujisaki model,The Fujisaki model is a superpositional model for representing F0 contour of speech.
specialized digital signal processors,"Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations."
signal processing operations,"Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations."
digital processing,"Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations."
wireless communications,"Digital signal processing is also fundamental to digital technology, such as digital telecommunication and wireless communications."
digital technology,"Digital signal processing is also fundamental to digital technology, such as digital telecommunication and wireless communications."
also fundamental,"Digital signal processing is also fundamental to digital technology, such as digital telecommunication and wireless communications."
digital telecommunication,"Digital signal processing is also fundamental to digital technology, such as digital telecommunication and wireless communications."
fpgas  digital signal controllers,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
industrial applications,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
programmable gate arrays,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
motor control,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
additional technologies,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
powerful general purpose microprocessors,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
stream processors,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
digital signal processing include,"Additional technologies for digital signal processing include more powerful general purpose microprocessors, graphics processing units, field-programmable gate arrays (FPGAs), digital signal controllers (mostly for industrial applications such as motor control), and stream processors."
general inner product spaces,Its analogue over general inner product spaces is the Householder operator.
householder operator,Its analogue over general inner product spaces is the Householder operator.
recent numerical schemes,"In numerical mathematics, the gradient discretisation method (GDM) is a framework which contains classical and recent numerical schemes for diffusion problems of various kinds: linear or non-linear, steady-state or time-dependent."
contains classical,"In numerical mathematics, the gradient discretisation method (GDM) is a framework which contains classical and recent numerical schemes for diffusion problems of various kinds: linear or non-linear, steady-state or time-dependent."
raphale herbin,"The Gradient Discretisation Method by Jrme Droniou, Robert Eymard, Thierry Gallout, Cindy Guichard and Raphale Herbin"
cindy guichard,"The Gradient Discretisation Method by Jrme Droniou, Robert Eymard, Thierry Gallout, Cindy Guichard and Raphale Herbin"
jrme droniou,"The Gradient Discretisation Method by Jrme Droniou, Robert Eymard, Thierry Gallout, Cindy Guichard and Raphale Herbin"
thierry gallout,"The Gradient Discretisation Method by Jrme Droniou, Robert Eymard, Thierry Gallout, Cindy Guichard and Raphale Herbin"
robert eymard,"The Gradient Discretisation Method by Jrme Droniou, Robert Eymard, Thierry Gallout, Cindy Guichard and Raphale Herbin"
contains multiple self,"Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion."
single self,"Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion."
single recursion,"Single recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space. !! Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion. !! For example, while computing the Fibonacci sequence naively entails multiple iteration, as each value requires two previous values, it can be computed by single recursion by passing two successive values as parameters. !! Multiple recursion can sometimes be converted to single recursion (and, if desired, thence to iteration). !! Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search."
multiple recursion include tree traversal,"Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search."
standard examples,"Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search."
factorial function,"Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search."
single recursion include list traversal,"Standard examples of single recursion include list traversal, such as in a linear search, or computing the factorial function, while standard examples of multiple recursion include tree traversal, such as in a depth-first search."
iterative computation,"Single recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space."
requiring constant space,"Single recursion is often much more efficient than multiple recursion, and can generally be replaced by an iterative computation, running in linear time and requiring constant space."
value requires two previous values,"For example, while computing the Fibonacci sequence naively entails multiple iteration, as each value requires two previous values, it can be computed by single recursion by passing two successive values as parameters."
passing two successive values,"For example, while computing the Fibonacci sequence naively entails multiple iteration, as each value requires two previous values, it can be computed by single recursion by passing two successive values as parameters."
stable model semantics,"The properties of the stable model semantics stated above for traditional programs hold in the presence of constraints as well. !! The discovery of these relationships was a key step towards the invention of the stable model semantics. !! The stable model semantics, which is used to give a semantics to logic programming with negation as failure, can be seen as a simplified form of autoepistemic logic. !! The stable model semantics, in its basic form, can be viewed as a reformulation of this idea that avoids explicit references to autoepistemic logic. !! If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering. !! The stable model semantics uses the same idea, but it does not explicitly refer to default logic."
key step towards,The discovery of these relationships was a key step towards the invention of the stable model semantics.
avoids explicit references,"The stable model semantics, in its basic form, can be viewed as a reformulation of this idea that avoids explicit references to autoepistemic logic."
autoepistemic logic,"While propositional logic can only express facts, autoepistemic logic can express knowledge and lack of knowledge about facts. !! The autoepistemic logic is a formal logic for the representation and reasoning of knowledge about knowledge. !! The semantics of autoepistemic logic is based on the expansions of a theory, which have a role similar to models in propositional logic. !! The stable model semantics, which is used to give a semantics to logic programming with negation as failure, can be seen as a simplified form of autoepistemic logic. !! are tautologies of autoepistemic logic, but not of S5. !! The stable model semantics, in its basic form, can be viewed as a reformulation of this idea that avoids explicit references to autoepistemic logic."
default logic,"The stable model semantics uses the same idea, but it does not explicitly refer to default logic."
explicitly refer,"The stable model semantics uses the same idea, but it does not explicitly refer to default logic."
stable model semantics uses,"The stable model semantics uses the same idea, but it does not explicitly refer to default logic."
unambiguous specification,If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering.
style query answering,If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering.
judged unsatisfactory,If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering.
programs without,If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering.
unique stable model,If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering.
stable model semantics stated,The properties of the stable model semantics stated above for traditional programs hold in the presence of constraints as well.
traditional programs hold,The properties of the stable model semantics stated above for traditional programs hold in the presence of constraints as well.
current scale,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
transistors get smaller,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
power density stays constant,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
scaling law,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
states roughly,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
mosfet scaling,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
power use stays,"Dennard scaling, also known as MOSFET scaling, is a scaling law which states roughly that, as transistors get smaller, their power density stays constant, so that the power use stays in proportion with area; both voltage and current scale (downward) with length."
every 18 months,"Combined with Dennard scaling, this means that performance per watt grows even faster, doubling about every 18 months (1."
one generation,"Historically, the transistor power reduction afforded by Dennard scaling allowed manufacturers to drastically raise clock frequencies from one generation to the next without significantly increasing overall circuit power consumption."
transistor power reduction afforded,"Historically, the transistor power reduction afforded by Dennard scaling allowed manufacturers to drastically raise clock frequencies from one generation to the next without significantly increasing overall circuit power consumption."
dennard scaling allowed manufacturers,"Historically, the transistor power reduction afforded by Dennard scaling allowed manufacturers to drastically raise clock frequencies from one generation to the next without significantly increasing overall circuit power consumption."
drastically raise clock frequencies,"Historically, the transistor power reduction afforded by Dennard scaling allowed manufacturers to drastically raise clock frequencies from one generation to the next without significantly increasing overall circuit power consumption."
since around 20052007 dennard scaling appears,Since around 20052007 Dennard scaling appears to have broken down.
increase clock frequencies significantly,The breakdown of Dennard scaling and resulting inability to increase clock frequencies significantly has caused most CPU manufacturers to focus on multicore processors as an alternative way to improve performance.
resulting inability,The breakdown of Dennard scaling and resulting inability to increase clock frequencies significantly has caused most CPU manufacturers to focus on multicore processors as an alternative way to improve performance.
cpu manufacturers,The breakdown of Dennard scaling and resulting inability to increase clock frequencies significantly has caused most CPU manufacturers to focus on multicore processors as an alternative way to improve performance.
alternative way,The breakdown of Dennard scaling and resulting inability to increase clock frequencies significantly has caused most CPU manufacturers to focus on multicore processors as an alternative way to improve performance.
daily usage,"The average CPU power (ACP) is the power consumption of central processing units, especially server processors, under ""average"" daily usage as defined by Advanced Micro Devices (AMD) for use in its line of processors based on the K10 microarchitecture (Opteron 8300 and 2300 series processors)."
processors based,"The average CPU power (ACP) is the power consumption of central processing units, especially server processors, under ""average"" daily usage as defined by Advanced Micro Devices (AMD) for use in its line of processors based on the K10 microarchitecture (Opteron 8300 and 2300 series processors)."
2300 series processors,"The average CPU power (ACP) is the power consumption of central processing units, especially server processors, under ""average"" daily usage as defined by Advanced Micro Devices (AMD) for use in its line of processors based on the K10 microarchitecture (Opteron 8300 and 2300 series processors)."
especially server processors,"The average CPU power (ACP) is the power consumption of central processing units, especially server processors, under ""average"" daily usage as defined by Advanced Micro Devices (AMD) for use in its line of processors based on the K10 microarchitecture (Opteron 8300 and 2300 series processors)."
use unlabeled data,"Because of this assumption, a manifold regularization algorithm can use unlabeled data to inform where the learned function is allowed to change quickly and where it is not, using an extension of the technique of Tikhonov regularization."
change quickly,"Because of this assumption, a manifold regularization algorithm can use unlabeled data to inform where the learned function is allowed to change quickly and where it is not, using an extension of the technique of Tikhonov regularization."
learned function,"Because of this assumption, a manifold regularization algorithm can use unlabeled data to inform where the learned function is allowed to change quickly and where it is not, using an extension of the technique of Tikhonov regularization."
transductive learning settings,"Manifold regularization algorithms can extend supervised learning algorithms in semi-supervised learning and transductive learning settings, where unlabeled data are available."
penalizing complex solutions,"Manifold regularization is a type of regularization, a family of techniques that reduces overfitting and ensures that a problem is well-posed by penalizing complex solutions."
reduces overfitting,"Manifold regularization is a type of regularization, a family of techniques that reduces overfitting and ensures that a problem is well-posed by penalizing complex solutions."
manifold regularization extends,"In particular, manifold regularization extends the technique of Tikhonov regularization as applied to Reproducing kernel Hilbert spaces (RKHSs)."
reproducing kernel hilbert spaces,"In particular, manifold regularization extends the technique of Tikhonov regularization as applied to Reproducing kernel Hilbert spaces (RKHSs)."
create malicious attacks,Adversarial machine learning is a machine learning technique that attempts to exploit models by taking advantage of obtainable model information and using it to create malicious attacks.
exploit models,Adversarial machine learning is a machine learning technique that attempts to exploit models by taking advantage of obtainable model information and using it to create malicious attacks.
taking advantage,Adversarial machine learning is a machine learning technique that attempts to exploit models by taking advantage of obtainable model information and using it to create malicious attacks.
also perform well,Frosst also believe that the adversarial machine learning community incorrectly assumes models trained on a certain data distribution will also perform well on a completely different data distribution.
completely different data distribution,Frosst also believe that the adversarial machine learning community incorrectly assumes models trained on a certain data distribution will also perform well on a completely different data distribution.
certain data distribution,Frosst also believe that the adversarial machine learning community incorrectly assumes models trained on a certain data distribution will also perform well on a completely different data distribution.
frosst also believe,Frosst also believe that the adversarial machine learning community incorrectly assumes models trained on a certain data distribution will also perform well on a completely different data distribution.
begun curating documentation,"While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks."
heavily rooted,"While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks."
adversarial machine learning continues,"While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks."
concretely assess,"While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks."
allow others,"While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks."
large tech companies,"While adversarial machine learning continues to be heavily rooted in academia, large tech companies such as Google, Microsoft, and IBM have begun curating documentation and open source code bases to allow others to concretely assess the robustness of machine learning models and minimize the risk of adversarial attacks."
adversarial machine learning assumes,Black box attacks in adversarial machine learning assumes that the adversary can only get outputs for provided inputs and has no knowledge of the model structure or parameters.
provided inputs,Black box attacks in adversarial machine learning assumes that the adversary can only get outputs for provided inputs and has no knowledge of the model structure or parameters.
get outputs,Black box attacks in adversarial machine learning assumes that the adversary can only get outputs for provided inputs and has no knowledge of the model structure or parameters.
data cleansing,"The problem of database repair is a question about relational databases which has been studied in database theory, and which is a particular kind of data cleansing."
particular kind,"A Boolean network is a particular kind of sequential dynamical system, where time and states are discrete, i. e. both the set of variables and the set of states in the time series each have a bijection onto an integer series. !! In computer science, specifically software engineering and hardware engineering, formal methods are a particular kind of mathematically rigorous techniques for the specification, development and verification of software and hardware systems. !! The problem of database repair is a question about relational databases which has been studied in database theory, and which is a particular kind of data cleansing."
database repair,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs. !! The problem of database repair is a question about relational databases which has been studied in database theory, and which is a particular kind of data cleansing."
different problem variants,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
without explicitly materializing,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
minimal subset repairs,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
efficiently determine information,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
minimal number,"In mathematics and computer science, optimal addition-chain exponentiation is a method of exponentiation by positive integer powers that requires a minimal number of multiplications. !! which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
repaired databases,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
minimal subset,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
minimal cardinality repairs,"which repaired databases do we study: those where we only change a minimal subset of the database tuples (e. g. , minimal subset repairs), those where we only change a minimal number of database tuples (e. g. , minimal cardinality repairs)The problem of database repair has been studied to understand what is the complexity of these different problem variants, i. e. , can we efficiently determine information about the state of the repairs, without explicitly materializing all of these repairs."
historically approached,Laplacian regularization has been historically approached through graph-Laplacian.
electronic data established,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
dutch pronunciation,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
two belgian cryptographers,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
rijndael block cipher developed,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
aes selection process,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
aes  also known,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
vincent rijmen,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
original name rijndael,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
joan daemen,"The Advanced Encryption Standard (AES), also known by its original name Rijndael (Dutch pronunciation: [rindal]), is a specification for the encryption of electronic data established by the U. S. National Institute of Standards and Technology (NIST) in 2001. AES is a variant of the Rijndael block cipher developed by two Belgian cryptographers, Joan Daemen and Vincent Rijmen, who submitted a proposal to NIST during the AES selection process."
fifteen competing designs,"This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details)."
see advanced encryption standard process,"This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details)."
rijndael cipher,"This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details)."
year standardization process,"This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details)."
announcement followed,"This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details)."
lanczos algorithm,"The Lanczos algorithm is most often brought up in the context of finding the eigenvalues and eigenvectors of a matrix, but whereas an ordinary diagonalization of a matrix would make eigenvectors and eigenvalues apparent from inspection, the same is not true for the tridiagonalization performed by the Lanczos algorithm; nontrivial additional steps are needed to compute even a single eigenvalue or eigenvector. !! The combination of good performance for sparse matrices and the ability to compute several (without computing all) eigenvalues are the main reasons for choosing to use the Lanczos algorithm. !! ; the Lanczos algorithm can be very fast for sparse matrices. !! Nonetheless, applying the Lanczos algorithm is often a significant step forward in computing the eigendecomposition. !! region, the Lanczos algorithm can be viewed as a lossy compression scheme for Hermitian matrices, that emphasises preserving the extreme eigenvalues."
matrix would make eigenvectors,"The Lanczos algorithm is most often brought up in the context of finding the eigenvalues and eigenvectors of a matrix, but whereas an ordinary diagonalization of a matrix would make eigenvectors and eigenvalues apparent from inspection, the same is not true for the tridiagonalization performed by the Lanczos algorithm; nontrivial additional steps are needed to compute even a single eigenvalue or eigenvector."
eigenvalues apparent,"The Lanczos algorithm is most often brought up in the context of finding the eigenvalues and eigenvectors of a matrix, but whereas an ordinary diagonalization of a matrix would make eigenvectors and eigenvalues apparent from inspection, the same is not true for the tridiagonalization performed by the Lanczos algorithm; nontrivial additional steps are needed to compute even a single eigenvalue or eigenvector."
compute even,"The Lanczos algorithm is most often brought up in the context of finding the eigenvalues and eigenvectors of a matrix, but whereas an ordinary diagonalization of a matrix would make eigenvectors and eigenvalues apparent from inspection, the same is not true for the tridiagonalization performed by the Lanczos algorithm; nontrivial additional steps are needed to compute even a single eigenvalue or eigenvector."
tridiagonalization performed,"The Lanczos algorithm is most often brought up in the context of finding the eigenvalues and eigenvectors of a matrix, but whereas an ordinary diagonalization of a matrix would make eigenvectors and eigenvalues apparent from inspection, the same is not true for the tridiagonalization performed by the Lanczos algorithm; nontrivial additional steps are needed to compute even a single eigenvalue or eigenvector."
often brought,"The Lanczos algorithm is most often brought up in the context of finding the eigenvalues and eigenvectors of a matrix, but whereas an ordinary diagonalization of a matrix would make eigenvectors and eigenvalues apparent from inspection, the same is not true for the tridiagonalization performed by the Lanczos algorithm; nontrivial additional steps are needed to compute even a single eigenvalue or eigenvector."
significant step forward,"Nonetheless, applying the Lanczos algorithm is often a significant step forward in computing the eigendecomposition."
hermitian matrices,"region, the Lanczos algorithm can be viewed as a lossy compression scheme for Hermitian matrices, that emphasises preserving the extreme eigenvalues."
emphasises preserving,"region, the Lanczos algorithm can be viewed as a lossy compression scheme for Hermitian matrices, that emphasises preserving the extreme eigenvalues."
without computing,The combination of good performance for sparse matrices and the ability to compute several (without computing all) eigenvalues are the main reasons for choosing to use the Lanczos algorithm.
compute several,The combination of good performance for sparse matrices and the ability to compute several (without computing all) eigenvalues are the main reasons for choosing to use the Lanczos algorithm.
good performance,The combination of good performance for sparse matrices and the ability to compute several (without computing all) eigenvalues are the main reasons for choosing to use the Lanczos algorithm.
study using cognitive psychology,Cognitive engineering is a method of study using cognitive psychology to design and develop engineering systems to support the cognitive processes of users.
develop engineering systems,Cognitive engineering is a method of study using cognitive psychology to design and develop engineering systems to support the cognitive processes of users.
techniques employed,Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order.
performing memory disambiguation,"The mechanisms for performing memory disambiguation, implemented using digital logic inside the microprocessor core, detect true dependencies between memory operations at execution time and allow the processor to recover when a dependence has been violated."
detect true dependencies,"The mechanisms for performing memory disambiguation, implemented using digital logic inside the microprocessor core, detect true dependencies between memory operations at execution time and allow the processor to recover when a dependence has been violated."
implemented using digital logic inside,"The mechanisms for performing memory disambiguation, implemented using digital logic inside the microprocessor core, detect true dependencies between memory operations at execution time and allow the processor to recover when a dependence has been violated."
microprocessor core,"The mechanisms for performing memory disambiguation, implemented using digital logic inside the microprocessor core, detect true dependencies between memory operations at execution time and allow the processor to recover when a dependence has been violated."
andrey tikhonov,"Tikhonov regularization, named for Andrey Tikhonov, is a method of regularization of ill-posed problems."
posed problems,"Tikhonov regularization, named for Andrey Tikhonov, is a method of regularization of ill-posed problems."
general approach,A more general approach to Tikhonov regularization is discussed below.
invented independently,Tikhonov regularization has been invented independently in many different contexts.
many different contexts,Tikhonov regularization has been invented independently in many different contexts.
typically discrete linear ill,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
dimensional context,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
conditioned problems result,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
original infinite,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
categorical logic represents,"In broad terms, categorical logic represents both syntax and semantics by a category, and an interpretation by a functor."
broad terms,"In broad terms, categorical logic represents both syntax and semantics by a category, and an interpretation by a functor."
particular case,Categorical logic introduces the notion of structure valued in a category C with the classical model theoretic notion of a structure appearing in the particular case where C is the category of sets and functions.
categorical logic introduces,Categorical logic introduces the notion of structure valued in a category C with the classical model theoretic notion of a structure appearing in the particular case where C is the category of sets and functions.
structure appearing,Categorical logic introduces the notion of structure valued in a category C with the classical model theoretic notion of a structure appearing in the particular case where C is the category of sets and functions.
classical model theoretic notion,Categorical logic introduces the notion of structure valued in a category C with the classical model theoretic notion of a structure appearing in the particular case where C is the category of sets and functions.
structure valued,Categorical logic introduces the notion of structure valued in a category C with the classical model theoretic notion of a structure appearing in the particular case where C is the category of sets and functions.
adjoint functor,"It was found that the connectives of pre-categorical logic were more clearly understood using the concept of adjoint functor, and that the quantifiers were also best understood using adjoint functors."
clearly understood using,"It was found that the connectives of pre-categorical logic were more clearly understood using the concept of adjoint functor, and that the quantifiers were also best understood using adjoint functors."
term voice recognition,The term voice recognition can refer to speaker recognition or speech recognition.
speaker verification,"Speaker verification (also called speaker authentication) contrasts with identification, and speaker recognition differs from speaker diarisation (recognizing when the same speaker is speaking)."
speaker recognition differs,"Speaker verification (also called speaker authentication) contrasts with identification, and speaker recognition differs from speaker diarisation (recognizing when the same speaker is speaking)."
also called speaker authentication,"Speaker verification (also called speaker authentication) contrasts with identification, and speaker recognition differs from speaker diarisation (recognizing when the same speaker is speaking)."
history dating back,Speaker recognition has a history dating back some four decades as of 2019 and uses the acoustic features of speech that have been found to differ between individuals.
acoustic features,Speaker recognition has a history dating back some four decades as of 2019 and uses the acoustic features of speech that have been found to differ between individuals.
four decades,Speaker recognition has a history dating back some four decades as of 2019 and uses the acoustic features of speech that have been found to differ between individuals.
two major applications,There are two major applications of speaker recognition technologies and methodologies.
string literal containing one,"In computer programming, string interpolation (or variable interpolation, variable substitution, or variable expansion) is the process of evaluating a string literal containing one or more placeholders, yielding a result in which the placeholders are replaced with their corresponding values."
string interpolation,"String interpolation is an alternative to building string via concatenation, which requires repeated quoting and unquoting; or substituting into a printf format string, where the variable is far from where it is used. !! Some languages do not offer string interpolation, instead using concatenation, simple formatting functions, or template libraries. !! In computer programming, string interpolation (or variable interpolation, variable substitution, or variable expansion) is the process of evaluating a string literal containing one or more placeholders, yielding a result in which the placeholders are replaced with their corresponding values. !! String interpolation is common in many programming languages which make heavy use of string representations of data, such as Apache Groovy, Julia, Kotlin, Perl, PHP, Python, Ruby, Scala, Swift, Tcl and most Unix shells. !! Language support for string interpolation varies widely."
variable substitution,"In computer programming, string interpolation (or variable interpolation, variable substitution, or variable expansion) is the process of evaluating a string literal containing one or more placeholders, yielding a result in which the placeholders are replaced with their corresponding values."
printf format string,"String interpolation is an alternative to building string via concatenation, which requires repeated quoting and unquoting; or substituting into a printf format string, where the variable is far from where it is used."
requires repeated quoting,"String interpolation is an alternative to building string via concatenation, which requires repeated quoting and unquoting; or substituting into a printf format string, where the variable is far from where it is used."
building string via concatenation,"String interpolation is an alternative to building string via concatenation, which requires repeated quoting and unquoting; or substituting into a printf format string, where the variable is far from where it is used."
string interpolation varies widely,Language support for string interpolation varies widely.
instead using concatenation,"Some languages do not offer string interpolation, instead using concatenation, simple formatting functions, or template libraries."
offer string interpolation,"Some languages do not offer string interpolation, instead using concatenation, simple formatting functions, or template libraries."
make heavy use,"String interpolation is common in many programming languages which make heavy use of string representations of data, such as Apache Groovy, Julia, Kotlin, Perl, PHP, Python, Ruby, Scala, Swift, Tcl and most Unix shells."
apache groovy,"String interpolation is common in many programming languages which make heavy use of string representations of data, such as Apache Groovy, Julia, Kotlin, Perl, PHP, Python, Ruby, Scala, Swift, Tcl and most Unix shells."
hard real,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
hardware feature found,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
minimize latencies,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
load certain tasks,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
save energy,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
power designs,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
embedded autonomous peripherals,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
improve throughput,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
program uses,Memory footprint refers to the amount of main memory that a program uses or references while running.
memory footprint refers,Memory footprint refers to the amount of main memory that a program uses or references while running.
software application indicates,"In computing, the memory footprint of a software application indicates its runtime memory requirements, while the program executes."
runtime memory requirements,"In computing, the memory footprint of a software application indicates its runtime memory requirements, while the program executes."
program executes,"In computing, the memory footprint of a software application indicates its runtime memory requirements, while the program executes."
static data areas contribute,"An application's memory footprint is roughly proportionate to the number and sizes of shared libraries or classes it loads, whereas static libraries, executable programs and static data areas contribute to a fixed (constant) portion."
roughly proportionate,"An application's memory footprint is roughly proportionate to the number and sizes of shared libraries or classes it loads, whereas static libraries, executable programs and static data areas contribute to a fixed (constant) portion."
time environment take,"Programs themselves often do not contribute the largest portions to their own memory footprints; rather, structures introduced by the run-time environment take up most of the memory."
structures introduced,"Programs themselves often do not contribute the largest portions to their own memory footprints; rather, structures introduced by the run-time environment take up most of the memory."
later execution,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
defer required,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
microsoft windows operating system mechanism,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
priority tasks,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
allows high,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
microsoft docs,Microsoft Docs: Deferred Procedure Calls (DPCs)Specific
single piece,"In computer programming, bidirectional transformations (bx) are programs in which a single piece of code can be run in several ways, such that the same data are sometimes considered as input, and sometimes as output."
several ways,"In computer programming, bidirectional transformations (bx) are programs in which a single piece of code can be run in several ways, such that the same data are sometimes considered as input, and sometimes as output. !! The definition can be extended in several ways, leading to different classes of generalized bent functions that share many of the useful properties of the original."
sometimes considered,"In computer programming, bidirectional transformations (bx) are programs in which a single piece of code can be run in several ways, such that the same data are sometimes considered as input, and sometimes as output."
code word,"Code words are typically used for reasons of reliability, clarity, brevity, or secrecy. !! Each code word is assembled in accordance with the specific rules of the code and assigned a unique meaning. !! In communication, a code word is an element of a standardized code or protocol."
unique meaning,Each code word is assembled in accordance with the specific rules of the code and assigned a unique meaning.
specific rules,Each code word is assembled in accordance with the specific rules of the code and assigned a unique meaning.
code words,"Code words are typically used for reasons of reliability, clarity, brevity, or secrecy."
popular model,A popular model for doing computable analysis is Turing machines.
type 1 computability,Type 1 computability is the naive form of computable analysis in which one restricts the inputs to a machine to be computable numbers instead of arbitrary real numbers.
computable numbers instead,Type 1 computability is the naive form of computable analysis in which one restricts the inputs to a machine to be computable numbers instead of arbitrary real numbers.
one restricts,Type 1 computability is the naive form of computable analysis in which one restricts the inputs to a machine to be computable numbers instead of arbitrary real numbers.
arbitrary real numbers,Type 1 computability is the naive form of computable analysis in which one restricts the inputs to a machine to be computable numbers instead of arbitrary real numbers.
naive form,Type 1 computability is the naive form of computable analysis in which one restricts the inputs to a machine to be computable numbers instead of arbitrary real numbers.
realisability topos called,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
constructive analysis,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
reduce computable analysis,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
low level,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
kleenevesley topos,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
somewhat arbitrary,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
using turing machines,"In the event that one is unhappy with using Turing machines (on the grounds that they are low level and somewhat arbitrary), there is a realisability topos called the KleeneVesley topos in which one can reduce computable analysis to constructive analysis."
1980  computable analysis,"Oliver Aberth (1980), Computable analysis, McGraw-Hill, ISBN 0-0700-0079-4."
oliver aberth,"Oliver Aberth (1980), Computable analysis, McGraw-Hill, ISBN 0-0700-0079-4."
compressed speech refers,Time-compressed speech refers to an audio recording of verbal text in which the text is presented in a much shorter time interval than it would through normally-paced real time speech.
much shorter time interval,Time-compressed speech refers to an audio recording of verbal text in which the text is presented in a much shorter time interval than it would through normally-paced real time speech.
paced real time speech,Time-compressed speech refers to an audio recording of verbal text in which the text is presented in a much shorter time interval than it would through normally-paced real time speech.
verbal text,Time-compressed speech refers to an audio recording of verbal text in which the text is presented in a much shorter time interval than it would through normally-paced real time speech.
compressed speech,"The advantage of time-compressed speech is that the same number of words can be compressed into a smaller amount of time, reducing advertising costs, and/or allowing more information to be included in a given radio or TV advertisement. !! Time-compressed speech is frequently used in television and radio advertising. !! While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech. !! The term ""time-compressed speech"" should not be confused with ""speech compression"", which controls the volume range of a sound, but does not alter its time envelope."
time envelope,"The term ""time-compressed speech"" should not be confused with ""speech compression"", which controls the volume range of a sound, but does not alter its time envelope."
volume range,"The term ""time-compressed speech"" should not be confused with ""speech compression"", which controls the volume range of a sound, but does not alter its time envelope."
voice talents,"While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech."
electronic processing,"While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech."
recorded speech,"While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech."
general norms,"While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech."
rates significantly,"While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech."
radio advertising,Time-compressed speech is frequently used in television and radio advertising.
given radio,"The advantage of time-compressed speech is that the same number of words can be compressed into a smaller amount of time, reducing advertising costs, and/or allowing more information to be included in a given radio or TV advertisement."
reducing advertising costs,"The advantage of time-compressed speech is that the same number of words can be compressed into a smaller amount of time, reducing advertising costs, and/or allowing more information to be included in a given radio or TV advertisement."
smaller amount,"The advantage of time-compressed speech is that the same number of words can be compressed into a smaller amount of time, reducing advertising costs, and/or allowing more information to be included in a given radio or TV advertisement."
tv advertisement,"The advantage of time-compressed speech is that the same number of words can be compressed into a smaller amount of time, reducing advertising costs, and/or allowing more information to be included in a given radio or TV advertisement."
mobile users,Mobile interaction is the study of interaction between mobile users and computers. !! The main reason behind those trends is to understand the requirements and needs of mobile users which is the main goal for mobile interaction.
mobile interaction,"The main reason behind those trends is to understand the requirements and needs of mobile users which is the main goal for mobile interaction. !! Mobile interaction is the study of interaction between mobile users and computers. !! Mobile interaction is a multidisciplinary area with various academic subjects making contributions to it. !! Mobile interaction is an aspect of humancomputer interaction that emerged when computers became small enough to enable mobile usage, around the 1990s. !! The history of mobile interaction includes different design trends."
computers became small enough,"Mobile interaction is an aspect of humancomputer interaction that emerged when computers became small enough to enable mobile usage, around the 1990s."
enable mobile usage,"Mobile interaction is an aspect of humancomputer interaction that emerged when computers became small enough to enable mobile usage, around the 1990s."
main reason behind,The main reason behind those trends is to understand the requirements and needs of mobile users which is the main goal for mobile interaction.
main goal,The main reason behind those trends is to understand the requirements and needs of mobile users which is the main goal for mobile interaction.
various academic subjects making contributions,Mobile interaction is a multidisciplinary area with various academic subjects making contributions to it.
multidisciplinary area,Mobile interaction is a multidisciplinary area with various academic subjects making contributions to it.
continuous scale onto discrete,"A Thurstonian model is a stochastic transitivity model with latent variables for describing the mapping of some continuous scale onto discrete, possibly ordered categories of response."
stochastic transitivity model,"A Thurstonian model is a stochastic transitivity model with latent variables for describing the mapping of some continuous scale onto discrete, possibly ordered categories of response."
thurstonian model,"In Chapter 7 of this book, a closed form expression, derived in 1988, is given for a Euclidean-Gaussian similarity model that provides a solution to the well-known problem that many Thurstonian models are computationally complex often involving multiple integration. !! Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring. !! Developments over the last two decades, however, have led to Thurstonian models that allow unequal variance and non zero covariance terms. !! Thurstonian models have been used as an alternative to generalized linear models in analysis of sensory discrimination tasks. !! A Thurstonian model is a stochastic transitivity model with latent variables for describing the mapping of some continuous scale onto discrete, possibly ordered categories of response."
possibly ordered categories,"A Thurstonian model is a stochastic transitivity model with latent variables for describing the mapping of some continuous scale onto discrete, possibly ordered categories of response."
last two decades,"Developments over the last two decades, however, have led to Thurstonian models that allow unequal variance and non zero covariance terms."
non zero covariance terms,"Developments over the last two decades, however, have led to Thurstonian models that allow unequal variance and non zero covariance terms."
thurstonian models,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring. !! Thurstonian models have been used as an alternative to generalized linear models in analysis of sensory discrimination tasks. !! Developments over the last two decades, however, have led to Thurstonian models that allow unequal variance and non zero covariance terms."
allow unequal variance,"Developments over the last two decades, however, have led to Thurstonian models that allow unequal variance and non zero covariance terms."
sensory discrimination tasks,Thurstonian models have been used as an alternative to generalized linear models in analysis of sensory discrimination tasks.
generalized linear models,Thurstonian models have been used as an alternative to generalized linear models in analysis of sensory discrimination tasks.
dual pair,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
ennis provides,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
comprehensive account,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
applicability scoring,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
last choice,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
behavioral tasks including preferential choice,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
many thurstonian models,"In Chapter 7 of this book, a closed form expression, derived in 1988, is given for a Euclidean-Gaussian similarity model that provides a solution to the well-known problem that many Thurstonian models are computationally complex often involving multiple integration."
closed form expression,"In Chapter 7 of this book, a closed form expression, derived in 1988, is given for a Euclidean-Gaussian similarity model that provides a solution to the well-known problem that many Thurstonian models are computationally complex often involving multiple integration."
used within type systems,"Data types are used within type systems, which offer various ways of defining, implementing, and using them."
offer various ways,"Data types are used within type systems, which offer various ways of defining, implementing, and using them."
new data type,"Most programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type."
define additional data types,"Most programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type."
programming languages also allow,"Most programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type."
combining multiple elements,"Most programming languages also allow the programmer to define additional data types, usually by combining multiple elements of other types and defining the valid operations of the new data type."
typically types,Primitive data types are typically types that are built-in or basic to a language implementation.
language implementation,Primitive data types are typically types that are built-in or basic to a language implementation.
signed data types,"Because of two's complement, the machine language and machine doesn't need to distinguish between these unsigned and signed data types for the most part."
machine language,"Because of two's complement, the machine language and machine doesn't need to distinguish between these unsigned and signed data types for the most part."
picked randomly according,"In stochastic pooling, the conventional deterministic pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region."
activation within,"In stochastic pooling, the conventional deterministic pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region."
pooling region,"In stochastic pooling, the conventional deterministic pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region."
activities within,"In stochastic pooling, the conventional deterministic pooling operations are replaced with a stochastic procedure, where the activation within each pooling region is picked randomly according to a multinomial distribution, given by the activities within the pooling region."
many copies,"An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations."
alternate view,"An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations."
standard max pooling,"An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations."
input image,"An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations."
small local deformations,"An alternate view of stochastic pooling is that it is equivalent to standard max pooling but with many copies of an input image, each having small local deformations."
exponential number,Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.
using stochastic pooling,Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.
deformations since,Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.
multilayer model gives,Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.
higher layers,Using stochastic pooling in a multilayer model gives an exponential number of deformations since the selections in higher layers are independent of those below.
partial list,The following is a partial list of Intel CPU microarchitectures.
support mobile app development,A mobile development framework is a software framework that is designed to support mobile app development.
parsing methods,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
shift-reduce parser,"A shift-reduce parser works by doing some combination of Shift steps and Reduce steps, hence the name. !! A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar. !! A shift-reduce parser scans and parses the input text in one forward pass over the text, without backing up. !! All shift-reduce parsers have similar outward effects, in the incremental order in which they build a parse tree or call specific output actions. !! Shift-reduce parsers use a context-free grammar that deals just with local patterns of symbols."
driven bottom,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
notations formally defined,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
reduce parser,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
computer languages,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
reduce parsers,"All shift-reduce parsers have similar outward effects, in the incremental order in which they build a parse tree or call specific output actions."
similar outward effects,"All shift-reduce parsers have similar outward effects, in the incremental order in which they build a parse tree or call specific output actions."
incremental order,"All shift-reduce parsers have similar outward effects, in the incremental order in which they build a parse tree or call specific output actions."
call specific output actions,"All shift-reduce parsers have similar outward effects, in the incremental order in which they build a parse tree or call specific output actions."
one forward pass,"A shift-reduce parser scans and parses the input text in one forward pass over the text, without backing up."
without backing,"A shift-reduce parser scans and parses the input text in one forward pass over the text, without backing up."
reduce parser scans,"A shift-reduce parser scans and parses the input text in one forward pass over the text, without backing up."
input text,"A shift-reduce parser scans and parses the input text in one forward pass over the text, without backing up."
shift steps,"A shift-reduce parser works by doing some combination of Shift steps and Reduce steps, hence the name."
reduce parser works,"A shift-reduce parser works by doing some combination of Shift steps and Reduce steps, hence the name."
reduce steps,"A shift-reduce parser works by doing some combination of Shift steps and Reduce steps, hence the name."
reduce parsers use,Shift-reduce parsers use a context-free grammar that deals just with local patterns of symbols.
local patterns,Shift-reduce parsers use a context-free grammar that deals just with local patterns of symbols.
complexity axis,Cognitive complexity describes cognition along a simplicity-complexity axis.
cognitive complexity describes cognition along,Cognitive complexity describes cognition along a simplicity-complexity axis.
humans perceive relevance,"In an attempt to explain how humans perceive relevance, cognitive complexity is defined as an extension of the notion of Kolmogorov complexity."
see simplicity theory  situations,Cognitive complexity is related to probability (see Simplicity theory): situations are cognitively improbable if they are simpler to describe than to generate.
cognitively improbable,Cognitive complexity is related to probability (see Simplicity theory): situations are cognitively improbable if they are simpler to describe than to generate.
psychological variable,Cognitive complexity is a psychological characteristic or psychological variable that indicates how complex or simple is the frame and perceptual skill of a person.
psychological characteristic,Cognitive complexity is a psychological characteristic or psychological variable that indicates how complex or simple is the frame and perceptual skill of a person.
perceptual skill,Cognitive complexity is a psychological characteristic or psychological variable that indicates how complex or simple is the frame and perceptual skill of a person.
cognitive complexity tends,"A person who is measured high on cognitive complexity tends to perceive nuances and subtle differences which a person with a lower measure, indicating a less complex cognitive structure for the task or activity, does not."
less complex cognitive structure,"A person who is measured high on cognitive complexity tends to perceive nuances and subtle differences which a person with a lower measure, indicating a less complex cognitive structure for the task or activity, does not."
perceive nuances,"A person who is measured high on cognitive complexity tends to perceive nuances and subtle differences which a person with a lower measure, indicating a less complex cognitive structure for the task or activity, does not."
measured high,"A person who is measured high on cognitive complexity tends to perceive nuances and subtle differences which a person with a lower measure, indicating a less complex cognitive structure for the task or activity, does not."
lower measure,"A person who is measured high on cognitive complexity tends to perceive nuances and subtle differences which a person with a lower measure, indicating a less complex cognitive structure for the task or activity, does not."
subtle differences,"A person who is measured high on cognitive complexity tends to perceive nuances and subtle differences which a person with a lower measure, indicating a less complex cognitive structure for the task or activity, does not."
squarified treemap,"Hypermedia exploration with interactive dynamic maps Paper by Zizi and Beaudouin-Lafon introducing the squarified treemap layout algorithm (named ""improved treemap layout"" at the time)."
hypermedia exploration,"Hypermedia exploration with interactive dynamic maps Paper by Zizi and Beaudouin-Lafon introducing the squarified treemap layout algorithm (named ""improved treemap layout"" at the time)."
improved treemap layout,"Hypermedia exploration with interactive dynamic maps Paper by Zizi and Beaudouin-Lafon introducing the squarified treemap layout algorithm (named ""improved treemap layout"" at the time)."
lafon introducing,"Hypermedia exploration with interactive dynamic maps Paper by Zizi and Beaudouin-Lafon introducing the squarified treemap layout algorithm (named ""improved treemap layout"" at the time)."
interactive dynamic maps paper,"Hypermedia exploration with interactive dynamic maps Paper by Zizi and Beaudouin-Lafon introducing the squarified treemap layout algorithm (named ""improved treemap layout"" at the time)."
reinforce human cognition,Information visualization (or visualisation) is the study of visual representations of abstract data to reinforce human cognition.
abstract data,Information visualization (or visualisation) is the study of visual representations of abstract data to reinforce human cognition.
spatial representation,"One definition is that it's information visualization when the spatial representation (e. g. , the page layout of a graphic design) is chosen, whereas it's scientific visualization when the spatial representation is given."
page layout,"One definition is that it's information visualization when the spatial representation (e. g. , the page layout of a graphic design) is chosen, whereas it's scientific visualization when the spatial representation is given."
business methods,"The field of information visualization has emerged ""from research in humancomputer interaction, computer science, graphics, visual design, psychology, and business methods."
human eyes broad bandwidth pathway,"Information visualization presumes that ""visual representations and interaction techniques take advantage of the human eyes broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once."
information visualization presumes,"Information visualization presumes that ""visual representations and interaction techniques take advantage of the human eyes broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once."
allow users,"End-User Development can be defined as a set of methods, techniques, and tools that allow users of software systems, who are acting as non-professional software developers, at some point to create, modify or extend a software artifact. !! Information visualization presumes that ""visual representations and interaction techniques take advantage of the human eyes broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once."
understand large amounts,"Information visualization presumes that ""visual representations and interaction techniques take advantage of the human eyes broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once."
interaction techniques take advantage,"Information visualization presumes that ""visual representations and interaction techniques take advantage of the human eyes broad bandwidth pathway into the mind to allow users to see, explore, and understand large amounts of information at once."
conveying abstract information,Information visualization focused on the creation of approaches for conveying abstract information in intuitive ways.
intuitive ways,Information visualization focused on the creation of approaches for conveying abstract information in intuitive ways.
information visualization focused,Information visualization focused on the creation of approaches for conveying abstract information in intuitive ways.
achieving concurrency,"In computer programming, a thread pool is a software design pattern for achieving concurrency of execution in a computer program."
crew model,"Often also called a replicated workers or worker-crew model, a thread pool maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program."
concurrent execution,"Often also called a replicated workers or worker-crew model, a thread pool maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program."
supervising program,"Often also called a replicated workers or worker-crew model, a thread pool maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program."
replicated workers,"Often also called a replicated workers or worker-crew model, a thread pool maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program."
often also called,"Often also called a replicated workers or worker-crew model, a thread pool maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program."
executing tasks,The size of a thread pool is the number of threads kept in reserve for executing tasks.
threads kept,The size of a thread pool is the number of threads kept in reserve for executing tasks.
optimize performance,Deciding the optimal thread pool size is crucial to optimize performance.
optimal thread pool size,Deciding the optimal thread pool size is crucial to optimize performance.
may result,"This may result in implementing lower-level features in terms of higher-level ones, thus the term 'abstraction inversion'. !! One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
initial creation,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
thread creation,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
better system stability,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
better performance,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
destruction overhead,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
one benefit,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
new thread,"One benefit of a thread pool over creating a new thread for each task is that thread creation and destruction overhead is restricted to the initial creation of the pool, which may result in better performance and better system stability."
multimodal interaction provides,Multimodal interaction provides the user with multiple modes of interacting with a system.
multimodal interaction,"""Using cloud for involving shared computational resources in managing the complexity of multimodal interaction represents an opportunity. !! Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output. !! Multimodal interaction provides the user with multiple modes of interacting with a system. !! The pervasive use of mobile devices, sensors and web technologies can offer adequate computational resources to manage the complexity implied by the multimodal interaction. !! W3C's Multimodal Interaction Activity an initiative from W3C aiming to provide means (mostly XML) to support Multimodal Interaction scenarios on the Web."
multiple modes,Multimodal interaction provides the user with multiple modes of interacting with a system.
computer interaction refers,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
multimodal human,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
automated systems,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
interfacing users,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
natural modes,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
natural communication,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
multimodal interaction enables,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
physical environment,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
complexity implied,"The pervasive use of mobile devices, sensors and web technologies can offer adequate computational resources to manage the complexity implied by the multimodal interaction."
pervasive use,"The pervasive use of mobile devices, sensors and web technologies can offer adequate computational resources to manage the complexity implied by the multimodal interaction."
offer adequate computational resources,"The pervasive use of mobile devices, sensors and web technologies can offer adequate computational resources to manage the complexity implied by the multimodal interaction."
multimodal interaction represents,"""Using cloud for involving shared computational resources in managing the complexity of multimodal interaction represents an opportunity."
involving shared computational resources,"""Using cloud for involving shared computational resources in managing the complexity of multimodal interaction represents an opportunity."
using cloud,"""Using cloud for involving shared computational resources in managing the complexity of multimodal interaction represents an opportunity."
mostly xml,W3C's Multimodal Interaction Activity an initiative from W3C aiming to provide means (mostly XML) to support Multimodal Interaction scenarios on the Web.
support multimodal interaction scenarios,W3C's Multimodal Interaction Activity an initiative from W3C aiming to provide means (mostly XML) to support Multimodal Interaction scenarios on the Web.
w3c aiming,W3C's Multimodal Interaction Activity an initiative from W3C aiming to provide means (mostly XML) to support Multimodal Interaction scenarios on the Web.
provide means,W3C's Multimodal Interaction Activity an initiative from W3C aiming to provide means (mostly XML) to support Multimodal Interaction scenarios on the Web.
interdisciplinary area,"Augmented cognition is an interdisciplinary area of psychology and engineering, attracting researchers from the more traditional fields of human-computer interaction, psychology, ergonomics and neuroscience. !! Agent mining is an interdisciplinary area that synergizes multiagent systems with data mining and machine learning."
traditional fields,"Augmented cognition is an interdisciplinary area of psychology and engineering, attracting researchers from the more traditional fields of human-computer interaction, psychology, ergonomics and neuroscience."
attracting researchers,"Augmented cognition is an interdisciplinary area of psychology and engineering, attracting researchers from the more traditional fields of human-computer interaction, psychology, ergonomics and neuroscience."
interfaces already exist,Augmented cognition research generally focuses on tasks and environments where humancomputer interaction and interfaces already exist.
augmented cognition research generally focuses,Augmented cognition research generally focuses on tasks and environments where humancomputer interaction and interfaces already exist.
conceptual framework,"In 1962 Douglas C. Engelbart released the report ""Augmenting Human Intellect: A Conceptual Framework"" which introduced, and laid the groundwork for, augmented cognition."
augmenting human intellect,"In 1962 Douglas C. Engelbart released the report ""Augmenting Human Intellect: A Conceptual Framework"" which introduced, and laid the groundwork for, augmented cognition."
engelbart released,"In 1962 Douglas C. Engelbart released the report ""Augmenting Human Intellect: A Conceptual Framework"" which introduced, and laid the groundwork for, augmented cognition."
modern augmented cognition began,"""Modern augmented cognition began to emerge in the early 2000s."
neurological sciences,"Advances in cognitive, behavioral, and neurological sciences during the 1990s set the stage for the emerging field of augmented cognition this period has been termed the ""Decade of the Brain. """
emerging field,"Advances in cognitive, behavioral, and neurological sciences during the 1990s set the stage for the emerging field of augmented cognition this period has been termed the ""Decade of the Brain. """
order constraints,"In compiler theory, dependence analysis produces execution-order constraints between statements/instructions."
dependence analysis determines whether,Dependence analysis determines whether it is safe to reorder or parallelize statements.
dependence framework given,"The problem of computing dependencies within loops, which is a significant and nontrivial problem, is tackled by loop dependence analysis, which extends the dependence framework given here."
nontrivial problem,"The problem of computing dependencies within loops, which is a significant and nontrivial problem, is tackled by loop dependence analysis, which extends the dependence framework given here."
computing dependencies within loops,"The problem of computing dependencies within loops, which is a significant and nontrivial problem, is tackled by loop dependence analysis, which extends the dependence framework given here."
optimizes material layout within,"Topology optimization is a mathematical method that optimizes material layout within a given design space, for a given set of loads, boundary conditions and constraints with the goal of maximizing the performance of the system."
given design space,"Topology optimization is a mathematical method that optimizes material layout within a given design space, for a given set of loads, boundary conditions and constraints with the goal of maximizing the performance of the system."
shape within,"Topology optimization is different from shape optimization and sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations."
design space,"Topology optimization is different from shape optimization and sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations."
predefined configurations,"Topology optimization is different from shape optimization and sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations."
design performance,The conventional topology optimization formulation uses a finite element method (FEM) to evaluate the design performance.
conventional topology optimization formulation uses,The conventional topology optimization formulation uses a finite element method (FEM) to evaluate the design performance.
civil engineering,"Topology optimization has a wide range of applications in aerospace, mechanical, bio-chemical and civil engineering."
design process,"Currently, engineers mostly use topology optimization at the concept level of a design process. !! The service-orientation design principles are applied during the service-oriented analysis and design process."
engineers mostly use topology optimization,"Currently, engineers mostly use topology optimization at the concept level of a design process."
concept level,"Currently, engineers mostly use topology optimization at the concept level of a design process."
primitive operations allowed,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
cost operations,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
unit cost,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
simply unit,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
wider sample,"In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
statistical distance quantifies,"In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
two probability distributions,"In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
two random variables,"In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
two statistical objects,"In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
statistical distance,"Statistical distances that satisfy (1) and (2) are referred to as divergences. !! Many statistical distances are not metrics, because they lack one or more properties of proper metrics. !! Statistical distance measures are not typically metrics, and they need not be symmetric. !! Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures. !! In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
individual sample point,"In statistics, probability theory, and information theory, a statistical distance quantifies the distance between two statistical objects, which can be two random variables, or two probability distributions or samples, or the distance can be between an individual sample point and a population or a wider sample of points."
statistical distance measures relate,"Where statistical distance measures relate to the differences between random variables, these may have statistical dependence, and hence these distances are not directly related to measures of distances between probability measures."
typically metrics,"Statistical distance measures are not typically metrics, and they need not be symmetric."
proper metrics,"Many statistical distances are not metrics, because they lack one or more properties of proper metrics."
many statistical distances,"Many statistical distances are not metrics, because they lack one or more properties of proper metrics."
lack one,"Many statistical distances are not metrics, because they lack one or more properties of proper metrics."
architecture used,Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning.
long short,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units. !! Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture used in the field of deep learning. !! ""Long Short-Term Memory in Recurrent Neural Networks"" (PDF)."
term memory networks,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units. !! 5 billion automatic translations every day using long short-term memory networks."
widely used long short,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
novel neural network,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
certain data sets,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
term memory neural network,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
study describes,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
performs better,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
digital equipment corporation,"In computing, the Distributed Computing Environment (DCE) software system was developed in the early 1990s from the work of the Open Software Foundation (OSF), a consortium (founded in 1988) that included Apollo Computer (part of Hewlett-Packard from 1989), IBM, Digital Equipment Corporation, and others. !! Digital Data Communications Message Protocol (DDCMP) is a byte-oriented communications protocol devised by Digital Equipment Corporation in 1974 to allow communication over point-to-point network links for the company's DECnet Phase I network protocol suite."
included apollo computer,"In computing, the Distributed Computing Environment (DCE) software system was developed in the early 1990s from the work of the Open Software Foundation (OSF), a consortium (founded in 1988) that included Apollo Computer (part of Hewlett-Packard from 1989), IBM, Digital Equipment Corporation, and others."
open software foundation,"In computing, the Distributed Computing Environment (DCE) software system was developed in the early 1990s from the work of the Open Software Foundation (OSF), a consortium (founded in 1988) that included Apollo Computer (part of Hewlett-Packard from 1989), IBM, Digital Equipment Corporation, and others."
osf offerings,"The Distributed Computing Environment is a component of the OSF offerings, along with Motif, OSF/1 and the Distributed Management Environment (DME)."
distributed management environment,"The Distributed Computing Environment is a component of the OSF offerings, along with Motif, OSF/1 and the Distributed Management Environment (DME)."
integrating security,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
larger network,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
distributed services,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
osf could offer,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
supporting system,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
namely osf,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
information displayed,"An error message is information displayed when an unforeseen problem occurs, usually on a computer or other device."
unforeseen problem occurs,"An error message is information displayed when an unforeseen problem occurs, usually on a computer or other device."
often displayed using dialog boxes,"On modern operating systems with graphical user interfaces, error messages are often displayed using dialog boxes."
error messages,"Proper design of error messages is an important topic in usability and other fields of humancomputer interaction. !! On modern operating systems with graphical user interfaces, error messages are often displayed using dialog boxes. !! Error messages are seen widely throughout computing, and are part of every operating system or computer hardware device. !! Error messages are used when user intervention is required, to indicate that a desired operation has failed, or to relay important warnings (such as warning a computer user that they are almost out of hard disk space)."
computer user,"Error messages are used when user intervention is required, to indicate that a desired operation has failed, or to relay important warnings (such as warning a computer user that they are almost out of hard disk space)."
desired operation,"Error messages are used when user intervention is required, to indicate that a desired operation has failed, or to relay important warnings (such as warning a computer user that they are almost out of hard disk space)."
relay important warnings,"Error messages are used when user intervention is required, to indicate that a desired operation has failed, or to relay important warnings (such as warning a computer user that they are almost out of hard disk space)."
every operating system,"Error messages are seen widely throughout computing, and are part of every operating system or computer hardware device."
seen widely throughout computing,"Error messages are seen widely throughout computing, and are part of every operating system or computer hardware device."
important topic,Proper design of error messages is an important topic in usability and other fields of humancomputer interaction.
proper design,Proper design of error messages is an important topic in usability and other fields of humancomputer interaction.
structure data provide alternatives,"In bioinformatics, alignment-free sequence analysis approaches to molecular sequence and structure data provide alternatives over alignment-based approaches."
molecular sequence,"In bioinformatics, alignment-free sequence analysis approaches to molecular sequence and structure data provide alternatives over alignment-based approaches."
free sequence analysis approaches,"In bioinformatics, alignment-free sequence analysis approaches to molecular sequence and structure data provide alternatives over alignment-based approaches."
provided successful methods,Information Theory has provided successful methods for alignment-free sequence analysis and comparison.
software requirements,"Software Requirements (3rd ed. !! Note that the wording Software requirements is additionally used in software release notes to explain, which depending software packages are required for a certain software to be built/installed/used. !! Embedded Software Requirements. !! Managing Software Requirements: A Unified Approach. !! The activities related to working with software requirements can broadly be broken down into elicitation, analysis, specification, and management."
activities related,"The activities related to working with software requirements can broadly be broken down into elicitation, analysis, specification, and management."
additionally used,"Note that the wording Software requirements is additionally used in software release notes to explain, which depending software packages are required for a certain software to be built/installed/used."
certain software,"Note that the wording Software requirements is additionally used in software release notes to explain, which depending software packages are required for a certain software to be built/installed/used."
wording software requirements,"Note that the wording Software requirements is additionally used in software release notes to explain, which depending software packages are required for a certain software to be built/installed/used."
depending software packages,"Note that the wording Software requirements is additionally used in software release notes to explain, which depending software packages are required for a certain software to be built/installed/used."
software release notes,"Note that the wording Software requirements is additionally used in software release notes to explain, which depending software packages are required for a certain software to be built/installed/used."
3rd ed,Introduction to the Theory of Computation (3rd ed. !! Software Requirements (3rd ed. !! The Data Warehouse Toolkit: The Definitive Guide to Dimensional Modeling (3rd ed. !! Geometric Modeling (3rd ed.
managing software requirements,Managing Software Requirements: A Unified Approach.
unified approach,Managing Software Requirements: A Unified Approach.
voronoi cells,The Voronoi cells in a weighted Voronoi diagram are defined in terms of a distance function.
also called circular dirichlet tessellation,"In the plane under the ordinary Euclidean distance, the multiplicatively weighted Voronoi diagram is also called circular Dirichlet tessellation and its edges are circular arcs and straight line segments."
circular arcs,"In the plane under the ordinary Euclidean distance, the multiplicatively weighted Voronoi diagram is also called circular Dirichlet tessellation and its edges are circular arcs and straight line segments."
lost objects,Bayesian search theory is the application of Bayesian statistics to the search for lost objects.
bayesian search theory,"Bayesian search theory is incorporated into the CASP (Computer Assisted Search Program) mission planning software used by the United States Coast Guard for search and rescue. !! Bayesian search theory is the application of Bayesian statistics to the search for lost objects. !! Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
uss scorpion,"Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
mv derbyshire,"Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
ss central america,"Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
bayesian search theory include,"Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
largest british vessel ever lost,"Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
vessels located,"Apart from the USS Scorpion, other vessels located by Bayesian search theory include the MV Derbyshire, the largest British vessel ever lost at sea, and the SS Central America."
united states coast guard,Bayesian search theory is incorporated into the CASP (Computer Assisted Search Program) mission planning software used by the United States Coast Guard for search and rescue.
computer assisted search program,Bayesian search theory is incorporated into the CASP (Computer Assisted Search Program) mission planning software used by the United States Coast Guard for search and rescue.
mission planning software used,Bayesian search theory is incorporated into the CASP (Computer Assisted Search Program) mission planning software used by the United States Coast Guard for search and rescue.
logic families,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits. !! CMOS chips often work with a broader range of power supply voltages than other logic families. !! Some such logic families use static techniques to minimize design complexity. !! Other such logic families, such as domino logic, use clocked dynamic techniques to minimize size, power consumption and delay. !! The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
related basic logical functions,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits."
create systems,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits."
many logic families,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits."
individual components,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits."
complex integrated circuits,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits."
containing one,"Many logic families were produced as individual components, each containing one or a few related basic logical functions, which could be used as ""building-blocks"" to create systems or as so-called ""glue"" to interconnect more complex integrated circuits."
logic families use static techniques,Some such logic families use static techniques to minimize design complexity.
minimize design complexity,Some such logic families use static techniques to minimize design complexity.
minimize size,"Other such logic families, such as domino logic, use clocked dynamic techniques to minimize size, power consumption and delay."
use clocked dynamic techniques,"Other such logic families, such as domino logic, use clocked dynamic techniques to minimize size, power consumption and delay."
domino logic,"Other such logic families, such as domino logic, use clocked dynamic techniques to minimize size, power consumption and delay."
generally considered obsolete,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
relatively short periods,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
i2l logic families,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
special purpose custom large,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
scale integration circuits devices,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
broader range,CMOS chips often work with a broader range of power supply voltages than other logic families.
power supply voltages,CMOS chips often work with a broader range of power supply voltages than other logic families.
cmos chips often work,CMOS chips often work with a broader range of power supply voltages than other logic families.
whole input,"Because it does not know the whole input, an online algorithm is forced to make decisions that may later turn out not to be optimal, and the study of online algorithms has focused on the quality of decision-making that is possible in this setting."
may later turn,"Because it does not know the whole input, an online algorithm is forced to make decisions that may later turn out not to be optimal, and the study of online algorithms has focused on the quality of decision-making that is possible in this setting."
canadian traveller problem,A problem exemplifying the concepts of online algorithms is the Canadian Traveller Problem.
problem exemplifying,A problem exemplifying the concepts of online algorithms is the Canadian Traveller Problem.
sorted list,Comparison sorts may run faster on some lists; many adaptive sorts such as insertion sort run in O(n) time on an already-sorted or nearly-sorted list.
comparison sorts may run faster,Comparison sorts may run faster on some lists; many adaptive sorts such as insertion sort run in O(n) time on an already-sorted or nearly-sorted list.
insertion sort run,Comparison sorts may run faster on some lists; many adaptive sorts such as insertion sort run in O(n) time on an already-sorted or nearly-sorted list.
many adaptive sorts,Comparison sorts may run faster on some lists; many adaptive sorts such as insertion sort run in O(n) time on an already-sorted or nearly-sorted list.
comparison sorts offer,"Despite these limitations, comparison sorts offer the notable practical advantage that control over the comparison function allows sorting of many different datatypes and fine control over how the list is sorted."
comparison function allows sorting,"Despite these limitations, comparison sorts offer the notable practical advantage that control over the comparison function allows sorting of many different datatypes and fine control over how the list is sorted."
many different datatypes,"Despite these limitations, comparison sorts offer the notable practical advantage that control over the comparison function allows sorting of many different datatypes and fine control over how the list is sorted."
notable practical advantage,"Despite these limitations, comparison sorts offer the notable practical advantage that control over the comparison function allows sorting of many different datatypes and fine control over how the list is sorted."
fine control,"Despite these limitations, comparison sorts offer the notable practical advantage that control over the comparison function allows sorting of many different datatypes and fine control over how the list is sorted."
order polynomial,"The order polynomial is a polynomial studied in mathematics, in particular in algebraic graph theory and algebraic combinatorics."
polynomial studied,"The order polynomial is a polynomial studied in mathematics, in particular in algebraic graph theory and algebraic combinatorics."
recent developments,"Recent developments are dedicated to multi-label active learning, hybrid active learning and active learning in a single-pass (on-line) context, combining concepts from the field of machine learning (e. g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning."
combining concepts,"Recent developments are dedicated to multi-label active learning, hybrid active learning and active learning in a single-pass (on-line) context, combining concepts from the field of machine learning (e. g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning."
label active learning,"Recent developments are dedicated to multi-label active learning, hybrid active learning and active learning in a single-pass (on-line) context, combining concepts from the field of machine learning (e. g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning."
program components,"In computer programming, symbolic programming is a programming paradigm in which the program can manipulate its own formulas and program components as if they were plain data."
plain data,"In computer programming, symbolic programming is a programming paradigm in which the program can manipulate its own formulas and program components as if they were plain data."
combining smaller units,"Through symbolic programming, complex processes can be developed that build other more intricate processes by combining smaller units of logic or functionality."
complex processes,"Through symbolic programming, complex processes can be developed that build other more intricate processes by combining smaller units of logic or functionality."
intricate processes,"Through symbolic programming, complex processes can be developed that build other more intricate processes by combining smaller units of logic or functionality."
wolfram language,"Languages that support symbolic programming include homoiconic languages such as Wolfram Language, LISP and Prolog."
traditional graphical user interface,"A physical icon, or phicon, is the tangible computing equivalent of an icon in a traditional graphical user interface, or GUI."
physical icon,"A physical icon, or phicon, is the tangible computing equivalent of an icon in a traditional graphical user interface, or GUI. !! Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT."
tangible computing equivalent,"A physical icon, or phicon, is the tangible computing equivalent of an icon in a traditional graphical user interface, or GUI."
tangible bits research group,Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT.
physical icons,Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT.
metadesk project built,Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT.
tangible interfaces,Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT.
professor hiroshi ishii,Physical icons were first used as tangible interfaces in the metaDesk project built in 1997 by Professor Hiroshi Ishii's tangible bits research group at MIT.
parity learning,"The noisy version of the parity learning problem is conjectured to be hard. !! Parity learning is a problem in machine learning. !! Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, On agnostic boosting and parity learning, in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629638, http://portal."
parity learning problem,The noisy version of the parity learning problem is conjectured to be hard.
noisy version,The noisy version of the parity learning problem is conjectured to be hard.
yishay mansour,"Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, On agnostic boosting and parity learning, in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629638, http://portal."
british columbia,"Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, On agnostic boosting and parity learning, in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629638, http://portal."
elad verbin,"Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, On agnostic boosting and parity learning, in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629638, http://portal."
adam tauman kalai,"Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, On agnostic boosting and parity learning, in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629638, http://portal."
40th annual acm symposium,"Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, On agnostic boosting and parity learning, in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629638, http://portal."
behaves according,The OR gate is a digital logic gate that implements logical disjunction () from mathematical logic it behaves according to the truth table above.
implements logical disjunction,The OR gate is a digital logic gate that implements logical disjunction () from mathematical logic it behaves according to the truth table above.
two symbols,"There are two symbols of OR gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol."
deprecated din symbol,"There are two symbols of OR gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol. !! There are three symbols for AND gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol."
iec  european,"There are two symbols of OR gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol. !! There are three symbols for AND gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol."
rectangular  symbol,"There are two symbols of OR gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol. !! There are three symbols for AND gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol."
military  symbol,"There are two symbols of OR gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol. !! There are three symbols for AND gates: the American (ANSI or 'military') symbol and the IEC ('European' or 'rectangular') symbol, as well as the deprecated DIN symbol."
cmos ics logic families,"OR gates are basic logic gates, and are available in TTL and CMOS ICs logic families."
standard 4000 series cmos ic,"The standard 4000 series CMOS IC is the 4071, which includes four independent two-input OR gates."
includes four independent two,"The standard 4000 series CMOS IC is the 4071, which includes four independent two-input OR gates."
many offshoots,"There are many offshoots of the original 7432 OR gate, all having the same pinout but different internal architecture, allowing them to operate in different voltage ranges and/or at higher speeds."
higher speeds,"There are many offshoots of the original 7432 OR gate, all having the same pinout but different internal architecture, allowing them to operate in different voltage ranges and/or at higher speeds."
different internal architecture,"There are many offshoots of the original 7432 OR gate, all having the same pinout but different internal architecture, allowing them to operate in different voltage ranges and/or at higher speeds."
different voltage ranges,"There are many offshoots of the original 7432 OR gate, all having the same pinout but different internal architecture, allowing them to operate in different voltage ranges and/or at higher speeds."
also called offset mapping,Parallax mapping (also called offset mapping or virtual displacement mapping) is an enhancement of the bump mapping or normal mapping techniques applied to textures in 3D rendering applications such as video games.
normal mapping techniques applied,Parallax mapping (also called offset mapping or virtual displacement mapping) is an enhancement of the bump mapping or normal mapping techniques applied to textures in 3D rendering applications such as video games.
3d rendering applications,Parallax mapping (also called offset mapping or virtual displacement mapping) is an enhancement of the bump mapping or normal mapping techniques applied to textures in 3D rendering applications such as video games.
bump mapping,Parallax mapping (also called offset mapping or virtual displacement mapping) is an enhancement of the bump mapping or normal mapping techniques applied to textures in 3D rendering applications such as video games.
tomomichi kaneko et al,Parallax mapping was introduced by Tomomichi Kaneko et al.
view angle,Parallax mapping is implemented by displacing the texture coordinates at a point on the rendered polygon by a function of the view angle in tangent space (the angle relative to the surface normal) and the value of the height map at that point.
rendered polygon,Parallax mapping is implemented by displacing the texture coordinates at a point on the rendered polygon by a function of the view angle in tangent space (the angle relative to the surface normal) and the value of the height map at that point.
surface normal,Parallax mapping is implemented by displacing the texture coordinates at a point on the rendered polygon by a function of the view angle in tangent space (the angle relative to the surface normal) and the value of the height map at that point.
angle relative,Parallax mapping is implemented by displacing the texture coordinates at a point on the rendered polygon by a function of the view angle in tangent space (the angle relative to the surface normal) and the value of the height map at that point.
height map,Parallax mapping is implemented by displacing the texture coordinates at a point on the rendered polygon by a function of the view angle in tangent space (the angle relative to the surface normal) and the value of the height map at that point.
parallax mapping described,Parallax mapping described by Kaneko is a single step process that does not account for occlusion.
single step process,Parallax mapping described by Kaneko is a single step process that does not account for occlusion.
one name,Steep parallax mapping is one name for the class of algorithms that trace rays against heightfields.
steep parallax mapping,Steep parallax mapping is one name for the class of algorithms that trace rays against heightfields.
trace rays,Steep parallax mapping is one name for the class of algorithms that trace rays against heightfields.
symbolic manipulation program,"Symbolic Manipulation Program, usually called SMP, was a computer algebra system designed by Chris A. Cole and Stephen Wolfram at Caltech circa 1979."
stephen wolfram,"Symbolic Manipulation Program, usually called SMP, was a computer algebra system designed by Chris A. Cole and Stephen Wolfram at Caltech circa 1979."
computer algebra system designed,"Symbolic Manipulation Program, usually called SMP, was a computer algebra system designed by Chris A. Cole and Stephen Wolfram at Caltech circa 1979."
caltech circa 1979,"Symbolic Manipulation Program, usually called SMP, was a computer algebra system designed by Chris A. Cole and Stephen Wolfram at Caltech circa 1979."
usually called smp,"Symbolic Manipulation Program, usually called SMP, was a computer algebra system designed by Chris A. Cole and Stephen Wolfram at Caltech circa 1979."
vast sums,"In Japan and elsewhere, vast sums were spent investigating the so-called ""fifth-generation"" languages that incorporated logic programming constructs."
programming constructs,"In Japan and elsewhere, vast sums were spent investigating the so-called ""fifth-generation"" languages that incorporated logic programming constructs. !! Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs."
spent investigating,"In Japan and elsewhere, vast sums were spent investigating the so-called ""fifth-generation"" languages that incorporated logic programming constructs."
incorporated logic programming constructs,"In Japan and elsewhere, vast sums were spent investigating the so-called ""fifth-generation"" languages that incorporated logic programming constructs."
developed notable module systems,"Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs."
often wedded,"Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs."
generic programming constructs,"Modula-2, Ada, and ML all developed notable module systems in the 1980s, which were often wedded to generic programming constructs."
also chi,"In probability theory and statistics, the chi-squared distribution (also chi-square or 2-distribution) with k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables."
widely used probability distributions,"The chi-squared distribution is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing and in construction of confidence intervals."
hypothesis testing,"The chi-squared distribution is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing and in construction of confidence intervals."
confidence intervals,"The chi-squared distribution is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing and in construction of confidence intervals."
inferential statistics,"The chi-squared distribution is a special case of the gamma distribution and is one of the most widely used probability distributions in inferential statistics, notably in hypothesis testing and in construction of confidence intervals."
general noncentral chi,"This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution."
central chi,"This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution."
observed distribution,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
qualitative data,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
two criteria,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
population standard deviation,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
common chi,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
theoretical one,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
squared tests,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
sample standard deviation,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
confidence interval estimation,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
distributed according,is distributed according to the chi-squared distribution with k degrees of freedom.
relaxed variant,"In computer science, partial sorting is a relaxed variant of the sorting problem."
total sorting,"Total sorting is the problem of returning a list of items such that its elements all appear in order, while partial sorting is returning a list of the k smallest (or k largest) elements in order."
common practical example,"A common practical example of partial sorting is computing the ""Top 100"" of some list."
first k elements,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
problem equivalent,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
selection algorithm,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
total cost,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
k smallest elements,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
without requiring,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
relaxation requiring,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
original partial sorting problem,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
specialized partial sorting algorithms based,More efficient than the aforementioned are specialized partial sorting algorithms based on mergesort and quicksort.
pronounced sh,"In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
monte carlo simulations,"In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
definite matrix,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition. !! In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
efficient numerical solutions,"In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
conjugate transpose,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition. !! In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
roughly twice,"When it is applicable, the Cholesky decomposition is roughly twice as efficient as the LU decomposition for solving systems of linear equations."
lu decomposition,"Computers usually solve square systems of linear equations using LU decomposition, and it is also a key step when inverting a matrix or computing the determinant of a matrix. !! LU reduction is an algorithm related to LU decomposition. !! LU decomposition can be viewed as the matrix form of Gaussian elimination. !! It provides also the structure of the LU decomposition of the Vandermonde matrix. !! When it is applicable, the Cholesky decomposition is roughly twice as efficient as the LU decomposition for solving systems of linear equations. !! One way to find the LU decomposition of this simple matrix would be to simply solve the linear equations by inspection. !! Therefore, to find the unique LU decomposition, it is necessary to put some restriction on L and U matrices. !! The LU decomposition was introduced by the Polish mathematician Tadeusz Banachiewicz in 1938."
positive diagonal entries,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
every hermitian positive,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
valued symmetric positive,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
unique cholesky decomposition,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
thus also every real,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
free cholesky decomposition,"For this reason, the LDL decomposition is often called the square-root-free Cholesky decomposition."
ldl decomposition,"For this reason, the LDL decomposition is often called the square-root-free Cholesky decomposition. !! Some indefinite matrices for which no Cholesky decomposition exists have an LDL decomposition with negative entries in D: it suffices that the first n1 leading principal minors of A are non-singular."
indefinite matrices,Some indefinite matrices for which no Cholesky decomposition exists have an LDL decomposition with negative entries in D: it suffices that the first n1 leading principal minors of A are non-singular.
negative entries,Some indefinite matrices for which no Cholesky decomposition exists have an LDL decomposition with negative entries in D: it suffices that the first n1 leading principal minors of A are non-singular.
first n1 leading principal minors,Some indefinite matrices for which no Cholesky decomposition exists have an LDL decomposition with negative entries in D: it suffices that the first n1 leading principal minors of A are non-singular.
cholesky decomposition exists,Some indefinite matrices for which no Cholesky decomposition exists have an LDL decomposition with negative entries in D: it suffices that the first n1 leading principal minors of A are non-singular.
sorted order,"Merge algorithms are a family of algorithms that take multiple sorted lists as input and produce a single list as output, containing all the elements of the inputs lists in sorted order. !! In computer science, the longest increasing subsequence problem is to find a subsequence of a given sequence in which the subsequence's elements are in sorted order, lowest to highest, and in which the subsequence is as long as possible."
representation theory,"Longest increasing subsequences are studied in the context of various disciplines related to mathematics, including algorithmics, random matrix theory, representation theory, and physics."
various disciplines related,"Longest increasing subsequences are studied in the context of various disciplines related to mathematics, including algorithmics, random matrix theory, representation theory, and physics."
including algorithmics,"Longest increasing subsequences are studied in the context of various disciplines related to mathematics, including algorithmics, random matrix theory, representation theory, and physics."
input sequence,"An in-place algorithm updates its input sequence only through replacement or swapping of elements. !! The longest increasing subsequence problem is solvable in time O(n log n), where n denotes the length of the input sequence."
quadratic time dynamic programming solution,"The longest increasing subsequence problem is closely related to the longest common subsequence problem, which has a quadratic time dynamic programming solution: the longest increasing subsequence of a sequence S is the longest common subsequence of S and T, where T is the result of sorting S. However, for the special case in which the input is a permutation of the integers 1, 2, ."
clique problem efficiently,"Therefore, longest increasing subsequence algorithms can be used to solve the clique problem efficiently in permutation graphs."
corrupted since,Code signing is the process of digitally signing executables and scripts to confirm the software author and guarantee that the code has not been altered or corrupted since it was signed.
software author,Code signing is the process of digitally signing executables and scripts to confirm the software author and guarantee that the code has not been altered or corrupted since it was signed.
digitally signing executables,Code signing is the process of digitally signing executables and scripts to confirm the software author and guarantee that the code has not been altered or corrupted since it was signed.
provide several valuable features,Code signing can provide several valuable features.
help prevent namespace conflicts,"The most common use of code signing is to provide security when deploying; in some programming languages, it can also be used to help prevent namespace conflicts."
provide security,"The most common use of code signing is to provide security when deploying; in some programming languages, it can also be used to help prevent namespace conflicts."
build system,"Almost every code signing implementation will provide some sort of digital signature mechanism to verify the identity of the author or build system, and a checksum to verify that the object has not been modified."
almost every code signing implementation,"Almost every code signing implementation will provide some sort of digital signature mechanism to verify the identity of the author or build system, and a checksum to verify that the object has not been modified."
digital signature mechanism,"Almost every code signing implementation will provide some sort of digital signature mechanism to verify the identity of the author or build system, and a checksum to verify that the object has not been modified."
underpinning signing keys,The efficacy of code signing as an authentication mechanism for software depends on the security of underpinning signing keys.
software depends,The efficacy of code signing as an authentication mechanism for software depends on the security of underpinning signing keys.
optimal foraging theory,Information foraging is a theory that applies the ideas from optimal foraging theory to understand how human users search for information.
human users search,Information foraging is a theory that applies the ideas from optimal foraging theory to understand how human users search for information.
information foraging,Some tendencies in the behaviour of web users are easily understood from the information foraging theory standpoint. !! Attempts have been made to develop computational cognitive models to characterize information foraging behavior on the Web. !! Recently these information foraging models have been extended to explain social information behavior. !! The most important concept in the information foraging theory is information scent. !! Information foraging is a theory that applies the ideas from optimal foraging theory to understand how human users search for information.
information foraging theory,The most important concept in the information foraging theory is information scent.
important concept,The most important concept in the information foraging theory is information scent.
information scent,The most important concept in the information foraging theory is information scent.
easily understood,Some tendencies in the behaviour of web users are easily understood from the information foraging theory standpoint.
web users,Some tendencies in the behaviour of web users are easily understood from the information foraging theory standpoint.
information foraging theory standpoint,Some tendencies in the behaviour of web users are easily understood from the information foraging theory standpoint.
characterize information foraging behavior,Attempts have been made to develop computational cognitive models to characterize information foraging behavior on the Web.
develop computational cognitive models,Attempts have been made to develop computational cognitive models to characterize information foraging behavior on the Web.
explain social information behavior,Recently these information foraging models have been extended to explain social information behavior.
information foraging models,Recently these information foraging models have been extended to explain social information behavior.
predictive modelling approaches used,"Decision tree learning or induction of decision trees is one of the predictive modelling approaches used in statistics, data mining and machine learning."
method commonly used,Decision tree learning is a method commonly used in data mining.
computer animation language specifically designed,"The Rich Representation Language, often abbreviated as RRL, is a computer animation language specifically designed to facilitate the interaction of two or more animated characters."
animated characters,"The Rich Representation Language, often abbreviated as RRL, is a computer animation language specifically designed to facilitate the interaction of two or more animated characters."
real logarithm also apply,"Many properties of the real logarithm also apply to the logarithmic derivative, even when the function does not take values in the positive reals."
logarithmic derivative,"So for positive-real-valued functions, the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors. !! Many properties of the real logarithm also apply to the logarithmic derivative, even when the function does not take values in the positive reals. !! Logarithmic derivatives can simplify the computation of derivatives requiring the product rule while producing the same result. !! In summary, both derivatives and logarithms have a product rule, a reciprocal rule, a quotient rule, and a power rule (compare the list of logarithmic identities); each pair of rules is related through the logarithmic derivative. !! Thus, it is true for any function that the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors (when they are defined)."
take values,"Many properties of the real logarithm also apply to the logarithmic derivative, even when the function does not take values in the positive reals."
positive reals,"Many properties of the real logarithm also apply to the logarithmic derivative, even when the function does not take values in the positive reals."
logarithmic derivatives,"So for positive-real-valued functions, the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors. !! Logarithmic derivatives can simplify the computation of derivatives requiring the product rule while producing the same result. !! Thus, it is true for any function that the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors (when they are defined)."
logarithmic identities,"In summary, both derivatives and logarithms have a product rule, a reciprocal rule, a quotient rule, and a power rule (compare the list of logarithmic identities); each pair of rules is related through the logarithmic derivative."
power rule,"In summary, both derivatives and logarithms have a product rule, a reciprocal rule, a quotient rule, and a power rule (compare the list of logarithmic identities); each pair of rules is related through the logarithmic derivative."
quotient rule,"In summary, both derivatives and logarithms have a product rule, a reciprocal rule, a quotient rule, and a power rule (compare the list of logarithmic identities); each pair of rules is related through the logarithmic derivative."
product rule,"In summary, both derivatives and logarithms have a product rule, a reciprocal rule, a quotient rule, and a power rule (compare the list of logarithmic identities); each pair of rules is related through the logarithmic derivative. !! Logarithmic derivatives can simplify the computation of derivatives requiring the product rule while producing the same result."
derivatives requiring,Logarithmic derivatives can simplify the computation of derivatives requiring the product rule while producing the same result.
valued vector,"In natural language processing (NLP), word embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning."
obtained using,Word embeddings can be obtained using a set of language modeling and feature learning techniques where words or phrases from the vocabulary are mapped to vectors of real numbers.
research area,"In linguistics, word embeddings were discussed in the research area of distributional semantics."
different styles,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
linguistic contexts,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
words occur,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
occurring words,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
lavelli et al,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
two different styles,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
word embeddings come,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
new word embedding techniques,"Most new word embedding techniques after about 2005 rely on a neural network architecture instead of more probabilistic and algebraic models, since some foundational work by Yoshua Bengio and colleagues."
yoshua bengio,"Most new word embedding techniques after about 2005 rely on a neural network architecture instead of more probabilistic and algebraic models, since some foundational work by Yoshua Bengio and colleagues."
algebraic models,"Most new word embedding techniques after about 2005 rely on a neural network architecture instead of more probabilistic and algebraic models, since some foundational work by Yoshua Bengio and colleagues."
neural network architecture instead,"Most new word embedding techniques after about 2005 rely on a neural network architecture instead of more probabilistic and algebraic models, since some foundational work by Yoshua Bengio and colleagues."
foundational work,"Most new word embedding techniques after about 2005 rely on a neural network architecture instead of more probabilistic and algebraic models, since some foundational work by Yoshua Bengio and colleagues."
theoretical capacity,"Artificial intuition is a theoretical capacity of an artificial software to function similarly to human consciousness, specifically in the capacity of human consciousness known as intuition."
function similarly,"Artificial intuition is a theoretical capacity of an artificial software to function similarly to human consciousness, specifically in the capacity of human consciousness known as intuition."
artificial software,"Artificial intuition is a theoretical capacity of an artificial software to function similarly to human consciousness, specifically in the capacity of human consciousness known as intuition."
human consciousness,"Artificial intuition is a theoretical capacity of an artificial software to function similarly to human consciousness, specifically in the capacity of human consciousness known as intuition."
human consciousness known,"Artificial intuition is a theoretical capacity of an artificial software to function similarly to human consciousness, specifically in the capacity of human consciousness known as intuition."
sophisticated function,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
process upon,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
macroscopic scale identifying something like,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
artificial mind would,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
locate hidden factors functioning,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
context described,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
gestalt psychology,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
interpret data,"Artificial intuition is theoretically (or otherwise) a sophisticated function of an artifice that is able to interpret data with depth and locate hidden factors functioning in Gestalt psychology, and that intuition in the artificial mind would, in the context described here, be a bottom-up process upon a macroscopic scale identifying something like the archetypal (see )."
higher functioning,"To create artificial intuition supposes the possibility of the re-creation of a higher functioning of the human mind, with capabilities such as what might be found in semantic memory and learning."
create artificial intuition supposes,"To create artificial intuition supposes the possibility of the re-creation of a higher functioning of the human mind, with capabilities such as what might be found in semantic memory and learning."
usually shown,"Artificial intelligence in fiction often crosses the line to apparent artificial intuition, although it can't be shown if the intent of the fiction creator was to show a simulation of intuition or that real artificial intuition is part of the story's AI, because this depends on the internal structure of the programming of the AI, which is not usually shown in stories."
apparent artificial intuition,"Artificial intelligence in fiction often crosses the line to apparent artificial intuition, although it can't be shown if the intent of the fiction creator was to show a simulation of intuition or that real artificial intuition is part of the story's AI, because this depends on the internal structure of the programming of the AI, which is not usually shown in stories."
fiction creator,"Artificial intelligence in fiction often crosses the line to apparent artificial intuition, although it can't be shown if the intent of the fiction creator was to show a simulation of intuition or that real artificial intuition is part of the story's AI, because this depends on the internal structure of the programming of the AI, which is not usually shown in stories."
fiction often crosses,"Artificial intelligence in fiction often crosses the line to apparent artificial intuition, although it can't be shown if the intent of the fiction creator was to show a simulation of intuition or that real artificial intuition is part of the story's AI, because this depends on the internal structure of the programming of the AI, which is not usually shown in stories."
internal structure,"Artificial intelligence in fiction often crosses the line to apparent artificial intuition, although it can't be shown if the intent of the fiction creator was to show a simulation of intuition or that real artificial intuition is part of the story's AI, because this depends on the internal structure of the programming of the AI, which is not usually shown in stories."
real artificial intuition,"Artificial intelligence in fiction often crosses the line to apparent artificial intuition, although it can't be shown if the intent of the fiction creator was to show a simulation of intuition or that real artificial intuition is part of the story's AI, because this depends on the internal structure of the programming of the AI, which is not usually shown in stories."
star trek,"Star trek, (written by Gene Roddenberry) Data is a humanoid who shows artificial intelligence, but it can't be shown he is showing artificial intuition, since his programming is not disclosed."
showing artificial intuition,"Star trek, (written by Gene Roddenberry) Data is a humanoid who shows artificial intelligence, but it can't be shown he is showing artificial intuition, since his programming is not disclosed."
gene roddenberry,"Star trek, (written by Gene Roddenberry) Data is a humanoid who shows artificial intelligence, but it can't be shown he is showing artificial intuition, since his programming is not disclosed."
shows artificial intelligence,"Star trek, (written by Gene Roddenberry) Data is a humanoid who shows artificial intelligence, but it can't be shown he is showing artificial intuition, since his programming is not disclosed."
radix heap,A radix heap is a data structure for realizing the operations of a monotone priority queue.
pattern grammar,"Hunston, Susan; Francis, Gill, Pattern Grammar: A corpus-driven approach to the lexical grammar of English, John Benjamins, 2000. !! Pattern Grammar is a model for describing the syntactic environments of individual lexical items, derived from studying their occurrences in authentic linguistic corpora."
syntactic environments,"Pattern Grammar is a model for describing the syntactic environments of individual lexical items, derived from studying their occurrences in authentic linguistic corpora."
authentic linguistic corpora,"Pattern Grammar is a model for describing the syntactic environments of individual lexical items, derived from studying their occurrences in authentic linguistic corpora."
driven approach,"From methodological point of view: providing the Model Driven Interoperability (MDI) Method as a method (principle and structure) to enable interoperable Enterprise Software Applications (ESA), starting from the level of the Enterprise Model rather than from the code level and using a model-driven approach, combined with use of ontologies and semantic annotations. !! Hunston, Susan; Francis, Gill, Pattern Grammar: A corpus-driven approach to the lexical grammar of English, John Benjamins, 2000."
john benjamins,"Hunston, Susan; Francis, Gill, Pattern Grammar: A corpus-driven approach to the lexical grammar of English, John Benjamins, 2000."
largest integer present,"In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is a polynomial in the numeric value of the input (the largest integer present in the input)but not necessarily in the length of the input (the number of bits required to represent it), which is the case for polynomial time algorithms."
bits required,"In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is a polynomial in the numeric value of the input (the largest integer present in the input)but not necessarily in the length of the input (the number of bits required to represent it), which is the case for polynomial time algorithms."
numeric value,"In general, the numeric value of the input is exponential in the input length, which is why a pseudo-polynomial time algorithm does not necessarily run in polynomial time with respect to the input length. !! In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is a polynomial in the numeric value of the input (the largest integer present in the input)but not necessarily in the length of the input (the number of bits required to represent it), which is the case for polynomial time algorithms."
numeric algorithm runs,"In computational complexity theory, a numeric algorithm runs in pseudo-polynomial time if its running time is a polynomial in the numeric value of the input (the largest integer present in the input)but not necessarily in the length of the input (the number of bits required to represent it), which is the case for polynomial time algorithms."
necessarily run,"In general, the numeric value of the input is exponential in the input length, which is why a pseudo-polynomial time algorithm does not necessarily run in polynomial time with respect to the input length."
input length,"In general, the numeric value of the input is exponential in the input length, which is why a pseudo-polynomial time algorithm does not necessarily run in polynomial time with respect to the input length."
known pseudo,An NP-complete problem with known pseudo-polynomial time algorithms is called weakly NP-complete.
complete problem,"An NP-complete problem is called strongly NP-complete if it is proven that it cannot be solved by a pseudo-polynomial time algorithm unless P = NP. !! An NP-complete problem with known pseudo-polynomial time algorithms is called weakly NP-complete. !! In computational complexity theory, a pseudo-polynomial transformation is a function which maps instances of one strongly NP-complete problem into another and is computable in pseudo-polynomial time."
called weakly np,An NP-complete problem with known pseudo-polynomial time algorithms is called weakly NP-complete.
called strongly np,An NP-complete problem is called strongly NP-complete if it is proven that it cannot be solved by a pseudo-polynomial time algorithm unless P = NP.
polynomial time algorithm unless p,An NP-complete problem is called strongly NP-complete if it is proven that it cannot be solved by a pseudo-polynomial time algorithm unless P = NP.
different domains interact,"Cross-domain interoperability exists when organizations or systems from different domains interact in information exchange, services, and/or goods to achieve their own or common goals."
common goals,"Cross-domain interoperability exists when organizations or systems from different domains interact in information exchange, services, and/or goods to achieve their own or common goals."
domain interoperability exists,"Cross-domain interoperability exists when organizations or systems from different domains interact in information exchange, services, and/or goods to achieve their own or common goals."
information exchange,"Cross-domain interoperability exists when organizations or systems from different domains interact in information exchange, services, and/or goods to achieve their own or common goals."
government operations become,The capability of cross-domain interoperability is becoming increasingly important as business and government operations become more global and interdependent.
domain interoperability,"Cross-domain interoperability is characterized by common understanding and agreements on both sides of a domain boundary that enable individual organizations to tailor or make their products, assets or services interoperable within the larger community. !! Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange. !! The capability of cross-domain interoperability is becoming increasingly important as business and government operations become more global and interdependent."
extends product utility,"Cross-domain interoperability enables synergy, extends product utility and enables users to be more effective and successful within their own domains and the combined effort."
enables users,"Cross-domain interoperability enables synergy, extends product utility and enables users to be more effective and successful within their own domains and the combined effort. !! A virtual private network (VPN) extends a private network across a public network and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network."
domain interoperability enables synergy,"Cross-domain interoperability enables synergy, extends product utility and enables users to be more effective and successful within their own domains and the combined effort."
combined effort,"Cross-domain interoperability enables synergy, extends product utility and enables users to be more effective and successful within their own domains and the combined effort."
successful within,"Cross-domain interoperability enables synergy, extends product utility and enables users to be more effective and successful within their own domains and the combined effort."
common understanding,"Cross-domain interoperability is characterized by common understanding and agreements on both sides of a domain boundary that enable individual organizations to tailor or make their products, assets or services interoperable within the larger community."
enable individual organizations,"Cross-domain interoperability is characterized by common understanding and agreements on both sides of a domain boundary that enable individual organizations to tailor or make their products, assets or services interoperable within the larger community."
larger community,"Cross-domain interoperability is characterized by common understanding and agreements on both sides of a domain boundary that enable individual organizations to tailor or make their products, assets or services interoperable within the larger community."
domain boundary,"Cross-domain interoperability is characterized by common understanding and agreements on both sides of a domain boundary that enable individual organizations to tailor or make their products, assets or services interoperable within the larger community."
services interoperable within,"Cross-domain interoperability is characterized by common understanding and agreements on both sides of a domain boundary that enable individual organizations to tailor or make their products, assets or services interoperable within the larger community."
interoperable environment,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
individual patients,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
enable participants,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
divergent computer platforms,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
healthcare providers perform,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
insurance companies,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
overall success,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
different domains,"ODDS ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains. !! Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
effectively exchange information,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
individual functions using,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
essential services,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
another effort,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
state governments,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
affordable care act,"Another effort where cross-domain interoperability will be critical to overall success is implementation of the U. S. Affordable Care Act, in which federal and state governments, insurance companies and healthcare providers perform their individual functions using a variety of networks and divergent computer platforms an interoperable environment will enable participants in these different domains to effectively exchange information and perform their essential services, while protecting the privacy and rights of individual patients during the exchange."
related building components,"This article will present an overview of the skill of navigation and try to identify the basic blocks of a robot navigation system, types of navigation systems, and closer look at its related building components."
robot navigation,"Map-building and map interpretationSome robot navigation systems use simultaneous localization and mapping to generate 3D reconstructions of their surroundings. !! This article will present an overview of the skill of navigation and try to identify the basic blocks of a robot navigation system, types of navigation systems, and closer look at its related building components. !! Vision for mobile robot navigation: A survey. !! Robot navigation means the robot's ability to determine its own position in its frame of reference and then to plan a path towards some goal location. !! The basic reference of indoor and outdoor navigation systems is ""Vision for mobile robot navigation: a survey"" by Guilherme N. DeSouza and Avinash C. Kak."
robot navigation system,"This article will present an overview of the skill of navigation and try to identify the basic blocks of a robot navigation system, types of navigation systems, and closer look at its related building components."
basic blocks,"This article will present an overview of the skill of navigation and try to identify the basic blocks of a robot navigation system, types of navigation systems, and closer look at its related building components."
robot navigation means,Robot navigation means the robot's ability to determine its own position in its frame of reference and then to plan a path towards some goal location.
path towards,Robot navigation means the robot's ability to determine its own position in its frame of reference and then to plan a path towards some goal location.
goal location,Robot navigation means the robot's ability to determine its own position in its frame of reference and then to plan a path towards some goal location.
generate 3d reconstructions,Map-building and map interpretationSome robot navigation systems use simultaneous localization and mapping to generate 3D reconstructions of their surroundings.
mobile robot navigation,"Vision for mobile robot navigation: A survey. !! The basic reference of indoor and outdoor navigation systems is ""Vision for mobile robot navigation: a survey"" by Guilherme N. DeSouza and Avinash C. Kak."
outdoor navigation systems,"The basic reference of indoor and outdoor navigation systems is ""Vision for mobile robot navigation: a survey"" by Guilherme N. DeSouza and Avinash C. Kak."
basic reference,"The basic reference of indoor and outdoor navigation systems is ""Vision for mobile robot navigation: a survey"" by Guilherme N. DeSouza and Avinash C. Kak."
way comparison takes two values,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy."
determines whether,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy."
three-way comparison,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy. !! In C, the functions strcmp and memcmp perform a three-way comparison between strings and memory buffers, respectively. !! In some cases, three-way comparison can be simulated by subtracting A and B and examining the sign of the result, exploiting special instructions for examining the sign of a number. !! When implementing a three-way comparison where a three-way comparison operator or method is not already available, it is common to combine two comparisons, such as A = B and A < B, or A < B and A > B. !! Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object. !! A comparison sort is a type of sorting algorithm that only reads the list elements through a single abstract comparison operation (often a ""less than or equal to"" operator or a three-way comparison) that determines which of two elements should occur first in the final sorted list."
mathematical law,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy."
single operation,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy."
functions strcmp,"In C, the functions strcmp and memcmp perform a three-way comparison between strings and memory buffers, respectively."
memcmp perform,"In C, the functions strcmp and memcmp perform a three-way comparison between strings and memory buffers, respectively."
another given object,"Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object."
many object,"Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object."
way comparison method,"Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object."
combine two comparisons,"When implementing a three-way comparison where a three-way comparison operator or method is not already available, it is common to combine two comparisons, such as A = B and A < B, or A < B and A > B."
way comparison operator,"When implementing a three-way comparison where a three-way comparison operator or method is not already available, it is common to combine two comparisons, such as A = B and A < B, or A < B and A > B."
already available,"When implementing a three-way comparison where a three-way comparison operator or method is not already available, it is common to combine two comparisons, such as A = B and A < B, or A < B and A > B."
exploiting special instructions,"In some cases, three-way comparison can be simulated by subtracting A and B and examining the sign of the result, exploiting special instructions for examining the sign of a number."
evolving programs,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators). !! In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs."
applying operations analogous,"In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs."
particular task,"In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs."
usually random,"In artificial intelligence, genetic programming (GP) is a technique of evolving programs, starting from a population of unfit (usually random) programs, fit for a particular task by applying operations analogous to natural genetic processes to the population of programs."
two specially designed languages,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
nichael cramer published evolved programs,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
current amongst john hollands students,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
suitably defined ga,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
first genetic algorithms,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
computer language lisp,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
procedural languages organized,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
based structures,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
first statement,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
koza followed,"Koza followed this with 205 publications on Genetic Programming (GP), name coined by David Goldberg, also a PhD student of John Holland."
phd student,"Koza followed this with 205 publications on Genetic Programming (GP), name coined by David Goldberg, also a PhD student of John Holland."
john holland,"Koza followed this with 205 publications on Genetic Programming (GP), name coined by David Goldberg, also a PhD student of John Holland."
david goldberg,"Koza followed this with 205 publications on Genetic Programming (GP), name coined by David Goldberg, also a PhD student of John Holland."
gp  name coined,"Koza followed this with 205 publications on Genetic Programming (GP), name coined by David Goldberg, also a PhD student of John Holland."
genetic programming bibliography,"Subsequently, there was an enormous expansion of the number of publications with the Genetic Programming Bibliography, surpassing 10,000 entries."
enormous expansion,"Subsequently, there was an enormous expansion of the number of publications with the Genetic Programming Bibliography, surpassing 10,000 entries."
human competitive,"In 2010, Koza listed 77 results where Genetic Programming was human competitive."
koza listed 77 results,"In 2010, Koza listed 77 results where Genetic Programming was human competitive."
vertices together,"A minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight."
minimum possible total edge weight,"A minimum spanning tree (MST) or minimum weight spanning tree is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight."
necessarily connected,"More generally, any edge-weighted undirected graph (not necessarily connected) has a minimum spanning forest, which is a union of the minimum spanning trees for its connected components."
minimum spanning forest,"However, running Prim's algorithm separately for each connected component of the graph, it can also be used to find the minimum spanning forest. !! These algorithms find the minimum spanning forest in a possibly disconnected graph; in contrast, the most basic form of Prim's algorithm only finds minimum spanning trees in connected graphs. !! More generally, any edge-weighted undirected graph (not necessarily connected) has a minimum spanning forest, which is a union of the minimum spanning trees for its connected components."
many use cases,There are many use cases for minimum spanning trees.
minimum spanning tree would,"A minimum spanning tree would be one with the lowest total cost, representing the least expensive path for laying the cable."
lowest total cost,"A minimum spanning tree would be one with the lowest total cost, representing the least expensive path for laying the cable."
least expensive path,"A minimum spanning tree would be one with the lowest total cost, representing the least expensive path for laying the cable."
every spanning tree,"There may be several minimum spanning trees of the same weight; in particular, if all the edge weights of a given graph are the same, then every spanning tree of that graph is minimum."
complex definitions create abstract machines,"More complex definitions create abstract machines with full instruction sets, registers and models of memory."
thought experiments regarding computability,"In the theory of computation, abstract machines are often used in thought experiments regarding computability or to analyze the complexity of algorithms."
operational semantics,"Abstract machines can also be used to model abstract data types, which can be specified in terms of their operational semantics on an abstract machine."
model abstract data types,"Abstract machines can also be used to model abstract data types, which can be specified in terms of their operational semantics on an abstract machine."
abstract machine,"Abstract machines can also be used to model abstract data types, which can be specified in terms of their operational semantics on an abstract machine."
computer file system,An access control expression with respect to a computer file system is a list of Boolean expressions attached to a file object.
access control expression,"An access control expression specifies a Boolean formula that defines which users or system processes are granted access to objects, as well as what operations are allowed on given objects. !! Conventional access control lists can be viewed as a subset of access control expressions in which the only combining operation allowed is OR. !! For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob. !! Each entry in a typical access control expression specifies an operation and an expression and an operation. !! An access control expression with respect to a computer file system is a list of Boolean expressions attached to a file object."
boolean expressions attached,An access control expression with respect to a computer file system is a list of Boolean expressions attached to a file object.
file object,"An access control expression with respect to a computer file system is a list of Boolean expressions attached to a file object. !! For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
boolean formula,"An access control expression specifies a Boolean formula that defines which users or system processes are granted access to objects, as well as what operations are allowed on given objects."
granted access,"An access control expression specifies a Boolean formula that defines which users or system processes are granted access to objects, as well as what operations are allowed on given objects."
system processes,"An access control expression specifies a Boolean formula that defines which users or system processes are granted access to objects, as well as what operations are allowed on given objects."
access control expression specifies,"An access control expression specifies a Boolean formula that defines which users or system processes are granted access to objects, as well as what operations are allowed on given objects."
given objects,"An access control expression specifies a Boolean formula that defines which users or system processes are granted access to objects, as well as what operations are allowed on given objects."
typical access control expression specifies,Each entry in a typical access control expression specifies an operation and an expression and an operation.
user named bob,"For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
user named alice permission,"For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
would allow,"He also theorised that bionic architecture would solve many problems associated with design and construction because it would allow for the perfect protection through mimicking the same survival mechanisms used by organisms. !! For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
would give,"For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
alice  write  g,"For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
system group,"For instance, if a file object has an access control expression that contains (read=(g:system OR u:Alice), write=(g:system AND !u:Bob))), this would give any member of the system group or the user named Alice permission to read the file but would allow only members of the system group to write the file, except for the user named Bob."
access control expressions,Conventional access control lists can be viewed as a subset of access control expressions in which the only combining operation allowed is OR.
combining operation allowed,Conventional access control lists can be viewed as a subset of access control expressions in which the only combining operation allowed is OR.
conventional access control lists,Conventional access control lists can be viewed as a subset of access control expressions in which the only combining operation allowed is OR.
improve human,"The Artificial Intelligence of Things (AIoT) is the combination of Artificial intelligence (AI) technologies with the Internet of things (IoT) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance data management and analytics."
efficient iot operations,"The Artificial Intelligence of Things (AIoT) is the combination of Artificial intelligence (AI) technologies with the Internet of things (IoT) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance data management and analytics."
machine interactions,"The Artificial Intelligence of Things (AIoT) is the combination of Artificial intelligence (AI) technologies with the Internet of things (IoT) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance data management and analytics."
enhance data management,"The Artificial Intelligence of Things (AIoT) is the combination of Artificial intelligence (AI) technologies with the Internet of things (IoT) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance data management and analytics."
enterprise cognitive system,"While general-purpose cognitive systems can be used for different outputs, prescriptive, suggestive, instructive, or simply entertaining, an enterprise cognitive system is focused on action, not insight, to help in assessing what to do in a complex situation. !! Enterprise cognitive systems (ECS) are part of a broader shift in computing, from a programmatic to a probabilistic approach, called cognitive computing. !! It is rare to have to directly process sensor, audio or visual data in real-time as direct input into the enterprise cognitive system. !! An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
called cognitive computing,"Enterprise cognitive systems (ECS) are part of a broader shift in computing, from a programmatic to a probabilistic approach, called cognitive computing."
broader shift,"Enterprise cognitive systems (ECS) are part of a broader shift in computing, from a programmatic to a probabilistic approach, called cognitive computing."
complex decision support problems computable,"An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
enterprise cognitive system makes,"An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
usually assessed today,"An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
new class,"In class-based programming, inheritance is done by defining new classes as extensions of existing classes: the existing class is the parent class and the new class is the child class. !! An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
business context,"An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
business user,"An Enterprise Cognitive System makes a new class of complex decision support problems computable, where the business context is ambiguous, multi-faceted, and fast-evolving, and what to do in such a situation is usually assessed today by the business user."
purpose cognitive systems,"While general-purpose cognitive systems can be used for different outputs, prescriptive, suggestive, instructive, or simply entertaining, an enterprise cognitive system is focused on action, not insight, to help in assessing what to do in a complex situation."
simply entertaining,"While general-purpose cognitive systems can be used for different outputs, prescriptive, suggestive, instructive, or simply entertaining, an enterprise cognitive system is focused on action, not insight, to help in assessing what to do in a complex situation."
complex situation,"While general-purpose cognitive systems can be used for different outputs, prescriptive, suggestive, instructive, or simply entertaining, an enterprise cognitive system is focused on action, not insight, to help in assessing what to do in a complex situation."
different outputs,"While general-purpose cognitive systems can be used for different outputs, prescriptive, suggestive, instructive, or simply entertaining, an enterprise cognitive system is focused on action, not insight, to help in assessing what to do in a complex situation."
directly process sensor,"It is rare to have to directly process sensor, audio or visual data in real-time as direct input into the enterprise cognitive system."
direct input,"It is rare to have to directly process sensor, audio or visual data in real-time as direct input into the enterprise cognitive system."
visual data,"It is rare to have to directly process sensor, audio or visual data in real-time as direct input into the enterprise cognitive system."
solving mazes,A version of depth-first search was investigated in the 19th century by French mathematician Charles Pierre Trmaux as a strategy for solving mazes.
french mathematician charles pierre trmaux,A version of depth-first search was investigated in the 19th century by French mathematician Charles Pierre Trmaux as a strategy for solving mazes.
increasing limits,"When an appropriate depth limit is not known a priori, iterative deepening depth-first search applies DFS repeatedly with a sequence of increasing limits."
iterative deepening depth,"When an appropriate depth limit is not known a priori, iterative deepening depth-first search applies DFS repeatedly with a sequence of increasing limits."
appropriate depth limit,"When an appropriate depth limit is not known a priori, iterative deepening depth-first search applies DFS repeatedly with a sequence of increasing limits."
first search applies dfs repeatedly,"When an appropriate depth limit is not known a priori, iterative deepening depth-first search applies DFS repeatedly with a sequence of increasing limits."
left edges,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
important applications,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory. !! One of the most important applications of sparse dictionary learning is in the field of compressed sensing or signal recovery."
small graph,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
search form,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
shown graph,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
right edges,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
edges traversed,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
trmaux tree,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
first search starting,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
following order,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
search remembers previously visited nodes,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
vertices reached,The result of a depth-first search of a graph can be conveniently described in terms of a spanning tree of the vertices reached during the search.
conveniently described,The result of a depth-first search of a graph can be conveniently described in terms of a spanning tree of the vertices reached during the search.
computer software performed without executing,"Static program analysis is the analysis of computer software performed without executing any programs, in contrast with dynamic analysis, which is performed on programs during their execution."
widely called,"Its square is widely called the discriminant, though some sources call the Vandermonde polynomial itself the discriminant."
sources call,"Its square is widely called the discriminant, though some sources call the Vandermonde polynomial itself the discriminant."
humancomputer interaction research lab,"GroupLens Research is a humancomputer interaction research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems and online communities."
twin cities specializing,"GroupLens Research is a humancomputer interaction research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems and online communities."
grouplens research,"GroupLens researchers have also explored visualizations of the edit history of Wikipedia articles. !! GroupLens Research is a humancomputer interaction research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems and online communities. !! In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
online communities,"GroupLens Research is a humancomputer interaction research lab in the Department of Computer Science and Engineering at the University of Minnesota, Twin Cities specializing in recommender systems and online communities."
grouplens researchers,GroupLens researchers have also explored visualizations of the edit history of Wikipedia articles.
wikipedia articles,GroupLens researchers have also explored visualizations of the edit history of Wikipedia articles.
edit history,GroupLens researchers have also explored visualizations of the edit history of Wikipedia articles.
also explored visualizations,GroupLens researchers have also explored visualizations of the edit history of Wikipedia articles.
popular editors,"In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
scientific exploration,"In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
gender imbalance,"In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
female editors,"In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
grouplens researchers completed,"In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
large gap,"In 2011, the GroupLens researchers completed a scientific exploration of gender imbalance in Wikipedia's popular editors, resulting in finding that there was a large gap between male and female editors."
background role,"In human-computer interaction, low-key feedback is a type of output that takes a background role by being very subtle, sometimes nearly imperceptible."
sometimes nearly imperceptible,"In human-computer interaction, low-key feedback is a type of output that takes a background role by being very subtle, sometimes nearly imperceptible."
key feedback,"Physical machines often provide rich low-key feedback as a byproduct of their design. !! In human-computer interaction, low-key feedback is a type of output that takes a background role by being very subtle, sometimes nearly imperceptible. !! The benefit of low-key feedback is that it can provide always available indication without cluttering the user interface with explicit indicators such as text labels or indicator lights. !! The downside of low-key feedback is that it can be too subtle to some users and it often cannot be self-describing to beginners."
low-key feedback,"In human-computer interaction, low-key feedback is a type of output that takes a background role by being very subtle, sometimes nearly imperceptible. !! In computer software, the low-key feedback usually needs to be designed in. !! Physical machines often provide rich low-key feedback as a byproduct of their design. !! The benefit of low-key feedback is that it can provide always available indication without cluttering the user interface with explicit indicators such as text labels or indicator lights. !! The downside of low-key feedback is that it can be too subtle to some users and it often cannot be self-describing to beginners."
computer software,"In computer software, the low-key feedback usually needs to be designed in."
key feedback usually needs,"In computer software, the low-key feedback usually needs to be designed in."
indicator lights,The benefit of low-key feedback is that it can provide always available indication without cluttering the user interface with explicit indicators such as text labels or indicator lights.
text labels,The benefit of low-key feedback is that it can provide always available indication without cluttering the user interface with explicit indicators such as text labels or indicator lights.
explicit indicators,The benefit of low-key feedback is that it can provide always available indication without cluttering the user interface with explicit indicators such as text labels or indicator lights.
often cannot,The downside of low-key feedback is that it can be too subtle to some users and it often cannot be self-describing to beginners.
eye tracking,"Retrospective think aloud protocol is a technique used in usability, and eye tracking in particular, to gather qualitative information on the user intents and reasoning during a test."
retrospective think aloud protocol,"Retrospective think aloud protocol is a technique used in usability, and eye tracking in particular, to gather qualitative information on the user intents and reasoning during a test."
retrospective think aloud,"Retrospective think aloud protocol is a technique used in usability, and eye tracking in particular, to gather qualitative information on the user intents and reasoning during a test. !! Using Retrospective Think Aloud With Eye Tracking Usability Testing."
user intents,"Retrospective think aloud protocol is a technique used in usability, and eye tracking in particular, to gather qualitative information on the user intents and reasoning during a test."
gather qualitative information,"Retrospective think aloud protocol is a technique used in usability, and eye tracking in particular, to gather qualitative information on the user intents and reasoning during a test."
eye tracking usability testing,Using Retrospective Think Aloud With Eye Tracking Usability Testing.
using retrospective think aloud,Using Retrospective Think Aloud With Eye Tracking Usability Testing.
important technique,"Bayesian inference is an important technique in statistics, and especially in mathematical statistics. !! Microarchitecture simulation is an important technique in computer architecture research and computer science education."
input types,Microarchitecture simulation can be classified into multiple categories according to input types and level of details.
multiple categories according,Microarchitecture simulation can be classified into multiple categories according to input types and level of details.
various software package metrics,Various software package metrics are used in modular programming.
software package metrics,Various software package metrics are used in modular programming.
modular programming,Various software package metrics are used in modular programming.
electromagnetic modeling,"Computational electromagnetics (CEM), computational electrodynamics or electromagnetic modeling is the process of modeling the interaction of electromagnetic fields with physical objects and the environment."
physical objects,"Computational electromagnetics (CEM), computational electrodynamics or electromagnetic modeling is the process of modeling the interaction of electromagnetic fields with physical objects and the environment."
cem  computational electrodynamics,"Computational electromagnetics (CEM), computational electrodynamics or electromagnetic modeling is the process of modeling the interaction of electromagnetic fields with physical objects and the environment."
phone antenna design,"This makes computational electromagnetics (CEM) important to the design, and modeling of antenna, radar, satellite and other communication systems, nanophotonic devices and high speed silicon electronics, medical imaging, cell-phone antenna design, among other applications."
high speed silicon electronics,"This makes computational electromagnetics (CEM) important to the design, and modeling of antenna, radar, satellite and other communication systems, nanophotonic devices and high speed silicon electronics, medical imaging, cell-phone antenna design, among other applications."
nanophotonic devices,"This makes computational electromagnetics (CEM) important to the design, and modeling of antenna, radar, satellite and other communication systems, nanophotonic devices and high speed silicon electronics, medical imaging, cell-phone antenna design, among other applications."
makes computational electromagnetics,"This makes computational electromagnetics (CEM) important to the design, and modeling of antenna, radar, satellite and other communication systems, nanophotonic devices and high speed silicon electronics, medical imaging, cell-phone antenna design, among other applications."
engheta et al,The first application of the FMM in computational electromagnetics was by Engheta et al.
first application,The first application of the FMM in computational electromagnetics was by Engheta et al.
wayback machine,"Computational electromagnetics: a review Archived 2016-03-15 at the Wayback Machine !! Peter Suber, Formal Systems and Machines: An Isomorphism Archived 2011-05-24 at the Wayback Machine, 1997."
review archived 2016,Computational electromagnetics: a review Archived 2016-03-15 at the Wayback Machine
data structures serve,Data structures serve as the basis for abstract data types (ADT).
highly specialized,"Different types of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks."
specific tasks,"This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which were trained with large language datasets, such as the Wikipedia Corpus and Common Crawl, and can be fine-tuned for specific tasks. !! Different types of data structures are suited to different kinds of applications, and some are highly specialized to specific tasks."
data structures provide,Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services.
data efficiently,Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services.
large databases,Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services.
manage large amounts,Data structures provide a means to manage large amounts of data efficiently for uses such as large databases and internet indexing services.
designing efficient algorithms,"Usually, efficient data structures are key to designing efficient algorithms."
key organizing factor,"Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design."
programming languages emphasize data structures,"Some formal design methods and programming languages emphasize data structures, rather than algorithms, as the key organizing factor in software design."
certain aspects,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract."
adts proper,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract."
abstract type,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract. !! When a class is used as a type, it is an abstract type that refers to a hidden representation. !! ""Abstract Types Have Existential Type"" (PDF)."
opaque data types,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract."
various language features correspond,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract."
include abstract types,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract."
easily confused,"However, various language features correspond to certain aspects of ADTs, and are easily confused with ADTs proper; these include abstract types, opaque data types, protocols, and design by contract."
existential type,"""Abstract Types Have Existential Type"" (PDF)."
abstract types,"""Abstract Types Have Existential Type"" (PDF)."
quite arbitrarily,An unrestricted algorithm envisages a situation in which a user may stipulate the value of x and also the precision required in g(x) quite arbitrarily.
precision required,An unrestricted algorithm envisages a situation in which a user may stipulate the value of x and also the precision required in g(x) quite arbitrarily.
unrestricted algorithm envisages,An unrestricted algorithm envisages a situation in which a user may stipulate the value of x and also the precision required in g(x) quite arbitrarily.
user may stipulate,An unrestricted algorithm envisages a situation in which a user may stipulate the value of x and also the precision required in g(x) quite arbitrarily.
integer programming problem,"The vehicle routing problem (VRP) is a combinatorial optimization and integer programming problem which asks ""What is the optimal set of routes for a fleet of vehicles to traverse in order to deliver to a given set of customers""."
optimal set,"The vehicle routing problem (VRP) is a combinatorial optimization and integer programming problem which asks ""What is the optimal set of routes for a fleet of vehicles to traverse in order to deliver to a given set of customers""."
goods need,Vehicle Routing Problem with Pickup and Delivery (VRPPD): A number of goods need to be moved from certain pickup locations to other delivery locations.
delivery locations,Vehicle Routing Problem with Time Windows (VRPTW): The delivery locations have time windows within which the deliveries (or visits) must be made. !! Vehicle Routing Problem with Pickup and Delivery (VRPPD): A number of goods need to be moved from certain pickup locations to other delivery locations.
certain pickup locations,Vehicle Routing Problem with Pickup and Delivery (VRPPD): A number of goods need to be moved from certain pickup locations to other delivery locations.
additional restriction,"Vehicle Routing Problem with LIFO: Similar to the VRPPD, except an additional restriction is placed on the loading of the vehicles: at any delivery location, the item being delivered must be the item most recently picked up."
delivery location,"Vehicle Routing Problem with LIFO: Similar to the VRPPD, except an additional restriction is placed on the loading of the vehicles: at any delivery location, the item being delivered must be the item most recently picked up."
delivered must,"Vehicle Routing Problem with LIFO: Similar to the VRPPD, except an additional restriction is placed on the loading of the vehicles: at any delivery location, the item being delivered must be the item most recently picked up."
recently picked,"Vehicle Routing Problem with LIFO: Similar to the VRPPD, except an additional restriction is placed on the loading of the vehicles: at any delivery location, the item being delivered must be the item most recently picked up."
time windows,Vehicle Routing Problem with Time Windows (VRPTW): The delivery locations have time windows within which the deliveries (or visits) must be made.
time windows within,Vehicle Routing Problem with Time Windows (VRPTW): The delivery locations have time windows within which the deliveries (or visits) must be made.
popular name,The Abelian sandpile model (ASM) is the more popular name of the original BakTangWiesenfeld model (BTW).
original baktangwiesenfeld model,The Abelian sandpile model (ASM) is the more popular name of the original BakTangWiesenfeld model (BTW).
abelian dynamics,Three years later Deepak Dhar invented that the BTW sandpile model indeed follows the abelian dynamics and therefore referred to this model as the Abelian sandpile model.
btw sandpile model indeed follows,Three years later Deepak Dhar invented that the BTW sandpile model indeed follows the abelian dynamics and therefore referred to this model as the Abelian sandpile model.
therefore referred,Three years later Deepak Dhar invented that the BTW sandpile model indeed follows the abelian dynamics and therefore referred to this model as the Abelian sandpile model.
abelian group,"Dhar showed that all such addition operators form an abelian group, hence the name Abelian sandpile model."
dhar showed,"Dhar showed that all such addition operators form an abelian group, hence the name Abelian sandpile model."
addition operators form,"Dhar showed that all such addition operators form an abelian group, hence the name Abelian sandpile model."
name abelian sandpile model,"Dhar showed that all such addition operators form an abelian group, hence the name Abelian sandpile model."
computer game hexplode,"The computer game Hexplode is based around the Abelian sandpile model on a finite hexagonal grid where instead of random grain placement, grains are placed by players."
finite hexagonal grid,"The computer game Hexplode is based around the Abelian sandpile model on a finite hexagonal grid where instead of random grain placement, grains are placed by players."
based around,"The computer game Hexplode is based around the Abelian sandpile model on a finite hexagonal grid where instead of random grain placement, grains are placed by players."
random grain placement,"The computer game Hexplode is based around the Abelian sandpile model on a finite hexagonal grid where instead of random grain placement, grains are placed by players."
markov models,Several well-known algorithms for hidden Markov models exist. !! Two kinds of Hierarchical Markov Models are the Hierarchical hidden Markov model and the Abstract Hidden Markov Model. !! Hierarchical Markov models can be applied to categorize human behavior at various levels of abstraction.
various levels,Hierarchical Markov models can be applied to categorize human behavior at various levels of abstraction.
categorize human behavior,Hierarchical Markov models can be applied to categorize human behavior at various levels of abstraction.
two kinds,Two kinds of Hierarchical Markov Models are the Hierarchical hidden Markov model and the Abstract Hidden Markov Model.
coupled designs,Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
use loosely,Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
open standard published,Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
application response measurement,Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
oriented architectures,Service-orientation design principles are proposed principles for developing the solution logic of services within service-oriented architectures (SOA). !! Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
information seeking projects,"Collaborative information seeking (CIS) is a field of research that involves studying situations, motivations, and methods for people working in collaborative groups for information seeking projects, as well as building systems for supporting such activities."
building systems,"Collaborative information seeking (CIS) is a field of research that involves studying situations, motivations, and methods for people working in collaborative groups for information seeking projects, as well as building systems for supporting such activities."
people working,"Collaborative information seeking (CIS) is a field of research that involves studying situations, motivations, and methods for people working in collaborative groups for information seeking projects, as well as building systems for supporting such activities."
collaborative groups,"Collaborative information seeking (CIS) is a field of research that involves studying situations, motivations, and methods for people working in collaborative groups for information seeking projects, as well as building systems for supporting such activities."
involves studying situations,"Collaborative information seeking (CIS) is a field of research that involves studying situations, motivations, and methods for people working in collaborative groups for information seeking projects, as well as building systems for supporting such activities."
collaborative information seeking,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably. !! Collaborative information seeking (CIS) is a field of research that involves studying situations, motivations, and methods for people working in collaborative groups for information seeking projects, as well as building systems for supporting such activities. !! There are also several models to explain information seeking and information behavior, but the areas of collaborative information seeking and collaborative information behavior remain understudied. !! Some of the situations for doing collaborative information seeking in this survey were travel planning, shopping, and literature search. !! Foley and Smeaton defined two key aspects of collaborative information seeking as division of labor and the sharing of knowledge."
explain information seeking,"There are also several models to explain information seeking and information behavior, but the areas of collaborative information seeking and collaborative information behavior remain understudied."
information behavior,"There are also several models to explain information seeking and information behavior, but the areas of collaborative information seeking and collaborative information behavior remain understudied."
collaborative information behavior remain understudied,"There are also several models to explain information seeking and information behavior, but the areas of collaborative information seeking and collaborative information behavior remain understudied."
also several models,"There are also several models to explain information seeking and information behavior, but the areas of collaborative information seeking and collaborative information behavior remain understudied."
collaborative information behavior,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
collaborative information synthesis,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
use terms,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
social searching,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
collaborative exploratory search,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
concurrent search,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
collaborative information retrieval,"The literature is filled with works that use terms such as collaborative information retrieval, social searching, concurrent search, collaborative exploratory search, co-browsing, collaborative information behavior, collaborative information synthesis, and collaborative information seeking, which are often used interchangeably."
smeaton defined two key aspects,Foley and Smeaton defined two key aspects of collaborative information seeking as division of labor and the sharing of knowledge.
literature search,"Some of the situations for doing collaborative information seeking in this survey were travel planning, shopping, and literature search."
travel planning,"Some of the situations for doing collaborative information seeking in this survey were travel planning, shopping, and literature search."
comparison sorting algorithm published,"In computer science, merge-insertion sort or the FordJohnson algorithm is a comparison sorting algorithm published in 1959 by L. R. Ford Jr. and Selmer M. Johnson."
ford jr,"In computer science, merge-insertion sort or the FordJohnson algorithm is a comparison sorting algorithm published in 1959 by L. R. Ford Jr. and Selmer M. Johnson."
comparisons made,"Merge-insertion sort also performs fewer comparisons than the sorting numbers, which count the comparisons made by binary insertion sort or merge sort in the worst case."
input lengths,"For 20 years, merge-insertion sort was the sorting algorithm with the fewest comparisons known for all input lengths."
fewest comparisons known,"For 20 years, merge-insertion sort was the sorting algorithm with the fewest comparisons known for all input lengths."
used modifications,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
breaking sorting algorithms,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
later record,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
insertion sort ideas,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
intelligent control,"Intelligent control is a class of control techniques that use various artificial intelligence computing approaches like neural networks, Bayesian probability, fuzzy logic, machine learning, reinforcement learning, evolutionary computation and genetic algorithms."
applies deep learning,Deep Instinct is a cybersecurity company that applies deep learning to cybersecurity.
cybersecurity company,Deep Instinct is a cybersecurity company that applies deep learning to cybersecurity.
deep instinct,"In April 2019, Deep Instinct commissioned an art project, titled ""The Persistence of Chaos"", by Chinese artist, Guo O Dong, consisting of a laptop infected with 6 pieces of malware that represented $95 billion in damages. !! In 2015, Deep Instinct was founded by Guy Caspi, Dr. Eli David, and Nadav Maman. !! In 2019, Globes reported that, HP Inc partnered with Deep Instinct to launch their security solution HP SureSense, which has been applied to the EliteBook and Zbook devices. !! Deep Instinct is a cybersecurity company that applies deep learning to cybersecurity."
eli david,"In 2015, Deep Instinct was founded by Guy Caspi, Dr. Eli David, and Nadav Maman."
guy caspi,"In 2015, Deep Instinct was founded by Guy Caspi, Dr. Eli David, and Nadav Maman."
nadav maman,"In 2015, Deep Instinct was founded by Guy Caspi, Dr. Eli David, and Nadav Maman."
art project,"In April 2019, Deep Instinct commissioned an art project, titled ""The Persistence of Chaos"", by Chinese artist, Guo O Dong, consisting of a laptop infected with 6 pieces of malware that represented $95 billion in damages."
laptop infected,"In April 2019, Deep Instinct commissioned an art project, titled ""The Persistence of Chaos"", by Chinese artist, Guo O Dong, consisting of a laptop infected with 6 pieces of malware that represented $95 billion in damages."
deep instinct commissioned,"In April 2019, Deep Instinct commissioned an art project, titled ""The Persistence of Chaos"", by Chinese artist, Guo O Dong, consisting of a laptop infected with 6 pieces of malware that represented $95 billion in damages."
chinese artist,"In April 2019, Deep Instinct commissioned an art project, titled ""The Persistence of Chaos"", by Chinese artist, Guo O Dong, consisting of a laptop infected with 6 pieces of malware that represented $95 billion in damages."
zbook devices,"In 2019, Globes reported that, HP Inc partnered with Deep Instinct to launch their security solution HP SureSense, which has been applied to the EliteBook and Zbook devices."
globes reported,"In 2019, Globes reported that, HP Inc partnered with Deep Instinct to launch their security solution HP SureSense, which has been applied to the EliteBook and Zbook devices."
security solution hp suresense,"In 2019, Globes reported that, HP Inc partnered with Deep Instinct to launch their security solution HP SureSense, which has been applied to the EliteBook and Zbook devices."
hp inc partnered,"In 2019, Globes reported that, HP Inc partnered with Deep Instinct to launch their security solution HP SureSense, which has been applied to the EliteBook and Zbook devices."
store operations,Stack machines extend push-down automaton with additional load/store operations or multiple stacks and hence are Turing-complete.
multiple stacks,Stack machines extend push-down automaton with additional load/store operations or multiple stacks and hence are Turing-complete.
additional load,Stack machines extend push-down automaton with additional load/store operations or multiple stacks and hence are Turing-complete.
stack machines,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits. !! Some stack machines have a stack of limited size, implemented as a register file. !! Stack machines extend push-down automaton with additional load/store operations or multiple stacks and hence are Turing-complete. !! All practical stack machines have variants of the loadstore opcodes for accessing local variables and formal parameters without explicit address calculations. !! Stack machines may have their expression stack and their call-return stack separated or as one integrated structure."
stack machines extend push,Stack machines extend push-down automaton with additional load/store operations or multiple stacks and hence are Turing-complete.
still fit together,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
load immediates,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
compact group,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
argument field,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
frequent cases,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
store instructions require,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
stack machines often arrange,"Branches, load immediates, and load/store instructions require an argument field, but stack machines often arrange that the frequent cases of these still fit together with the opcode into a compact group of bits."
practical stack machines,All practical stack machines have variants of the loadstore opcodes for accessing local variables and formal parameters without explicit address calculations.
loadstore opcodes,All practical stack machines have variants of the loadstore opcodes for accessing local variables and formal parameters without explicit address calculations.
accessing local variables,All practical stack machines have variants of the loadstore opcodes for accessing local variables and formal parameters without explicit address calculations.
expression stack,Stack machines may have their expression stack and their call-return stack separated or as one integrated structure.
return stack separated,Stack machines may have their expression stack and their call-return stack separated or as one integrated structure.
one integrated structure,Stack machines may have their expression stack and their call-return stack separated or as one integrated structure.
stack machines may,Stack machines may have their expression stack and their call-return stack separated or as one integrated structure.
limited size,"Some stack machines have a stack of limited size, implemented as a register file."
register file,"Some stack machines have a stack of limited size, implemented as a register file."
spin model checker,"Bitstate hashing is utilized in the SPIN model checker for deciding whether a state was already visited by a nested-depth-first search algorithm or not. !! Holzmann, G. J. , The SPIN Model Checker: Primer and Reference Manual."
reference manual,"Holzmann, G. J. , The SPIN Model Checker: Primer and Reference Manual."
data mining concerned,Sequential pattern mining is a topic of data mining concerned with finding statistically relevant patterns between data examples where the values are delivered in a sequence.
data examples,Sequential pattern mining is a topic of data mining concerned with finding statistically relevant patterns between data examples where the values are delivered in a sequence.
finding statistically relevant patterns,Sequential pattern mining is a topic of data mining concerned with finding statistically relevant patterns between data examples where the values are delivered in a sequence.
batch norm,Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scaling.
make artificial neural networks faster,Batch normalization (also known as batch norm) is a method used to make artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scaling.
reasons behind,"While the effect of batch normalization is evident, the reasons behind its effectiveness remain under discussion."
effectiveness remain,"While the effect of batch normalization is evident, the reasons behind its effectiveness remain under discussion."
reduce internal covariate shift,"Recently, some scholars have argued that batch normalization does not reduce internal covariate shift, but rather smooths the objective function, which in turn improves the performance."
turn improves,"Recently, some scholars have argued that batch normalization does not reduce internal covariate shift, but rather smooths the objective function, which in turn improves the performance."
rather smooths,"Recently, some scholars have argued that batch normalization does not reduce internal covariate shift, but rather smooths the objective function, which in turn improves the performance."
fact induces severe gradient explosion,"However, at initialization, batch normalization in fact induces severe gradient explosion in deep networks, which is only alleviated by skip connections in residual networks."
skip connections,"However, at initialization, batch normalization in fact induces severe gradient explosion in deep networks, which is only alleviated by skip connections in residual networks."
direction decoupling,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
others sustain,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
thereby accelerates neural networks,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
batch normalization achieves length,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
language technology,Gesture recognition is a topic in computer science and language technology with the goal of interpreting human gestures via mathematical algorithms.
field include emotion recognition,Current focuses in the field include emotion recognition from face and hand gesture recognition.
current focuses,Current focuses in the field include emotion recognition from face and hand gesture recognition.
human behaviors,"However, the identification and recognition of posture, gait, proxemics, and human behaviors is also the subject of gesture recognition techniques."
interact naturally without,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
mechanical devices,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
even guis,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
understand human body language,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
still limit,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
primitive text user interfaces,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
richer bridge,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
thus building,"Gesture recognition can be seen as a way for computers to begin to understand human body language, thus building a richer bridge between machines and humans than primitive text user interfaces or even GUIs (graphical user interfaces), which still limit the majority of input to keyboard and mouse and interact naturally without any mechanical devices."
automated sign language translationgesture recognition,Automated sign language translationGesture recognition can be conducted with techniques from computer vision and image processing.
tree returns,"In computer science, a Cartesian tree is a binary tree derived from a sequence of numbers; it can be uniquely defined from the properties that it is heap-ordered and that a symmetric (in-order) traversal of the tree returns the original sequence."
cartesian tree,"The Cartesian tree for a sequence may be constructed in linear time using a stack-based algorithm for finding all nearest smaller values in a sequence. !! From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value. !! Introduced by Vuillemin (1980) in the context of geometric range searching data structures, Cartesian trees have also been used in the definition of the treap and randomized binary search tree data structures for binary search problems. !! In computer science, a Cartesian tree is a binary tree derived from a sequence of numbers; it can be uniquely defined from the properties that it is heap-ordered and that a symmetric (in-order) traversal of the tree returns the original sequence. !! The Cartesian tree for a sequence has one node for each number in the sequence."
original sequence,"In computer science, a Cartesian tree is a binary tree derived from a sequence of numbers; it can be uniquely defined from the properties that it is heap-ordered and that a symmetric (in-order) traversal of the tree returns the original sequence."
uniquely defined,"In computer science, a Cartesian tree is a binary tree derived from a sequence of numbers; it can be uniquely defined from the properties that it is heap-ordered and that a symmetric (in-order) traversal of the tree returns the original sequence."
binary tree derived,"In computer science, a Cartesian tree is a binary tree derived from a sequence of numbers; it can be uniquely defined from the properties that it is heap-ordered and that a symmetric (in-order) traversal of the tree returns the original sequence."
cartesian trees,"From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value. !! Introduced by Vuillemin (1980) in the context of geometric range searching data structures, Cartesian trees have also been used in the definition of the treap and randomized binary search tree data structures for binary search problems."
nearest smaller values,The Cartesian tree for a sequence may be constructed in linear time using a stack-based algorithm for finding all nearest smaller values in a sequence.
sequence may,"The Cartesian tree for a sequence may be constructed in linear time using a stack-based algorithm for finding all nearest smaller values in a sequence. !! Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums."
based algorithm,"The Cartesian tree for a sequence may be constructed in linear time using a stack-based algorithm for finding all nearest smaller values in a sequence. !! Thom's paper 'Subquadratic computation of vector generating polynomials and improvement of the block Wiedemann algorithm' uses a more sophisticated FFT-based algorithm for computing the vector generating polynomials, and describes a practical implementation with imax = jmax = 4 used to compute a kernel vector of a 484603484603 matrix of entries modulo 26071, and hence to compute discrete logarithms in the field GF(2607)."
linear time using,The Cartesian tree for a sequence may be constructed in linear time using a stack-based algorithm for finding all nearest smaller values in a sequence.
one node,The Cartesian tree for a sequence has one node for each number in the sequence.
minimum value,"From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value."
root value,"From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value."
right subtrees,"From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value."
defined recursively,"From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value."
fewer dimensions,"In multivariate statistics, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions."
perform dimensionality reduction,"In multivariate statistics, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions."
spectral clustering techniques make use,"In multivariate statistics, spectral clustering techniques make use of the spectrum (eigenvalues) of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions."
based object categorization,"In application to image segmentation, spectral clustering is known as segmentation-based object categorization."
spring system,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system."
well known,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system. !! Many programming paradigms are as well known for the techniques they forbid as for those they enable."
data point,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system."
edge describing,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system."
two related data points,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system."
spring stiffness corresponds,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system."
shimalik algorithm introduced,"A popular normalized spectral clustering technique is the normalized cuts algorithm or ShiMalik algorithm introduced by Jianbo Shi and Jitendra Malik, commonly used for image segmentation."
jianbo shi,"A popular normalized spectral clustering technique is the normalized cuts algorithm or ShiMalik algorithm introduced by Jianbo Shi and Jitendra Malik, commonly used for image segmentation."
popular normalized spectral clustering technique,"A popular normalized spectral clustering technique is the normalized cuts algorithm or ShiMalik algorithm introduced by Jianbo Shi and Jitendra Malik, commonly used for image segmentation."
jitendra malik,"A popular normalized spectral clustering technique is the normalized cuts algorithm or ShiMalik algorithm introduced by Jianbo Shi and Jitendra Malik, commonly used for image segmentation."
abstract syntactic structure,"In computer science, an abstract syntax tree (AST), or just syntax tree, is a tree representation of the abstract syntactic structure of text (often source code) written in a formal language."
often source code,"In computer science, an abstract syntax tree (AST), or just syntax tree, is a tree representation of the abstract syntactic structure of text (often source code) written in a formal language."
distinguishes abstract syntax trees,"This distinguishes abstract syntax trees from concrete syntax trees, traditionally designated parse trees."
concrete syntax trees,"This distinguishes abstract syntax trees from concrete syntax trees, traditionally designated parse trees."
traditionally designated parse trees,"This distinguishes abstract syntax trees from concrete syntax trees, traditionally designated parse trees."
program transformation systems,Abstract syntax trees are also used in program analysis and program transformation systems.
data structures widely used,Abstract syntax trees are data structures widely used in compilers to represent the structure of program code.
program code,Abstract syntax trees are data structures widely used in compilers to represent the structure of program code.
abstract syntax tree implementation idioms,"""Abstract Syntax Tree Implementation Idioms"" (PDF)."
interactive animated character,"The Office Assistant is a discontinued ""intelligent"" user interface for Microsoft Office that assisted users by way of an interactive animated character which interfaced with the Office help content."
office assistant,"The Office Assistant is a discontinued ""intelligent"" user interface for Microsoft Office that assisted users by way of an interactive animated character which interfaced with the Office help content. !! In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants. !! Furthermore, the Office Assistant could use the Lernout & Hauspie TruVoice Text-to-Speech Engine to provide output speech capabilities to Microsoft Agent, but it required SAPI 4. !! The Office Assistant used technology initially from Microsoft Bob and later Microsoft Agent, offering advice based on Bayesian algorithms. !! First introduced in Microsoft Office 97, the Office Assistant was codenamed TFC during development."
assisted users,"The Office Assistant is a discontinued ""intelligent"" user interface for Microsoft Office that assisted users by way of an interactive animated character which interfaced with the Office help content."
microsoft office,"Microsoft Software Assurance (SA) is a Microsoft maintenance program aimed at business users who use Microsoft Windows, Microsoft Office, and other server and desktop applications. !! The Office Assistant is a discontinued ""intelligent"" user interface for Microsoft Office that assisted users by way of an interactive animated character which interfaced with the Office help content."
office help content,"The Office Assistant is a discontinued ""intelligent"" user interface for Microsoft Office that assisted users by way of an interactive animated character which interfaced with the Office help content."
codenamed tfc,"First introduced in Microsoft Office 97, the Office Assistant was codenamed TFC during development."
microsoft office 97,"First introduced in Microsoft Office 97, the Office Assistant was codenamed TFC during development."
default character,"In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants."
different office assistant character,"In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants."
office installation cd,"In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants."
office assistants,"In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants."
remains widely known compared,"In many cases the Office installation CD was necessary to activate a different Office assistant character, so the default character, Clippit, remains widely known compared to other Office Assistants."
microsoft bob,"The Office Assistant used technology initially from Microsoft Bob and later Microsoft Agent, offering advice based on Bayesian algorithms."
later microsoft agent,"The Office Assistant used technology initially from Microsoft Bob and later Microsoft Agent, offering advice based on Bayesian algorithms."
offering advice based,"The Office Assistant used technology initially from Microsoft Bob and later Microsoft Agent, offering advice based on Bayesian algorithms."
office assistant used technology initially,"The Office Assistant used technology initially from Microsoft Bob and later Microsoft Agent, offering advice based on Bayesian algorithms."
office assistant could use,"Furthermore, the Office Assistant could use the Lernout & Hauspie TruVoice Text-to-Speech Engine to provide output speech capabilities to Microsoft Agent, but it required SAPI 4."
required sapi 4,"Furthermore, the Office Assistant could use the Lernout & Hauspie TruVoice Text-to-Speech Engine to provide output speech capabilities to Microsoft Agent, but it required SAPI 4."
provide output speech capabilities,"Furthermore, the Office Assistant could use the Lernout & Hauspie TruVoice Text-to-Speech Engine to provide output speech capabilities to Microsoft Agent, but it required SAPI 4."
hauspie truvoice text,"Furthermore, the Office Assistant could use the Lernout & Hauspie TruVoice Text-to-Speech Engine to provide output speech capabilities to Microsoft Agent, but it required SAPI 4."
normal hearing,"Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information."
auditory disability,"Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information."
neurodevelopmental disorder affecting,"Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information."
brain processes auditory information,"Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information."
kopetzky syndrome,"Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information."
auditory processing disorder,"The pattern of results is suggestive that auditory processing disorder may be related to conditions of autosomal dominant inheritance. !! Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information. !! Inheritance of auditory processing disorder refers to whether the condition is inherited from your parents or ""runs"" in families. !! The systematic review mentioned here described this overlap between APD and other behavioral disorders and whether or not it was easy to distinguish those children that solely had auditory processing disorder. !! Auditory processing disorder can be associated with conditions affected by genetic traits, such as various developmental disorders."
apd  rarely known,"Auditory processing disorder (APD), rarely known as King-Kopetzky syndrome or auditory disability with normal hearing (ADN), is a neurodevelopmental disorder affecting the way the brain processes auditory information."
behavioral disorders,The systematic review mentioned here described this overlap between APD and other behavioral disorders and whether or not it was easy to distinguish those children that solely had auditory processing disorder.
systematic review mentioned,The systematic review mentioned here described this overlap between APD and other behavioral disorders and whether or not it was easy to distinguish those children that solely had auditory processing disorder.
auditory processing disorder may,The pattern of results is suggestive that auditory processing disorder may be related to conditions of autosomal dominant inheritance.
various developmental disorders,"Auditory processing disorder can be associated with conditions affected by genetic traits, such as various developmental disorders."
genetic traits,"Auditory processing disorder can be associated with conditions affected by genetic traits, such as various developmental disorders."
conditions affected,"Auditory processing disorder can be associated with conditions affected by genetic traits, such as various developmental disorders."
auditory processing disorder refers,"Inheritance of auditory processing disorder refers to whether the condition is inherited from your parents or ""runs"" in families."
certain class,"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc. !! Object detection is a computer technology related to computer vision and image processing that deals with detecting instances of semantic objects of a certain class (such as humans, buildings, or cars) in digital images and videos."
team winning,"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc."
logit model,"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc."
event taking place,"In statistics, the logistic model (or logit model) is used to model the probability of a certain class or event taking place, such as the probability of a team winning, of a patient being healthy, etc."
logit regression,"In regression analysis, logistic regression (or logit regression) is estimating the parameters of a logistic model (a form of binary regression)."
indicator variable,"In the logistic model, the log-odds (the logarithm of the odds) for the value labeled ""1"" is a linear combination of one or more independent variables (""predictors""); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value). !! Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled ""0"" and ""1""."
dependent variable,"In a binary logistic regression model, the dependent variable has two levels (categorical). !! Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled ""0"" and ""1""."
two values,"Outputs with more than two values are modeled by multinomial logistic regression and, if the multiple categories are ordered, by ordinal logistic regression (for example the proportional odds ordinal logistic model). !! Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled ""0"" and ""1""."
two possible values,"Mathematically, a binary logistic model has a dependent variable with two possible values, such as pass/fail which is represented by an indicator variable, where the two values are labeled ""0"" and ""1""."
independent variables  predictors,"In the logistic model, the log-odds (the logarithm of the odds) for the value labeled ""1"" is a linear combination of one or more independent variables (""predictors""); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value)."
value labeled,"In the logistic model, the log-odds (the logarithm of the odds) for the value labeled ""1"" is a linear combination of one or more independent variables (""predictors""); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value)."
real value,"In the logistic model, the log-odds (the logarithm of the odds) for the value labeled ""1"" is a linear combination of one or more independent variables (""predictors""); the independent variables can each be a binary variable (two classes, coded by an indicator variable) or a continuous variable (any real value)."
isa  also called computer architecture,"In computer science, an instruction set architecture (ISA), also called computer architecture, is an abstract model of a computer."
particular processor,"An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set."
processor design techniques used,"An instruction set architecture is distinguished from a microarchitecture, which is the set of processor design techniques used, in a particular processor, to implement the instruction set."
religious books,"Controversial literature is a subdivision of the Library of Congress Subject Headings, used in the description of religious books."
congress subject headings,"Controversial literature is a subdivision of the Library of Congress Subject Headings, used in the description of religious books."
controversial literature,"Controversial literature is a subdivision of the Library of Congress Subject Headings, used in the description of religious books."
gaussseidel method,"In numerical linear algebra, the method of successive over-relaxation (SOR) is a variant of the GaussSeidel method for solving a linear system of equations, resulting in faster convergence."
faster convergence,"In numerical linear algebra, the method of successive over-relaxation (SOR) is a variant of the GaussSeidel method for solving a linear system of equations, resulting in faster convergence."
successive over-relaxation,"The method of successive over-relaxation is an iterative technique that solves the left hand side of this expression for x, using previous value for x on the right hand side. !! According to the successive over-relaxation algorithm, the following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, (3, 2, 2, 1), in 38 steps. !! In numerical linear algebra, the method of successive over-relaxation (SOR) is a variant of the GaussSeidel method for solving a linear system of equations, resulting in faster convergence."
using previous value,"The method of successive over-relaxation is an iterative technique that solves the left hand side of this expression for x, using previous value for x on the right hand side."
iterative technique,"The method of successive over-relaxation is an iterative technique that solves the left hand side of this expression for x, using previous value for x on the right hand side."
right hand side,"The method of successive over-relaxation is an iterative technique that solves the left hand side of this expression for x, using previous value for x on the right hand side."
left hand side,"The method of successive over-relaxation is an iterative technique that solves the left hand side of this expression for x, using previous value for x on the right hand side."
exact solution,"According to the successive over-relaxation algorithm, the following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, (3, 2, 2, 1), in 38 steps."
following table,"According to the successive over-relaxation algorithm, the following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, (3, 2, 2, 1), in 38 steps."
relaxation algorithm,"According to the successive over-relaxation algorithm, the following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, (3, 2, 2, 1), in 38 steps."
exemplary iteration,"According to the successive over-relaxation algorithm, the following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, (3, 2, 2, 1), in 38 steps."
douglas hofstadter,"Typographical Number Theory (TNT) is a formal axiomatic system describing the natural numbers that appears in Douglas Hofstadter's book Gdel, Escher, Bach."
book gdel,"Typographical Number Theory (TNT) is a formal axiomatic system describing the natural numbers that appears in Douglas Hofstadter's book Gdel, Escher, Bach."
formal axiomatic system describing,"Typographical Number Theory (TNT) is a formal axiomatic system describing the natural numbers that appears in Douglas Hofstadter's book Gdel, Escher, Bach."
usual symbols,"In Typographical Number Theory, the usual symbols of ""+"" for additions, and """" for multiplications are used."
negation operator,"In Typographical Number Theory, negation, i. e. the turning of a statement to its opposite, is denoted by the ""~"" or negation operator."
atom symbols,"All the symbols of propositional calculus apart from the Atom symbols are used in Typographical Number Theory, and they retain their interpretations."
propositional calculus apart,"All the symbols of propositional calculus apart from the Atom symbols are used in Typographical Number Theory, and they retain their interpretations."
adaptive dimensional search algorithms differ,Adaptive dimensional search algorithms differ from nature-inspired metaheuristic techniques in the sense that they do not use any metaphor as an underlying principle for implementation.
underlying principle,Adaptive dimensional search algorithms differ from nature-inspired metaheuristic techniques in the sense that they do not use any metaphor as an underlying principle for implementation. !! The underlying principle of the XOR linked list can be applied to any reversible binary operation.
inspired metaheuristic techniques,Adaptive dimensional search algorithms differ from nature-inspired metaheuristic techniques in the sense that they do not use any metaphor as an underlying principle for implementation.
controlled states,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units."
gated memory,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units."
gated state,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units."
turbulent flows,Computational aeroacoustics is a branch of aeroacoustics that aims to analyze the generation of noise by turbulent flows through numerical methods.
computational aeroacoustics,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [. !! Computational aeroacoustics is a branch of aeroacoustics that aims to analyze the generation of noise by turbulent flows through numerical methods. !! A Fourier pseudospectral time-domain method can be applied to wave propagation problems pertinent to computational aeroacoustics."
computed directly,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [."
vorticity fields,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [."
computational fluid mechanics,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [."
continuous velocity,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [."
first principles determination,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [."
advancing rapidly,"the field of computational fluid mechanics has been advancing rapidly in the past few years and now offers the hope that ""computational aeroacoustics,"" where noise is computed directly from a first principles determination of continuous velocity and vorticity fields, might be possible, [."
fourier pseudospectral time,A Fourier pseudospectral time-domain method can be applied to wave propagation problems pertinent to computational aeroacoustics.
wave propagation problems pertinent,A Fourier pseudospectral time-domain method can be applied to wave propagation problems pertinent to computational aeroacoustics.
continuous simulation refers,Continuous Simulation refers to simulation approaches where a system is modeled with the help of variables that change continuously according to a set of differential equations.
change continuously according,Continuous Simulation refers to simulation approaches where a system is modeled with the help of variables that change continuously according to a set of differential equations.
simulation approaches,Continuous Simulation refers to simulation approaches where a system is modeled with the help of variables that change continuously according to a set of differential equations.
continuous simulation,"In continuous simulation, continuously changing state variables of a system are modeled by differential equations. !! Continuous Simulation refers to simulation approaches where a system is modeled with the help of variables that change continuously according to a set of differential equations. !! Since that time continuous simulation has been proven invaluable in military and private endeavors with complex systems. !! Only analog computers can run truly continuous simulations. !! Consequently, digital computers cannot run truly continuous simulations."
proven invaluable,Since that time continuous simulation has been proven invaluable in military and private endeavors with complex systems.
private endeavors,Since that time continuous simulation has been proven invaluable in military and private endeavors with complex systems.
complex systems,Since that time continuous simulation has been proven invaluable in military and private endeavors with complex systems.
continuously changing state variables,"In continuous simulation, continuously changing state variables of a system are modeled by differential equations."
analog computers,Only analog computers can run truly continuous simulations.
run truly continuous simulations,Only analog computers can run truly continuous simulations.
single binary digit,A redundant binary representation (RBR) is a numeral system that uses more bits than needed to represent a single binary digit so that most numbers have several representations.
numeral system,A redundant binary representation (RBR) is a numeral system that uses more bits than needed to represent a single binary digit so that most numbers have several representations.
several representations,A redundant binary representation (RBR) is a numeral system that uses more bits than needed to represent a single binary digit so that most numbers have several representations.
gaussian process governed,"In statistics, originally in geostatistics, kriging or Kriging, also known as Gaussian process regression, is a method of interpolation based on Gaussian process governed by prior covariances."
prior covariances,"In statistics, originally in geostatistics, kriging or Kriging, also known as Gaussian process regression, is a method of interpolation based on Gaussian process governed by prior covariances."
interpolation based,"In statistics, originally in geostatistics, kriging or Kriging, also known as Gaussian process regression, is a method of interpolation based on Gaussian process governed by prior covariances."
four russians,"In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values."
generally algorithms involving matrices,"In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values."
cell may take,"In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values."
algorithms involving boolean matrices,"In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values."
method of four russians,"In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values. !! The Method of Four Russians matrix inversion algorithm published by Bard is implemented in M4RI library for fast arithmetic with dense matrices over F2."
bounded number,"In computer science, the Method of Four Russians is a technique for speeding up algorithms involving Boolean matrices, or more generally algorithms involving matrices in which each cell may take on only a bounded number of possible values."
fast arithmetic,The Method of Four Russians matrix inversion algorithm published by Bard is implemented in M4RI library for fast arithmetic with dense matrices over F2.
m4ri library,The Method of Four Russians matrix inversion algorithm published by Bard is implemented in M4RI library for fast arithmetic with dense matrices over F2.
place algorithm,"In computer science, an in-place algorithm is an algorithm which transforms input using no auxiliary data structure. !! Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is."
transforms input using,"In computer science, an in-place algorithm is an algorithm which transforms input using no auxiliary data structure."
auxiliary data structure,"In computer science, an in-place algorithm is an algorithm which transforms input using no auxiliary data structure."
place algorithm updates,An in-place algorithm updates its input sequence only through replacement or swapping of elements.
place algorithms usually overwrite,"Since in-place algorithms usually overwrite their input with output, no additional space is needed."
additional space,"Since in-place algorithms usually overwrite their input with output, no additional space is needed."
reversal using,"Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is."
instead overwrite,"Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is."
need constant number,"Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is."
auxiliary variables,"Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is."
longer need,"Since we no longer need a, we can instead overwrite it with its own reversal using this in-place algorithm which will only need constant number (2) of integers for the auxiliary variables i and tmp, no matter how large the array is."
place category,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
constant space technically takes quicksort,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
usually considered,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
place algorithms,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
algorithms needing,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
additional pointers,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
cut whose size,"For a graph, a maximum cut is a cut whose size is at least the size of any other cut."
optimal inspection tour,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
intersecting curve,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
two subsets form,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
shortest tour,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
planar graphs,"The route inspection problem may be solved in polynomial time, and this duality allows the maximum cut problem to also be solved in polynomial time for planar graphs. !! However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
edges whose duals appear,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
optimal inspection tour forms,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
route inspection problem,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
winding number,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
dual graph,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
duality allows,"The route inspection problem may be solved in polynomial time, and this duality allows the maximum cut problem to also be solved in polynomial time for planar graphs."
route inspection problem may,"The route inspection problem may be solved in polynomial time, and this duality allows the maximum cut problem to also be solved in polynomial time for planar graphs."
computer time,"In computer science, the time complexity is the computational complexity that describes the amount of computer time it takes to run an algorithm."
elementary operations performed,"Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform."
fixed amount,"Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform."
commonly estimated,"Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform."
elementary operation takes,"Time complexity is commonly estimated by counting the number of elementary operations performed by the algorithm, supposing that each elementary operation takes a fixed amount of time to perform."
case time complexity,"Since an algorithm's running time may vary among different inputs of the same size, one commonly considers the worst-case time complexity, which is the maximum amount of time required for inputs of a given size."
one commonly considers,"Since an algorithm's running time may vary among different inputs of the same size, one commonly considers the worst-case time complexity, which is the maximum amount of time required for inputs of a given size."
given size,"Since an algorithm's running time may vary among different inputs of the same size, one commonly considers the worst-case time complexity, which is the maximum amount of time required for inputs of a given size."
time required,"A carry-lookahead adder improves speed by reducing the amount of time required to determine carry bits. !! Since an algorithm's running time may vary among different inputs of the same size, one commonly considers the worst-case time complexity, which is the maximum amount of time required for inputs of a given size. !! A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
generally expressed,"In both cases, the time complexity is generally expressed as a function of the size of the input."
take linear time,"An algorithm is said to take linear time, or O(n) time, if its time complexity is O(n)."
making participants,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
wendy kellogg,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
activities visible,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
social awareness,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
social translucence,"There are some theories that explain how this social translucence can affect the behavior of people in real-life scenarios. !! Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another"". !! Social translucence mechanisms have been made available in many web 2. !! facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available. !! proposed the principle of identity as a fourth dimension for social translucence by arguing that the design of socio-technical systems should have a rich description of who is visible, to give people control over disclosure and mechanisms to advocate for their needs."
support coherent behavior,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
thomas erickson,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
design digital systems,"Social translucence (also referred as social awareness) is a term that was proposed by Thomas Erickson and Wendy Kellogg to refer to ""design digital systems that support coherent behavior by making participants and their activities visible to one another""."
online social networking,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
facilitate navigation,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
social navigation,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
online identity,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
activity feeds,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
people activities,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
systems make available,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
instance present,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
core element,"facilitate navigation (social navigation)Social translucence is, in particular, a core element in online social networking such as Facebook or LinkedIn, in which they intervene in the possibility for people to expose their online identity, but also in the creation of awareness of other people activities, that are for instance present in the activity feeds that these systems make available."
many web 2,Social translucence mechanisms have been made available in many web 2.
social translucence mechanisms,Social translucence mechanisms have been made available in many web 2.
life scenarios,There are some theories that explain how this social translucence can affect the behavior of people in real-life scenarios.
fourth dimension,"proposed the principle of identity as a fourth dimension for social translucence by arguing that the design of socio-technical systems should have a rich description of who is visible, to give people control over disclosure and mechanisms to advocate for their needs."
technical systems,"In community informatics, there are several considerations which are the social context, shared values, distinct processes that are taken by members in a community, and social and technical systems. !! proposed the principle of identity as a fourth dimension for social translucence by arguing that the design of socio-technical systems should have a rich description of who is visible, to give people control over disclosure and mechanisms to advocate for their needs."
rich description,"proposed the principle of identity as a fourth dimension for social translucence by arguing that the design of socio-technical systems should have a rich description of who is visible, to give people control over disclosure and mechanisms to advocate for their needs."
give people control,"proposed the principle of identity as a fourth dimension for social translucence by arguing that the design of socio-technical systems should have a rich description of who is visible, to give people control over disclosure and mechanisms to advocate for their needs."
entropy and information,"Gray, R. M. (2011), Entropy and Information Theory, Springer."
classical definitions,"In mathematics, the quantum Markov chain is a reformulation of the ideas of a classical Markov chain, replacing the classical definitions of probability with quantum probability."
initial state,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
quantum markov chain resembles,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
positive operator valued measures,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
projection operators,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
important substitutions,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
many automaton,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
give theoretical bounds,Empirical risk minimization (ERM) is a principle in statistical learning theory which defines a family of learning algorithms and is used to give theoretical bounds on their performance.
1 loss function,Empirical risk minimization for a classification problem with a 0-1 loss function is known to be an NP-hard problem even for such a relatively simple class of functions as linear classifiers.
hard problem even,Empirical risk minimization for a classification problem with a 0-1 loss function is known to be an NP-hard problem even for such a relatively simple class of functions as linear classifiers.
relatively simple class,Empirical risk minimization for a classification problem with a 0-1 loss function is known to be an NP-hard problem even for such a relatively simple class of functions as linear classifiers.
directly executed,Specification languages are generally not directly executed.
specification languages,An important use of specification languages is enabling the creation of proofs of program correctness (see theorem prover). !! Specification languages are generally not directly executed. !! Media related to Specification languages at Wikimedia Commons
see theorem prover,An important use of specification languages is enabling the creation of proofs of program correctness (see theorem prover).
important use,An important use of specification languages is enabling the creation of proofs of program correctness (see theorem prover).
process done,Animal identification using a means of marking is a process done to identify and track specific animals.
animal identification using,Animal identification using a means of marking is a process done to identify and track specific animals.
animal identification,Animal identification using a means of marking is a process done to identify and track specific animals.
track specific animals,Animal identification using a means of marking is a process done to identify and track specific animals.
support write,"The MESI protocol is an Invalidate-based cache coherence protocol, and is one of the most common protocols that support write-back caches."
based cache coherence protocol,"The MESI protocol is an Invalidate-based cache coherence protocol, and is one of the most common protocols that support write-back caches."
write references,Illustration of MESI protocol operationsLet us assume that the following stream of read/write references.
mesi protocol operationslet us assume,Illustration of MESI protocol operationsLet us assume that the following stream of read/write references.
following stream,Illustration of MESI protocol operationsLet us assume that the following stream of read/write references.
processor trying,The operation is issued by a processor trying to write into a cache line that is in the shared (S) or invalid (I) states of the MESI protocol.
striking difference,"The most striking difference between the two protocols is the extra ""exclusive"" state present in the MESI protocol."
state present,"The most striking difference between the two protocols is the extra ""exclusive"" state present in the MESI protocol."
two protocols,"The most striking difference between the two protocols is the extra ""exclusive"" state present in the MESI protocol."
bus request,"Thus, MESI protocol overcomes this limitation by adding an Exclusive state, which results in saving a bus request."
exclusive state,"Thus, MESI protocol overcomes this limitation by adding an Exclusive state, which results in saving a bus request."
mesi protocol overcomes,"Thus, MESI protocol overcomes this limitation by adding an Exclusive state, which results in saving a bus request."
uses advanced computing capabilities,"Computational science, also known as scientific computing or scientific computation (SC), is a rapidly growing field that uses advanced computing capabilities to understand and solve complex problems."
solve complex problems,"Computational science, also known as scientific computing or scientific computation (SC), is a rapidly growing field that uses advanced computing capabilities to understand and solve complex problems."
rapidly growing field,"Computational science, also known as scientific computing or scientific computation (SC), is a rapidly growing field that uses advanced computing capabilities to understand and solve complex problems."
third mode,"Computational science is now commonly considered a third mode of science, complementing and adding to experimentation/observation and theory (see image on the right)."
see image,"Computational science is now commonly considered a third mode of science, complementing and adding to experimentation/observation and theory (see image on the right)."
developing algorithms,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
simulation generates adequately realistic results,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
studied conditionssubstantial effort,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
suitable level,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
efficient implementation,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
validating computational results,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
computational scientist trusts,"repeat the cycle until a suitable level of validation is obtained: the computational scientist trusts that the simulation generates adequately realistic results for the system under the studied conditionsSubstantial effort in computational sciences has been devoted to developing algorithms, efficient implementation in programming languages, and validating computational results."
electric instrument signals,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
low power audio amplifiers,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
treble  tone controls,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
electric bass  equalization,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
electric guitar,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
preceding stages,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
perform tasks like pre,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
particularly associated,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
microphone signals,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
mixing different input signals,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
record turntable signals,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
adding electronic effects,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
audio amplifier,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb. !! Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET). !! Power MOSFETs were soon manufactured by Yamaha for their hi-fi audio amplifiers. !! The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907. !! Most audio amplifiers are linear amplifiers operating in class AB."
first practical amplifying electrical component,"The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907."
invented around 1912,"The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907."
british english,"The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907."
triode vacuum tube,"The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907."
lee de forest,"The audio amplifier was invented around 1912 by Lee de Forest, made possible by his invention of the first practical amplifying electrical component, the triode vacuum tube (or ""valve"" in British English) in 1907."
effect transistor,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
state transistors,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
metaloxidesemiconductor field,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
bipolar junction transistor,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
modern audio amplifiers,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
fi audio amplifiers,Power MOSFETs were soon manufactured by Yamaha for their hi-fi audio amplifiers.
power mosfets,Power MOSFETs were soon manufactured by Yamaha for their hi-fi audio amplifiers.
soon manufactured,Power MOSFETs were soon manufactured by Yamaha for their hi-fi audio amplifiers.
audio amplifiers,Most audio amplifiers are linear amplifiers operating in class AB.
class ab,Most audio amplifiers are linear amplifiers operating in class AB.
linear amplifiers operating,Most audio amplifiers are linear amplifiers operating in class AB.
two main,There have been two main 'families' of the Microsoft Speech API.
generally understood,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour."
novelty detection,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour. !! The term one-class classification (OCC) was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection."
deviate significantly,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour."
rare items,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour."
normal behaviour,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour."
well defined notion,"In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behaviour."
large collection,ODDS ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.
ground truth,ODDS ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.
odds odds,ODDS ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.
publicly available outlier detection datasets,ODDS ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.
whose goal,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
universities space research association,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
joint initiative,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
quantum ai lab,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
pioneer research,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
google research,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
quantum computing might help,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
quantum artificial intelligence lab,"The Quantum Artificial Intelligence Lab (also called the Quantum AI Lab or QuAIL) is a joint initiative of NASA, Universities Space Research Association, and Google (specifically, Google Research) whose goal is to pioneer research on how quantum computing might help with machine learning and other difficult computer science problems."
explicitly call,"In computer science, anonymous recursion is recursion which does not explicitly call a function by name."
provides reflection facilities,"In programming practice, anonymous recursion is notably used in JavaScript, which provides reflection facilities to support it."
notably used,"In programming practice, anonymous recursion is notably used in JavaScript, which provides reflection facilities to support it."
less clear,"Anonymous recursion via explicitly passing functions as arguments is possible in any language that supports functions as arguments, though this is rarely used in practice, as it is longer and less clear than explicitly recursing by name."
rarely used,"Anonymous recursion via explicitly passing functions as arguments is possible in any language that supports functions as arguments, though this is rarely used in practice, as it is longer and less clear than explicitly recursing by name."
supports functions,"Anonymous recursion via explicitly passing functions as arguments is possible in any language that supports functions as arguments, though this is rarely used in practice, as it is longer and less clear than explicitly recursing by name."
explicitly recursing,"Anonymous recursion via explicitly passing functions as arguments is possible in any language that supports functions as arguments, though this is rarely used in practice, as it is longer and less clear than explicitly recursing by name."
point combinators,This anonymous recursion can be produced generically via fixed-point combinators.
produced generically via fixed,This anonymous recursion can be produced generically via fixed-point combinators.
operational needs,"A digital signal processor (DSP) is a specialized microprocessor chip, with its architecture optimized for the operational needs of digital signal processing."
specialized microprocessor chip,"A digital signal processor (DSP) is a specialized microprocessor chip, with its architecture optimized for the operational needs of digital signal processing."
architecture optimized,"A digital signal processor (DSP) is a specialized microprocessor chip, with its architecture optimized for the operational needs of digital signal processing."
typically implemented using bit,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
early digital signal processing applications,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
slice chips,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
alone digital signal processor,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
technological centerpiece,"Two years later in 1978, they produced the first Speak & Spell, with the technological centerpiece being the TMS5100, the industry's first digital signal processor."
first digital signal processor,"Two years later in 1978, they produced the first Speak & Spell, with the technological centerpiece being the TMS5100, the industry's first digital signal processor."
first speak,"Two years later in 1978, they produced the first Speak & Spell, with the technological centerpiece being the TMS5100, the industry's first digital signal processor."
two years later,"Two years later in 1978, they produced the first Speak & Spell, with the technological centerpiece being the TMS5100, the industry's first digital signal processor."
general use processor,The Blackfin family of embedded digital signal processors combine the features of a DSP with those of a general use processor.
embedded digital signal processors combine,The Blackfin family of embedded digital signal processors combine the features of a DSP with those of a general use processor.
blackfin family,The Blackfin family of embedded digital signal processors combine the features of a DSP with those of a general use processor.
data structure used,An XOR linked list is a type of data structure used in computer programming.
existing node,"XOR linked lists do not provide some of the important advantages of doubly linked lists, such as the ability to delete a node from the list knowing only its address or the ability to insert a new node before or after an existing node when knowing only the address of the existing node."
important advantages,"XOR linked lists do not provide some of the important advantages of doubly linked lists, such as the ability to delete a node from the list knowing only its address or the ability to insert a new node before or after an existing node when knowing only the address of the existing node."
list knowing,"XOR linked lists do not provide some of the important advantages of doubly linked lists, such as the ability to delete a node from the list knowing only its address or the ability to insert a new node before or after an existing node when knowing only the address of the existing node."
reversible binary operation,The underlying principle of the XOR linked list can be applied to any reversible binary operation.
zero link field,"This kind of list has exactly the same properties as the XOR linked list, except that a zero link field is not a ""mirror""."
instruction sequences needed,"This kind of list differs from the standard ""traditional"" XOR linked list in that the instruction sequences needed to traverse the list forwards is different from the sequence needed to traverse the list in reverse."
list forwards,"This kind of list differs from the standard ""traditional"" XOR linked list in that the instruction sequences needed to traverse the list forwards is different from the sequence needed to traverse the list in reverse."
list differs,"This kind of list differs from the standard ""traditional"" XOR linked list in that the instruction sequences needed to traverse the list forwards is different from the sequence needed to traverse the list in reverse."
sequence needed,"This kind of list differs from the standard ""traditional"" XOR linked list in that the instruction sequences needed to traverse the list forwards is different from the sequence needed to traverse the list in reverse."
entire system,The entire system is that of a hidden Markov model (HMM).
standard type,"In the standard type of hidden Markov model considered here, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution)."
hidden markov model considered,"In the standard type of hidden Markov model considered here, the state space of the hidden variables is discrete, while the observations themselves can either be discrete (typically generated from a categorical distribution) or continuous (typically from a Gaussian distribution)."
transition probabilities,"Maximal entropy random walk (MERW) is a popular type of biased random walk on a graph, in which transition probabilities are chosen accordingly to the principle of maximum entropy, which says that the probability distribution which best represents the current state of knowledge is the one with largest entropy. !! The parameters of a hidden Markov model are of two types, transition probabilities and emission probabilities (also known as output probabilities)."
output probabilities,"The parameters of a hidden Markov model are of two types, transition probabilities and emission probabilities (also known as output probabilities)."
emission probabilities,"The parameters of a hidden Markov model are of two types, transition probabilities and emission probabilities (also known as output probabilities)."
goal state,"An admissible heuristic is used to estimate the cost of reaching the goal state in an informed search algorithm. !! Crucial to the understanding of knowledge level modeling are Allen Newell's notions of the knowledge level, operators, and an agent's goal state. !! State space search is a process used in the field of computer science, including artificial intelligence (AI), in which successive configurations or states of an instance are considered, with the intention of finding a goal state with the desired property."
every tile,The Manhattan distance is an admissible heuristic in this case because every tile will have to be moved at least the number of spots in between itself and its correct position.
correct position,The Manhattan distance is an admissible heuristic in this case because every tile will have to be moved at least the number of spots in between itself and its correct position.
per iteration,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
several candidate paths,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
current cost,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
never closes,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
exploration reaches,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
special care,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
lowest evaluation,"If an admissible heuristic is used in an algorithm that, per iteration, progresses only the path of lowest evaluation (current cost + heuristic) of several candidate paths, terminates the moment it's exploration reaches the goal and, crucially, never closes all optimal paths before terminating (something that's possible with A* search algorithm if special care isn't taken), then this algorithm can only terminate on an optimal path."
seval strue,"On the other hand, an admissible heuristic would require that Seval Strue which combined with the above inequalities gives us Teval < Ttrue and more specifically Teval Ttrue."
admissible heuristic would require,"On the other hand, an admissible heuristic would require that Seval Strue which combined with the above inequalities gives us Teval < Ttrue and more specifically Teval Ttrue."
inequalities gives us teval,"On the other hand, an admissible heuristic would require that Seval Strue which combined with the above inequalities gives us Teval < Ttrue and more specifically Teval Ttrue."
specifically teval ttrue,"On the other hand, an admissible heuristic would require that Seval Strue which combined with the above inequalities gives us Teval < Ttrue and more specifically Teval Ttrue."
ensure optimality,"This way, an admissible heuristic can ensure optimality."
access memory,"Random-access memory (RAM; ) is a form of computer memory that can be read and changed in any order, typically used to store working data and machine code. !! RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed. !! The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM)."
store working data,"Random-access memory (RAM; ) is a form of computer memory that can be read and changed in any order, typically used to store working data and machine code."
arm movement,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
access data storage media,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
older magnetic tapes,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
mechanical limitations,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
recording medium,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
media rotation speeds,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
time irrespective,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
physical location,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
physical locations,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
data inside,"A random-access memory device allows data items to be read or written in almost the same amount of time irrespective of the physical location of data inside the memory, in contrast with other direct-access data storage media (such as hard disks, CD-RWs, DVD-RWs and the older magnetic tapes and drum memory), where the time required to read and write data items varies significantly depending on their physical locations on the recording medium, due to mechanical limitations such as media rotation speeds and arm movement."
access memory takes,"In today's technology, random-access memory takes the form of integrated circuit (IC) chips with MOS (metal-oxide-semiconductor) memory cells."
integrated circuit,"In today's technology, random-access memory takes the form of integrated circuit (IC) chips with MOS (metal-oxide-semiconductor) memory cells."
memory cells,"In today's technology, random-access memory takes the form of integrated circuit (IC) chips with MOS (metal-oxide-semiconductor) memory cells."
volatile types,"RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed."
dynamic random,"The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM). !! RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed."
normally associated,"RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed."
although non,"RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed."
stored information,"RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed."
access semiconductor memory,The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM).
static random,The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM).
two main types,The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM).
volatile random,The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM).
oriented approach,Object-oriented modeling (OOM) is an approach to modeling an application that is used at the beginning of the software life cycle when using an object-oriented approach to software development.
oriented modeling,"IBM announced service-oriented modeling and architecture (SOMA) as its SOA-related methodology in 2004 and published parts of it subsequently. !! Service-oriented modeling is the discipline of modeling business and software systems, for the purpose of designing and specifying service-oriented business systems within a variety of architectural styles and paradigms, such as application architecture, service-oriented architecture, microservices, and cloud computing. !! Media related to Real-Time Object-Oriented Modeling at Wikimedia Commons !! Object-oriented modeling (OOM) is an approach to modeling an application that is used at the beginning of the software life cycle when using an object-oriented approach to software development. !! The most common language used to do object-oriented modeling is the Object Management Group's Unified Modeling Language (UML). !! Object-oriented modeling is typically done via use cases and abstract definitions of the most important objects. !! Real-Time Object-Oriented Modeling (ROOM) is a domain specific language."
abstract definitions,Object-oriented modeling is typically done via use cases and abstract definitions of the most important objects.
important objects,Object-oriented modeling is typically done via use cases and abstract definitions of the most important objects.
typically done via use cases,Object-oriented modeling is typically done via use cases and abstract definitions of the most important objects.
unified modeling language,The most common language used to do object-oriented modeling is the Object Management Group's Unified Modeling Language (UML).
common language used,The most common language used to do object-oriented modeling is the Object Management Group's Unified Modeling Language (UML).
truncated power function,Truncated power functions are refinable. !! Truncated power functions can be used for construction of B-splines.
truncated power functions,Truncated power functions are refinable. !! Truncated power functions can be used for construction of B-splines.
industrial design field,"In the industrial design field of humancomputer interaction, a user interface (UI) is the space where interactions between humans and machines occur."
machines occur,"In the industrial design field of humancomputer interaction, a user interface (UI) is the space where interactions between humans and machines occur."
interactive aspects,"Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls."
user interfaces include,"Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls."
process controls,"Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls."
broad concept,"Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls."
hand tools,"Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls."
heavy machinery operator controls,"Examples of this broad concept of user interfaces include the interactive aspects of computer operating systems, hand tools, heavy machinery operator controls, and process controls."
design considerations applicable,"The design considerations applicable when creating user interfaces are related to, or involve such disciplines as, ergonomics and psychology."
creating user interfaces,"The design considerations applicable when creating user interfaces are related to, or involve such disciplines as, ergonomics and psychology."
desired result,"Generally, the goal of user interface design is to produce a user interface that makes it easy, efficient, and enjoyable (user-friendly) to operate a machine in the way which produces the desired result (i. e. maximum usability)."
maximum usability,"Generally, the goal of user interface design is to produce a user interface that makes it easy, efficient, and enjoyable (user-friendly) to operate a machine in the way which produces the desired result (i. e. maximum usability)."
physical input hardware,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers."
machine interface,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers."
output hardware,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers."
interfaces machines,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers."
computer monitors,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers."
game pads,"User interfaces are composed of one or more layers, including a human-machine interface (HMI) that interfaces machines with physical input hardware such as keyboards, mice, or game pads, and output hardware such as computer monitors, speakers, and printers."
paper folding,"In the mathematics of paper folding, map folding and stamp folding are two problems of counting the number of ways that a piece of paper can be folded."
stamp folding,"Eric W. Weisstein, Map Folding (Stamp Folding) at MathWorld. !! In the mathematics of paper folding, map folding and stamp folding are two problems of counting the number of ways that a piece of paper can be folded."
two problems,"In the mathematics of paper folding, map folding and stamp folding are two problems of counting the number of ways that a piece of paper can be folded."
map folding,"Eric W. Weisstein, Map Folding (Stamp Folding) at MathWorld. !! The map folding and stamp folding problems are related to a problem in the mathematics of origami of whether a square with a crease pattern can be folded to a flat figure. !! In the map folding problem, the paper is a map, divided by creases into rectangles, and the folds must again lie only along these creases. !! In the mathematics of paper folding, map folding and stamp folding are two problems of counting the number of ways that a piece of paper can be folded. !! Map folding is the question of how many ways there are to fold a rectangular map along its creases, allowing each crease to form either a mountain or a valley fold."
folds must,"In the map folding problem, the paper is a map, divided by creases into rectangles, and the folds must again lie only along these creases."
form either,"Map folding is the question of how many ways there are to fold a rectangular map along its creases, allowing each crease to form either a mountain or a valley fold."
valley fold,"Map folding is the question of how many ways there are to fold a rectangular map along its creases, allowing each crease to form either a mountain or a valley fold."
rectangular map along,"Map folding is the question of how many ways there are to fold a rectangular map along its creases, allowing each crease to form either a mountain or a valley fold."
many ways,"In any of its forms, temporal multithreading is similar in many ways to simultaneous multithreading. !! Map folding is the question of how many ways there are to fold a rectangular map along its creases, allowing each crease to form either a mountain or a valley fold."
flat figure,The map folding and stamp folding problems are related to a problem in the mathematics of origami of whether a square with a crease pattern can be folded to a flat figure.
represents objects defined,"A spatial database is a general-purpose database (usually a relational database) that has been enhanced to include spatial data that represents objects defined in a geometric space, along with tools for querying and analyzing such data."
purpose database,"A spatial database is a general-purpose database (usually a relational database) that has been enhanced to include spatial data that represents objects defined in a geometric space, along with tools for querying and analyzing such data."
spatial database,"Some spatial databases handle more complex structures such as 3D objects, topological coverages, linear networks, and TINs (triangulated irregular network). !! Most spatial databases allow the representation of simple geometric objects such as points, lines and polygons. !! A geodatabase (also geographical database and geospatial database) is a database of geographic data, such as countries, administrative divisions, cities, and related information. !! A spatial database is a general-purpose database (usually a relational database) that has been enhanced to include spatial data that represents objects defined in a geometric space, along with tools for querying and analyzing such data. !! Instead, spatial databases use a spatial index to speed up database operations."
include spatial data,"A spatial database is a general-purpose database (usually a relational database) that has been enhanced to include spatial data that represents objects defined in a geometric space, along with tools for querying and analyzing such data."
simple geometric objects,"Most spatial databases allow the representation of simple geometric objects such as points, lines and polygons."
spatial databases allow,"Most spatial databases allow the representation of simple geometric objects such as points, lines and polygons."
complex structures,"Some spatial databases handle more complex structures such as 3D objects, topological coverages, linear networks, and TINs (triangulated irregular network)."
spatial databases handle,"Some spatial databases handle more complex structures such as 3D objects, topological coverages, linear networks, and TINs (triangulated irregular network)."
also geographical database,"A geodatabase (also geographical database and geospatial database) is a database of geographic data, such as countries, administrative divisions, cities, and related information."
geographic data,"A geodatabase (also geographical database and geospatial database) is a database of geographic data, such as countries, administrative divisions, cities, and related information."
related information,"A geodatabase (also geographical database and geospatial database) is a database of geographic data, such as countries, administrative divisions, cities, and related information."
administrative divisions,"A geodatabase (also geographical database and geospatial database) is a database of geographic data, such as countries, administrative divisions, cities, and related information."
geospatial database,"A geodatabase (also geographical database and geospatial database) is a database of geographic data, such as countries, administrative divisions, cities, and related information."
database operations,"Instead, spatial databases use a spatial index to speed up database operations."
spatial index,"Instead, spatial databases use a spatial index to speed up database operations."
spatial databases use,"Instead, spatial databases use a spatial index to speed up database operations."
rules applied,"An acceptable use policy (AUP), acceptable usage policy or fair use policy is a set of rules applied by the owner, creator or administrator of a computer network website, or service."
aup  acceptable usage policy,"An acceptable use policy (AUP), acceptable usage policy or fair use policy is a set of rules applied by the owner, creator or administrator of a computer network website, or service."
fair use policy,"An acceptable use policy (AUP), acceptable usage policy or fair use policy is a set of rules applied by the owner, creator or administrator of a computer network website, or service."
computer network website,"An acceptable use policy (AUP), acceptable usage policy or fair use policy is a set of rules applied by the owner, creator or administrator of a computer network website, or service."
organisation sponsoring connection,"Often Acceptable Use Policy documents provide a statement about the use of the network and/or Internet and its uses and advantages to the business, school or other organisation sponsoring connection to the Internet."
found violating,"Lee v. PMSI, Inc. , a U. S. District Court Case that found violating an acceptable use policy did not violate the Computer Fraud and Abuse Act."
computer fraud,"Lee v. PMSI, Inc. , a U. S. District Court Case that found violating an acceptable use policy did not violate the Computer Fraud and Abuse Act."
abuse act,"Lee v. PMSI, Inc. , a U. S. District Court Case that found violating an acceptable use policy did not violate the Computer Fraud and Abuse Act."
district court case,"Lee v. PMSI, Inc. , a U. S. District Court Case that found violating an acceptable use policy did not violate the Computer Fraud and Abuse Act."
information becomes available,Bayesian inference is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available.
found application,"Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law. !! Markov processes are the basis for general stochastic simulation methods known as Markov chain Monte Carlo, which are used for simulating sampling from complex probability distributions, and have found application in Bayesian statistics, thermodynamics, statistical mechanics, physics, chemistry, economics, finance, signal processing, information theory and speech processing."
including science,"Bayesian inference has found application in a wide range of activities, including science, engineering, philosophy, medicine, sport, and law."
bayesian inference derives,"Bayesian inference derives the posterior probability as a consequence of two antecedents: a prior probability and a ""likelihood function"" derived from a statistical model for the observed data."
two antecedents,"Bayesian inference derives the posterior probability as a consequence of two antecedents: a prior probability and a ""likelihood function"" derived from a statistical model for the observed data."
posterior probability,"Bayesian inference derives the posterior probability as a consequence of two antecedents: a prior probability and a ""likelihood function"" derived from a statistical model for the observed data."
geometric shapes defined,"Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons."
creating visual images directly,"Vector graphics, as a form of computer graphics, is the set of mechanisms for creating visual images directly from geometric shapes defined on a Cartesian plane, such as points, lines, curves, and polygons."
specific situations,"Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations."
raster graphics,"Vector graphics is an alternative to raster graphics, each having advantages and disadvantages in general and in specific situations."
term vector,"Vector graphics are based on the mathematics of analytic or coordinate geometry, and is not related to other mathematical uses of the term vector, including vector fields and vector calculus."
mathematical uses,"Vector graphics are based on the mathematics of analytic or coordinate geometry, and is not related to other mathematical uses of the term vector, including vector fields and vector calculus."
including vector fields,"Vector graphics are based on the mathematics of analytic or coordinate geometry, and is not related to other mathematical uses of the term vector, including vector fields and vector calculus."
en route air traffic control,Vector graphics systems were retired from the U. S. en route air traffic control in 1999.
decrease time,"Pin compatibility is a property desired by systems integrators as it allows a product to be updated without redesigning printed circuit boards, which can reduce costs and decrease time to market."
reduce costs,"Pin compatibility is a property desired by systems integrators as it allows a product to be updated without redesigning printed circuit boards, which can reduce costs and decrease time to market."
pin compatibility,"Pin compatibility is a property desired by systems integrators as it allows a product to be updated without redesigning printed circuit boards, which can reduce costs and decrease time to market."
property desired,"Pin compatibility is a property desired by systems integrators as it allows a product to be updated without redesigning printed circuit boards, which can reduce costs and decrease time to market."
systems integrators,"Pin compatibility is a property desired by systems integrators as it allows a product to be updated without redesigning printed circuit boards, which can reduce costs and decrease time to market."
particular programming language,"In computer science, a syntax error is an error in the syntax of a sequence of characters or tokens that is intended to be written in a particular programming language."
error messages might,"For interpreted languages, however, a syntax error may be detected during program execution, and an interpreter's error messages might not differentiate syntax errors from errors of other kinds."
syntax error may,"For interpreted languages, however, a syntax error may be detected during program execution, and an interpreter's error messages might not differentiate syntax errors from errors of other kinds."
differentiate syntax errors,"For interpreted languages, however, a syntax error may be detected during program execution, and an interpreter's error messages might not differentiate syntax errors from errors of other kinds."
external systems,"For systems, the security policy addresses constraints on functions and flow among them, constraints on access by external systems and adversaries including programs and access to data by people."
adversaries including programs,"For systems, the security policy addresses constraints on functions and flow among them, constraints on access by external systems and adversaries including programs and access to data by people."
security policy addresses constraints,"For systems, the security policy addresses constraints on functions and flow among them, constraints on access by external systems and adversaries including programs and access to data by people."
flow among,"For systems, the security policy addresses constraints on functions and flow among them, constraints on access by external systems and adversaries including programs and access to data by people."
meaningless without,"Consequently, a top-level security policy is essential to any serious security scheme and sub-policies and rules of operation are meaningless without it."
serious security scheme,"Consequently, a top-level security policy is essential to any serious security scheme and sub-policies and rules of operation are meaningless without it."
level security policy,"Consequently, a top-level security policy is essential to any serious security scheme and sub-policies and rules of operation are meaningless without it."
knowledge representation,"Knowledge representation incorporates findings from psychology about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build. !! The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959. !! In communication networks, cognitive network (CN) is a new type of data network that makes use of cutting edge technology from several research areas (i. e. machine learning, knowledge representation, computer network, network management) to solve some problems current networks are faced with. !! Knowledge representation and reasoning (KRR, KR&R, KR) is the field of artificial intelligence (AI) dedicated to representing information about the world in a form that a computer system can use to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language. !! Knowledge representation and reasoning also incorporates findings from logic to automate various kinds of reasoning, such as the application of rules or the relations of sets and subsets. !! Examples of knowledge representation formalisms include semantic nets, systems architecture, frames, rules, and ontologies."
solve complex tasks,"Knowledge representation and reasoning (KRR, KR&R, KR) is the field of artificial intelligence (AI) dedicated to representing information about the world in a form that a computer system can use to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language."
representing information,"XML data binding refers to a means of representing information in an XML document as a business object in computer memory. !! Knowledge representation and reasoning (KRR, KR&R, KR) is the field of artificial intelligence (AI) dedicated to representing information about the world in a form that a computer system can use to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language."
medical condition,"Knowledge representation and reasoning (KRR, KR&R, KR) is the field of artificial intelligence (AI) dedicated to representing information about the world in a form that a computer system can use to solve complex tasks such as diagnosing a medical condition or having a dialog in a natural language."
knowledge representation incorporates findings,Knowledge representation incorporates findings from psychology about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build.
represent knowledge,Knowledge representation incorporates findings from psychology about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build.
make complex systems easier,Knowledge representation incorporates findings from psychology about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build.
humans solve problems,Knowledge representation incorporates findings from psychology about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build.
design formalisms,Knowledge representation incorporates findings from psychology about how humans solve problems and represent knowledge in order to design formalisms that will make complex systems easier to design and build.
automate various kinds,"Knowledge representation and reasoning also incorporates findings from logic to automate various kinds of reasoning, such as the application of rules or the relations of sets and subsets."
reasoning also incorporates findings,"Knowledge representation and reasoning also incorporates findings from logic to automate various kinds of reasoning, such as the application of rules or the relations of sets and subsets."
system developed,The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959.
earliest work,The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959.
general problem solver,The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959.
simaentik ereo,"Semantic Error (Korean: ; RR: Simaentik Ereo) is a 2022 South Korean streaming television series based on a manhwa by Jeo Soo-ri and Angy Kim, starring Park Seo-ham and Park Jae-chan."
park jae,"Semantic Error (Korean: ; RR: Simaentik Ereo) is a 2022 South Korean streaming television series based on a manhwa by Jeo Soo-ri and Angy Kim, starring Park Seo-ham and Park Jae-chan."
jeo soo,"Semantic Error (Korean: ; RR: Simaentik Ereo) is a 2022 South Korean streaming television series based on a manhwa by Jeo Soo-ri and Angy Kim, starring Park Seo-ham and Park Jae-chan."
angy kim,"Semantic Error (Korean: ; RR: Simaentik Ereo) is a 2022 South Korean streaming television series based on a manhwa by Jeo Soo-ri and Angy Kim, starring Park Seo-ham and Park Jae-chan."
starring park seo,"Semantic Error (Korean: ; RR: Simaentik Ereo) is a 2022 South Korean streaming television series based on a manhwa by Jeo Soo-ri and Angy Kim, starring Park Seo-ham and Park Jae-chan."
three children rather,"In computer science, a ternary search tree is a type of trie (sometimes called a prefix tree) where nodes are arranged in a manner similar to a binary search tree, but with up to three children rather than the binary tree's limit of two."
manner similar,"In computer science, a ternary search tree is a type of trie (sometimes called a prefix tree) where nodes are arranged in a manner similar to a binary search tree, but with up to three children rather than the binary tree's limit of two."
space efficient compared,"However, ternary search trees are more space efficient compared to standard prefix trees, at the cost of speed."
ternary search trees include spell,Common applications for ternary search trees include spell-checking and auto-completion.
common applications,Common applications for ternary search trees include spell-checking and auto-completion.
object depending,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
single character,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
ternary search tree stores,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
referred respectively,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
child  lower,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
hi kid,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
lo kid,"Each node of a ternary search tree stores a single character, an object (or a pointer to an object depending on implementation), and pointers to its three children conventionally named equal kid, lo kid and hi kid, which can also be referred respectively as middle (child), lower (child) and higher (child)."
also indicating 1,"As shown in the table to the right there are two sets of symbols for binary prefixes, one set established by International Electrotechnical Commission (IEC) and several other standards and trade organizations using two letter symbols, e. g. Mi indicating 1,048,576 with a second set established by semiconductor industry convention using one letter symbols, e. g. , M also indicating 1,048,576."
mi indicating 1,"As shown in the table to the right there are two sets of symbols for binary prefixes, one set established by International Electrotechnical Commission (IEC) and several other standards and trade organizations using two letter symbols, e. g. Mi indicating 1,048,576 with a second set established by semiconductor industry convention using one letter symbols, e. g. , M also indicating 1,048,576."
one set established,"As shown in the table to the right there are two sets of symbols for binary prefixes, one set established by International Electrotechnical Commission (IEC) and several other standards and trade organizations using two letter symbols, e. g. Mi indicating 1,048,576 with a second set established by semiconductor industry convention using one letter symbols, e. g. , M also indicating 1,048,576."
international electrotechnical commission,"As shown in the table to the right there are two sets of symbols for binary prefixes, one set established by International Electrotechnical Commission (IEC) and several other standards and trade organizations using two letter symbols, e. g. Mi indicating 1,048,576 with a second set established by semiconductor industry convention using one letter symbols, e. g. , M also indicating 1,048,576."
second set established,"As shown in the table to the right there are two sets of symbols for binary prefixes, one set established by International Electrotechnical Commission (IEC) and several other standards and trade organizations using two letter symbols, e. g. Mi indicating 1,048,576 with a second set established by semiconductor industry convention using one letter symbols, e. g. , M also indicating 1,048,576."
starting around 1998,"Starting around 1998, the IEC and several other standards and trade organizations attempted to address the ambiguity by publishing standards and recommendations for a set of binary prefixes that refer exclusively to powers of 1024."
refer exclusively,"Starting around 1998, the IEC and several other standards and trade organizations attempted to address the ambiguity by publishing standards and recommendations for a set of binary prefixes that refer exclusively to powers of 1024."
publishing standards,"Starting around 1998, the IEC and several other standards and trade organizations attempted to address the ambiguity by publishing standards and recommendations for a set of binary prefixes that refer exclusively to powers of 1024."
trade organizations attempted,"Starting around 1998, the IEC and several other standards and trade organizations attempted to address the ambiguity by publishing standards and recommendations for a set of binary prefixes that refer exclusively to powers of 1024."
binary prefixes kibi,"In 1998, the International Electrotechnical Commission IEC introduced the binary prefixes kibi, mebi, gibi ."
international electrotechnical commission iec introduced,"In 1998, the International Electrotechnical Commission IEC introduced the binary prefixes kibi, mebi, gibi ."
customary binary prefixes show,The cylinder count of 306 is not conveniently close to any power of 1024; operating systems and programs using the customary binary prefixes show this as 9.
cylinder count,The cylinder count of 306 is not conveniently close to any power of 1024; operating systems and programs using the customary binary prefixes show this as 9.
conveniently close,The cylinder count of 306 is not conveniently close to any power of 1024; operating systems and programs using the customary binary prefixes show this as 9.
programs using,The cylinder count of 306 is not conveniently close to any power of 1024; operating systems and programs using the customary binary prefixes show this as 9.
previous versions,(Previous versions of Mac OS X used binary prefixes. )
mac os x used binary prefixes,(Previous versions of Mac OS X used binary prefixes. )
input exactly,"In computing, a one-pass algorithm or single-pass algorithm is a streaming algorithm which reads its input exactly once."
pass algorithm,"An example of a one-pass algorithm is the Sondik partially observable Markov decision process. !! In computing, a one-pass algorithm or single-pass algorithm is a streaming algorithm which reads its input exactly once."
pass algorithm generally requires,"A one-pass algorithm generally requires O(n) (see 'big O' notation) time and less than O(n) storage (typically O(1)), where n is the size of the input."
pass algorithms,The two-pass algorithms above are still streaming algorithms but not one-pass algorithms.
still streaming algorithms,The two-pass algorithms above are still streaming algorithms but not one-pass algorithms.
integral domain,"In mathematics, a square-free polynomial is a polynomial defined over a field (or more generally, an integral domain) that does not have as a divisor any square of a non-constant polynomial."
polynomial defined,"In mathematics, a square-free polynomial is a polynomial defined over a field (or more generally, an integral domain) that does not have as a divisor any square of a non-constant polynomial."
free polynomial,"In mathematics, a square-free polynomial is a polynomial defined over a field (or more generally, an integral domain) that does not have as a divisor any square of a non-constant polynomial. !! This motivates that, in applications in physics and engineering, a square-free polynomial is commonly called a polynomial with no repeated roots."
repeated roots,"This motivates that, in applications in physics and engineering, a square-free polynomial is commonly called a polynomial with no repeated roots."
commonly called,"This motivates that, in applications in physics and engineering, a square-free polynomial is commonly called a polynomial with no repeated roots."
pairwise coprime square,"where those of the ak that are non-constant are pairwise coprime square-free polynomials (here, two polynomials are said coprime is their greatest common divisor is a constant; in other words that is the coprimality over the field of fractions of the coefficients that is considered)."
free polynomials,"where those of the ak that are non-constant are pairwise coprime square-free polynomials (here, two polynomials are said coprime is their greatest common divisor is a constant; in other words that is the coprimality over the field of fractions of the coefficients that is considered)."
two polynomials,"where those of the ak that are non-constant are pairwise coprime square-free polynomials (here, two polynomials are said coprime is their greatest common divisor is a constant; in other words that is the coprimality over the field of fractions of the coefficients that is considered)."
said coprime,"where those of the ak that are non-constant are pairwise coprime square-free polynomials (here, two polynomials are said coprime is their greatest common divisor is a constant; in other words that is the coprimality over the field of fractions of the coefficients that is considered)."
computerized system composed,"A multi-agent system (MAS or ""self-organized system"") is a computerized system composed of multiple interacting intelligent agents."
agent system,"Despite considerable overlap, a multi-agent system is not always the same as an agent-based model (ABM). !! A multi-agent system (MAS or ""self-organized system"") is a computerized system composed of multiple interacting intelligent agents."
organized system,"A multi-agent system (MAS or ""self-organized system"") is a computerized system composed of multiple interacting intelligent agents."
agent systems,"Agent-based modeling is related to, but distinct from, the concept of multi-agent systems or multi-agent simulation in that the goal of ABM is to search for explanatory insight into the collective behavior of agents obeying simple rules, typically in natural systems, rather than in designing agents or solving specific practical or engineering problems. !! Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a monolithic system to solve."
individual agent,Multi-agent systems can solve problems that are difficult or impossible for an individual agent or a monolithic system to solve.
based model,"Despite considerable overlap, a multi-agent system is not always the same as an agent-based model (ABM). !! An agent-based model (ABM) is a computational model for simulating the actions and interactions of autonomous agents (both individual or collective entities such as organizations or groups) in order to understand the behavior of a system and what governs its outcomes."
despite considerable overlap,"Despite considerable overlap, a multi-agent system is not always the same as an agent-based model (ABM)."
agent systems research may deliver,"Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling."
appropriate approach include online trading,"Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling."
disaster response,"Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling."
target surveillance,"Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling."
social structure modelling,"Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling."
agent systems consist,Multi-agent systems consist of agents and their environment.
application compatibility layers,Windows's application compatibility layers to attempt to run poorly written applications or those written for earlier versions of the platform.
run poorly written applications,Windows's application compatibility layers to attempt to run poorly written applications or those written for earlier versions of the platform.
compatibility layers,Windows's application compatibility layers to attempt to run poorly written applications or those written for earlier versions of the platform. !! Some hardware compatibility layers involve breakout boxes because breakout boxes can provide compatibility for certain computer buses that are otherwise incompatible with the machine. !! Hardware compatibility layers involve tools that allow hardware emulation.
earlier versions,"Windows's application compatibility layers to attempt to run poorly written applications or those written for earlier versions of the platform. !! A standard supports forward compatibility if a product that complies with earlier versions can ""gracefully"" process input designed for later versions of the standard, ignoring new parts which it does not understand."
allow hardware emulation,Hardware compatibility layers involve tools that allow hardware emulation.
hardware compatibility layers involve tools,Hardware compatibility layers involve tools that allow hardware emulation.
certain computer buses,Some hardware compatibility layers involve breakout boxes because breakout boxes can provide compatibility for certain computer buses that are otherwise incompatible with the machine.
breakout boxes,Some hardware compatibility layers involve breakout boxes because breakout boxes can provide compatibility for certain computer buses that are otherwise incompatible with the machine.
otherwise incompatible,Some hardware compatibility layers involve breakout boxes because breakout boxes can provide compatibility for certain computer buses that are otherwise incompatible with the machine.
provide compatibility,Some hardware compatibility layers involve breakout boxes because breakout boxes can provide compatibility for certain computer buses that are otherwise incompatible with the machine.
quantum machine learning utilizes qubits,"While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program."
data storage done,"While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program."
compute immense quantities,"While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program."
specialized quantum systems,"While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program."
improve computational speed,"While machine learning algorithms are used to compute immense quantities of data, quantum machine learning utilizes qubits and quantum operations or specialized quantum systems to improve computational speed and data storage done by algorithms in a program."
phase transitions,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
creating new quantum experiments,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
classical machine learning methods applied,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
quantum experiments,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
beyond quantum computing,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
also associated,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
quantum systems,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
data generated,"Beyond quantum computing, the term ""quantum machine learning"" is also associated with classical machine learning methods applied to data generated from quantum experiments (i. e. machine learning of quantum systems), such as learning the phase transitions of a quantum system or creating new quantum experiments."
structural similarities,"Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks."
learning systems,"Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks."
quantum machine learning also extends,"Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks."
particular neural networks,"Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks."
explores methodological,"Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks."
certain physical systems,"Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks."
scale universal quantum computer,"While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices."
many proposals,"While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices."
quantum machine learning algorithms,"While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices."
special purpose quantum devices,"While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices."
still purely theoretical,"While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices."
social semiotic system,"Systemic functional linguistics (SFL) is an approach to linguistics, among functional linguistics, that considers language as a social semiotic system."
among functional linguistics,"Systemic functional linguistics (SFL) is an approach to linguistics, among functional linguistics, that considers language as a social semiotic system."
considers language,"Systemic functional linguistics (SFL) is an approach to linguistics, among functional linguistics, that considers language as a social semiotic system."
avoid confusion,"To avoid confusion, the full designationsystemic functional linguisticsis typically used, rather than functional grammar or functional linguistics."
functional linguistics,"To avoid confusion, the full designationsystemic functional linguisticsis typically used, rather than functional grammar or functional linguistics."
functional grammar,"To avoid confusion, the full designationsystemic functional linguisticsis typically used, rather than functional grammar or functional linguistics."
defining aspect,"As the name suggests, the notion of system is a defining aspect of systemic functional linguistics."
name suggests,"As the name suggests, the notion of system is a defining aspect of systemic functional linguistics."
general 20th,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
smaller components,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
century reaction,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
sought within smaller,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
atomistic approaches,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
system perspective,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
trinocular perspective,"In systemic functional linguistics, this has been described as the trinocular perspective."
connectionist representations,Global Information Network Architecture (GINA) is a software framework that bridges the symbolic and the connectionist representations of the world through executable conceptual models.
executable conceptual models,Global Information Network Architecture (GINA) is a software framework that bridges the symbolic and the connectionist representations of the world through executable conceptual models.
global information network architecture,Global Information Network Architecture (GINA) is a software framework that bridges the symbolic and the connectionist representations of the world through executable conceptual models.
models applicable,Meta-process modeling is a type of metamodeling used in software engineering and systems engineering for the analysis and construction of models applicable and useful to some predefined problems.
process modeling,Meta-process modeling is a type of metamodeling used in software engineering and systems engineering for the analysis and construction of models applicable and useful to some predefined problems.
metamodeling used,Meta-process modeling is a type of metamodeling used in software engineering and systems engineering for the analysis and construction of models applicable and useful to some predefined problems.
predefined problems,Meta-process modeling is a type of metamodeling used in software engineering and systems engineering for the analysis and construction of models applicable and useful to some predefined problems.
creating flexible process models,Meta-process modeling supports the effort of creating flexible process models.
process modeling supports,Meta-process modeling supports the effort of creating flexible process models.
constructing process models,Meta-process modeling focuses on and supports the process of constructing process models.
process modeling focuses,Meta-process modeling focuses on and supports the process of constructing process models.
assumed probability distribution,"In statistics, maximum likelihood estimation (MLE) is a method of estimating the parameters of an assumed probability distribution, given some observed data."
largest likelihood,"Using maximum likelihood estimation, the coin that has the largest likelihood can be found, given the data that were observed."
using maximum likelihood estimation,"Using maximum likelihood estimation, the coin that has the largest likelihood can be found, given the data that were observed."
weakly normalizing,A rewriting system has the weak normalization property or is (weakly) normalizing (WN) if every object is weakly normalizing.
weak normalization property,"The pure untyped lambda calculus does not satisfy the strong normalization property, and not even the weak normalization property. !! A rewriting system has the weak normalization property or is (weakly) normalizing (WN) if every object is weakly normalizing."
normalization property,"The pure untyped lambda calculus does not satisfy the strong normalization property, and not even the weak normalization property. !! An abstract rewriting system is strongly normalizing, terminating, noetherian, or has the (strong) normalization property (SN), if each of its objects is strongly normalizing. !! Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks. !! A rewriting system has the weak normalization property or is (weakly) normalizing (WN) if every object is weakly normalizing. !! A lambda calculus system with the normalization property can be viewed as a programming language with the property that every program terminates."
rewriting system,A rewriting system has the weak normalization property or is (weakly) normalizing (WN) if every object is weakly normalizing.
strongly normalizing,"An abstract rewriting system is strongly normalizing, terminating, noetherian, or has the (strong) normalization property (SN), if each of its objects is strongly normalizing."
pure untyped lambda calculus,"The pure untyped lambda calculus does not satisfy the strong normalization property, and not even the weak normalization property."
strong normalization property,"The pure untyped lambda calculus does not satisfy the strong normalization property, and not even the weak normalization property."
every program terminates,A lambda calculus system with the normalization property can be viewed as a programming language with the property that every program terminates.
normalization property cannot,"Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks."
useful property,"Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks. !! The maximal nonlinearity means approximating a bent function by an affine (linear) function is hard, a useful property in the defense against linear cryptanalysis."
otherwise one could solve,"Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks."
program type,"Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks."
stochastic interpretation,Stochastic quantum mechanics (or the stochastic interpretation) is an interpretation of quantum mechanics.
called stochastic electrodynamics,Stochastic quantum mechanics can be applied to the field of electrodynamics and is called stochastic electrodynamics (SED).
eliminates expressions,"In compiler theory, partial redundancy elimination (PRE) is a compiler optimization that eliminates expressions that are redundant on some but not necessarily all paths through a program."
simple algorithm,"Paleri, V. K. , Srikant, Y. N. , and Shankar, P. A Simple Algorithm for Partial Redundancy Elimination."
computer science vol,"VanDrunen, T. , and Hosking, A. L. Value-Based Partial Redundancy Elimination, Lecture Notes in Computer Science Vol."
based partial redundancy elimination,"Cai, Q. and Xue, J. Optimal and Efficient Speculation-Based Partial Redundancy Elimination"". !! VanDrunen, T. , and Hosking, A. L. Value-Based Partial Redundancy Elimination, Lecture Notes in Computer Science Vol."
efficient speculation,"Cai, Q. and Xue, J. Optimal and Efficient Speculation-Based Partial Redundancy Elimination""."
place stable sorting,"Block sort, or block merge sort, is a sorting algorithm combining at least two merge operations with an insertion sort to arrive at O(n log n) in-place stable sorting."
least two merge operations,"Block sort, or block merge sort, is a sorting algorithm combining at least two merge operations with an insertion sort to arrive at O(n log n) in-place stable sorting."
sorting algorithm combining,"Block sort, or block merge sort, is a sorting algorithm combining at least two merge operations with an insertion sort to arrive at O(n log n) in-place stable sorting."
sort merges pairs,"The outer loop of block sort is identical to a bottom-up merge sort, where each level of the sort merges pairs of subarrays, A and B, in sizes of 1, then 2, then 4, 8, 16, and so on, until both subarrays combined are the array itself."
subarrays combined,"The outer loop of block sort is identical to a bottom-up merge sort, where each level of the sort merges pairs of subarrays, A and B, in sizes of 1, then 2, then 4, 8, 16, and so on, until both subarrays combined are the array itself."
last position,"Block sort uses two variants: one which finds the first position to insert a value in the sorted array, and one which finds the last position."
first position,"Block sort uses two variants: one which finds the first position to insert a value in the sorted array, and one which finds the last position."
block sort uses two variants,"Block sort uses two variants: one which finds the first position to insert a value in the sorted array, and one which finds the last position."
previously stated,"As previously stated, the outer loop of a block sort is identical to a bottom-up merge sort."
every level,"After repeating these steps for every level of the bottom-up merge sort, the block sort is completed."
step refinement process,Low-level design (LLD) is a component-level design process that follows a step-by-step refinement process.
level design,"Low-level design (LLD) is a component-level design process that follows a step-by-step refinement process. !! Documenting software architecture facilitates communication between stakeholders, captures early decisions about the high-level design, and allows reuse of design components between projects. !! Low-level design is created based on the high-level design."
level design process,Low-level design (LLD) is a component-level design process that follows a step-by-step refinement process.
hipo diagrams typify,Detailed or low-level designStructured flow charts and HIPO diagrams typify the class of software design tools and these provide a high-level overview of a program.
level overview,Detailed or low-level designStructured flow charts and HIPO diagrams typify the class of software design tools and these provide a high-level overview of a program.
level designstructured flow charts,Detailed or low-level designStructured flow charts and HIPO diagrams typify the class of software design tools and these provide a high-level overview of a program.
software design tools,Detailed or low-level designStructured flow charts and HIPO diagrams typify the class of software design tools and these provide a high-level overview of a program.
level design document,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document. !! The goal of LLD or a low-level design document (LLDD) is to give the internal logical design of the actual program code.
actual program code,The goal of LLD or a low-level design document (LLDD) is to give the internal logical design of the actual program code.
internal logical design,The goal of LLD or a low-level design document (LLDD) is to give the internal logical design of the actual program code.
created based,Low-level design is created based on the high-level design.
good low,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
proper analysis,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
program easy,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
level design document makes,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
specific computing result  usually,"Computer programming is the process of performing a particular computation (or more generally, accomplishing a specific computing result), usually by designing/building an executable computer program."
particular computation,"Computer programming is the process of performing a particular computation (or more generally, accomplishing a specific computing result), usually by designing/building an executable computer program."
executable computer program,"Computer programming is the process of performing a particular computation (or more generally, accomplishing a specific computing result), usually by designing/building an executable computer program."
control flow,"In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code. !! In computer science, control-flow analysis (CFA) is a static-code-analysis technique for determining the control flow of a program."
readability refers,"In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code."
human reader,"In computer programming, readability refers to the ease with which a human reader can comprehend the purpose, control flow, and operation of source code."
largely concerned,The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
engineering practice,The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
given class,The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
academic field,The academic field and the engineering practice of computer programming are both largely concerned with discovering and implementing the most efficient algorithms for a given class of problems.
algorithms etc,languages of the Microsoft Visual Studio IDE are not visual programming languages: the representation of algorithms etc.
microsoft visual studio ide,languages of the Microsoft Visual Studio IDE are not visual programming languages: the representation of algorithms etc.
implemented using graph grammars,Parsers for visual programming languages can be implemented using graph grammars.
notable visual programming languages,The following contains a list of notable visual programming languages.
following contains,The following contains a list of notable visual programming languages.
graph visual programming languages,Godot game engine allows game scripts and graphics shaders to be built using node-graph visual programming languages.
built using node,Godot game engine allows game scripts and graphics shaders to be built using node-graph visual programming languages.
simply boilerplate,"In computer programming, boilerplate code, or simply boilerplate, are sections of code that are repeated in multiple places with little to no variation."
multiple places,"In computer programming, boilerplate code, or simply boilerplate, are sections of code that are repeated in multiple places with little to no variation."
using languages,"When using languages that are considered verbose, the programmer must write a lot of boilerplate code to accomplish only minor functionality."
minor functionality,"When using languages that are considered verbose, the programmer must write a lot of boilerplate code to accomplish only minor functionality."
considered verbose,"When using languages that are considered verbose, the programmer must write a lot of boilerplate code to accomplish only minor functionality."
programmer must write,"When using languages that are considered verbose, the programmer must write a lot of boilerplate code to accomplish only minor functionality."
level mechanisms,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
needed boilerplate code,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
every project,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
provides good default values,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
compile time  convention,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
uses models,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
specify program details,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
computer automatically write,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
manual boilerplate code,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
code generators,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
driven engineering,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
computer interaction research,"Hands-on computing is a branch of human-computer interaction research which focuses on computer interfaces that respond to human touch or expression, allowing the machine and the user to interact physically."
hands-on computing,"Hands-on computing can make complicated computer tasks more natural to users by attempting to respond to motions and interactions that are natural to human behavior. !! Hands-on computing is a branch of human-computer interaction research which focuses on computer interfaces that respond to human touch or expression, allowing the machine and the user to interact physically. !! Thus hands-on computing is a component of user-centered design, focusing on how users physically respond to virtual environments. !! New developments in hands-on computing have led to the creation of interfaces that can respond to gestures and facial signaling. !! Keyboards and typewriters are some of the earliest hands-on computing devices."
interact physically,"Hands-on computing is a branch of human-computer interaction research which focuses on computer interfaces that respond to human touch or expression, allowing the machine and the user to interact physically."
human touch,"Hands-on computing is a branch of human-computer interaction research which focuses on computer interfaces that respond to human touch or expression, allowing the machine and the user to interact physically."
computer interfaces,"Hands-on computing is a branch of human-computer interaction research which focuses on computer interfaces that respond to human touch or expression, allowing the machine and the user to interact physically."
human behavior,Hands-on computing can make complicated computer tasks more natural to users by attempting to respond to motions and interactions that are natural to human behavior.
make complicated computer tasks,Hands-on computing can make complicated computer tasks more natural to users by attempting to respond to motions and interactions that are natural to human behavior.
users physically respond,"Thus hands-on computing is a component of user-centered design, focusing on how users physically respond to virtual environments."
thus hands,"Thus hands-on computing is a component of user-centered design, focusing on how users physically respond to virtual environments."
earliest hands,Keyboards and typewriters are some of the earliest hands-on computing devices.
computing devices,A virtual private network (VPN) extends a private network across a public network and enables users to send and receive data across shared or public networks as if their computing devices were directly connected to the private network. !! Keyboards and typewriters are some of the earliest hands-on computing devices.
new developments,New developments in hands-on computing have led to the creation of interfaces that can respond to gestures and facial signaling.
facial signaling,New developments in hands-on computing have led to the creation of interfaces that can respond to gestures and facial signaling.
pickle standard library module,"The core general serialization mechanism is the pickle standard library module, alluding to the database systems term pickling to describe data serialization (unpickling for deserializing)."
describe data serialization,"The core general serialization mechanism is the pickle standard library module, alluding to the database systems term pickling to describe data serialization (unpickling for deserializing)."
database systems term pickling,"The core general serialization mechanism is the pickle standard library module, alluding to the database systems term pickling to describe data serialization (unpickling for deserializing)."
core general serialization mechanism,"The core general serialization mechanism is the pickle standard library module, alluding to the database systems term pickling to describe data serialization (unpickling for deserializing)."
rprotobuf provides cross,"RProtoBuf provides cross-language data serialization in R, using Protocol Buffers."
using protocol buffers,"RProtoBuf provides cross-language data serialization in R, using Protocol Buffers."
language data serialization,"RProtoBuf provides cross-language data serialization in R, using Protocol Buffers."
logistic distribution receives,"The logistic distribution receives its name from its cumulative distribution function, which is an instance of the family of logistic functions."
scaled version,The cumulative distribution function of the logistic distribution is also a scaled version of the hyperbolic tangent.
hyperbolic tangent,The cumulative distribution function of the logistic distribution is also a scaled version of the hyperbolic tangent.
quantile function,The inverse cumulative distribution function (quantile function) of the logistic distribution is a generalization of the logit function.
inverse cumulative distribution function,The inverse cumulative distribution function (quantile function) of the logistic distribution is a generalization of the logit function.
logit function,The inverse cumulative distribution function (quantile function) of the logistic distribution is a generalization of the logit function.
generating images,Computer graphics deals with generating images with the aid of computers.
computer graphics deals,Computer graphics deals with generating images with the aid of computers.
many specialized applications,"Today, computer graphics is a core technology in digital photography, film, video games, cell phone and computer displays, and many specialized applications."
core technology,"Today, computer graphics is a core technology in digital photography, film, video games, cell phone and computer displays, and many specialized applications."
cell phone,"Today, computer graphics is a core technology in digital photography, film, video games, cell phone and computer displays, and many specialized applications."
digital photography,"Today, computer graphics is a core technology in digital photography, film, video games, cell phone and computer displays, and many specialized applications."
great deal,"A great deal of specialized hardware and software has been developed, with the displays of most devices being driven by computer graphics hardware."
computer graphics hardware,"A great deal of specialized hardware and software has been developed, with the displays of most devices being driven by computer graphics hardware."
specialized hardware,"Although no commercially successful general-purpose computer hardware has used a dataflow architecture, it has been successfully implemented in specialized hardware such as in digital signal processing, network routing, graphics processing, telemetry, and more recently in data warehousing, and artificial intelligence. !! A great deal of specialized hardware and software has been developed, with the displays of most devices being driven by computer graphics hardware."
computer graphics researchers verne hudson,The phrase was coined in 1960 by computer graphics researchers Verne Hudson and William Fetter of Boeing.
william fetter,The phrase was coined in 1960 by computer graphics researchers Verne Hudson and William Fetter of Boeing.
artistic aspects,The non-artistic aspects of computer graphics are the subject of computer science research.
multiple definitions,The term dead code has multiple definitions.
term dead code,The term dead code has multiple definitions.
dead code,"In some areas of computer programming, dead code is a section in the source code of a program which is executed but whose result is never used in any other computation. !! The execution of dead code wastes computation time and memory. !! The term dead code has multiple definitions. !! Compiler optimizations are typically conservative in their approach to dead code removal if there is any ambiguity as to whether removal of the dead code will affect the program output. !! Therefore, the removal of the dead code may change the output of the program."
never used,"In some areas of computer programming, dead code is a section in the source code of a program which is executed but whose result is never used in any other computation."
whose result,"In some areas of computer programming, dead code is a section in the source code of a program which is executed but whose result is never used in any other computation."
dead code wastes computation time,The execution of dead code wastes computation time and memory.
program output,Compiler optimizations are typically conservative in their approach to dead code removal if there is any ambiguity as to whether removal of the dead code will affect the program output.
whether removal,Compiler optimizations are typically conservative in their approach to dead code removal if there is any ambiguity as to whether removal of the dead code will affect the program output.
typically conservative,Compiler optimizations are typically conservative in their approach to dead code removal if there is any ambiguity as to whether removal of the dead code will affect the program output.
dead code may change,"Therefore, the removal of the dead code may change the output of the program."
shanks transformation,"In numerical analysis, the Shanks transformation is a non-linear series acceleration method to increase the rate of convergence of a sequence. !! The generalized Shanks transformation is closely related to Pad approximants and Pad tables. !! Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums. !! The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate. !! the above expression for the kth-order Shanks transformation is obtained."
linear series acceleration method,"In numerical analysis, the Shanks transformation is a non-linear series acceleration method to increase the rate of convergence of a sequence."
partial sums,"Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums. !! The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate."
shanks transformation operates,"Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums."
usually thought,"Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums."
shanks transformation operate,"Both Aitken's method and the Shanks transformation operate on a sequence, but the sequence the Shanks transformation operates on is usually thought of as being a sequence of partial sums, although any sequence may be viewed as a sequence of partial sums."
right shows,"The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate."
shanks transformation results,"The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate."
clearly showing,"The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate."
improved accuracy,"The figure to the right shows the absolute error for the partial sums and Shanks transformation results, clearly showing the improved accuracy and convergence rate."
order shanks transformation,the above expression for the kth-order Shanks transformation is obtained.
pad approximants,The generalized Shanks transformation is closely related to Pad approximants and Pad tables.
pad tables,The generalized Shanks transformation is closely related to Pad approximants and Pad tables.
generalized shanks transformation,The generalized Shanks transformation is closely related to Pad approximants and Pad tables.
finite alphabet,Truncated binary encoding is an entropy encoding typically used for uniform probability distributions with a finite alphabet.
entropy encoding typically used,Truncated binary encoding is an entropy encoding typically used for uniform probability distributions with a finite alphabet.
truncated binary encoding assigns,"Truncated binary encoding assigns the first u symbols the codewords 00, 01, and 10, all of length 2, then assigns the last n - u symbols the codewords 110 and 111, the last two codewords of length 3. !! Truncated binary encoding assigns the first u symbols codewords of length k and then assigns the remaining n - u symbols the last n - u codewords of length k + 1."
first u symbols codewords,Truncated binary encoding assigns the first u symbols codewords of length k and then assigns the remaining n - u symbols the last n - u codewords of length k + 1.
first u symbols,"Truncated binary encoding assigns the first u symbols the codewords 00, 01, and 10, all of length 2, then assigns the last n - u symbols the codewords 110 and 111, the last two codewords of length 3."
last two codewords,"Truncated binary encoding assigns the first u symbols the codewords 00, 01, and 10, all of length 2, then assigns the last n - u symbols the codewords 110 and 111, the last two codewords of length 3."
truncated binary encoding allocates,"For example, if n is 5, plain binary encoding and truncated binary encoding allocates the following codewords."
following codewords,"For example, if n is 5, plain binary encoding and truncated binary encoding allocates the following codewords."
plain binary encoding,"For example, if n is 5, plain binary encoding and truncated binary encoding allocates the following codewords."
3d sound localization technology,3D sound reconstruction is the application of reconstruction techniques to 3D sound localization technology.
3d sound reconstruction,3D sound reconstruction is the application of reconstruction techniques to 3D sound localization technology.
reconstruction techniques,3D sound reconstruction is the application of reconstruction techniques to 3D sound localization technology.
sound reconstruction,3D sound reconstruction is the application of reconstruction techniques to 3D sound localization technology.
procedure call,"In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction."
another computer,"In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction."
different address space,"In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction."
computer program causes,"In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction."
programmer explicitly coding,"In distributed computing, a remote procedure call (RPC) is when a computer program causes a procedure (subroutine) to execute in a different address space (commonly on another computer on a shared network), which is coded as if it were a normal (local) procedure call, without the programmer explicitly coding the details for the remote interaction."
requestresponse protocols date,"Requestresponse protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s."
early distributed computing,"Requestresponse protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s."
practical implementations date,"Requestresponse protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s."
network operations date,"Requestresponse protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s."
theoretical proposals,"Requestresponse protocols date to early distributed computing in the late 1960s, theoretical proposals of remote procedure calls as the model of network operations date to the 1970s, and practical implementations date to the early 1980s."
generally credited,"Bruce Jay Nelson is generally credited with coining the term ""remote procedure call"" in 1981."
bruce jay nelson,"Bruce Jay Nelson is generally credited with coining the term ""remote procedure call"" in 1981."
roots back,"Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system, which used a request-response communication protocol for process synchronization."
remote procedure calls used,"Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system, which used a request-response communication protocol for process synchronization."
modern operating systems trace,"Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system, which used a request-response communication protocol for process synchronization."
rc 4000 multiprogramming system,"Remote procedure calls used in modern operating systems trace their roots back to the RC 4000 multiprogramming system, which used a request-response communication protocol for process synchronization."
treating network operations,The idea of treating network operations as remote procedure calls goes back at least to the 1970s in early ARPANET documents.
remote procedure calls goes back,The idea of treating network operations as remote procedure calls goes back at least to the 1970s in early ARPANET documents.
early arpanet documents,The idea of treating network operations as remote procedure calls goes back at least to the 1970s in early ARPANET documents.
broadcast radiation,A broadcast storm or broadcast radiation is the accumulation of broadcast and multicast traffic on a computer network.
multicast traffic,A broadcast storm or broadcast radiation is the accumulation of broadcast and multicast traffic on a computer network.
broadcast storm,"Extreme amounts of broadcast traffic constitute a ""broadcast storm"". !! In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host. !! Routers and firewalls can be configured to detect and prevent maliciously inducted broadcast storms (e. g. due to a magnification attack). !! Broadcast storm control is a feature of many managed switches in which the switch intentionally ceases to forward all broadcast traffic if the bandwidth consumed by incoming broadcast frames exceeds a designated threshold. !! A broadcast storm or broadcast radiation is the accumulation of broadcast and multicast traffic on a computer network."
broadcast traffic constitute,"Extreme amounts of broadcast traffic constitute a ""broadcast storm""."
extreme amounts,"Extreme amounts of broadcast traffic constitute a ""broadcast storm""."
icmp echo packet containing,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
packet amplification attacks,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
using one,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
spoof source address,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
victim host,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
attacker sends,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host. !! In computer networking, ARP spoofing, ARP cache poisoning, or ARP poison routing, is a technique by which an attacker sends (spoofed) Address Resolution Protocol (ARP) messages onto a local area network."
icmp echo requests,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
fraggle attack,"In some cases, a broadcast storm can be instigated for the purpose of a denial of service (DOS) using one of the packet amplification attacks, such as the smurf attack or fraggle attack, where an attacker sends a large amount of ICMP Echo Requests (ping) traffic to a broadcast address, with each ICMP Echo packet containing the spoof source address of the victim host."
prevent maliciously inducted broadcast storms,Routers and firewalls can be configured to detect and prevent maliciously inducted broadcast storms (e. g. due to a magnification attack).
bandwidth consumed,Broadcast storm control is a feature of many managed switches in which the switch intentionally ceases to forward all broadcast traffic if the bandwidth consumed by incoming broadcast frames exceeds a designated threshold.
many managed switches,Broadcast storm control is a feature of many managed switches in which the switch intentionally ceases to forward all broadcast traffic if the bandwidth consumed by incoming broadcast frames exceeds a designated threshold.
incoming broadcast frames exceeds,Broadcast storm control is a feature of many managed switches in which the switch intentionally ceases to forward all broadcast traffic if the bandwidth consumed by incoming broadcast frames exceeds a designated threshold.
designated threshold,Broadcast storm control is a feature of many managed switches in which the switch intentionally ceases to forward all broadcast traffic if the bandwidth consumed by incoming broadcast frames exceeds a designated threshold.
switch intentionally ceases,Broadcast storm control is a feature of many managed switches in which the switch intentionally ceases to forward all broadcast traffic if the bandwidth consumed by incoming broadcast frames exceeds a designated threshold.
metaphorical software robots,Robotic process automation (RPA) is a form of business process automation technology based on metaphorical software robots (bots) or on artificial intelligence (AI)/digital workers.
business process automation technology based,Robotic process automation (RPA) is a form of business process automation technology based on metaphorical software robots (bots) or on artificial intelligence (AI)/digital workers.
explicit state space exploration,"In explicit state space exploration, partial order reduction usually refers to the specific technique of expanding a representative subset of all enabled transitions."
basic linguistic assumption,The basic linguistic assumption of proximity searching is that the proximity of the words in a document implies a relationship between the words.
inefficient algorithm,Algorithm analysis is important in practice because the accidental or unintentional use of an inefficient algorithm can significantly impact system performance.
particular data analysis technique,"Data mining is a particular data analysis technique that focuses on statistical modelling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information."
bit output block,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
size n bits,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
two paired algorithms,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
nested recursively inside larger problems,"If sub-problems can be nested recursively inside larger problems, so that dynamic programming methods are applicable, then there is a relation between the value of the larger problem and the values of the sub-problems."
larger problem,"If sub-problems can be nested recursively inside larger problems, so that dynamic programming methods are applicable, then there is a relation between the value of the larger problem and the values of the sub-problems."
experimental scientific simulations,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
internal possibility distribution,A Random-fuzzy variable can be constructed using an Internal possibility distribution(rinternal) and a random possibility distribution(rrandom).
designing autonomous services,The service autonomy principle attempts to provide guidelines for designing autonomous services so that the resulting services are more predictable and reliable.
multiple programs,"In computer science, shared memory is memory that may be simultaneously accessed by multiple programs with an intent to provide communication among them or avoid redundant copies."
several different central processing units,"In computer hardware, shared memory refers to a (typically large) block of random access memory (RAM) that can be accessed by several different central processing units (CPUs) in a multiprocessor computer system."
original representation,Autoencoders can be used to learn nonlinear dimension reduction functions and codings together with an inverse function from the coding to the original representation.
dimension space,"Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space."
pca  linear discriminant analysis,"Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space."
lda  canonical correlation analysis,"Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space."
generic model,An algorithmic paradigm or algorithm design paradigm is a generic model or framework which underlies the design of a class of algorithms.
query technique,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
search query,"Reverse image search is a content-based image retrieval (CBIR) query technique that involves providing the CBIR system with a sample image that it will then base its search upon; in terms of information retrieval, the sample image is what formulates a search query."
search terms,"In particular, reverse image search is characterized by a lack of search terms."
particular singular value decomposition,This particular singular value decomposition is not unique.
valid singular value decomposition,is also a valid singular value decomposition.
bittorrent file,The Cache Discovery Protocol (CDP) is an extension to the BitTorrent file-distribution system.
projection process,This section explains the actual geo warping or re-projection process when applied to radar video in real time.
digital aspect,""":xxvii,30 Beyond the digital aspect, interaction design is also useful when creating physical (non-digital) products, exploring how a user might interact with it."
computationally efficient,Generative training algorithms are often simpler and more computationally efficient than discriminative training algorithms.
stronger memory color effect,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
time reduction,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions. !! In computational complexity theory, a polynomial-time reduction is a method for solving one problem using another."
time reductions,Polynomial-time reductions are frequently used in complexity theory for defining both complexity classes and complete problems for those classes.
turing reductions,"The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
single binary operation,"For example, in a signature consisting of a single binary operation, the term algebra over a set X of variables is exactly the free magma generated by X."
function interaction,"Use of hash functions relies on statistical properties of key and function interaction: worst-case behaviour is intolerably bad with a vanishingly small probability, and average-case behaviour can be nearly optimal (minimal collision)."
sibling calls,Sibling calls do not appear in a stack trace.
hurwitz stable,Hadamard product: The Hadamard (coefficient-wise) product of two Hurwitz stable polynomials is again Hurwitz stable.
hadamard product,"If A and B are each real-valued matrices, the Frobenius inner product is the sum of the entries of the Hadamard product. !! Hadamard product: The Hadamard (coefficient-wise) product of two Hurwitz stable polynomials is again Hurwitz stable."
categorical label,"In machine learning, sequence labeling is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values."
known classes,Difference in genetic representations is one of the major criteria drawing a line between known classes of evolutionary computation.
global solutions,"Deterministic global optimization is a branch of numerical optimization which focuses on finding the global solutions of an optimization problem whilst providing theoretical guarantees that the reported solution is indeed the global one, within some predefined tolerance."
internet protocol suite,"In the Internet Protocol Suite (TCP/IP), the data link layer functionality is contained within the link layer, the lowest layer of the descriptive model, which is assumed to be independent of physical infrastructure. !! The Internet Protocol (IP) is the network layer communications protocol in the Internet protocol suite for relaying datagrams across network boundaries. !! The Internet protocol suite is therefore often referred to as TCP/IP. !! The Internet Control Message Protocol (ICMP) is a supporting protocol in the Internet protocol suite. !! The Common Open Policy Service (COPS) Protocol is part of the internet protocol suite as defined by the RFC 2748. !! The network architecture of the Internet is predominantly expressed by its use of the Internet protocol suite, rather than a specific model for interconnecting networks or nodes in the network, or the usage of specific types of hardware links."
learning vector quantization,"See the 'Bibliography on the Self-Organizing Map (SOM) and Learning Vector Quantization (LVQ)'. !! In computer science, learning vector quantization (LVQ) is a prototype-based supervised classification algorithm. !! Self-Organizing Maps and Learning Vector Quantization for Feature Sequences, Somervuo and Kohonen."
nm matrix,"In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM."
situ matrix transposition,"In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM."
n log n comparisons,"Comparison sorting algorithms have a fundamental requirement of (n log n) comparisons (some input sequences will require a multiple of n log n comparisons, where n is the number of elements in the array to be sorted)."
time delays,Matlab: The neural network toolbox has explicit functionality designed to produce a time delay neural network give the step size of time delays and an optional training function.
traditional artificial intelligence,Behavior-based robotics sets itself apart from traditional artificial intelligence by using biological systems as a model. !! Bio-Inspired computing can be distinguished from traditional artificial intelligence by its approach to computer learning.
file overwrites,"Runtime error detection can identify defects that manifest themselves only at runtime (for example, file overwrites) and zeroing in on the root causes of the application crashing, running slowly, or behaving unpredictably."
unlabeled data,"Manifold regularization algorithms can extend supervised learning algorithms in semi-supervised learning and transductive learning settings, where unlabeled data are available. !! Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. !! Semi-supervised learning combines this information to surpass the classification performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning."
labeled data,Semi-supervised learning is an approach to machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training.
support vectors,"This extends the geometric interpretation of SVMfor linear classification, the empirical risk is minimized by any function whose margins lie between the support vectors, and the simplest of these is the max-margin classifier. !! The support-vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data."
simple directed graphs,"More specifically, directed graphs without loops are addressed as simple directed graphs, while directed graphs with loops are addressed as loop-digraphs (see section Types of directed graphs)."
render could,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
microsoft windows,"Windows Media is a discontinued multimedia framework for media creation and distribution for Microsoft Windows. !! In computing, Dynamic Data Exchange (DDE) is a technology for interprocess communication used in early versions of Microsoft Windows and OS/2. !! MKS Toolkit is a software package produced and maintained by PTC that provides a Unix-like environment for scripting, connectivity and porting Unix and Linux software to Microsoft Windows. !! The dominant general-purpose personal computer operating system is Microsoft Windows with a market share of around 76. !! Symantec Workspace Virtualization (abbreviated as SWV) is an application virtualization solution for Microsoft Windows by Symantec, now known as Symantec Endpoint Virtualization Suite (SEVS)."
windows media sdk,The Windows Media SDK was replaced by Media Foundation when Windows Vista was released.
prolog iii,"The first implementations of constraint logic programming were Prolog III, CLP(R), and CHIP."
modified form,"It is becoming increasingly common to use a general purpose graphics processing unit (GPGPU) as a modified form of stream processor (or a vector processor), running compute kernels."
compress raw images,"Lossless JPEG has some popularity in medical imaging, and is used in DNG and some digital cameras to compress raw images, but otherwise was never widely adopted."
functional principle,"The functional principle is similar to the one SDL Trados, XTM and memoQ feature: Just like the server solutions of these two programs, Across Language Server also saves translation units or terminology entries (depending on the project's configuration) into a local or a central MSSQL database."
terminology entries,"The functional principle is similar to the one SDL Trados, XTM and memoQ feature: Just like the server solutions of these two programs, Across Language Server also saves translation units or terminology entries (depending on the project's configuration) into a local or a central MSSQL database."
generalized fibonacci polynomials,Divisibility properties of generalized Fibonacci Polynomials.
generalized lucas polynomials,Generalized Lucas polynomials and Fibonacci polynomials.
memory colors,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
canonical hues,This suggests that the memory color effect is related to the emergence of trichromacy because it has been argued that trichromacy evolved to optimize the ability to detect ripe fruitsobjects that appear in canonical hues.
two major failure modes,"In computer programming, primary clustering is one of two major failure modes of open addressing based hash tables, especially those using linear probing."
nondeterministic context,The languages of this class have great practical importance in computer science as they can be parsed much more efficiently than nondeterministic context-free languages.
common adversarial machine learning strategies,"The four most common adversarial machine learning strategies are evasion, poisoning, model stealing (extraction), and inference."
execute memory access instructions,Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order.
sizing optimization,"Topology optimization is different from shape optimization and sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations."
modern operating systems,"On modern operating systems with graphical user interfaces, error messages are often displayed using dialog boxes."
multiplicatively weighted voronoi diagram,"In a multiplicatively weighted Voronoi diagram, the distance between a point and a site is divided by the (positive) weight of the site. !! In the plane under the ordinary Euclidean distance, the multiplicatively weighted Voronoi diagram is also called circular Dirichlet tessellation and its edges are circular arcs and straight line segments."
ordinary euclidean distance,"In the plane under the ordinary Euclidean distance, the multiplicatively weighted Voronoi diagram is also called circular Dirichlet tessellation and its edges are circular arcs and straight line segments."
several minimum spanning trees,"There may be several minimum spanning trees of the same weight; in particular, if all the edge weights of a given graph are the same, then every spanning tree of that graph is minimum."
full instruction sets,"More complex definitions create abstract machines with full instruction sets, registers and models of memory."
gartners report notes,Gartners report notes that this trend was kicked off with robotic process automation (RPA).
code points represent essentially,Unicode equivalence is the specification by the Unicode character encoding standard that some sequences of code points represent essentially the same character.
large toolkit,"Since no single form of classification is appropriate for all data sets, a large toolkit of classification algorithms have been developed."
positive rates,"More recently, receiver operating characteristic (ROC) curves have been used to evaluate the tradeoff between true- and false-positive rates of classification algorithms."
model elements,"However, special-purpose model transformation languages can offer advantages, such as syntax that makes it easy to refer to model elements. !! A requirement diagram is a diagram specially used in SysML in which requirements and the relations between them and their relationship to other model elements are shown as discussed in the following paragraphs."
portland pattern repository,"Principle of Least Astonishment at Portland Pattern Repository !! Abstraction Inversion at Portland Pattern Repository - extensive discussion, much of it taking ""abstraction inversion"" in the sense of ""concealed complexity"" !! Proxy pattern description from the Portland Pattern Repository"
bad command or file name,"""Bad command or file name"" is a common and ambiguous error message in MS-DOS and some other operating systems."
bad command,"""Bad command or file name"" is a common and ambiguous error message in MS-DOS and some other operating systems."
ambiguous error message,"""Bad command or file name"" is a common and ambiguous error message in MS-DOS and some other operating systems."
flow min,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink. !! The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal. !! Max-flow min-cut theorem. !! The other half of the max-flow min-cut theorem refers to a different aspect of a network: the collection of cuts. !! In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
cut theorem states,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink. !! In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
smallest total weight,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink."
removed would disconnect,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink."
flow passing,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink."
total weight,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink."
monadic second,"In the study of graph algorithms, Courcelle's theorem is the statement that every graph property definable in the monadic second-order logic of graphs can be decided in linear time on graphs of bounded treewidth. !! Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2."
canonical example,A canonical example of a data-flow analysis is reaching definitions.
input locally,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
perform data,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
objective optimization,"Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. !! Reward-based selection can be used within Multi-armed bandit framework for Multi-objective optimization to obtain a better approximation of the Pareto front. !! Multi-objective optimization has been applied in many fields of science, including engineering, economics and logistics where optimal decisions need to be taken in the presence of trade-offs between two or more conflicting objectives. !! Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously."
multiple criteria decision making,"Multi-objective optimization (also known as multi-objective programming, vector optimization, multicriteria optimization, multiattribute optimization or Pareto optimization) is an area of multiple criteria decision making that is concerned with mathematical optimization problems involving more than one objective function to be optimized simultaneously."
systems sciences,"Since then research concerning anchor modeling is being done in a collaboration between the creators Olle Regardt and Lars Rnnbck and a team at the Department of Computer and Systems Sciences, Stockholm University."
asymptotically faster since,"Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
occurring subproducts,"Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
term summation,"Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
binary splitting requires,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors. !! Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
precision division,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors."
naive evaluation scheme,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors."
schnhagestrassen must,"To take full advantage of the scheme, fast multiplication algorithms such as ToomCook and SchnhageStrassen must be used; with ordinary O(n2) multiplication, binary splitting may render no speedup at all or be slower."
software design document,"A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
design document,"A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
recording design information,"A software design description (a. k. a. software design document or SDD; just design document; also Software Design Specification) is a representation of a software design that is to be used for recording design information, addressing various design concerns, and communicating that information to the designs stakeholders."
titled ieee standard,"IEEE 1016-2009, titled IEEE Standard for Information TechnologySystems DesignSoftware Design Descriptions, is an IEEE standard that specifies ""the required information content and organization"" for an SDD."
free network,"Depending on the parameters used in the optimization mechanism, the algorithm can build three types of networks: a star network, a random network, and a scale-free network."
power grid,"Optimization mechanism is thought to be the underlying mechanism in several real networks, such as transportation networks, power grid, router networks, the network of highways, etc."
transportation networks,"Optimization mechanism is thought to be the underlying mechanism in several real networks, such as transportation networks, power grid, router networks, the network of highways, etc."
learns patterns,Unsupervised learning is a type of algorithm that learns patterns from untagged data.
two broad methods,Two broad methods in Unsupervised Learning are Neural Networks and Probabilistic Methods.
donald hebb,"The classical example of unsupervised learning in the study of neural networks is Donald Hebb's principle, that is, neurons that fire together wire together."
chaos theory states,"Chaos theory states that within the apparent randomness of chaotic complex systems, there are underlying patterns, interconnectedness, constant feedback loops, repetition, self-similarity, fractals, and self-organization."
assembly processes,"The theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory, and self-assembly processes."
pel motion,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
qpel motion,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
motion estimation,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
motion compensation,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
luma sample positions,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
pixel motion,H. 264 decoders always support quarter-pixel motion. !! Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
pixel motion compensation,"Quarter-pixel motion compensation, much like half-pixel, is achieved through interpolation."
domain models,"Statistical relational learning (SRL) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure."
relational structure,"Statistical relational learning (SRL) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure. !! Avoiding redundancy eventually leads to proper ""Data hierarchy"" representing the relationship between data and revealing its relational structure."
order probabilistic languages,"Therefore, alternative terms that reflect the main foci of the field include statistical relational learning and reasoning (emphasizing the importance of reasoning) and first-order probabilistic languages (emphasizing the key properties of the languages with which models are represented)."
valuation function,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation. !! Furthermore, the international organizations such as the I. M. F. and the World Bank have independent evaluation functions."
international organizations,"Furthermore, the international organizations such as the I. M. F. and the World Bank have independent evaluation functions."
database dump,"Database dumps are often published by free content projects, to allow reuse or forking, as well as local searching of the database using tools such as grep. !! A database dump (also: SQL dump) contains a record of the table structure and/or the data from a database and is usually in the form of a list of SQL statements. !! A database dump is most often used for backing up a database so that its contents can be restored in the event of data loss."
database using tools,"Database dumps are often published by free content projects, to allow reuse or forking, as well as local searching of the database using tools such as grep."
deadlock basics,Deadlock Basics + Modelling + Ostrich Algorithm
support react,"To support React's concept of unidirectional data flow (which might be contrasted with AngularJS's bidirectional flow), the Flux architecture was developed as an alternative to the popular modelviewcontroller architecture."
ergodic system correspond,"For systems that obey the ergodic hypothesis, the evolution of one molecular dynamics simulation may be used to determine macroscopic thermodynamic properties of the system: the time averages of an ergodic system correspond to microcanonical ensemble averages."
nmr spectroscopy,"The results of MD simulations can be tested through comparison to experiments that measure molecular dynamics, of which a popular method is NMR spectroscopy."
experimental structure,"a central embarrassment of molecular mechanics, namely that energy minimization or molecular dynamics generally leads to a model that is less like the experimental structure. """
implemented molecular dynamics simulation,implemented molecular dynamics simulation to identify compounds that complement the receptor while causing minimal disruption of the conformation and flexibility of the active site.
active site,implemented molecular dynamics simulation to identify compounds that complement the receptor while causing minimal disruption of the conformation and flexibility of the active site.
causing minimal disruption,implemented molecular dynamics simulation to identify compounds that complement the receptor while causing minimal disruption of the conformation and flexibility of the active site.
particular language behavior,"Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
resource acquisition is initialization,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct. !! Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
less code,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
stroustrup wrote,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
resource acquisitions,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
realistic systems,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
comparing raii,"Comparing RAII with the finally construct used in Java, Stroustrup wrote that In realistic systems, there are far more resource acquisitions than kinds of resources, so the 'resource acquisition is initialization' technique leads to less code than use of a 'finally' construct."
application virtual machines,Application virtualization software refers to both application virtual machines and software responsible for implementing them.
software responsible,Application virtualization software refers to both application virtual machines and software responsible for implementing them.
application virtualization software refers,Application virtualization software refers to both application virtual machines and software responsible for implementing them.
competitive learning works,"A variant of Hebbian learning, competitive learning works by increasing the specialization of each node in the network."
simplify data management,"Third normal form (3NF) is a database schema design approach for relational databases which uses normalizing principles to reduce the duplication of data, avoid data anomalies, ensure referential integrity, and simplify data management."
functionally dependent,A database relation (e. g. a database table) is said to meet third normal form standards if all the attributes (e. g. database columns) are functionally dependent on solely the primary key.
hypothetical example,A hypothetical example of a failure to meet third normal form would be a hospital database having a table of patients which included a column for the telephone number of their doctor.
hospital database,A hypothetical example of a failure to meet third normal form would be a hospital database having a table of patients which included a column for the telephone number of their doctor.
compliant data model,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
sean malone,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
nist sha,"The SANDstorm hash is a cryptographic hash function designed in 2008 by Mark Torgerson, Richard Schroeppel, Tim Draelos, Nathan Dautenhahn, Sean Malone, Andrea Walker, Michael Collins, and Hilarie Orman for the NIST SHA-3 competition."
scale applications,"For this reason, ranking-based similarity learning is easier to apply in real large-scale applications."
based similarity learning,"For this reason, ranking-based similarity learning is easier to apply in real large-scale applications."
negative elements,"Non-negative matrix factorization (NMF or NNMF), also non-negative matrix approximation is a group of algorithms in multivariate analysis and linear algebra where a matrix V is factorized into (usually) two matrices W and H, with the property that all three matrices have no negative elements."
chemometrics non,"In chemometrics non-negative matrix factorization has a long history under the name ""self modeling curve resolution""."
based decomposition,In Learning the parts of objects by non-negative matrix factorization Lee and Seung proposed NMF mainly for parts-based decomposition of images.
rayleigh quotient corresponding,"Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration."
rayleigh quotient iteration,"Rayleigh quotient iteration is an eigenvalue algorithm which extends the idea of the inverse iteration by using the Rayleigh quotient to obtain increasingly accurate eigenvalue estimates. !! Rayleigh quotient iteration is an iterative method, that is, it delivers a sequence of approximate solutions that converges to a true solution in the limit. !! Typically, the method is used in combination with some other method which finds approximate eigenvalues: the standard example is the bisection eigenvalue algorithm, another example is the Rayleigh quotient iteration, which is actually the same inverse iteration with the choice of the approximate eigenvalue as the Rayleigh quotient corresponding to the vector obtained on the previous step of the iteration. !! The Rayleigh quotient iteration algorithm converges cubically for Hermitian or symmetric matrices, given an initial vector that is sufficiently close to an eigenvector of the matrix that is being analyzed."
biological neurons,"A neural network is a network or circuit of biological neurons, or, in a modern sense, an artificial neural network, composed of artificial neurons or nodes. !! Thus, a neural network is either a biological neural network, made up of biological neurons, or an artificial neural network, used for solving artificial intelligence (AI) problems."
modern sense,"A neural network is a network or circuit of biological neurons, or, in a modern sense, an artificial neural network, composed of artificial neurons or nodes. !! Terminology invoking ""objects"" and ""oriented"" in the modern sense of object-oriented programming made its first appearance at MIT in the late 1950s and early 1960s."
biological neural network,"Thus, a neural network is either a biological neural network, made up of biological neurons, or an artificial neural network, used for solving artificial intelligence (AI) problems. !! A biological neural network is composed of a groups of chemically connected or functionally associated neurons."
solving artificial intelligence,"Thus, a neural network is either a biological neural network, made up of biological neurons, or an artificial neural network, used for solving artificial intelligence (AI) problems."
biological neuron,The connections of the biological neuron are modeled in artificial neural networks as weights between nodes.
functionally associated neurons,A biological neural network is composed of a groups of chemically connected or functionally associated neurons.
past security breaches,"In cryptanalysis and computer security, a dictionary attack is an attack using a restricted subset of a keyspace to defeat a cipher or authentication mechanism by trying to determine its decryption key or passphrase, sometimes trying thousands or millions of likely possibilities often obtained from lists of past security breaches."
passwords recovered,"Such attacks originally used words found in a dictionary (hence the phrase dictionary attack); however, now there are much larger lists available on the open Internet containing hundreds of millions of passwords recovered from past data breaches."
valued matrices,"If A and B are each real-valued matrices, the Frobenius inner product is the sum of the entries of the Hadamard product."
usual euclidean inner product,Tensor product of Hilbert spaces the Frobenius inner product is the special case where the vector spaces are finite-dimensional real or complex vector spaces with the usual Euclidean inner product
dimensional real,Tensor product of Hilbert spaces the Frobenius inner product is the special case where the vector spaces are finite-dimensional real or complex vector spaces with the usual Euclidean inner product
oriented programming,"Eric S. Raymond, a Unix programmer and open-source software advocate, has been critical of claims that present object-oriented programming as the ""One True Solution"", and has written that object-oriented programming languages tend to encourage thickly layered programs that destroy transparency. !! Uniform Function Call Syntax (UFCS) or Uniform Calling Syntax (UCS) or sometimes Universal Function Call Syntax is a programming language feature in D and Nim that allows any function to be called using the syntax for method calls (as in object-oriented programming), by using the receiver as the first parameter, and the given arguments as the remaining parameters. !! In object-oriented programming, a member variable (sometimes called a member field) is a variable that is associated with a specific object, and accessible for all its methods (member functions). !! In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension. !! Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class. !! The notion of abstract data types is related to the concept of data abstraction, important in object-oriented programming and design by contract methodologies for software development. !! Later, the term feature-oriented programming was coined; this work exposed interactions between layers. !! Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance occurs via defining classes of objects, instead of inheritance occurring via the objects alone (compare prototype-based programming). !! In computer programming, feature-oriented programming (FOP) or feature-oriented software development (FOSD) is a programming paradigm for program generation in software product lines (SPLs) and for incremental development of programs. !! An object database is a database management system in which information is represented in the form of objects as used in object-oriented programming. !! Simula introduced important concepts that are today an essential part of object-oriented programming, such as class and object, inheritance, and dynamic binding. !! The software architect concept began to take hold when object-oriented programming or OOP, was coming into more widespread use (in the late 1990s and early years of the 21st century). !! are multi-paradigm and they support object-oriented programming to a greater or lesser degree, typically in combination with imperative, procedural programming. !! Experimentation with various extensions to Lisp (such as LOOPS and Flavors introducing multiple inheritance and mixins) eventually led to the Common Lisp Object System, which integrates functional programming and object-oriented programming and allows extension via a Meta-object protocol. !! In computing, subject-oriented programming is an object-oriented software paradigm in which the state (fields) and behavior (methods) of objects are not seen as intrinsic to the objects themselves, but are provided by various subjective perceptions (""subjects"") of the objects. !! In object-oriented programming, ""immutable interface"" is a pattern for designing an immutable object. !! Strings and other concrete objects are typically expressed as immutable objects to improve readability and runtime efficiency in object-oriented programming. !! Like aspect-oriented programming, subject-oriented programming, composition filters, feature oriented programming and adaptive methods are considered to be aspect-oriented software development approaches. !! The introduction of aspect-oriented programming in 1997 raised questions about its relationship to subject-oriented programming, and about the difference between subjects and aspects. !! Object-oriented programming (OOP) is a programming paradigm based on the concept of ""objects"", which can contain data and code: data in the form of fields (often known as attributes or properties), and code, in the form of procedures (often known as methods). !! In object-oriented programming, sequential coupling (also known as temporal coupling) is a form of coupling where a class requires its methods to be called in a particular sequence. !! Object-oriented analysis and design (OOAD) is a technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality."
containing instances,Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class.
composition over inheritance,An implementation of composition over inheritance typically begins with the creation of various interfaces representing the behaviors that the system must exhibit. !! To favor composition over inheritance is a design principle that gives the design higher flexibility. !! Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class.
composite reuse principle,Composition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class.
ssa form,"Kennedy, R. , Chan, S. , Liu, S. M. , Lo, R. , Peng, T. , and Chow, F. Partial Redundancy Elimination in SSA Form. !! In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used."
static single assignment form,"A Correspondence between Continuation Passing Style and Static Single Assignment Form. !! In compiler design, static single assignment form (often abbreviated as SSA form or simply SSA) is a property of an intermediate representation (IR), which requires that each variable be assigned exactly once, and every variable be defined before it is used."
intermediate representation based,"0 to ""internally use an intermediate representation based on Static Single Assignment (SSA). """
continuation passing style,A Correspondence between Continuation Passing Style and Static Single Assignment Form.
sebastian buchwald,"Matthias Braun; Sebastian Buchwald; Sebastian Hack; Roland Leia; Christoph Mallon; Andreas Zwinkau (2013), ""Simple and Efficient Construction of Static Single Assignment Form"", Compiler Construction, Lecture Notes in Computer Science, vol."
conquer algorithms,"In the analysis of algorithms, the master theorem for divide-and-conquer recurrences provides an asymptotic analysis (using Big O notation) for recurrence relations of types that occur in the analysis of many divide and conquer algorithms. !! These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops. !! Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide and conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, timespace tradeoffs, and upper and lower bounds. !! Designing efficient divide-and-conquer algorithms can be difficult. !! The master theorem always yields asymptotically tight bounds to recurrences from divide and conquer algorithms that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem."
names abbreviated cfs,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
climate forecast system,The Climate Forecast System or coupled forecast system (both names abbreviated CFS) is a medium to long range numerical weather prediction and a climate model run by the National Centers for Environmental Prediction (NCEP) to bridge weather and climate timescales.
global register allocation,"Register allocation can happen over a basic block (local register allocation), over a whole function/procedure (global register allocation), or across function boundaries traversed via call-graph (interprocedural register allocation)."
basic block,"Register allocation can happen over a basic block (local register allocation), over a whole function/procedure (global register allocation), or across function boundaries traversed via call-graph (interprocedural register allocation). !! Array access analysis aims to obtain the knowledge of which portions or even which elements of the array are accessed by a given code segment (basic block, loop, or even at the procedure level)."
whole function,"Register allocation can happen over a basic block (local register allocation), over a whole function/procedure (global register allocation), or across function boundaries traversed via call-graph (interprocedural register allocation)."
register allocation consists therefore,"Register allocation consists therefore in choosing where to store the variables at runtime, i. e. inside or outside registers."
outside registers,"Register allocation consists therefore in choosing where to store the variables at runtime, i. e. inside or outside registers."
ski combinator calculus,"SKI combinator calculus can also implement Boolean logic in the form of an if-then-else structure. !! O'Donnell, Mike ""The SKI Combinator Calculus as a Universal System. "" !! The SKI combinator calculus is a combinatory logic system and a computational system."
combinatory logic system,The SKI combinator calculus is a combinatory logic system and a computational system.
else structure,SKI combinator calculus can also implement Boolean logic in the form of an if-then-else structure.
universal system,"O'Donnell, Mike ""The SKI Combinator Calculus as a Universal System. """
different balance,"There are general, spatial, temporal, spatiotemporal, and fuzzy description logics, and each description logic features a different balance between expressive power and reasoning complexity by supporting different sets of mathematical constructors."
expressive power,"While the expressive power of combinatory logic typically exceeds that of first-order logic, the expressive power of predicate functor logic is identical to that of first order logic (Quine 1960, 1966, 1976). !! There are general, spatial, temporal, spatiotemporal, and fuzzy description logics, and each description logic features a different balance between expressive power and reasoning complexity by supporting different sets of mathematical constructors."
description logic features,"There are general, spatial, temporal, spatiotemporal, and fuzzy description logics, and each description logic features a different balance between expressive power and reasoning complexity by supporting different sets of mathematical constructors."
reasoning complexity,"There are general, spatial, temporal, spatiotemporal, and fuzzy description logics, and each description logic features a different balance between expressive power and reasoning complexity by supporting different sets of mathematical constructors."
models concepts,"A description logic (DL) models concepts, roles and individuals, and their relationships."
operationally equivalent notions,The description logic community uses different terminology than the first-order logic (FOL) community for operationally equivalent notions; some examples are given below.
operators allowed,"There are many varieties of description logics and there is an informal naming convention, roughly describing the operators allowed."
series acceleration,"Series acceleration techniques may also be used, for example, to obtain a variety of identities on special functions. !! Two classical techniques for series acceleration are Euler's transformation of series and Kummer's transformation of series. !! Techniques for series acceleration are often applied in numerical analysis, where they are used to improve the speed of numerical integration. !! In mathematics, series acceleration is one of a collection of sequence transformations for improving the rate of convergence of a series."
special functions,"Series acceleration techniques may also be used, for example, to obtain a variety of identities on special functions. !! First, for known target functions approximation theory is the branch of numerical analysis that investigates how certain known functions (for example, special functions) can be approximated by a specific class of functions (for example, polynomials or rational functions) that often have desirable properties (inexpensive computation, continuity, integral and limit values, etc."
series acceleration techniques may also,"Series acceleration techniques may also be used, for example, to obtain a variety of identities on special functions."
concise representation,The sequitur algorithm constructs a grammar by substituting repeating phrases in the given sequence with new rules and therefore produces a concise representation of the sequence.
substituting repeating phrases,The sequitur algorithm constructs a grammar by substituting repeating phrases in the given sequence with new rules and therefore produces a concise representation of the sequence.
randomly chosen function,"In computer science, a randomization function or randomizing function is an algorithm or procedure that implements a randomly chosen function between two specific sets, suitable for use in a randomized algorithm."
truly random,"In theory, randomization functions are assumed to be truly random, and yield an unpredictably different function every time the algorithm is executed. !! Although sequences that are closer to truly random can be generated using hardware random number generators, pseudorandom number generators are important in practice for their speed in number generation and their reproducibility."
externally observable parameter,"The randomization technique would not work if, at every execution of the algorithm, the randomization function always performed the same mapping, or a mapping entirely determined by some externally observable parameter (such as the program's startup time)."
independent variables multiplicatively scales,"Analogous models with a different sigmoid function instead of the logistic function can also be used, such as the probit model; the defining characteristic of the logistic model is that increasing one of the independent variables multiplicatively scales the odds of the given outcome at a constant rate, with each independent variable having its own parameter; for a binary dependent variable this generalizes the odds ratio."
term learning automaton,"However, the term learning automaton was not used until Narendra and Thathachar introduced it in a survey paper in 1974."
adaptive decision,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
visualised demo,A visualised demo / Art Work of a single Learning Automaton had been developed by Systems (microSystems) Research Group at Newcastle University.
single learning automaton,A visualised demo / Art Work of a single Learning Automaton had been developed by Systems (microSystems) Research Group at Newcastle University.
autonomic networking follows,"Autonomic Networking follows the concept of Autonomic Computing, an initiative started by IBM in 2001."
initiative started,"Autonomic Networking follows the concept of Autonomic Computing, an initiative started by IBM in 2001. !! UGV Interoperability Profile (UGV IOP), Robotics and Autonomous Systems Ground IOP (RAS-G IOP) or simply IOP was originally an initiative started by the United States Department of Defense (DoD) to organize and maintain open architecture interoperability standards for Unmanned Ground Vehicles (UGV)."
layering approach,"Instead of a layering approach, autonomic networking targets a more flexible structure termed compartmentalization."
flexible structure termed compartmentalization,"Instead of a layering approach, autonomic networking targets a more flexible structure termed compartmentalization."
autonomic networking targets,"Instead of a layering approach, autonomic networking targets a more flexible structure termed compartmentalization."
real distribution,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
overfitting resulting,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
membership inference relies heavily,"However, membership inference relies heavily on overfitting resulting from poor machine learning practices, meaning a model that generalizes well to the real distribution of data should theoretically be more secure to membership inference attacks."
tagged architecture,"In computer science, a tagged architecture is a particular type of computer architecture where every word of memory constitutes a tagged union, being divided into a number of bits of data, and a tag section that describes the type of the data: how it is to be interpreted, and, if it is a reference, the type of the object that it points to. !! In the Soviet Union, the Elbrus series of supercomputers pioneered the use of tagged architectures in 1973. !! Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
memory constitutes,"In computer science, a tagged architecture is a particular type of computer architecture where every word of memory constitutes a tagged union, being divided into a number of bits of data, and a tag section that describes the type of the data: how it is to be interpreted, and, if it is a reference, the type of the object that it points to."
tag section,"In computer science, a tagged architecture is a particular type of computer architecture where every word of memory constitutes a tagged union, being divided into a number of bits of data, and a tag section that describes the type of the data: how it is to be interpreted, and, if it is a reference, the type of the object that it points to."
tagged union,"In computer science, a tagged architecture is a particular type of computer architecture where every word of memory constitutes a tagged union, being divided into a number of bits of data, and a tag section that describes the type of the data: how it is to be interpreted, and, if it is a reference, the type of the object that it points to."
american tagged architectures,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
tagged pointer support,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
based architecture,"Interface-based programming, also known as interface-based architecture, is an architectural pattern for implementing modular programming at the component level in an object-oriented programming language which does not have a module system. !! Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
notable examples,"Notable examples of systems employing polymorphic recursion include Dussart, Henglein and Mossin's binding-time analysis and the TofteTalpin region-based memory management system. !! Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
burroughs large systems,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
commercial rice computer,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
opcode level,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
driven tagged,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
supercomputers pioneered,"In the Soviet Union, the Elbrus series of supercomputers pioneered the use of tagged architectures in 1973."
soviet union,"In the Soviet Union, the Elbrus series of supercomputers pioneered the use of tagged architectures in 1973. !! Research in learning automata can be traced back to the work of Michael Lvovitch Tsetlin in the early 1960s in the Soviet Union."
tagged architectures,"In the Soviet Union, the Elbrus series of supercomputers pioneered the use of tagged architectures in 1973."
large sparse matrices often appear,Large sparse matrices often appear in scientific or engineering applications when solving partial differential equations.
use specialized algorithms,"When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix."
manipulating sparse matrices,"When storing and manipulating sparse matrices on a computer, it is beneficial and often necessary to use specialized algorithms and data structures that take advantage of the sparse structure of the matrix."
public interface,"It is important that public interfaces be stable and designed to support future changes, enhancements, and deprecation in order for the interaction to continue. !! Use protocol classes to define public interfaces. !! In computer science, a public interface is the logical point at which independent software entities interact. !! The programmer must create fully insulated classes and insulate the public interfaces from compile-time dependencies."
support future changes,"It is important that public interfaces be stable and designed to support future changes, enhancements, and deprecation in order for the interaction to continue."
public interfaces,"It is important that public interfaces be stable and designed to support future changes, enhancements, and deprecation in order for the interaction to continue. !! The programmer must create fully insulated classes and insulate the public interfaces from compile-time dependencies."
time dependencies,The programmer must create fully insulated classes and insulate the public interfaces from compile-time dependencies.
use protocol classes,Use protocol classes to define public interfaces.
define public interfaces,Use protocol classes to define public interfaces.
complex economic ecosystems,"Value network analysis (VNA) is a methodology for understanding, using, visualizing, optimizing internal and external value networks and complex economic ecosystems."
sec filings,"Value network analysis offers a taxonomy for non-financial business reporting, which is becoming increasingly important in SEC Filings."
business model,"In contrast, value network analysis is one approach to assessing current and future capability for value creation and to describe and analyze a business model."
value network analysis addresses,Value network analysis addresses both financial and non-financial value.
model dynamic decisions,"Increasingly, operations research uses stochastic programming to model dynamic decisions that adapt to events; such problems can be solved with large-scale optimization and stochastic optimization methods."
interacting magnetic spins,"In statistical mechanics, the two-dimensional square lattice Ising model is a simple lattice model of interacting magnetic spins."
simple lattice model,"In statistical mechanics, the two-dimensional square lattice Ising model is a simple lattice model of interacting magnetic spins."
dimensional square lattice ising model,"In statistical mechanics, the two-dimensional square lattice Ising model is a simple lattice model of interacting magnetic spins."
corner free energies,"The bulk, surface and corner free energies of the square lattice Ising model."
toeplitz determinants,The square lattice Ising model on the rectangle III: Hankel and Toeplitz determinants.
rectangle iii,The square lattice Ising model on the rectangle III: Hankel and Toeplitz determinants.
output pairs,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. !! Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs."
4 gb limit,"Address Windowing Extensions (AWE) is a Microsoft Windows application programming interface that allows a 32-bit software application to access more physical memory than it has virtual address space, even in excess of the 4 GB limit."
bit software application,"Address Windowing Extensions (AWE) is a Microsoft Windows application programming interface that allows a 32-bit software application to access more physical memory than it has virtual address space, even in excess of the 4 GB limit."
address windowing extensions,"Address Windowing Extensions Coding Example !! Address Windowing Extensions (AWE) is a Microsoft Windows application programming interface that allows a 32-bit software application to access more physical memory than it has virtual address space, even in excess of the 4 GB limit. !! An article published in Dr. Dobb's Journal in 2004 noted that memory allocated using Address Windowing Extensions will not be written to the pagefile, and suggested that AWE regions could therefore be used as a way of protecting sensitive application data such as encryption keys."
protecting sensitive application data,"An article published in Dr. Dobb's Journal in 2004 noted that memory allocated using Address Windowing Extensions will not be written to the pagefile, and suggested that AWE regions could therefore be used as a way of protecting sensitive application data such as encryption keys."
multimodal architecture and interfaces,"The Multimodal Architecture and Interfaces recommendation introduces a generic structure and a communication protocol to allow the modules in a multimodal system to communicate with each other. !! Multimodal Architecture and Interfaces is an open standard developed by the World Wide Web Consortium since 2005. !! Papers presented to W3C's Multimodal Architecture and Interfaces Workshop, 1920 July 2004. !! The Multimodal Architecture and Interfaces specification is based on the MVC design pattern, that proposes to organize the user interface structure in three parts: the Model, the View and the Controller. !! Multimodal Architecture and Interfaces is the specified description of a larger services infrastructure called The Runtime Framework which provides the main functions that a multimodal system can need."
generic structure,The Multimodal Architecture and Interfaces recommendation introduces a generic structure and a communication protocol to allow the modules in a multimodal system to communicate with each other.
interfaces specification,"The Multimodal Architecture and Interfaces specification is based on the MVC design pattern, that proposes to organize the user interface structure in three parts: the Model, the View and the Controller."
singleton pattern forces,"In essence, the singleton pattern forces it to be responsible for ensuring that it is only instantiated once."
full semantic context,Semantic dictionary encoding (SDE) preserves the full semantic context of source programs while adding further information that can be used for accelerating the speed of code generation.
sampling instant,Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals.
past values,Transfer entropy from a process X to another process Y is the amount of uncertainty reduced in future values of Y by knowing the past values of X given past values of Y. !! Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals.
communication pattern,Active networking is a communication pattern that allows packets flowing through a telecommunications network to dynamically modify the operation of the network.
allows packets flowing,Active networking is a communication pattern that allows packets flowing through a telecommunications network to dynamically modify the operation of the network.
decimal formats,"In IEEE 754-2008, denormal numbers are renamed subnormal numbers and are supported in both binary and decimal formats."
denormal number,"In IEEE 754-2008, denormal numbers are renamed subnormal numbers and are supported in both binary and decimal formats."
renamed subnormal numbers,"In IEEE 754-2008, denormal numbers are renamed subnormal numbers and are supported in both binary and decimal formats."
medical intervention,"Medical imaging is the technique and process of imaging the interior of a body for clinical analysis and medical intervention, as well as visual representation of the function of some organs or tissues (physiology)."
clinical analysis,"Medical imaging is the technique and process of imaging the interior of a body for clinical analysis and medical intervention, as well as visual representation of the function of some organs or tissues (physiology)."
medical imaging seeks,"Medical imaging seeks to reveal internal structures hidden by the skin and bones, as well as to diagnose and treat disease."
treat disease,"Medical imaging seeks to reveal internal structures hidden by the skin and bones, as well as to diagnose and treat disease."
two matrices,"In mathematics, particularly in linear algebra, matrix multiplication is a binary operation that produces a matrix from two matrices. !! In numerical analysis, interpolative decomposition (ID) factors a matrix as the product of two matrices, one of which contains selected columns from the original matrix, and the other of which has a subset of columns consisting of the identity matrix and all its values are no greater than 2 in absolute value."
cellular phones,Operating systems are found on many devices that contain a computer from cellular phones and video game consoles to web servers and supercomputers.
video game consoles,Operating systems are found on many devices that contain a computer from cellular phones and video game consoles to web servers and supercomputers.
dynamically optimal,The geometry of binary search trees has been used to provide an algorithm which is dynamically optimal if any binary search tree algorithm is dynamically optimal.
crossing graph embedding,"In such contexts the stricter definition is described as ""non-crossing graph embedding""."
facilitate software developments,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
working system,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
size list data structure,"In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed."
hawks hunting,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
animal herding,"Examples of swarm intelligence in natural systems include ant colonies, bee colonies, bird flocking, hawks hunting, animal herding, bacterial growth, fish schooling and microbial intelligence."
principally convolutional codes,The BCJR algorithm is an algorithm for maximum a posteriori decoding of error correcting codes defined on trellises (principally convolutional codes).
posteriori decoding,The BCJR algorithm is an algorithm for maximum a posteriori decoding of error correcting codes defined on trellises (principally convolutional codes).
learning algorithms,"The online textbook: Information Theory, Inference, and Learning Algorithms, by David J. C. MacKay, discusses the BCJR algorithm in chapter 25. !! In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory. !! Empirical risk minimization (ERM) is a principle in statistical learning theory which defines a family of learning algorithms and is used to give theoretical bounds on their performance. !! In machine learning, weighted majority algorithm (WMA) is a meta learning algorithm used to construct a compound algorithm from a pool of prediction algorithms, which could be any type of learning algorithms, classifiers, or even real human experts."
efficient c  library,"Some publicly available implementations of ESNs are: (i) aureservoir: an efficient C++ library for various kinds of echo state networks with python/numpy bindings; and (ii) Matlab code: an efficient matlab for an echo state network, (iii) ReservoirComputing."
based implementation,"jl: an efficient Julia-based implementation of various types of echo state networks, and (iv) pyESN: simple echo state networks in Python."
backshifted version,"Another feature of the ESN is the autonomous operation in prediction: if the Echo State Network is trained with an input that is a backshifted version of the output, then it can be used for signal generation/prediction by using the previous output as input."
process arbitrary sequences,Recurrent neural networks are theoretically Turing complete and can run arbitrary programs to process arbitrary sequences of inputs.
equivalent difference equations,"Note that, by the Shannon sampling theorem, discrete time recurrent neural networks can be viewed as continuous-time recurrent neural networks where the differential equations have transformed into equivalent difference equations."
root last,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
order depth,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
depth zero,"The root node has depth zero, leaf nodes have height zero, and a tree with only a single node (hence both a root and leaf) has depth and height zero."
height zero,"The root node has depth zero, leaf nodes have height zero, and a tree with only a single node (hence both a root and leaf) has depth and height zero."
software instantiation,The research on cognitive architectures as software instantiation of cognitive theories was initiated by Allen Newell in 1990.
complex environments,"The Institute for Creative Technologies defines cognitive architecture as: ""hypothesis about the fixed structures that provide a mind, whether in natural or artificial systems, and how they work together in conjunction with knowledge and skills embodied within the architecture to yield intelligent behavior in a diversity of complex environments. "" !! Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments)."
true solution,"Rayleigh quotient iteration is an iterative method, that is, it delivers a sequence of approximate solutions that converges to a true solution in the limit."
approximate solutions,"Rayleigh quotient iteration is an iterative method, that is, it delivers a sequence of approximate solutions that converges to a true solution in the limit."
initial vector,"The Rayleigh quotient iteration algorithm converges cubically for Hermitian or symmetric matrices, given an initial vector that is sufficiently close to an eigenvector of the matrix that is being analyzed."
symmetric matrices,"The biconjugate gradient method provides a generalization to non-symmetric matrices. !! The Rayleigh quotient iteration algorithm converges cubically for Hermitian or symmetric matrices, given an initial vector that is sufficiently close to an eigenvector of the matrix that is being analyzed."
adapted automobile,An adapted automobile is an automobile adapted for ease of use by disabled people.
forward networks,Most Quantum neural networks are developed as feed-forward networks.
classical data,"Quantum neural networks refer to three different categories: Quantum computer with classical data, classical computer with quantum data, and quantum computer with quantum data."
objective value,"This can be regarded as the special case of mathematical optimization where the objective value is the same for every solution, and thus any solution is optimal."
level controllers,High-level controllers such as model predictive control (MPC) or real-time optimization (RTO) employ mathematical optimization.
time optimization,"Automatic vectorization, like any loop optimization or other compile-time optimization, must exactly preserve program behavior. !! High-level controllers such as model predictive control (MPC) or real-time optimization (RTO) employ mathematical optimization."
zfc axioms,"In axiomatic set theory (as developed, for example, in the ZFC axioms), the existence of the power set of any set is postulated by the axiom of power set."
notation 2s denoting,This fact as well as the reason of the notation 2S denoting the power set P(S) are demonstrated in the below.
original set,"The Helmholtz machine (named after Hermann von Helmholtz and his concept of Helmholtz free energy) is a type of artificial neural network that can account for the hidden structure of a set of data by being trained to create a generative model of the original set of data. !! Cantor's diagonal argument shows that the power set of a set (whether infinite or not) always has strictly higher cardinality than the set itself (or informally, the power set must be larger than the original set)."
embeds constraints,"Constraint programming takes its root from and can be expressed in the form of constraint logic programming, which embeds constraints into a logic program."
host language,"Constraint programming is an embedding of constraints in a host language. !! In computing, a meta-circular evaluator (MCE) or meta-circular interpreter (MCI) is an interpreter which defines each feature of the interpreted language using a similar facility of the interpreter's host language."
minimum cost,"Stochastic control aims to design the time path of the controlled variables that performs the desired control task with minimum cost, somehow defined, despite the presence of this noise."
controlled variables,"Stochastic control aims to design the time path of the controlled variables that performs the desired control task with minimum cost, somehow defined, despite the presence of this noise."
max-min item allocation,"The goal is to construct subsets that satisfy a given criterion of fairness, such as max-min item allocation."
economic complexity index,"The Economic Complexity Index (ECI) is a holistic measure of the productive capabilities of large economic systems, usually cities, regions, or countries. !! The product equivalent of the Economic Complexity Index is the Product Complexity Index or PCI. !! The original formulation of the Economic Complexity Index was published in PNAS in 2009."
large economic systems,"The Economic Complexity Index (ECI) is a holistic measure of the productive capabilities of large economic systems, usually cities, regions, or countries."
complexity index,"The Economic Complexity Index (ECI) is a holistic measure of the productive capabilities of large economic systems, usually cities, regions, or countries. !! The product equivalent of the Economic Complexity Index is the Product Complexity Index or PCI. !! The original formulation of the Economic Complexity Index was published in PNAS in 2009."
oriented displacements,Histogram of Oriented Displacements (HOD) is a 2D trajectory descriptor.
separate features,"Furthermore, convolutional neural networks are ideal for data with a grid-like topology (such as images) as spatial relations between separate features are taken into account during convolution and/or pooling."
varying signals,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
forward architecture,The feed-forward architecture of convolutional neural networks was extended in the neural abstraction pyramid by lateral and feedback connections.
recognition network,"A Helmholtz machine contains two networks, a bottom-up recognition network that takes the data as input and produces a distribution over hidden variables, and a top-down ""generative"" network that generates values of the hidden variables and the data itself."
learning architectures,"At the time, Helmholtz machines were one of a handful of learning architectures that used feedback as well as feedforward to ensure quality of learned models."
learned models,"At the time, Helmholtz machines were one of a handful of learning architectures that used feedback as well as feedforward to ensure quality of learned models."
invariant recognition,"Helmholtz machines may also be used in applications requiring a supervised learning algorithm (e. g. character recognition, or position-invariant recognition of an object within a field)."
implement electronic signatures,"Electronic signatures are a legal concept distinct from digital signatures, a cryptographic mechanism often used to implement electronic signatures. !! While an electronic signature can be as simple as a name entered in an electronic document, digital signatures are increasingly used in e-commerce and in regulatory filings to implement electronic signatures in a cryptographically protected way."
bit numbers,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
two adders,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
bit ripple,A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
carry adder,A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
bit carry,A 16-bit carry-select adder with variable size can be similarly created. !! A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
mechanized computational statistics,This marks the beginning of the era of mechanized computational statistics and semiautomatic data processing systems.
core system,A computer using a single core CPU is generally slower than a multi-core system.
board microcontrollers,Single core processors also used in hobbyist computers like the Raspberry Pi and Single-board microcontrollers.
additional storage,"In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM."
input bits,"In mathematics, a symmetric Boolean function is a Boolean function whose value does not depend on the order of its input bits, i. e. , it depends only on the number of ones (or zeros) in the input."
odd number,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour. !! Parity function: their value is 1 if the input vector has odd number of onesThe n-ary versions of AND, OR, XOR, NAND, NOR and XNOR are also symmetric Boolean functions."
input weight,"Effectively, an n-variable symmetric Boolean function corresponds to a log(n)-variable ordinary Boolean function acting on the base-2 representation of the input weight."
distributed solutions,Distributed Artificial Intelligence (DAI) also called Decentralized Artificial Intelligence is a subfield of artificial intelligence research dedicated to the development of distributed solutions for problems.
solving complex learning,"Distributed Artificial Intelligence (DAI) is an approach to solving complex learning, planning, and decision making problems."
intelligent entities,"Distributed artificial intelligence systems were conceived as a group of intelligent entities, called agents, that interacted by cooperation, by coexistence or by competition."
live closed captioning,"The term ""streaming media"" can apply to media other than video and audio, such as live closed captioning, ticker tape, and real-time text, which are all considered ""streaming text""."
time text,"The term ""streaming media"" can apply to media other than video and audio, such as live closed captioning, ticker tape, and real-time text, which are all considered ""streaming text""."
ticker tape,"The term ""streaming media"" can apply to media other than video and audio, such as live closed captioning, ticker tape, and real-time text, which are all considered ""streaming text""."
estimating entropy,"Lall, Ashwin; Sekar, Vyas; Ogihara, Mitsunori; Xu, Jun; Zhang, Hui (2006), ""Data streaming algorithms for estimating entropy of network traffic"", Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems (ACM SIGMETRICS 2006) (PDF), p. 145,"
network traffic  proceedings,"Lall, Ashwin; Sekar, Vyas; Ogihara, Mitsunori; Xu, Jun; Zhang, Hui (2006), ""Data streaming algorithms for estimating entropy of network traffic"", Proceedings of the Joint International Conference on Measurement and Modeling of Computer Systems (ACM SIGMETRICS 2006) (PDF), p. 145,"
oriented software paradigm,"In computing, subject-oriented programming is an object-oriented software paradigm in which the state (fields) and behavior (methods) of objects are not seen as intrinsic to the objects themselves, but are provided by various subjective perceptions (""subjects"") of the objects."
oriented programming advocates,"Subject-oriented programming advocates the organization of the classes that describe objects into ""subjects"", which may be composed to form larger subjects."
civil architecture,"Systems architecture depends heavily on practices and techniques which were developed over thousands of years in many other fields, perhaps the most important being civil architecture."
craig gentry,"Craig Gentry, Certificate-Based Encryption and the Certificate Revocation Problem, Lecture Notes in Computer Science, pp."
time system animation,Reactive programming has been proposed as a way to simplify the creation of interactive user interfaces and near-real-time system animation.
contributing factor,Bayesian networks are ideal for taking an event that occurred and predicting the likelihood that any one of several possible known causes was the contributing factor.
electrical engineering,"Von Zuben, (1999) ""Artificial Immune Systems: Part I -Basic Theory and Applications"", School of Computing and Electrical Engineering, State University of Campinas, Brazil, No. !! In electrical engineering and computer science, analog image processing is any image processing task conducted on two-dimensional analog signals by analog means (as opposed to digital image processing)."
linear context,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
anonymous binary,Code stylometry (also known as program authorship attribution or source code authorship analysis) is the application of stylometry to computer code to attribute authorship to anonymous binary or source code.
regular language,"The concept of regular expressions began in the 1950s, when the American mathematician Stephen Cole Kleene formalized the description of a regular language. !! In computational learning theory, induction of regular languages refers to the task of learning a formal description (e. g. grammar) of a regular language from a given set of example strings."
statistical performance,"Other higher-quality PRNGs, both in terms of computational and statistical performance, were developed before and after this date; these can be identified in the List of pseudorandom number generators."
random number,Random number are generated by Javascript pseudorandom number generators (PRNGs) algorithms
collision occurs,"Double hashing is a computer programming technique used in conjunction with open addressing in hash tables to resolve hash collisions, by using a secondary hash of the key as an offset when a collision occurs."
resolve hash collisions,"Double hashing is a computer programming technique used in conjunction with open addressing in hash tables to resolve hash collisions, by using a secondary hash of the key as an offset when a collision occurs."
tetrahedral number,"(a tetrahedral number), does solve the problem, a technique known as enhanced double hashing."
high bytes,"Thus, it is possible to add two numbers each two bytes wide using just a byte addition in steps: first add the low bytes then add the high bytes, but if it is necessary to carry out of the low bytes this is arithmetic overflow of the byte addition and it becomes necessary to detect and increment the sum of the high bytes."
margin hyperplane,"In the context of support-vector machines, the optimally separating hyperplane or maximum-margin hyperplane is a hyperplane which separates two convex hulls of points and is equidistant from the two."
thermographic cameras,"Self-driving cars combine a variety of sensors to perceive their surroundings, such as thermographic cameras, radar, lidar, sonar, GPS, odometry and inertial measurement units."
driving commercial car,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
driving cars available,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
fuse data,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
line map,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
minimal structures,"The structural induction proof is a proof that the proposition holds for all the minimal structures and that if it holds for the immediate substructures of a certain structure S, then it must hold for S also."
interlinked hierarchy,"The Internet routing registry works by providing an interlinked hierarchy of objects designed to facilitate the organization of IP routing between organizations, and also to provide data in an appropriate format for automatic programming of routers."
information measure,"In information theory, information dimension is an information measure for random vectors in Euclidean space, based on the normalized entropy of finely quantized versions of the random vectors."
heap supporting,"In computer science, a mergeable heap (also called a meldable heap) is an abstract data type, which is a heap supporting a merge operation."
mergeable heap,"In most mergeable heap structures, merging is the fundamental operation on which others are based. !! In computer science, a mergeable heap (also called a meldable heap) is an abstract data type, which is a heap supporting a merge operation."
spoken language,Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers with the main benefit of searchability.
structured documents,"Speech recognition applications include voice user interfaces such as voice dialing (e. g. ""call home""), call routing (e. g. ""I would like to make a collect call""), domotic appliance control, search key words (e. g. find a podcast where particular words were spoken), simple data entry (e. g. , entering a credit card number), preparation of structured documents (e. g. a radiology report), determining speaker characteristics, speech-to-text processing (e. g. , word processors or emails), and aircraft (usually termed direct voice input)."
analog levels,Simple digital signals represent information in discrete bands of analog levels.
discrete bands,Simple digital signals represent information in discrete bands of analog levels.
acoustic pressure,"In a digital signal, the physical quantity representing the information may be a variable electric current or voltage, the intensity, phase or polarization of an optical or other electromagnetic field, acoustic pressure, the magnetization of a magnetic storage media, etcetera."
state pattern,"The state pattern is a behavioral software design pattern that allows an object to alter its behavior when its internal state changes. !! The state pattern can be interpreted as a strategy pattern, which is able to switch a strategy through invocations of methods defined in the pattern's interface. !! The state pattern is used in computer programming to encapsulate varying behavior for the same object, based on its internal state."
network connecting,"Ambient intelligence would allow devices to work in concert to support people in carrying out their everyday life activities, tasks and rituals in an intuitive way using information and intelligence that is hidden in the network connecting these devices (for example: The Internet of Things)."
sound approximation,"In computer science, abstract interpretation is a theory of sound approximation of the semantics of computer programs, based on monotonic functions over ordered sets, especially lattices."
especially lattices,"In computer science, abstract interpretation is a theory of sound approximation of the semantics of computer programs, based on monotonic functions over ordered sets, especially lattices."
sub-optimal actions,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
needing sub-optimal actions,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
needing sub-optimal,"Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected."
first error-correcting,"The American mathematician Richard Hamming pioneered this field in the 1940s and invented the first error-correcting code in 1950: the Hamming (7,4) code."
first error-correcting code,"The American mathematician Richard Hamming pioneered this field in the 1940s and invented the first error-correcting code in 1950: the Hamming (7,4) code."
one-bit error,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
bit one-bit,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
error-correcting codeword,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
bit error-correcting codeword,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
bit error-correcting,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
bit one-bit error,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
4-bit one,"Here, each group of the same letter represents a 4-bit one-bit error-correcting codeword."
out-of-line copy,"This is because inline not only gives the compiler a hint that the function should be inlined, it also has an effect on whether the compiler will generate a callable out-of-line copy of the function (see storage classes of inline functions)."
variable-size input structures,"A recursive neural network is a kind of deep neural network created by applying the same set of weights recursively over a structured input, to produce a structured prediction over variable-size input structures, or a scalar prediction on it, by traversing a given structure in topological order."
frequency-domain analysis gives,An example of a field in which frequency-domain analysis gives a better understanding than time domain is music; the theory of operation of musical instruments and the musical notation used to record and discuss pieces of music is implicitly based on the breaking down of complex sounds into their separate component frequencies (musical notes).
k-fold cross validation may,"passes may still require quite a large computation time, in which case other approaches such as k-fold cross validation may be more appropriate."
l-fold cross validation,"Similar to the k*l-fold cross validation, the training set is used for model fitting and the validation set is used for model evaluation for each of the hyperparameter sets."
perform non-linear,"Maximum Variance Unfolding (MVU), also known as Semidefinite Embedding (SDE), is an algorithm in computer science that uses semidefinite programming to perform non-linear dimensionality reduction of high-dimensional vectorial input data."
perform non-linear dimensionality reduction,"Maximum Variance Unfolding (MVU), also known as Semidefinite Embedding (SDE), is an algorithm in computer science that uses semidefinite programming to perform non-linear dimensionality reduction of high-dimensional vectorial input data."
body-borne computer,"A wearable computer, also known as a wearable or body-borne computer, is a computing device worn on the body."
head-mounted display controlled,"Under the definition of wearable computers, we also include novel user interfaces such as Google Glass, an optical head-mounted display controlled by gestures."
optical head-mounted,"Under the definition of wearable computers, we also include novel user interfaces such as Google Glass, an optical head-mounted display controlled by gestures."
optical head-mounted display controlled,"Under the definition of wearable computers, we also include novel user interfaces such as Google Glass, an optical head-mounted display controlled by gestures."
monthly peer-reviewed scientific journal covering research,Computational Statistics & Data Analysis is a monthly peer-reviewed scientific journal covering research on and applications of computational statistics and data analysis.
monthly peer-reviewed,Computational Statistics & Data Analysis is a monthly peer-reviewed scientific journal covering research on and applications of computational statistics and data analysis.
peer-reviewed scientific journal covering research,Computational Statistics & Data Analysis is a monthly peer-reviewed scientific journal covering research on and applications of computational statistics and data analysis.
action-set learning automata,"Finite action-set learning automata (FALA) are a class of learning automata for which the number of possible actions is finite or, in more mathematical terms, for which the size of the action-set is finite."
tree-like structure,A hierarchical database model is a data model in which the data are organized into a tree-like structure.
algorithm-dependent parameters,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
tuning algorithm-dependent parameters,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
tuning algorithm-dependent,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
frequency-tuning technique,"This essentially uses a frequency-tuning technique to control the dynamic behaviour of a swarm of bats, and the balance between exploration and exploitation can be controlled by tuning algorithm-dependent parameters in bat algorithm."
loop inversion allows safe loop-invariant,"Additionally, loop inversion allows safe loop-invariant code motion."
loop-invariant code motion,"Additionally, loop inversion allows safe loop-invariant code motion."
loop inversion allows safe loop-invariant code motion,"Additionally, loop inversion allows safe loop-invariant code motion."
micro-lithography structures,Computational lithography means the use of computers to simulate printing of micro-lithography structures.
non-simply connected domain,The closure of the non-simply connected domain is called the solid Alexander horned sphere.
long-term goal,"Artificial Intelligence System (AIS) was a distributed computing project undertaken by Intelligence Realm, Inc. with the long-term goal of simulating the human brain in real time, complete with artificial consciousness and artificial general intelligence."
non-residual network may,"In the context of residual neural networks, a non-residual network may be described as a plain network."
interactive multi-objective,"Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure."
service-oriented infrastructure provides,A service-oriented infrastructure provides a foundation for IT services.
service-oriented infrastructure include industrialisation,"Key aspects of service-oriented infrastructure include industrialisation and virtualisation, providing IT infrastructure services via a pool of resources (web servers, application servers, database servers, servers, storage instances) instead of through discrete instances."
widely adopted service-oriented architecture,"While the IT industry has widely adopted service-oriented architecture (SOA), service-oriented infrastructure or SOI has lagged in its adoption."
widely adopted service-oriented,"While the IT industry has widely adopted service-oriented architecture (SOA), service-oriented infrastructure or SOI has lagged in its adoption."
weighted gene co-expression,"Weighted correlation network analysis, also known as weighted gene co-expression network analysis (WGCNA), is a widely used data mining method especially for studying biological networks based on pairwise correlations between variables."
entry-level information,"In an abstract argumentation framework, entry-level information is a set of abstract arguments that, for instance, represent data or a proposition."
low-dimensional representation retains,"Dimensionality reduction, or dimension reduction, is the transformation of data from a high-dimensional space into a low-dimensional space so that the low-dimensional representation retains some meaningful properties of the original data, ideally close to its intrinsic dimension."
end-user computing,"End-user computing (EUC) refers to systems in which non-programmers can create working applications. !! End-user computing can range in complexity from users simply clicking a series of buttons, to citizen developers writing scripts in a controlled scripting language, to being able to modify and execute code directly."
systems built using fourth-generation programming languages,"Examples of end-user computing are systems built using fourth-generation programming languages, such as MAPPER or SQL, or one of the fifth-generation programming languages, such as ICAD."
systems built using fourth-generation,"Examples of end-user computing are systems built using fourth-generation programming languages, such as MAPPER or SQL, or one of the fifth-generation programming languages, such as ICAD."
full-fledged ownership,End-user computing allows more user-input into system affairs that can range from personalization to full-fledged ownership of a system.
end-user computing allows,End-user computing allows more user-input into system affairs that can range from personalization to full-fledged ownership of a system.
constraint-based approach,"The boundaries of the polytopes, the data dependencies, and the transformations are often described using systems of constraints, and this approach is often referred to as a constraint-based approach to loop optimization."
modal logic-based system,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
modal logic-based,"It is sometimes also used to refer to tense logic, a modal logic-based system of temporal logic introduced by Arthur Prior in the late 1950s, with important contributions by Hans Kamp."
real-world data,"Analysis of algorithms typically focuses on the asymptotic performance, particularly at the elementary level, but in practical applications constant factors are important, and real-world data is in practice always limited in size."
error-prone task,"Usual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments)."
conventional text-based,"With the extensive amount of social media data available online in different forms such as videos and images, the conventional text-based sentiment analysis has evolved into more complex models of multimodal sentiment analysis, which can be applied in the development of virtual assistants, analysis of YouTube movie reviews, analysis of news videos, and emotion recognition (sometimes known as emotion detection) such as depression monitoring, among others. !! Similar to the conventional text-based sentiment analysis, some of the most commonly used textual features in multimodal sentiment analysis are unigrams and n-grams, which are basically a sequence of words in a given textual document."
step-wise planning methodology currently advocated,"The earliest rudiments of the step-wise planning methodology currently advocated by The Open Group Architecture Framework (TOGAF) and other EA frameworks can be traced back to the article of Marshall K. Evans and Lou R. Hague titled ""Master Plan for Information Systems"" published in 1962 in Harvard Business Review."
meta-learning algorithms intend,What optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.
based meta-learning algorithms intend,What optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.
optimization-based meta,What optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.
based meta-learning,What optimization-based meta-learning algorithms intend for is to adjust the optimization algorithm so that the model can be good at learning with a few examples.
scale software-integrated system,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
scale software-integrated,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
well-defined notation,Behavior trees employ a well-defined notation to unambiguously represent the hundreds or even thousands of natural language requirements that are typically used to express the stakeholder needs for a large-scale software-integrated system.
avoid short-term,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
avoid short-term memory overload,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
short-term memory overload,"The behavior tree representation, (with the help of the composition tree representation that resolves alias and other vocabulary problems with large sets of requirements) allows people to avoid short-term memory overload and produce a deep, accurate, holistic representation of system needs that can be understood by all stakeholders because it strictly uses the vocabulary of the original requirements."
online multi-institutional research,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
online multi-institutional,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
multi-institutional research,The Statistics Online Computational Resource (SOCR) is an online multi-institutional research and education organization.
two-sided ideal generated,The symmetric algebra S(V) can be built as the quotient of the tensor algebra T(V) by the two-sided ideal generated by the elements of the form x y y x.
classical widely-used,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
widely-used method,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
best input-output pairings,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
best input-output,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
input-output pairings,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
classical widely-used method,The Relative Gain Array (RGA) is a classical widely-used method for determining the best input-output pairings for multivariable process control systems.
maximum-length contiguous substring,"In computer science, the longest palindromic substring or longest symmetric factor problem is the problem of finding a maximum-length contiguous substring of a given string that is also a palindrome."
three main sub-categories,There are three main sub-categories of web mining.
organize web-based,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
organize web-based information,"The agent-based approach to web mining involves the development of sophisticated AI systems that can act autonomously or semi-autonomously on behalf of a particular user, to discover and organize web-based information."
human long-term,Sparse distributed memory (SDM) is a mathematical model of human long-term memory introduced by Pentti Kanerva in 1988 while he was at NASA Ames Research Center.
long-term memory introduced,Sparse distributed memory (SDM) is a mathematical model of human long-term memory introduced by Pentti Kanerva in 1988 while he was at NASA Ames Research Center.
human long-term memory introduced,Sparse distributed memory (SDM) is a mathematical model of human long-term memory introduced by Pentti Kanerva in 1988 while he was at NASA Ames Research Center.
uses high-dimensional,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network."
uses high-dimensional space,"Sparse distributed memory is a mathematical representation of human memory, and uses high-dimensional space to help model the large amounts of memory that mimics that of the human neural network."
ill-conditioned even,Thus eigenvalue algorithms that work by finding the roots of the characteristic polynomial can be ill-conditioned even when the problem is not.
using oct-tree,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
using oct-tree hashing,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
z-order curve naturally iterates,"Instead, if one stores the data in a hashtable, using oct-tree hashing, the Z-order curve naturally iterates the oct-tree in depth-first order."
constant worst-case,Perfect hash functions may be used to implement a lookup table with constant worst-case access time.
constant worst-case access time,Perfect hash functions may be used to implement a lookup table with constant worst-case access time.
non-dynamic perfect hash functions need,Non-dynamic perfect hash functions need to be re-constructed if S changes.
one-literal rule,Unit propagation (UP) or Boolean Constraint propagation (BCP) or the one-literal rule (OLR) is a procedure of automated theorem proving that can simplify a set of (usually propositional) clauses.
mode back-propagation,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
bunch-mode back,"This can perform significantly better than ""true"" stochastic gradient descent described, because the code can make use of vectorization libraries rather than computing each step separately as was first shown in where it was called ""the bunch-mode back-propagation algorithm""."
three-dimensional fields produced,"Statistical models were created based upon the three-dimensional fields produced by numerical weather models, surface observations and the climatological conditions for specific locations."
high-resolution mesoscale weather models,"Urban air quality models require a very fine computational mesh, requiring the use of high-resolution mesoscale weather models; in spite of this, the quality of numerical weather guidance is the main uncertainty in air quality forecasts."
non-global zones,"Later, there was a gradual move such that Solaris Containers specifically referred to non-global zones, with or without additional Resource Management."
on-line technical resources,The Solaris operating system provides man pages for Solaris Containers by default; more detailed documentation can be found at various on-line technical resources.
six-layer thalamocortical model,SpiNNaker (Spiking Neural Network Architecture) uses ARM processors as the building blocks of a massively parallel computing platform based on a six-layer thalamocortical model.
ai-generated fantasy worlds,"Fears of synthetic media include the potential to supercharge fake news, the spread of misinformation, distrust of reality, mass automation of creative and journalistic jobs, and potentially a complete retreat into AI-generated fantasy worlds."
computer-generated algorithmic art,"Some of the earliest known examples of computer-generated algorithmic art were created by Georg Nees, Frieder Nake, A. Michael Noll, Manfred Mohr and Vera Molnr in the early 1960s."
114-page document,The Data Reference Model version 2 released in November 2005 is a 114-page document with detailed architectural diagrams and an extensive glossary of terms.
perform unauthorized denial-of-service,"Marketed and promoted as stress-testing tools, they can be used to perform unauthorized denial-of-service attacks, and allow technically unsophisticated attackers access to sophisticated attack tools."
denial-of-service attacks typically involve,"Defensive responses to denial-of-service attacks typically involve the use of a combination of attack detection, traffic classification and response tools, aiming to block traffic that they identify as illegitimate and allow traffic that they identify as legitimate."
block denial-of-service,An ASIC based IPS may detect and block denial-of-service attacks because they have the processing power and the granularity to analyze the attacks and act like a circuit breaker in an automated way.
nano-scale mechanical testing applications due,"Digital image correlation (DIC) techniques have been increasing in popularity, especially in micro- and nano-scale mechanical testing applications due to its relative ease of implementation and use."
single non-negative,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
single non-negative integer,"A counter machine comprises a set of one or more unbounded registers, each of which can hold a single non-negative integer, and a list of (usually sequential) arithmetic and control instructions for the machine to follow."
discrete time-steps,"When used in this manner, the counter machine is used to model the discrete time-steps of a computational system in relation to memory accesses."
supporting decision-making,"Data analysis is a process of inspecting, cleansing, transforming, and modelling data with the goal of discovering useful information, informing conclusions, and supporting decision-making."
fixed-length groups,"In cryptography, a block cipher is a deterministic algorithm operating on fixed-length groups of bits, called blocks."
n-bit output block,"A block cipher consists of two paired algorithms, one for encryption, E, and the other for decryption, D. Both algorithms accept two inputs: an input block of size n bits and a key of size k bits; and both yield an n-bit output block."
corresponding 128-bit block,"For example, a block cipher encryption algorithm might take a 128-bit block of plaintext as input, and output a corresponding 128-bit block of ciphertext."
128-bit block,"For example, a block cipher encryption algorithm might take a 128-bit block of plaintext as input, and output a corresponding 128-bit block of ciphertext."
block-based texture compression algorithm developed,Adaptive scalable texture compression (ASTC) is a lossy block-based texture compression algorithm developed by Jrn Nystad et al.
lossy block-based,Adaptive scalable texture compression (ASTC) is a lossy block-based texture compression algorithm developed by Jrn Nystad et al.
lossy block-based texture compression algorithm developed,Adaptive scalable texture compression (ASTC) is a lossy block-based texture compression algorithm developed by Jrn Nystad et al.
trans-reality game,"A transreality game, sometimes written as trans-reality game, describes a type of video game or a mode of gameplay that combines playing a game in a virtual environment with game-related, physical experiences in the real world and vice versa."
real-world optimum,"Looking at a transreality game from that perspective it may also integrate (big) data feeds into the storylines of games as a means to make the gameplay more immersive, like in the setup of Liping Xie's experimental scientific simulations in which a population of sample individuals search a real-world optimum in a virtual problem space, driven by real world forces in that space."
soft-margin support vector machine described,The soft-margin support vector machine described above is an example of an empirical risk minimization (ERM) algorithm for the hinge loss.
pre-processing step followed,"Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space."
non-deterministic choice,"While the trace monoid had been studied by Pierre Cartier and Dominique Foata for its combinatorics in the 1960s, trace theory was first formulated by Antoni Mazurkiewicz in the 1970s, in an attempt to evade some of the problems in the theory of concurrent computation, including the problems of interleaving and non-deterministic choice with regards to refinement in process calculi."
computer-mediated reality system,"A synthetic vision system (SVS) is a computer-mediated reality system for aerial vehicles, that uses 3D to provide pilots with clear and intuitive means of understanding their flying environment."
unit-phase factor,"Consequently, if all singular values of a square matrix M are non-degenerate and non-zero, then its singular value decomposition is unique, up to multiplication of a column of U by a unit-phase factor and simultaneous multiplication of the corresponding column of V by the same unit-phase factor."
re-projection process,This section explains the actual geo warping or re-projection process when applied to radar video in real time.
non-flat display,"In humancomputer interaction, an organic user interface (OUI) is defined as a user interface with a non-flat display."
man-made objects,"Subsequent empirical studies have also shown the memory color effect on man-made objects (e. g. smurfs, German mailboxes), the effect being especially pronounced for blue and yellow objects."
yellowish-orange hues,"To explain this, researchers have argued that because natural daylight shifts from short wavelengths of light (i. e. , bluish hues) towards light of longer wavelengths (i. e. , yellowish-orange hues) during the day, the memory colors for blue and yellow objects are recruited by the visual system to a higher degree to compensate for this fluctuation in illumination, thereby providing a stronger memory color effect."
polynomial-time reduction proves,"A polynomial-time reduction proves that the first problem is no more difficult than the second one, because whenever an efficient algorithm exists for the second problem, one exists for the first problem as well."
time many-one,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
polynomial-time many,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
time many-one reductions,"The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
truth-table reductions,"The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
time many-one reduction,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction."
divide-and-conquer algorithm recursively breaks,"A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly."
general divide-and-conquer,"These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops."
x-generated algebras,"From a category theory perspective, a term algebra is the initial object for the category of all X-generated algebras of the same signature, and this object, unique up to isomorphism, is called an initial algebra; it generates by homomorphic projection all algebras in the category."
two-way digital radios,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios."
set-top boxes,"Bus encryption is used primarily in electronic systems that require high security, such as automated teller machines, TV set-top boxes, and secure data communication devices such as two-way digital radios. !! Unlike graphics processing units (GPUs), which are used for computer displays, media processors are targeted at digital televisions and set-top boxes."
so-called normal forms,"Database normalization is the process of structuring a database, usually a relational database, in accordance with a series of so-called normal forms in order to reduce data redundancy and improve data integrity."
second-tier journals,"As a general rule, publication of papers on metaphor-based metaheuristics has been limited to second-tier journals and conferences, but some recent exceptions to this rule can be found."
general-purpose emotion annotation,"An Emotion Markup Language (EML or EmotionML) has first been defined by the W3C Emotion Incubator Group (EmoXG) as a general-purpose emotion annotation and representation language, which should be usable in a large variety of technological contexts where emotions need to be represented."
self-balancing binary search tree inserts,"The insertion and deletion of elements in a sorted array executes at O(n), due to the need to shift all the elements following the element to be inserted or deleted; in comparison a self-balancing binary search tree inserts and deletes at O(log n)."
based system-on-a-chip,"A media processor, mostly used as an image/video processor, is a microprocessor-based system-on-a-chip which is designed to deal with digital streaming data in real-time (e. g. display refresh) rates."
processed using fixed-function,"DSP-like featuresPrevious to media processors, these streaming media datatypes were processed using fixed-function, hardwired ASICs, which could not be updated in the field."
"processed using fixed-function,","DSP-like featuresPrevious to media processors, these streaming media datatypes were processed using fixed-function, hardwired ASICs, which could not be updated in the field."
in-house media processor devices,"Companies such as Philips, Samsung, Matsushita, Fujitsu, Mitsubishi have their own in-house media processor devices."
multi-word sequences,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
also multi-word,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
also multi-word sequences,"There exist variants of the cache language model in which not only single words but also multi-word sequences that have occurred previously are assigned higher probabilities (e. g. , if ""San Francisco"" occurred near the beginning of the text subsequent instances of it would be assigned a higher probability)."
fetch-execute cycle,"The instruction cycle (also known as the fetchdecodeexecute cycle, or simply the fetch-execute cycle) is the cycle that the central processing unit (CPU) follows from boot-up until the computer has shut down in order to process instructions."
nondeterministic context-free,The languages of this class have great practical importance in computer science as they can be parsed much more efficiently than nondeterministic context-free languages.
enable face-to-face,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
face-to-face communication,"Graphically embodied agents aim to unite gesture, facial expression and speech to enable face-to-face communication with users, providing a powerful means of human-computer interaction."
typically two-dimensional,A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data.
typically two-dimensional),A self-organizing map (SOM) or self-organizing feature map (SOFM) is an unsupervised machine learning technique used to produce a low-dimensional (typically two-dimensional) representation of a higher dimensional data set while preserving the topological structure of the data.
k-independent hashing functions provide,"More generally, k-independent hashing functions provide a secure message authentication code as long as the key is used less than k times for k-ways independent hashing functions."
sensory-motor links,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
actions via sensory-motor,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
actions via sensory-motor links,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
exhibit complex-appearing,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
exhibit complex-appearing behaviors despite little internal variable state,"Behavior-based robotics (BBR) or behavioral robotics is an approach in robotics that focuses on robots that are able to exhibit complex-appearing behaviors despite little internal variable state to model its immediate environment, mostly gradually correcting its actions via sensory-motor links."
behavior-based robotics sets,Behavior-based robotics sets itself apart from traditional artificial intelligence by using biological systems as a model.
behavior-based robotics relies,"Rather than use preset calculations to tackle a situation, behavior-based robotics relies on adaptability."
allowed behavior-based,This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering.
allowed behavior-based robotics,This advancement has allowed behavior-based robotics to become commonplace in researching and data gathering.
peer-reviewed scientific journal covering applications,"Applied Artificial Intelligence is a peer-reviewed scientific journal covering applications of artificial intelligence in management, industry, engineering, administration, and education, as well as evaluations of existing AI systems and tools and their economic, social, and cultural impact."
short-circuit load,The above expressions can be substituted into the asymptotic gain model equation to find the overall gain G. The resulting gain is the current gain of the amplifier with a short-circuit load.
user-specified tolerance,"If the error exceeds a user-specified tolerance, the algorithm calls for subdividing the interval of integration in two and applying adaptive Simpson's method to each subinterval in a recursive manner."
new testable predictions far-from-equilibrium,"The Maximum Entropy thermodynamics has some important opposition, in part because of the relative paucity of published results from the MaxEnt school, especially with regard to new testable predictions far-from-equilibrium."
copy-on-write technique,Shadow paging is a copy-on-write technique for avoiding in-place updates of pages.
in-place updates,"Shadow paging is a copy-on-write technique for avoiding in-place updates of pages. !! Shadow paging is also similar to purely functional data structures, in that in-place updates are avoided."
single self-reference,"Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion."
contains multiple self-reference,"Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion."
contains multiple self-references,"Recursion that contains only a single self-reference is known as single recursion, while recursion that contains multiple self-references is known as multiple recursion."
prolog-style query answering,If we think of the stable model semantics as a description of the behavior of Prolog in the presence of negation then programs without a unique stable model can be judged unsatisfactory: they do not provide an unambiguous specification for Prolog-style query answering.
five-year standardization process,"This announcement followed a five-year standardization process in which fifteen competing designs were presented and evaluated, before the Rijndael cipher was selected as the most suitable (see Advanced Encryption Standard process for more details)."
original infinite-dimensional context,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
original infinite-dimensional,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
ill-conditioned problems result,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
infinite-dimensional context,"Typically discrete linear ill-conditioned problems result from discretization of integral equations, and one can formulate a Tikhonov regularization in the original infinite-dimensional context."
pre-categorical logic,"It was found that the connectives of pre-categorical logic were more clearly understood using the concept of adjoint functor, and that the quantifiers were also best understood using adjoint functors."
off-load certain tasks,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
hard real-time,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
hard real-time applications,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
ultra-low-power designs,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
low-power designs,"In computing, autonomous peripheral operation is a hardware feature found in some microcontroller architectures to off-load certain tasks into embedded autonomous peripherals in order to minimize latencies and improve throughput in hard real-time applications as well as to save energy in ultra-low-power designs."
run-time environment take,"Programs themselves often do not contribute the largest portions to their own memory footprints; rather, structures introduced by the run-time environment take up most of the memory."
allows high-priority tasks,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
allows high-priority,A Deferred Procedure Call (DPC) is a Microsoft Windows operating system mechanism which allows high-priority tasks (e. g. an interrupt handler) to defer required but lower-priority tasks for later execution.
normally-paced real time speech,Time-compressed speech refers to an audio recording of verbal text in which the text is presented in a much shorter time interval than it would through normally-paced real time speech.
time-compressed speech refers,Time-compressed speech refers to an audio recording of verbal text in which the text is presented in a much shorter time interval than it would through normally-paced real time speech.
"""time-compressed speech","While some voice talents are capable of speaking at rates significantly in excess of general norms, the term ""time-compressed speech"" most usually refers to examples in which the time-reduction has been accomplished through some form of electronic processing of the recorded speech. !! The term ""time-compressed speech"" should not be confused with ""speech compression"", which controls the volume range of a sound, but does not alter its time envelope."
time-compressed speech,Time-compressed speech is frequently used in television and radio advertising.
first-last choice,"Ennis provides a comprehensive account of the derivation of Thurstonian models for a wide variety of behavioral tasks including preferential choice, ratings, triads, tetrads, dual pair, same-different and degree of difference, ranks, first-last choice, and applicability scoring."
well-known problem,"In Chapter 7 of this book, a closed form expression, derived in 1988, is given for a Euclidean-Gaussian similarity model that provides a solution to the well-known problem that many Thurstonian models are computationally complex often involving multiple integration."
table-driven bottom,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
driven bottom-up,"A shift-reduce parser is a class of efficient, table-driven bottom-up parsing methods for computer languages and other notations formally defined by a grammar."
shift-reduce parser scans,"A shift-reduce parser scans and parses the input text in one forward pass over the text, without backing up."
shift-reduce parser works,"A shift-reduce parser works by doing some combination of Shift steps and Reduce steps, hence the name."
shift-reduce parsers use,Shift-reduce parsers use a context-free grammar that deals just with local patterns of symbols.
simplicity-complexity axis,Cognitive complexity describes cognition along a simplicity-complexity axis.
worker-crew model,"Often also called a replicated workers or worker-crew model, a thread pool maintains multiple threads waiting for tasks to be allocated for concurrent execution by the supervising program."
human-computer interaction refers,"Multimodal human-computer interaction refers to the ""interaction with the virtual and physical environment through natural modes of communication"", This implies that multimodal interaction enables a more free and natural communication, interfacing users with automated systems in both input and output."
execution-order constraints,"In compiler theory, dependence analysis produces execution-order constraints between statements/instructions."
dependence analysis produces execution-order constraints,"In compiler theory, dependence analysis produces execution-order constraints between statements/instructions."
unit-cost operations,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
simply unit-cost operations,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
simply unit-cost,"In the field of runtime analysis of algorithms, it is common to specify a computational model in terms of primitive operations allowed which have unit cost, or simply unit-cost operations."
short-term memory networks,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units. !! 5 billion automatic translations every day using long short-term memory networks."
5 billion automatic translations every day using long short-term memory networks,5 billion automatic translations every day using long short-term memory networks.
widely used long short-term memory neural network,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
widely used long short-term,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
short-term memory neural network,Their study describes a novel neural network that performs better on certain data sets than the widely used long short-term memory neural network.
dce-supporting system,"By integrating security, RPC and other distributed services on a single ""official"" distributed computing environment, OSF could offer a major advantage over SVR4, allowing any DCE-supporting system (namely OSF/1) to interoperate in a larger network."
alignment-free sequence analysis approaches,"In bioinformatics, alignment-free sequence analysis approaches to molecular sequence and structure data provide alternatives over alignment-based approaches."
alignment-based approaches,"In bioinformatics, alignment-free sequence analysis approaches to molecular sequence and structure data provide alternatives over alignment-based approaches."
large-scale integration circuits devices,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
special purpose custom large-scale,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
special purpose custom large-scale integration circuits devices,"The PMOS and I2L logic families were used for relatively short periods, mostly in special purpose custom large-scale integration circuits devices and are generally considered obsolete."
nearly-sorted list,Comparison sorts may run faster on some lists; many adaptive sorts such as insertion sort run in O(n) time on an already-sorted or nearly-sorted list.
multi-label active learning,"Recent developments are dedicated to multi-label active learning, hybrid active learning and active learning in a single-pass (on-line) context, combining concepts from the field of machine learning (e. g. conflict and ignorance) with adaptive, incremental learning policies in the field of online machine learning."
includes four independent two-input,"The standard 4000 series CMOS IC is the 4071, which includes four independent two-input OR gates."
also chi-square,"In probability theory and statistics, the chi-squared distribution (also chi-square or 2-distribution) with k degrees of freedom is the distribution of a sum of the squares of k independent standard normal random variables."
general noncentral chi-squared distribution,"This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution."
central chi-squared,"This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution."
general noncentral chi-squared,"This distribution is sometimes called the central chi-squared distribution, a special case of the more general noncentral chi-squared distribution."
common chi-squared,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
common chi-squared tests,"The chi-squared distribution is used in the common chi-squared tests for goodness of fit of an observed distribution to a theoretical one, the independence of two criteria of classification of qualitative data, and in confidence interval estimation for a population standard deviation of a normal distribution from a sample standard deviation."
partition-based selection,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
n-based selection,"A further relaxation requiring only a list of the k smallest elements, but without requiring that these be ordered, makes the problem equivalent to partition-based selection; the original partial sorting problem can be solved by such a selection algorithm to obtain an array where the first k elements are the k smallest, and sorting these, at a total cost of O(n + k log k) operations."
e-definite matrix,"In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
pronounced sh-les-kee),"In linear algebra, the Cholesky decomposition or Cholesky factorization (pronounced sh-LES-kee) is a decomposition of a Hermitian, positive-definite matrix into the product of a lower triangular matrix and its conjugate transpose, which is useful for efficient numerical solutions, e. g. , Monte Carlo simulations."
valued symmetric positive-definite matrix,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
thus also every real-valued,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
l-valued symmetric positive,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
thus also every real-valued symmetric positive,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
real-valued symmetric positive,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
valued symmetric positive-definite,"where L is a lower triangular matrix with real and positive diagonal entries, and L* denotes the conjugate transpose of L. Every Hermitian positive-definite matrix (and thus also every real-valued symmetric positive-definite matrix) has a unique Cholesky decomposition."
positive-real-valued functions,"So for positive-real-valued functions, the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors."
real-valued functions,"So for positive-real-valued functions, the logarithmic derivative of a product is the sum of the logarithmic derivatives of the factors."
real-valued vector,"In natural language processing (NLP), word embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning."
co-occurring words,"Word embeddings come in two different styles, one in which words are expressed as vectors of co-occurring words, and another in which words are expressed as vectors of linguistic contexts in which the words occur; these different styles are studied in (Lavelli et al."
corpus-driven approach,"Hunston, Susan; Francis, Gill, Pattern Grammar: A corpus-driven approach to the lexical grammar of English, John Benjamins, 2000."
known pseudo-polynomial,An NP-complete problem with known pseudo-polynomial time algorithms is called weakly NP-complete.
known pseudo-polynomial time algorithms,An NP-complete problem with known pseudo-polynomial time algorithms is called weakly NP-complete.
cross-domain interoperability exists,"Cross-domain interoperability exists when organizations or systems from different domains interact in information exchange, services, and/or goods to achieve their own or common goals."
cross-domain interoperability enables synergy,"Cross-domain interoperability enables synergy, extends product utility and enables users to be more effective and successful within their own domains and the combined effort."
three-way comparison takes two values,"In computer science, a three-way comparison takes two values A and B belonging to a type with a total order and determines whether A < B, A = B, or A > B in a single operation, in accordance with the mathematical law of trichotomy."
three-way comparison method,"Many object-oriented languages have a three-way comparison method, which performs a three-way comparison between the object and another given object."
three-way comparison operator,"When implementing a three-way comparison where a three-way comparison operator or method is not already available, it is common to combine two comparisons, such as A = B and A < B, or A < B and A > B."
tree-based structures,"Although the idea of evolving programs, initially in the computer language Lisp, was current amongst John Hollands students, it was not until they organised the first Genetic Algorithms (GA) conference in Pittsburgh that Nichael Cramer published evolved programs in two specially designed languages, which included the first statement of modern ""tree-based"" Genetic Programming (that is, procedural languages organized in tree-based structures and operated on by suitably defined GA-operators)."
improve human-machine,"The Artificial Intelligence of Things (AIoT) is the combination of Artificial intelligence (AI) technologies with the Internet of things (IoT) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance data management and analytics."
improve human-machine interactions,"The Artificial Intelligence of Things (AIoT) is the combination of Artificial intelligence (AI) technologies with the Internet of things (IoT) infrastructure to achieve more efficient IoT operations, improve human-machine interactions and enhance data management and analytics."
general-purpose cognitive systems,"While general-purpose cognitive systems can be used for different outputs, prescriptive, suggestive, instructive, or simply entertaining, an enterprise cognitive system is focused on action, not insight, to help in assessing what to do in a complex situation."
iterative deepening depth-first,"When an appropriate depth limit is not known a priori, iterative deepening depth-first search applies DFS repeatedly with a sequence of increasing limits."
depth-first search starting,"a depth-first search starting at the node A, assuming that the left edges in the shown graph are chosen before right edges, and assuming the search remembers previously visited nodes and will not repeat them (since this is a small graph), will visit the nodes in the following order: A, B, D, F, E, C, G. The edges traversed in this search form a Trmaux tree, a structure with important applications in graph theory."
low-key feedback usually needs,"In computer software, the low-key feedback usually needs to be designed in."
cell-phone antenna design,"This makes computational electromagnetics (CEM) important to the design, and modeling of antenna, radar, satellite and other communication systems, nanophotonic devices and high speed silicon electronics, medical imaging, cell-phone antenna design, among other applications."
use loosely-coupled designs,Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
use loosely-coupled,Application Response Measurement (ARM) is an open standard published by the Open Group for monitoring and diagnosing performance bottlenecks within complex enterprise applications that use loosely-coupled designs or service-oriented architectures.
later record-breaking,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
later record-breaking sorting algorithms,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
record-breaking sorting algorithms,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
merge-insertion sort ideas,and later record-breaking sorting algorithms have all used modifications of the merge-insertion sort ideas.
call-return stack separated,Stack machines may have their expression stack and their call-return stack separated or as one integrated structure.
length-direction decoupling,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
batch normalization achieves length-direction decoupling,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
batch normalization achieves length-direction,"Others sustain that batch normalization achieves length-direction decoupling, and thereby accelerates neural networks."
stack-based algorithm,The Cartesian tree for a sequence may be constructed in linear time using a stack-based algorithm for finding all nearest smaller values in a sequence.
mass-spring system,"Spectral clustering is well known to relate to partitioning of a mass-spring system, where each mass is associated with a data point and each spring stiffness corresponds to a weight of an edge describing a similarity of the two related data points, as in the spring system."
over-relaxation algorithm,"According to the successive over-relaxation algorithm, the following table is obtained, representing an exemplary iteration with approximations, which ideally, but not necessarily, finds the exact solution, (3, 2, 2, 1), in 38 steps."
nature-inspired metaheuristic techniques,Adaptive dimensional search algorithms differ from nature-inspired metaheuristic techniques in the sense that they do not use any metaphor as an underlying principle for implementation.
long short-term,"Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units."
time-domain method,A Fourier pseudospectral time-domain method can be applied to wave propagation problems pertinent to computational aeroacoustics.
in-place algorithm updates,An in-place algorithm updates its input sequence only through replacement or swapping of elements.
in-place algorithms usually overwrite,"Since in-place algorithms usually overwrite their input with output, no additional space is needed."
in-place category,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
non-constant space technically takes quicksort,"Although this non-constant space technically takes quicksort out of the in-place category, quicksort and other algorithms needing only O(log n) additional pointers are usually considered in-place algorithms."
maximum cut-set,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
self-intersecting curve,"However, in planar graphs, the Maximum-Cut Problem is dual to the route inspection problem (the problem of finding a shortest tour that visits each edge of a graph at least once), in the sense that the edges that do not belong to a maximum cut-set of a graph G are the duals of the edges that are doubled in an optimal inspection tour of the dual graph of G. The optimal inspection tour forms a self-intersecting curve that separates the plane into two subsets, the subset of points for which the winding number of the curve is even and the subset for which the winding number is odd; these two subsets form a cut that includes all of the edges whose duals appear an odd number of times in the tour."
real-life scenarios,There are some theories that explain how this social translucence can affect the behavior of people in real-life scenarios.
socio-technical systems,"proposed the principle of identity as a fourth dimension for social translucence by arguing that the design of socio-technical systems should have a rich description of who is visible, to give people control over disclosure and mechanisms to advocate for their needs."
measure-many automaton,"Very roughly, the theory of a quantum Markov chain resembles that of a measure-many automaton, with some important substitutions: the initial state is to be replaced by a density matrix, and the projection operators are to be replaced by positive operator valued measures."
0-1 loss function,Empirical risk minimization for a classification problem with a 0-1 loss function is known to be an NP-hard problem even for such a relatively simple class of functions as linear classifiers.
np-hard problem even,Empirical risk minimization for a classification problem with a 0-1 loss function is known to be an NP-hard problem even for such a relatively simple class of functions as linear classifiers.
support write-back,"The MESI protocol is an Invalidate-based cache coherence protocol, and is one of the most common protocols that support write-back caches."
support write-back caches,"The MESI protocol is an Invalidate-based cache coherence protocol, and is one of the most common protocols that support write-back caches."
invalidate-based cache coherence protocol,"The MESI protocol is an Invalidate-based cache coherence protocol, and is one of the most common protocols that support write-back caches."
perform tasks like pre-amplification,"The preceding stages in such a chain are low power audio amplifiers which perform tasks like pre-amplification of the signal (this is particularly associated with record turntable signals, microphone signals and electric instrument signals from pickups, such as the electric guitar and electric bass), equalization (e. g. , adjusting the bass and treble), tone controls, mixing different input signals or adding electronic effects such as reverb."
field-effect transistor,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
metaloxidesemiconductor field-effect transistor,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
metaloxidesemiconductor field-effect,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
solid-state transistors,"Since the 1970s, most modern audio amplifiers are based on solid-state transistors, especially the bipolar junction transistor (BJT) and the metaloxidesemiconductor field-effect transistor (MOSFET)."
hi-fi audio amplifiers,Power MOSFETs were soon manufactured by Yamaha for their hi-fi audio amplifiers.
fixed-point combinators,This anonymous recursion can be produced generically via fixed-point combinators.
produced generically via fixed-point,This anonymous recursion can be produced generically via fixed-point combinators.
produced generically via fixed-point combinators,This anonymous recursion can be produced generically via fixed-point combinators.
typically implemented using bit-slice chips,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
stand-alone digital signal processor,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
bit-slice chips,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
typically implemented using bit-slice,"Prior to the advent of stand-alone digital signal processor (DSP) chips, early digital signal processing applications were typically implemented using bit-slice chips."
random-access memory takes,"In today's technology, random-access memory takes the form of integrated circuit (IC) chips with MOS (metal-oxide-semiconductor) memory cells."
although non-volatile,"RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed."
dynamic random-access,"RAM is normally associated with volatile types of memory (such as dynamic random-access memory (DRAM) modules), where stored information is lost if power is removed, although non-volatile RAM has also been developed. !! The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM)."
static random-access,The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM).
volatile random-access,The two main types of volatile random-access semiconductor memory are static random-access memory (SRAM) and dynamic random-access memory (DRAM).
general-purpose database,"A spatial database is a general-purpose database (usually a relational database) that has been enhanced to include spatial data that represents objects defined in a geometric space, along with tools for querying and analyzing such data."
general problem-solvers,The earliest work in computerized knowledge representation was focused on general problem-solvers such as the General Problem Solver (GPS) system developed by Allen Newell and Herbert A. Simon in 1959.
ternary search trees include spell-checking,Common applications for ternary search trees include spell-checking and auto-completion.
one-pass algorithm generally requires,"A one-pass algorithm generally requires O(n) (see 'big O' notation) time and less than O(n) storage (typically O(1)), where n is the size of the input."
non-constant polynomial,"In mathematics, a square-free polynomial is a polynomial defined over a field (or more generally, an integral domain) that does not have as a divisor any square of a non-constant polynomial."
pairwise coprime square-free polynomials,"where those of the ak that are non-constant are pairwise coprime square-free polynomials (here, two polynomials are said coprime is their greatest common divisor is a constant; in other words that is the coprimality over the field of fractions of the coefficients that is considered)."
pairwise coprime square-free,"where those of the ak that are non-constant are pairwise coprime square-free polynomials (here, two polynomials are said coprime is their greatest common divisor is a constant; in other words that is the coprimality over the field of fractions of the coefficients that is considered)."
multi-agent systems research may deliver,"Applications where multi-agent systems research may deliver an appropriate approach include online trading, disaster response, target surveillance and social structure modelling."
multi-agent systems consist,Multi-agent systems consist of agents and their environment.
full-scale universal quantum computer,"While many proposals of quantum machine learning algorithms are still purely theoretical and require a full-scale universal quantum computer to be tested, others have been implemented on small-scale or special purpose quantum devices."
general 20th-,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
21st-century reaction,"In adopting a system perspective on language, systemic functional linguistics have been part of a more general 20th- and 21st-century reaction against atomistic approaches to science, in which an essence is sought within smaller and smaller components of the phenomenon under study."
meta-process modeling supports,Meta-process modeling supports the effort of creating flexible process models.
meta-process modeling focuses,Meta-process modeling focuses on and supports the process of constructing process models.
program type-checks,"Although this is a very useful property, it has a drawback: a programming language with the normalization property cannot be Turing complete, otherwise one could solve the halting problem by seeing if the program type-checks."
step-by-step refinement process,Low-level design (LLD) is a component-level design process that follows a step-by-step refinement process.
high-level overview,Detailed or low-level designStructured flow charts and HIPO diagrams typify the class of software design tools and these provide a high-level overview of a program.
good low-level,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
low-level design document makes,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
good low-level design document makes,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
good low-level design document,A good low-level design document makes the program easy to develop when proper analysis is utilized to create a low-level design document.
node-graph visual programming languages,Godot game engine allows game scripts and graphics shaders to be built using node-graph visual programming languages.
built using node-graph visual programming languages,Godot game engine allows game scripts and graphics shaders to be built using node-graph visual programming languages.
built using node-graph,Godot game engine allows game scripts and graphics shaders to be built using node-graph visual programming languages.
high-level mechanisms,"The need for boilerplate can be reduced through high-level mechanisms such as metaprogramming (which has the computer automatically write the needed boilerplate code or insert it at compile time), convention over configuration (which provides good default values, reducing the need to specify program details in every project) and model-driven engineering (which uses models and model-to-code generators, eliminating the need for manual boilerplate code)."
human-computer interaction research,"Hands-on computing is a branch of human-computer interaction research which focuses on computer interfaces that respond to human touch or expression, allowing the machine and the user to interact physically."
earliest hands-on,Keyboards and typewriters are some of the earliest hands-on computing devices.
cross-language data serialization,"RProtoBuf provides cross-language data serialization in R, using Protocol Buffers."
non-artistic aspects,The non-artistic aspects of computer graphics are the subject of computer science research.
non-linear series acceleration method,"In numerical analysis, the Shanks transformation is a non-linear series acceleration method to increase the rate of convergence of a sequence."
specifying service-oriented,"Service-oriented modeling is the discipline of modeling business and software systems, for the purpose of designing and specifying service-oriented business systems within a variety of architectural styles and paradigms, such as application architecture, service-oriented architecture, microservices, and cloud computing."
specifying service-oriented business systems within,"Service-oriented modeling is the discipline of modeling business and software systems, for the purpose of designing and specifying service-oriented business systems within a variety of architectural styles and paradigms, such as application architecture, service-oriented architecture, microservices, and cloud computing."
service-oriented business systems within,"Service-oriented modeling is the discipline of modeling business and software systems, for the purpose of designing and specifying service-oriented business systems within a variety of architectural styles and paradigms, such as application architecture, service-oriented architecture, microservices, and cloud computing."
service development life-cycle,"Any service-oriented modeling method typically includes a modeling language that can be employed by both the ""problem domain organization"" (the business), and ""solution domain organization"" (the information technology department), whose unique perspectives typically influence the service development life-cycle strategy and the projects implemented using that strategy."
service development life-cycle strategy,"Any service-oriented modeling method typically includes a modeling language that can be employed by both the ""problem domain organization"" (the business), and ""solution domain organization"" (the information technology department), whose unique perspectives typically influence the service development life-cycle strategy and the projects implemented using that strategy."
service-oriented modeling method typically includes,"Any service-oriented modeling method typically includes a modeling language that can be employed by both the ""problem domain organization"" (the business), and ""solution domain organization"" (the information technology department), whose unique perspectives typically influence the service development life-cycle strategy and the projects implemented using that strategy."
life-cycle strategy,"Any service-oriented modeling method typically includes a modeling language that can be employed by both the ""problem domain organization"" (the business), and ""solution domain organization"" (the information technology department), whose unique perspectives typically influence the service development life-cycle strategy and the projects implemented using that strategy."
service-oriented modeling typically strives,"Service-oriented modeling typically strives to create models that provide a comprehensive view of the analysis, design, and architecture of all software entities in an organization, which can be understood by individuals with diverse levels of business and technical understanding."
soa-related methodology,IBM announced service-oriented modeling and architecture (SOMA) as its SOA-related methodology in 2004 and published parts of it subsequently.
services within service-oriented,Service-orientation design principles are proposed principles for developing the solution logic of services within service-oriented architectures (SOA).
run-time type identification,"In computer programming, run-time type information or run-time type identification (RTTI) is a feature of some programming languages (such as C++, Object Pascal, and Ada) that exposes information about an object's data type at runtime."
run-time type information may,Run-time type information may be available for all types or only to types that explicitly have it (as is the case with Ada).
run-time type information,Run-time type information is a specialization of a more general concept called type introspection.
include run-time type information,"In the original C++ design, Bjarne Stroustrup did not include run-time type information, because he thought this mechanism was often misused."
include run-time,"In the original C++ design, Bjarne Stroustrup did not include run-time type information, because he thought this mechanism was often misused."
minimum-weight edge,"A path in the maximum spanning tree is the widest path in the graph between its two endpoints: among all possible paths, it maximizes the weight of the minimum-weight edge."
hacker-powered application security solutions offered,These are hacker-powered application security solutions offered by many websites and software developers by which individuals can receive recognition and compensation for reporting bugs.
self-similar fractal,The H tree is a self-similar fractal; its Hausdorff dimension is equal to 2.
well-defined communication interfaces,"Asynchronous systems much like object-oriented software are typically constructed out of modular 'hardware objects', each with well-defined communication interfaces."
object-oriented software,"Asynchronous systems much like object-oriented software are typically constructed out of modular 'hardware objects', each with well-defined communication interfaces."
correct-by-construction methodologies,"Hence, asynchronous systems match well the need for correct-by-construction methodologies in assembling large-scale heterogeneous and scalable systems."
large-scale heterogeneous,"Hence, asynchronous systems match well the need for correct-by-construction methodologies in assembling large-scale heterogeneous and scalable systems."
assembling large-scale,"Hence, asynchronous systems match well the need for correct-by-construction methodologies in assembling large-scale heterogeneous and scalable systems."
assembling large-scale heterogeneous,"Hence, asynchronous systems match well the need for correct-by-construction methodologies in assembling large-scale heterogeneous and scalable systems."
raster-graphics file format,"Portable Network Graphics (PNG, officially pronounced PING, colloquially pronounced PEE-en-JEE) is a raster-graphics file format that supports lossless data compression."
image-based observations,"Articulated body pose estimation in computer vision is the study of algorithms and systems that recover the pose of an articulated body, which consists of joints and rigid parts using image-based observations."
rigid parts using image-based observations,"Articulated body pose estimation in computer vision is the study of algorithms and systems that recover the pose of an articulated body, which consists of joints and rigid parts using image-based observations."
rigid parts using image-based,"Articulated body pose estimation in computer vision is the study of algorithms and systems that recover the pose of an articulated body, which consists of joints and rigid parts using image-based observations."
model-based approach,"The typical articulated body pose estimation system involves a model-based approach, in which the pose estimation is achieved by maximizing/minimizing a similarity/dissimilarity between an observation (input) and a template model."
specialized computer vision-based,A commercially successful but specialized computer vision-based articulated body pose estimation technique is optical motion capture.
specialized computer vision-based articulated body pose estimation technique,A commercially successful but specialized computer vision-based articulated body pose estimation technique is optical motion capture.
out-treeor making,"A rooted tree may be directed, called a directed rooted tree, either making all its edges point away from the rootin which case it is called an arborescence or out-treeor making all its edges point towards the rootin which case it is called an anti-arborescence or in-tree."
out-forestor making,"A rooted forest may be directed, called a directed rooted forest, either making all its edges point away from the root in each rooted treein which case it is called a branching or out-forestor making all its edges point towards the root in each rooted treein which case it is called an anti-branching or in-forest."
based brain-computer interface,Brain painting is a non-invasive P300-based brain-computer interface (BCI) that allows painting without the use of muscular activity.
p300-based brain,Brain painting is a non-invasive P300-based brain-computer interface (BCI) that allows painting without the use of muscular activity.
brain-computer interface,Brain painting is a non-invasive P300-based brain-computer interface (BCI) that allows painting without the use of muscular activity.
based brain-computer,Brain painting is a non-invasive P300-based brain-computer interface (BCI) that allows painting without the use of muscular activity.
non-strict functional programming language,"In computer science, strictness analysis refers to any algorithm used to prove that a function in a non-strict functional programming language is strict in one or more of its arguments."
high-dimensional data,"This led to new clustering algorithms for high-dimensional data that focus on subspace clustering (where only some attributes are used, and cluster models include the relevant attributes for the cluster) and correlation clustering that also looks for arbitrary rotated (""correlated"") subspace clusters that can be modeled by giving a correlation of their attributes. !! For high-dimensional data (e. g. , with number of dimensions more than 10) dimension reduction is usually performed prior to applying the k-NN algorithm in order to avoid the effects of the curse of dimensionality."
difficult-to-maintain source code,Spaghetti code is a pejorative phrase for unstructured and difficult-to-maintain source code.
forsaking object-oriented concepts like polymorphism,"Spaghetti code can also describe an anti-pattern in which object-oriented code is written in a procedural style, such as by creating classes whose methods are overly long and messy, or forsaking object-oriented concepts like polymorphism."
forsaking object-oriented,"Spaghetti code can also describe an anti-pattern in which object-oriented code is written in a procedural style, such as by creating classes whose methods are overly long and messy, or forsaking object-oriented concepts like polymorphism."
object-oriented concepts like polymorphism,"Spaghetti code can also describe an anti-pattern in which object-oriented code is written in a procedural style, such as by creating classes whose methods are overly long and messy, or forsaking object-oriented concepts like polymorphism."
compare prototype-based,"Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance occurs via defining classes of objects, instead of inheritance occurring via the objects alone (compare prototype-based programming)."
compare prototype-based programming,"Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance occurs via defining classes of objects, instead of inheritance occurring via the objects alone (compare prototype-based programming)."
commonly class-orientation,"Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance occurs via defining classes of objects, instead of inheritance occurring via the objects alone (compare prototype-based programming)."
"commonly class-orientation,","Class-based programming, or more commonly class-orientation, is a style of object-oriented programming (OOP) in which inheritance occurs via defining classes of objects, instead of inheritance occurring via the objects alone (compare prototype-based programming)."
called greedy best-first,This specific type of search is called greedy best-first search or pure heuristic search.
called greedy best-first search,This specific type of search is called greedy best-first search or pure heuristic search.
greedy best-first,"Neither A* nor B* is a greedy best-first search, as they incorporate the distance from the start in addition to estimated distances to the goal."
out-of-sample test space,"In regression analysis, ""mean squared error"", often referred to as mean squared prediction error or ""out-of-sample mean squared error"", can also refer to the mean value of the squared deviations of the predictions from the true values, over an out-of-sample test space, generated by a model estimated over a particular sample space."
non-uniform branching factor,"The Distributed Tree Search Algorithm (also known as KorfFerguson algorithm) was created to solve the following problem: ""Given a tree with non-uniform branching factor and depth, search it in parallel with an arbitrary number of processors as fast as possible. """
n-odd magic squares,"The Siamese method, or De la Loubre method, is a simple method to construct any size of n-odd magic squares (i. e. number squares in which the sums of all rows, columns and diagonals are identical)."
domain-specific facts,"In ""Applications of Abduction: Knowledge-Level Modeling"", Menzies proposes a new knowledge level modeling approach, called KLB, which specifies that ""a knowledge base should be divided into domain-specific facts and domain-independent abstract problem solving inference procedures. """
every context-free grammar,"Also, neither B nor C may be the start symbol, and the third production rule can only appear if is in L(G), the language produced by the context-free grammar G. :9293,106Every grammar in Chomsky normal form is context-free, and conversely, every context-free grammar can be transformed into an equivalent one which is in Chomsky normal form and has a size no larger than the square of the original grammar's size."
every context-free,"Also, neither B nor C may be the start symbol, and the third production rule can only appear if is in L(G), the language produced by the context-free grammar G. :9293,106Every grammar in Chomsky normal form is context-free, and conversely, every context-free grammar can be transformed into an equivalent one which is in Chomsky normal form and has a size no larger than the square of the original grammar's size."
worst-case height,"720 times the worst-case height of RB trees, so AVL trees are more rigidly balanced."
carry-lookahead adder improves speed,A carry-lookahead adder improves speed by reducing the amount of time required to determine carry bits.
carry-lookahead adder calculates one,"The carry-lookahead adder calculates one or more carry bits before the sum, which reduces the wait time to calculate the result of the larger-value bits of the adder."
larger-value bits,"The carry-lookahead adder calculates one or more carry bits before the sum, which reduces the wait time to calculate the result of the larger-value bits of the adder."
first carry-lookahead,"Konrad Zuse is thought to have implemented the first carry-lookahead adder in his 1930s binary mechanical computer, the Zuse Z1."
first carry-lookahead adder,"Konrad Zuse is thought to have implemented the first carry-lookahead adder in his 1930s binary mechanical computer, the Zuse Z1."
modern binary carry-lookahead adder,Gerald B. Rosenberger of IBM filed for a patent on a modern binary carry-lookahead adder in 1957.
modern binary carry-lookahead,Gerald B. Rosenberger of IBM filed for a patent on a modern binary carry-lookahead adder in 1957.
one sub-graph,"By extending the sharing to several BDDs, i. e. one sub-graph is used by several BDDs, the data structure Shared Reduced Ordered Binary Decision Diagram is defined."
mechanical speech-synthesizers continues,"Despite the success of purely electronic speech synthesis, research into mechanical speech-synthesizers continues."
mechanical speech-synthesizers,"Despite the success of purely electronic speech synthesis, research into mechanical speech-synthesizers continues."
speech-synthesizers continues,"Despite the success of purely electronic speech synthesis, research into mechanical speech-synthesizers continues."
two typesdeterministic finite-state machines,Finite-state machines are of two typesdeterministic finite-state machines and non-deterministic finite-state machines.
two typesdeterministic finite-state,Finite-state machines are of two typesdeterministic finite-state machines and non-deterministic finite-state machines.
non-deterministic finite,Finite-state machines are of two typesdeterministic finite-state machines and non-deterministic finite-state machines.
non-deterministic one,A deterministic finite-state machine can be constructed equivalent to any non-deterministic one.
density parity-check,"Applications of graphical models include causal inference, information extraction, speech recognition, computer vision, decoding of low-density parity-check codes, modeling of gene regulatory networks, gene finding and diagnosis of diseases, and graphical models for protein structure."
low-density parity,"Applications of graphical models include causal inference, information extraction, speech recognition, computer vision, decoding of low-density parity-check codes, modeling of gene regulatory networks, gene finding and diagnosis of diseases, and graphical models for protein structure."
density parity-check codes,"Applications of graphical models include causal inference, information extraction, speech recognition, computer vision, decoding of low-density parity-check codes, modeling of gene regulatory networks, gene finding and diagnosis of diseases, and graphical models for protein structure."
parity-check codes,"Applications of graphical models include causal inference, information extraction, speech recognition, computer vision, decoding of low-density parity-check codes, modeling of gene regulatory networks, gene finding and diagnosis of diseases, and graphical models for protein structure."
self-identified persuasive technology research focuses,"Most self-identified persuasive technology research focuses on interactive, computational technologies, including desktop computers, Internet services, video games, and mobile devices, but this incorporates and builds on the results, theories, and methods of experimental psychology, rhetoric, and human-computer interaction."
self-selection biases,Analyses aimed at identifying the presence and extent of self-selection biases in persuasive technology trials are not widespread yet.
non-diagonally-dominant cases,Two notable variants are the recursive SPIKE algorithm for non-diagonally-dominant cases and the truncated SPIKE algorithm for diagonally-dominant cases.
diagonally-dominant cases,Two notable variants are the recursive SPIKE algorithm for non-diagonally-dominant cases and the truncated SPIKE algorithm for diagonally-dominant cases.
spike-preconditioned iterative solver,"To solve a linear system Ax = b using a SPIKE-preconditioned iterative solver, one extracts center bands from A to form a banded preconditioner M and solves linear systems involving M in each iteration with the SPIKE algorithm."
transformational-generative grammar,"In linguistics, transformational grammar (TG) or transformational-generative grammar (TGG) is part of the theory of generative grammar, especially of natural languages."
non-negative edge weights,"Given an undirected graph with non-negative edge weights and a subset of vertices, usually referred to as terminals, the Steiner tree problem in graphs requires a tree of minimum weight that contains all terminals (but may include additional vertices). !! In weighted complete graphs with non-negative edge weights, the weighted longest path problem is the same as the Travelling salesman path problem, because the longest path always includes all vertices."
criss-cross algorithm also solve,"Variants of the criss-cross algorithm also solve more general problems with linear inequality constraints and nonlinear objective functions; there are criss-cross algorithms for linear-fractional programming problems, quadratic-programming problems, and linear complementarity problems."
service-orientation design paradigm,"Service abstraction is a design principle that is applied within the service-orientation design paradigm so that the information published in a service contract is limited to what is required to effectively utilize the service The service contract should not contain any superfluous information that is not required for its invocation. !! The service reusability principle is a design principle, applied within the service-orientation design paradigm, to create services that can be reused across a business."
discrete-time infinite,Impulse invariance is a technique for designing discrete-time infinite-impulse-response (IIR) filters from continuous-time filters in which the impulse response of the continuous-time system is sampled to produce the impulse response of the discrete-time system.
time infinite-impulse-response,Impulse invariance is a technique for designing discrete-time infinite-impulse-response (IIR) filters from continuous-time filters in which the impulse response of the continuous-time system is sampled to produce the impulse response of the discrete-time system.
continuous-time filters,Impulse invariance is a technique for designing discrete-time infinite-impulse-response (IIR) filters from continuous-time filters in which the impulse response of the continuous-time system is sampled to produce the impulse response of the discrete-time system.
designing discrete-time infinite,Impulse invariance is a technique for designing discrete-time infinite-impulse-response (IIR) filters from continuous-time filters in which the impulse response of the continuous-time system is sampled to produce the impulse response of the discrete-time system.
designing discrete-time,Impulse invariance is a technique for designing discrete-time infinite-impulse-response (IIR) filters from continuous-time filters in which the impulse response of the continuous-time system is sampled to produce the impulse response of the discrete-time system.
time infinite-impulse,Impulse invariance is a technique for designing discrete-time infinite-impulse-response (IIR) filters from continuous-time filters in which the impulse response of the continuous-time system is sampled to produce the impulse response of the discrete-time system.
discrete-time case,"The bilinear transform is an alternative to impulse invariance that uses a different mapping that maps the continuous-time system's frequency response, out to infinite frequency, into the range of frequencies up to the Nyquist frequency in the discrete-time case, as opposed to mapping frequencies linearly with circular overlap as impulse invariance does."
discrete-time impulse response,"If the system function has zeros as well as poles, they can be mapped the same way, but the result is no longer an impulse invariance result: the discrete-time impulse response is not equal simply to samples of the continuous-time impulse response."
continuous-time impulse response,"If the system function has zeros as well as poles, they can be mapped the same way, but the result is no longer an impulse invariance result: the discrete-time impulse response is not equal simply to samples of the continuous-time impulse response."
finite-state model,"In computer science, model checking or property checking is a method for checking whether a finite-state model of a system meets a given specification (also known as correctness)."
sometimes pronounced sea-surf),"Cross-site request forgery, also known as one-click attack or session riding and abbreviated as CSRF (sometimes pronounced sea-surf) or XSRF, is a type of malicious exploit of a website where unauthorized commands are submitted from a user that the web application trusts."
sometimes pronounced sea-surf,"Cross-site request forgery, also known as one-click attack or session riding and abbreviated as CSRF (sometimes pronounced sea-surf) or XSRF, is a type of malicious exploit of a website where unauthorized commands are submitted from a user that the web application trusts."
reflex excess-3,"Excess-3 Gray code (1956) (aka Gray excess-3 code, Gray 3-excess code, reflex excess-3 code, excess Gray code, Gray excess code, 10-excess-3 Gray code or GrayStibitz code), described by Frank P. Turvey Jr. of ITT."
reflex excess-3 code,"Excess-3 Gray code (1956) (aka Gray excess-3 code, Gray 3-excess code, reflex excess-3 code, excess Gray code, Gray excess code, 10-excess-3 Gray code or GrayStibitz code), described by Frank P. Turvey Jr. of ITT."
3-excess code,"Excess-3 Gray code (1956) (aka Gray excess-3 code, Gray 3-excess code, reflex excess-3 code, excess Gray code, Gray excess code, 10-excess-3 Gray code or GrayStibitz code), described by Frank P. Turvey Jr. of ITT."
utilizes real-world,Responsive computer-aided design (also simplified to responsive design) is an approach to computer-aided design (CAD) that utilizes real-world sensors and data to modify a three-dimensional (3D) computer model.
real-world sensors,Responsive computer-aided design (also simplified to responsive design) is an approach to computer-aided design (CAD) that utilizes real-world sensors and data to modify a three-dimensional (3D) computer model.
utilizes real-world sensors,Responsive computer-aided design (also simplified to responsive design) is an approach to computer-aided design (CAD) that utilizes real-world sensors and data to modify a three-dimensional (3D) computer model.
equational first-order,The superposition calculus is a calculus for reasoning in equational first-order logic.
equational first-order logic,The superposition calculus is a calculus for reasoning in equational first-order logic.
bicycle attack makes brute-forcing,"The bicycle attack makes brute-forcing of passwords much easier, because only passwords of the known length need to be tested."
pre-topological ordering gives,"In other cases, any pre-topological ordering gives a partial order."
cache coherent non-uniform,The MESIF protocol is a cache coherency and memory coherence protocol developed by Intel for cache coherent non-uniform memory architectures.
non-uniform memory architectures,The MESIF protocol is a cache coherency and memory coherence protocol developed by Intel for cache coherent non-uniform memory architectures.
direct cache-to-cache,The F state in the MESIF protocol is simply a way to choose one of the sharers of a clean cache line to respond to a read request for data using a direct cache-to-cache transfer instead of waiting for the data to come from the main memory.
cache-to-cache transfer instead,The F state in the MESIF protocol is simply a way to choose one of the sharers of a clean cache line to respond to a read request for data using a direct cache-to-cache transfer instead of waiting for the data to come from the main memory.
linear-time bound,"Various in-place merge algorithms have been devised, sometimes sacrificing the linear-time bound to produce an O(n log n) algorithm; see Merge sort Variants for discussion."
constraint-length convolutional codes,Sequential decoding is mainly used as an approximate decoding algorithm for long constraint-length convolutional codes.
long constraint-length convolutional codes,Sequential decoding is mainly used as an approximate decoding algorithm for long constraint-length convolutional codes.
long constraint-length,Sequential decoding is mainly used as an approximate decoding algorithm for long constraint-length convolutional codes.
many-body quantum mechanical,"Auxiliary-field Monte Carlo is a method that allows the calculation, by use of Monte Carlo techniques, of averages of operators in many-body quantum mechanical (Blankenbecler 1981, Ceperley 1977) or classical problems (Baeurle 2004, Baeurle 2003, Baeurle 2002a)."
auxiliary-field representation,"The distinctive ingredient of ""auxiliary-field Monte Carlo"" is the fact that the interactions are decoupled by means of the application of the HubbardStratonovich transformation, which permits the reformulation of many-body theory in terms of a scalar auxiliary-field representation."
scalar auxiliary-field,"The distinctive ingredient of ""auxiliary-field Monte Carlo"" is the fact that the interactions are decoupled by means of the application of the HubbardStratonovich transformation, which permits the reformulation of many-body theory in terms of a scalar auxiliary-field representation."
scalar auxiliary-field representation,"The distinctive ingredient of ""auxiliary-field Monte Carlo"" is the fact that the interactions are decoupled by means of the application of the HubbardStratonovich transformation, which permits the reformulation of many-body theory in terms of a scalar auxiliary-field representation."
many-body theory,"The distinctive ingredient of ""auxiliary-field Monte Carlo"" is the fact that the interactions are decoupled by means of the application of the HubbardStratonovich transformation, which permits the reformulation of many-body theory in terms of a scalar auxiliary-field representation."
well-defined element,"The lift F is unique modulo integers, therefore the rotation number is a well-defined element of R/Z."
step-by-step procedure,"Similarly, a quantum algorithm is a step-by-step procedure, where each of the steps can be performed on a quantum computer."
hypothetical computing machines using a848infinite-precision,"In computability theory, the theory of real computation deals with hypothetical computing machines using infinite-precision real numbers."
infinite-precision real numbers,"In computability theory, the theory of real computation deals with hypothetical computing machines using infinite-precision real numbers."
hypothetical computing machines using infinite-precision real numbers,"In computability theory, the theory of real computation deals with hypothetical computing machines using infinite-precision real numbers."
public-facing web servers,"According to Netcraft in May 2015, the industry standard for monitoring active TLS certificates, ""Although the global [TLS] ecosystem is competitive, it is dominated by a handful of major CAs three certificate authorities (Symantec, Comodo, GoDaddy) account for three-quarters of all issued [TLS] certificates on public-facing web servers."
non-zero coefficients,"In mathematics, the degree of a polynomial is the highest of the degrees of the polynomial's monomials (individual terms) with non-zero coefficients."
internet-speed development method,"Often one of the biggest problems in software engineering is that the requirements change quickly and the internet-speed development method was created to adapt to this situation. !! The goal of the internet-speed development method is to allow software developers to perform a project in a structured way, but still be able to adapt to the needs of the customer."
idea behind internet-speed development,"The idea behind internet-speed development is that the combination of these models will result in a method which does not have these disadvantages and is a better method to use in situations where requirements can change rapidly, but the project has to be executed in a structured way."
idea behind internet-speed,"The idea behind internet-speed development is that the combination of these models will result in a method which does not have these disadvantages and is a better method to use in situations where requirements can change rapidly, but the project has to be executed in a structured way."
fixed-size values,A hash function is any function that can be used to map data of arbitrary size to fixed-size values.
n-time analysis,Run-time analysis is a theoretical classification that estimates and anticipates the increase in running time (or run-time or execution time) of an algorithm as its input size (usually denoted as n) increases.
filter-like operations,"The set builder notation and list comprehension notation are both instances of a more general notation known as monad comprehensions, which permits map/filter-like operations over any monad with a zero element."
map/filter-like operations,"The set builder notation and list comprehension notation are both instances of a more general notation known as monad comprehensions, which permits map/filter-like operations over any monad with a zero element."
error-prone step,"Runtime verification avoids the complexity of traditional formal verification techniques, such as model checking and theorem proving, by analyzing only one or a few execution traces and by working directly with the actual system, thus scaling up relatively well and giving more confidence in the results of the analysis (because it avoids the tedious and error-prone step of formally modelling the system), at the expense of less coverage."
pre-specified model structure,"While conventional regression techniques seek to optimize the parameters for a pre-specified model structure, symbolic regression avoids imposing prior assumptions, and instead infers the model from the data."
higher-dimensional analogues,"This is inspired from the fact that the above is exactly equal for all nonzero x if = 0, and has the advantage of simple generalization to higher-dimensional analogues of the sign function (for example, the partial derivatives of x2 + y2)."
already nearly upper-triangular,"Moreover, because the Hessenberg form is already nearly upper-triangular (it has just one nonzero entry below each diagonal), using it as a starting point reduces the number of steps required for convergence of the QR algorithm."
positive-definite symmetric matrix,The basic QR algorithm can be visualized in the case where A is a positive-definite symmetric matrix.
e-mail spammers,Bayesian poisoning is a technique used by e-mail spammers to attempt to degrade the effectiveness of spam filters that rely on Bayesian spam filtering.
well-known variant,"One well-known variant, which is often used synonymously with the term Steiner tree problem, is the Steiner tree problem in graphs."
well-known variants,Further well-known variants are the Euclidean Steiner tree problem and the rectilinear minimum Steiner tree problem.
bit-serial adder,The serial binary adder or bit-serial adder is a digital circuit that performs binary addition bit by bit.
piece-by-piece input,The research on online optimization can be distinguished into online problems where multiple decisions are made sequentially based on a piece-by-piece input and those where a decision is made only once.
e-commerce platform,B2B Gateways provide businesses an e-commerce platform for integrating with key suppliers and customers quickly and easily.
information-theoretic lower bound,"In computer science, a succinct data structure is a data structure which uses an amount of space that is ""close"" to the information-theoretic lower bound, but (unlike other compressed representations) still allows for efficient query operations."
algorithm-specific indication,A string metric provides a number indicating an algorithm-specific indication of distance.
character-based methods,"Simplistic string metrics such as Levenshtein distance have expanded to include phonetic, token, grammatical and character-based methods of statistical comparisons."
first-order logic uses quantified variables,"First-order logic uses quantified variables over non-logical objects, and allows the use of sentences that contain variables, so that rather than propositions such as ""Socrates is a man"", one can have expressions in the form ""there exists x such that x is Socrates and x is a man"", where ""there exists"" is a quantifier, while x is a variable."
first-order logic together,"A theory about a topic is usually a first-order logic together with a specified domain of discourse (over which the quantified variables range), finitely many functions from that domain to itself, finitely many predicates defined on that domain, and a set of axioms believed to hold about them."
use breadth-first,"For example, in a chess endgame a chess engine may build the game tree from the current position by applying all possible moves, and use breadth-first search to find a win position for white."
use breadth-first search,"For example, in a chess endgame a chess engine may build the game tree from the current position by applying all possible moves, and use breadth-first search to find a win position for white."
problem-solving trees,Implicit trees (such as game trees or other problem-solving trees) may be of infinite size; breadth-first search is guaranteed to find a solution node if one exists.
socio-technical system,"Understood as a socio-technical system, the term enterprise defines the scope of the enterprise architecture."
including self-referential,"Similarly, since objects in computer memory are not inherently sequential, and may include links to other objects (including self-referential links), XML data binding mappings often have difficulty preserving all the information about an object when it is marshalled to XML."
called gradient-boosted trees,"When a decision tree is the weak learner, the resulting algorithm is called gradient-boosted trees; it usually outperforms random forest."
called gradient-boosted,"When a decision tree is the weak learner, the resulting algorithm is called gradient-boosted trees; it usually outperforms random forest."
gradient-boosted trees model,"A gradient-boosted trees model is built in a stage-wise fashion as in other boosting methods, but it generalizes the other methods by allowing optimization of an arbitrary differentiable loss function."
stage-wise fashion,"A gradient-boosted trees model is built in a stage-wise fashion as in other boosting methods, but it generalizes the other methods by allowing optimization of an arbitrary differentiable loss function."
well-researched domains,Well-researched domains of object detection include face detection and pedestrian detection.
non-neural approaches,Methods for object detection generally fall into either neural network-based or non-neural approaches.
either neural network-based,Methods for object detection generally fall into either neural network-based or non-neural approaches.
present object-oriented programming,"Eric S. Raymond, a Unix programmer and open-source software advocate, has been critical of claims that present object-oriented programming as the ""One True Solution"", and has written that object-oriented programming languages tend to encourage thickly layered programs that destroy transparency."
object-oriented programming languages tend,"Eric S. Raymond, a Unix programmer and open-source software advocate, has been critical of claims that present object-oriented programming as the ""One True Solution"", and has written that object-oriented programming languages tend to encourage thickly layered programs that destroy transparency."
present object-oriented,"Eric S. Raymond, a Unix programmer and open-source software advocate, has been critical of claims that present object-oriented programming as the ""One True Solution"", and has written that object-oriented programming languages tend to encourage thickly layered programs that destroy transparency."
min-max heaps support logarithmic insertion,"Like binary min-heaps and max-heaps, min-max heaps support logarithmic insertion and deletion and can be built in linear time."
maximally non-linear;,"In the mathematical field of combinatorics, a bent function is a special type of Boolean function which is maximally non-linear; it is as different as possible from the set of all linear and affine functions when measured by Hamming distance between truth tables."
maximally non-linear,"In the mathematical field of combinatorics, a bent function is a special type of Boolean function which is maximally non-linear; it is as different as possible from the set of all linear and affine functions when measured by Hamming distance between truth tables."
make different trade-offs,"There are many methods of texture filtering, which make different trade-offs between computational complexity, memory bandwidth and image quality."
model-based testing,The Test Template Framework (TTF) is a model-based testing (MBT) framework proposed by Phil Stocks and David Carrington in (Stocks & Carrington 1996) for the purpose of software testing.
applying object-oriented programming,"Object-oriented analysis and design (OOAD) is a technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality."
applying object-oriented,"Object-oriented analysis and design (OOAD) is a technical approach for analyzing and designing an application, system, or business by applying object-oriented programming, as well as using visual modeling throughout the software development process to guide stakeholder communication and product quality."
sinusoidal-hyperbolic transform functions,"In 2019 a new family of sinusoidal-hyperbolic transform functions, which have comparable properties and performance with DCT, were proposed for lossy compression."
high-risk workplace environments,"Therefore, interruption science typically examines the effects of interruptions in high-risk workplace environments such as aviation, medicine, and vehicle operation in which human error can have serious, potentially disastrous consequences."
coarse-grained temporal multithreading,"There are many possible variations of coarse-grained temporal multithreading, mainly concerning the algorithm that determines when thread switching occurs."
common half-duplex,A bus network is a network topology in which nodes are directly connected to a common half-duplex link called a bus.
half-duplex link called,A bus network is a network topology in which nodes are directly connected to a common half-duplex link called a bus.
common half-duplex link called,A bus network is a network topology in which nodes are directly connected to a common half-duplex link called a bus.
lower-level competencies,"Because a robot must have the ability to ""avoid objects"" in order to ""wander around"" effectively, the subsumption architecture creates a system in which the higher layers utilize the lower-level competencies."
input-output system,Embodied cognitive science differs from the traditionalist approach in that it denies the input-output system.
two-person zero,The linear search problem was solved by Anatole Beck and Donald J. Newman (1970) as a two-person zero-sum game.
person zero-sum,The linear search problem was solved by Anatole Beck and Donald J. Newman (1970) as a two-person zero-sum game.
zero-sum game,The linear search problem was solved by Anatole Beck and Donald J. Newman (1970) as a two-person zero-sum game.
person zero-sum game,The linear search problem was solved by Anatole Beck and Donald J. Newman (1970) as a two-person zero-sum game.
optimal addition-chain,"In mathematics and computer science, optimal addition-chain exponentiation is a method of exponentiation by positive integer powers that requires a minimal number of multiplications."
optimal addition-chain exponentiation,"In mathematics and computer science, optimal addition-chain exponentiation is a method of exponentiation by positive integer powers that requires a minimal number of multiplications."
non-minimal addition chains constructed,"More generally, addition-chain exponentiation may also refer to exponentiation by non-minimal addition chains constructed by a variety of algorithms (since a shortest addition chain is very difficult to find)."
addition-chain exponentiation may also refer,"More generally, addition-chain exponentiation may also refer to exponentiation by non-minimal addition chains constructed by a variety of algorithms (since a shortest addition chain is very difficult to find)."
addition-chain exponentiation requires,"Even given a shortest chain, addition-chain exponentiation requires more memory than the binary method, because it must potentially store many previous exponents from the chain."
shortest addition-chain exponentiation,"So in practice, shortest addition-chain exponentiation is primarily used for small fixed exponents for which a shortest chain can be precomputed and is not too large."
shortest addition-chain,"So in practice, shortest addition-chain exponentiation is primarily used for small fixed exponents for which a shortest chain can be precomputed and is not too large."
manner enables multi-word add,"The use of the carry flag in this manner enables multi-word add, subtract, shift, and rotate operations."
multi-word add,"The use of the carry flag in this manner enables multi-word add, subtract, shift, and rotate operations."
manner enables multi-word,"The use of the carry flag in this manner enables multi-word add, subtract, shift, and rotate operations."
brute-force attacks work,Brute-force attacks work by calculating every possible combination that could make up a password and testing it to see if it is the correct password.
previous brute-force,Credential recycling refers to the hacking practice of re-using username and password combinations gathered in previous brute-force attacks.
previous brute-force attacks,Credential recycling refers to the hacking practice of re-using username and password combinations gathered in previous brute-force attacks.
re-using username,Credential recycling refers to the hacking practice of re-using username and password combinations gathered in previous brute-force attacks.
m-way threaded binary tree,"In an m-way threaded binary tree with n nodes, there are n*m - (n-1) void links."
agent-based computational economics,"Agent-based computational economics (ACE) is the area of computational economics that studies economic processes, including whole economies, as dynamic systems of interacting agents."
grid-based approach,"Compared with the grid-based approach, the Monte Carlo localization is more accurate because the state represented in samples is not discretized."
non-standard variants,"However, some non-standard variants of set theory include a universal set."
reactor pattern completely separates application-specific code,"The reactor pattern completely separates application-specific code from the reactor implementation, which means that application components can be divided into modular, reusable parts."
reactor pattern completely separates application-specific,"The reactor pattern completely separates application-specific code from the reactor implementation, which means that application components can be divided into modular, reusable parts."
application-specific code,"The reactor pattern completely separates application-specific code from the reactor implementation, which means that application components can be divided into modular, reusable parts."
dimensional radiative-convective climate model,Effect of ice-albedo feedback on global sensitivity in a one-dimensional radiative-convective climate model.
radiative-convective climate model,Effect of ice-albedo feedback on global sensitivity in a one-dimensional radiative-convective climate model.
ice-albedo feedback,Effect of ice-albedo feedback on global sensitivity in a one-dimensional radiative-convective climate model.
dimensional radiative-convective,Effect of ice-albedo feedback on global sensitivity in a one-dimensional radiative-convective climate model.
one-dimensional radiative,Effect of ice-albedo feedback on global sensitivity in a one-dimensional radiative-convective climate model.
long-term human behaviour,Computational archaeology describes computer-based analytical methods for the study of long-term human behaviour and behavioural evolution.
computer-based analytical methods,Computational archaeology describes computer-based analytical methods for the study of long-term human behaviour and behavioural evolution.
human-natural systems science,"The Computational Archaeology Lab at San Diego State University focuses on Open-Science and Open-Source approaches to GIS, Agent Based Modeling, Imagery Analysis, and Computation in archaeology and coupled human-natural systems science."
coupled human-natural,"The Computational Archaeology Lab at San Diego State University focuses on Open-Science and Open-Source approaches to GIS, Agent Based Modeling, Imagery Analysis, and Computation in archaeology and coupled human-natural systems science."
coupled human-natural systems science,"The Computational Archaeology Lab at San Diego State University focuses on Open-Science and Open-Source approaches to GIS, Agent Based Modeling, Imagery Analysis, and Computation in archaeology and coupled human-natural systems science."
on-site web analytics,"There are at least two categories of web analytics, off-site and on-site web analytics."
gradient-descent algorithms used,"Among the most used adaptive algorithms is the Widrow-Hoffs least mean squares (LMS), which represents a class of stochastic gradient-descent algorithms used in adaptive filtering and machine learning."
stochastic gradient-descent algorithms used,"Among the most used adaptive algorithms is the Widrow-Hoffs least mean squares (LMS), which represents a class of stochastic gradient-descent algorithms used in adaptive filtering and machine learning."
re-write rules,"Grammar induction (or grammatical inference) is the process in machine learning of learning a formal grammar (usually as a collection of re-write rules or productions or alternatively as a finite state machine or automaton of some kind) from a set of observations, thus constructing a model which accounts for the characteristics of the observed objects."
sub-trees corresponds,"In the case of grammar induction, the transplantation of sub-trees corresponds to the swapping of production rules that enable the parsing of phrases from some language."
example-based translation,"The principle of grammar induction has been applied to other aspects of natural language processing, and has been applied (among many other problems) to semantic parsing, natural language understanding, example-based translation, morpheme analysis, and place name derivations."
grammar-based compression,Grammar induction has also been used for grammar-based compression and statistical inference via minimum message length (MML) and minimum description length (MDL) principles.
proportional-fair scheduling,"The simplest best-effort scheduling algorithms are round-robin, fair queuing (a max-min fair scheduling algorithm), proportional-fair scheduling and maximum throughput."
simplest best-effort,"The simplest best-effort scheduling algorithms are round-robin, fair queuing (a max-min fair scheduling algorithm), proportional-fair scheduling and maximum throughput."
simplest best-effort scheduling algorithms,"The simplest best-effort scheduling algorithms are round-robin, fair queuing (a max-min fair scheduling algorithm), proportional-fair scheduling and maximum throughput."
best-effort scheduling algorithms,"The simplest best-effort scheduling algorithms are round-robin, fair queuing (a max-min fair scheduling algorithm), proportional-fair scheduling and maximum throughput."
point-of-sale experience,"An Out-of-box experience (OOBE pronounced oo-bee) is the experience an end-user has when taking a product after unboxing, or for digital distribution, runs the installer, and is preparing to first use it, as opposed to the point-of-sale experience or the interaction experience of an expert user."
out-of-box experience,"An Out-of-box experience (OOBE pronounced oo-bee) is the experience an end-user has when taking a product after unboxing, or for digital distribution, runs the installer, and is preparing to first use it, as opposed to the point-of-sale experience or the interaction experience of an expert user."
text-based grammars differs,"Note that while the syntax for the text-based grammars differs, the syntax diagram for all of them can be the same because it is a metalanguage."
millimeter-sized devices operated,Neural dust is a term used to refer to millimeter-sized devices operated as wirelessly powered nerve sensors; it is a type of braincomputer interface.
interface-based programming defines,"Interface-based programming defines the application as a collection of components, in which Application Programming Interface (API) calls between components may only be made through abstract interfaces, not concrete classes."
upper-bound limits,"For this purpose, the field of limit analysis is based on a set of theorems, referred to as limit theorems, which are a set of theorems based on the law of conservation of energy that state properties regarding stresses and strains, lower and upper-bound limits for the collapse load and the exact collapse load."
2n2-dimensional vector space,"However the complex Hermitian matrices do form a vector space over the real numbers R. In the 2n2-dimensional vector space of complex nn matrices over R, the complex Hermitian matrices form a subspace of dimension n2."
implementing higher-level,"The NCP interface allowed application software to connect across the ARPANET by implementing higher-level communication protocols, an early example of the protocol layering concept."
implementing higher-level communication protocols,"The NCP interface allowed application software to connect across the ARPANET by implementing higher-level communication protocols, an early example of the protocol layering concept."
higher-level communication protocols,"The NCP interface allowed application software to connect across the ARPANET by implementing higher-level communication protocols, an early example of the protocol layering concept."
class-based programming languages,"In class-based programming languages, these are distinguished into two types: class variables (also called static member variables), where only one copy of the variable is shared with all instances of the class; and instance variables, where each instance of the class has its own independent copy of the variable."
linux-based operating system designed,Chrome OS (sometimes styled as chromeOS) is a Linux-based operating system designed by Google.
error-detecting code commonly used,A cyclic redundancy check (CRC) is an error-detecting code commonly used in digital networks and storage devices to detect accidental changes to raw data.
anti-pattern arising,"In computer programming, abstraction inversion is an anti-pattern arising when users of a construct need functions implemented within it but not exposed by its interface."
implementing lower-level,"This may result in implementing lower-level features in terms of higher-level ones, thus the term 'abstraction inversion'."
higher-level ones,"This may result in implementing lower-level features in terms of higher-level ones, thus the term 'abstraction inversion'."
implementing lower-level features,"This may result in implementing lower-level features in terms of higher-level ones, thus the term 'abstraction inversion'."
n-dimensional grid network,"In general, when an n-dimensional grid network is connected circularly in more than one dimension, the resulting network topology is a torus, and the network is called ""toroidal""."
flight-simulation work,"In 1967, flight-simulation work by Danny Cohen led to the development of the CohenSutherland computer graphics two- and three-dimensional line clipping algorithms, created with Ivan Sutherland."
universities rarely taught humanities-based,Humanistic informatics departments were generally started in the 1990s when universities rarely taught humanities-based approaches to the rapidly developing computerized society.
humanities-based approaches,Humanistic informatics departments were generally started in the 1990s when universities rarely taught humanities-based approaches to the rapidly developing computerized society.
universities rarely taught humanities-based approaches,Humanistic informatics departments were generally started in the 1990s when universities rarely taught humanities-based approaches to the rapidly developing computerized society.
4-input majority gate,"The few systems that calculate the majority function on an even number of inputs are often biased towards ""0""they produce ""0"" when exactly half the inputs are 0 -- for example, a 4-input majority gate has a 0 output only when two or more 0's appear at its inputs."
component sub-systems,"System integration is defined in engineering as the process of bringing together the component sub-systems into one system (an aggregation of subsystems cooperating so that the system is able to deliver the overarching functionality) and ensuring that the subsystems function together as a system, and in information technology as the process of linking together different computing systems and software applications physically or functionally, to act as a coordinated whole."
component sub-system,"System integration is defined in engineering as the process of bringing together the component sub-systems into one system (an aggregation of subsystems cooperating so that the system is able to deliver the overarching functionality) and ensuring that the subsystems function together as a system, and in information technology as the process of linking together different computing systems and software applications physically or functionally, to act as a coordinated whole."
hand-written rules,"Up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules."
ad-hoc webservice architectures,GraphQL is a data query language developed by Facebook as an alternate to REST and ad-hoc webservice architectures.
higher-level features,Deep learning is a class of machine learning algorithms that:199200 uses multiple layers to progressively extract higher-level features from the raw input.
progressively extract higher-level features,Deep learning is a class of machine learning algorithms that:199200 uses multiple layers to progressively extract higher-level features from the raw input.
progressively extract higher-level,Deep learning is a class of machine learning algorithms that:199200 uses multiple layers to progressively extract higher-level features from the raw input.
general-purpose hosts,"The nodes of a computer network may include personal computers, servers, networking hardware, or other specialised or general-purpose hosts."
user-selected master password,Some password managers use a user-selected master password or passphrase to form the key used to encrypt the protected passwords.
lowest-level programming paradigms,"The lowest-level programming paradigms are machine code, which directly represents the instructions (the contents of program memory) as a sequence of numbers, and assembly language where the machine instructions are represented by mnemonics and memory addresses can be given symbolic labels."
dominant general-purpose personal computer operating system,The dominant general-purpose personal computer operating system is Microsoft Windows with a market share of around 76.
dominant general-purpose,The dominant general-purpose personal computer operating system is Microsoft Windows with a market share of around 76.
general-purpose personal computer operating system,The dominant general-purpose personal computer operating system is Microsoft Windows with a market share of around 76.
"quantum algorithms include phase kick-back,","Some commonly used techniques/ideas in quantum algorithms include phase kick-back, phase estimation, the quantum Fourier transform, quantum walks, amplitude amplification and topological quantum field theory."
quantum algorithms include phase kick-back,"Some commonly used techniques/ideas in quantum algorithms include phase kick-back, phase estimation, the quantum Fourier transform, quantum walks, amplitude amplification and topological quantum field theory."
e-mail authentication details,"Some browser hijackers also contain spyware, for example, some install a software keylogger to gather information such as banking and e-mail authentication details."
first-come first,"In best-effort packet switching and other statistical multiplexing, round-robin scheduling can be used as an alternative to first-come first-served queuing."
best-effort packet switching,"In best-effort packet switching and other statistical multiplexing, round-robin scheduling can be used as an alternative to first-come first-served queuing."
come first-served,"In best-effort packet switching and other statistical multiplexing, round-robin scheduling can be used as an alternative to first-come first-served queuing."
come first-served queuing,"In best-effort packet switching and other statistical multiplexing, round-robin scheduling can be used as an alternative to first-come first-served queuing."
first-served queuing,"In best-effort packet switching and other statistical multiplexing, round-robin scheduling can be used as an alternative to first-come first-served queuing."
provides round-robin scheduling,"A multiplexer, switch, or router that provides round-robin scheduling has a separate queue for every data flow, where a data flow may be identified by its source and destination address."
provides round-robin,"A multiplexer, switch, or router that provides round-robin scheduling has a separate queue for every data flow, where a data flow may be identified by its source and destination address."
round-robin scheduling results,"Round-robin scheduling results in max-min fairness if the data packets are equally sized, since the data flow that has waited the longest time is given scheduling priority."
max-min fairness,"Round-robin scheduling results in max-min fairness if the data packets are equally sized, since the data flow that has waited the longest time is given scheduling priority."
well-known definition,One well-known definition of what constitutes a relational database system is composed of Codd's 12 rules.
domain-specific language,"A scripting language can be viewed as a domain-specific language for a particular environment; in the case of scripting an application, it is also known as an extension language."
compressed possible self-contained representation,"Informally, from the point of view of algorithmic information theory, the information content of a string is equivalent to the length of the most-compressed possible self-contained representation of that string."
self-contained representation,"Informally, from the point of view of algorithmic information theory, the information content of a string is equivalent to the length of the most-compressed possible self-contained representation of that string."
compressed possible self-contained,"Informally, from the point of view of algorithmic information theory, the information content of a string is equivalent to the length of the most-compressed possible self-contained representation of that string."
most-compressed possible self,"Informally, from the point of view of algorithmic information theory, the information content of a string is equivalent to the length of the most-compressed possible self-contained representation of that string."
vendor lock-in,"Data portability is a concept to protect users from having their data stored in ""silos"" or ""walled gardens"" that are incompatible with one another, i. e. closed platforms, thus subjecting them to vendor lock-in and making the creation of data backups difficult."
user-accessible local file,"Data portability requires common technical standards to facilitate the transfer from one data controller to another, such as the ability to export user data into a user-accessible local file, thus promoting interoperability, as well as facilitate searchability with sophisticated tools such as grep."
specialized tree-based,"In computer science, a heap is a specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: in a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. In a min heap, the key of P is less than or equal to the key of C. The node at the ""top"" of the heap (with no parents) is called the root node."
specialized tree-based data structure,"In computer science, a heap is a specialized tree-based data structure which is essentially an almost complete tree that satisfies the heap property: in a max heap, for any given node C, if P is a parent node of C, then the key (the value) of P is greater than or equal to the key of C. In a min heap, the key of P is less than or equal to the key of C. The node at the ""top"" of the heap (with no parents) is called the root node."
space-optimized trie,"In computer science, a radix tree (also radix trie or compact prefix tree) is a data structure that represents a space-optimized trie (prefix tree) in which each node that is the only child is merged with its parent."
acoustic-based method,"In computing, scratch input is an acoustic-based method of Human-Computer Interaction (HCI) that takes advantage of the characteristic sound produced when a finger nail or other object is dragged over a surface, such as a table or wall."
system-on-a-chip design,An application-specific instruction set processor (ASIP) is a component used in system-on-a-chip design.
x-ray images,"In the twenty-first century, intelligent databases have now become widespread, e. g. hospital databases can now call up patient histories consisting of charts, text and x-ray images just with a few mouse clicks, and many corporate databases include decision support tools based on sales pattern analysis."
twenty-first century,"In the twenty-first century, intelligent databases have now become widespread, e. g. hospital databases can now call up patient histories consisting of charts, text and x-ray images just with a few mouse clicks, and many corporate databases include decision support tools based on sales pattern analysis."
smallest context-free grammar,"In data compression and the theory of formal languages, the smallest grammar problem is the problem of finding the smallest context-free grammar that generates a given string of characters (but no other string)."
smallest context-free,"In data compression and the theory of formal languages, the smallest grammar problem is the problem of finding the smallest context-free grammar that generates a given string of characters (but no other string)."
translates layer-2 addresses,"The Reverse Address Resolution Protocol (Reverse ARP or RARP), like InARP, translates layer-2 addresses to layer-3 addresses."
translates layer-2,"The Reverse Address Resolution Protocol (Reverse ARP or RARP), like InARP, translates layer-2 addresses to layer-3 addresses."
same-length sequence,"In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency."
equally-spaced samples,"In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency."
complex-valued function,"In mathematics, the discrete Fourier transform (DFT) converts a finite sequence of equally-spaced samples of a function into a same-length sequence of equally-spaced samples of the discrete-time Fourier transform (DTFT), which is a complex-valued function of frequency."
odd-time odd,is known as an odd-time odd-frequency discrete Fourier transform (or O2 DFT).
time odd-frequency,is known as an odd-time odd-frequency discrete Fourier transform (or O2 DFT).
z-transforms correspond,"The discrete Fourier transform can be viewed as a special case of the z-transform, evaluated on the unit circle in the complex plane; more general z-transforms correspond to complex shifts a and b above."
general z-transforms correspond,"The discrete Fourier transform can be viewed as a special case of the z-transform, evaluated on the unit circle in the complex plane; more general z-transforms correspond to complex shifts a and b above."
encompasses high-throughput genomic,"In academia, computational immunology is a field of science that encompasses high-throughput genomic and bioinformatics approaches to immunology."
high-throughput genomic,"In academia, computational immunology is a field of science that encompasses high-throughput genomic and bioinformatics approaches to immunology."
encompasses high-throughput,"In academia, computational immunology is a field of science that encompasses high-throughput genomic and bioinformatics approaches to immunology."
j-th column,is used to denote the element of the i-th line and j-th column of the observed formation matrix.
i-th line,is used to denote the element of the i-th line and j-th column of the observed formation matrix.
open-loop solution,"Generally speaking, trajectory optimization is a technique for computing an open-loop solution to an optimal control problem."
closed-loop solution,"If a trajectory optimization problem can be solved at a rate given by the inverse of the Lipschitz constant, then it can be used iteratively to generate a closed-loop solution in the sense of Caratheodory."
activity-based learning,"There are a wide range of alternatives for the term active learning, such as: learning through play, technology-based learning, activity-based learning, group work, project method, etc."
technology-based learning,"There are a wide range of alternatives for the term active learning, such as: learning through play, technology-based learning, activity-based learning, group work, project method, etc."
mostly two-,"The shapes studied in geometric modeling are mostly two- or three-dimensional, although many of its tools and principles can be applied to sets of any finite dimension."
computer-based applications,Today most geometric modeling is done with computers and for computer-based applications.
individual-based models,"A review of recent literature on individual-based models, agent-based models, and multiagent systems shows that ABMs are used in many scientific domains including biology, ecology and social science."
decision-making heuristics,Most agent-based models are composed of: (1) numerous agents specified at various scales (typically referred to as agent-granularity); (2) decision-making heuristics; (3) learning rules or adaptive processes; (4) an interaction topology; and (5) an environment.
macro-language tradition,"The C preprocessor was part of a long macro-language tradition at Bell Labs, which was started by Douglas Eastwood and Douglas McIlroy in 1959."
long macro-language tradition,"The C preprocessor was part of a long macro-language tradition at Bell Labs, which was started by Douglas Eastwood and Douglas McIlroy in 1959."
long macro-language,"The C preprocessor was part of a long macro-language tradition at Bell Labs, which was started by Douglas Eastwood and Douglas McIlroy in 1959."
little-known usage pattern,One little-known usage pattern of the C preprocessor is known as X-Macros.
rejecting invalid e-mail addresses remains,"Callback verification can still work if rejecting all bounces happens at the DATA stage instead of the earlier MAIL FROM stage, while rejecting invalid e-mail addresses remains at the RCPT TO stage instead of also being moved to the DATA stage."
rejecting invalid e-mail,"Callback verification can still work if rejecting all bounces happens at the DATA stage instead of the earlier MAIL FROM stage, while rejecting invalid e-mail addresses remains at the RCPT TO stage instead of also being moved to the DATA stage."
e-mail addresses remains,"Callback verification can still work if rejecting all bounces happens at the DATA stage instead of the earlier MAIL FROM stage, while rejecting invalid e-mail addresses remains at the RCPT TO stage instead of also being moved to the DATA stage."
unsolicited bulk e-mail,"Some administrators consider any callback verification to be unsolicited bulk e-mail (UBE), and may block the originating SMTP client, report it as spam, or add it to DNSBLs, even if the backscatter is of low volume."
lower-dimensional space prior,"This is an instance of the more general strategy of dimensionality reduction, which seeks to map the input data into a lower-dimensional space prior to running the supervised learning algorithm."
possible end-users,"A database schema specifies, based on the database administrator's knowledge of possible applications, the facts that can enter the database, or those of interest to the possible end-users."
term feature-oriented programming,"Later, the term feature-oriented programming was coined; this work exposed interactions between layers."
term feature-oriented,"Later, the term feature-oriented programming was coined; this work exposed interactions between layers."
message-oriented middleware implementations depend,Many message-oriented middleware implementations depend on a message queue system.
many message-oriented middleware systems,"The primary disadvantage of many message-oriented middleware systems is that they require an extra component in the architecture, the message transfer agent (message broker)."
many message-oriented,"The primary disadvantage of many message-oriented middleware systems is that they require an extra component in the architecture, the message transfer agent (message broker)."
message-oriented middleware based,The eXtensible Messaging and Presence Protocol (XMPP) is a communications protocol for message-oriented middleware based on XML (Extensible Markup Language).
4-step design method,The process of dimensional modeling builds on a 4-step design method that helps to ensure the usability of the dimensional model and the use of the data warehouse.
e-mail announcing,"For example, a notification system can send an e-mail announcing when a computer network will be down for a scheduled maintenance."
vector-valued objective functions,Vector optimization is a subarea of mathematical optimization where optimization problems with a vector-valued objective functions are optimized with respect to a given partial ordering and subject to certain constraints.
problem-solving methods,"In education, computational thinking (CT) is a set of problem-solving methods that involve expressing problems and their solutions in ways that a computer could also execute."
model-based thinking,"Computational thinking involves ideas like abstraction, data representation, and logically organizing data, which are also prevalent in other kinds of thinking, such as scientific thinking, engineering thinking, systems thinking, design thinking, model-based thinking, and the like."
ostensibly written using human-readable,"Self-documenting code is ostensibly written using human-readable names, typically consisting of a phrase in a human language which reflects the symbol's meaning, such as article."
ostensibly written using human-readable names,"Self-documenting code is ostensibly written using human-readable names, typically consisting of a phrase in a human language which reflects the symbol's meaning, such as article."
human-readable names,"Self-documenting code is ostensibly written using human-readable names, typically consisting of a phrase in a human language which reflects the symbol's meaning, such as article."
expected fact-based,"Peirce indicated that abductive reasoning is driven by the need for ""economy in research"" -- the expected fact-based productivity of hypotheses, prior to deductive and inductive processes of verification."
fact-based productivity,"Peirce indicated that abductive reasoning is driven by the need for ""economy in research"" -- the expected fact-based productivity of hypotheses, prior to deductive and inductive processes of verification."
expected fact-based productivity,"Peirce indicated that abductive reasoning is driven by the need for ""economy in research"" -- the expected fact-based productivity of hypotheses, prior to deductive and inductive processes of verification."
manage public-key encryption,"A public key infrastructure (PKI) is a set of roles, policies, hardware, software and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption."
manage public-key,"A public key infrastructure (PKI) is a set of roles, policies, hardware, software and procedures needed to create, manage, distribute, use, store and revoke digital certificates and manage public-key encryption."
constant cross-multiplying,"It is called the shoelace formula because of the constant cross-multiplying for the coordinates making up the polygon, like threading shoelaces."
commercially successful general-purpose,"Although no commercially successful general-purpose computer hardware has used a dataflow architecture, it has been successfully implemented in specialized hardware such as in digital signal processing, network routing, graphics processing, telemetry, and more recently in data warehousing, and artificial intelligence."
commercially successful general-purpose computer hardware,"Although no commercially successful general-purpose computer hardware has used a dataflow architecture, it has been successfully implemented in specialized hardware such as in digital signal processing, network routing, graphics processing, telemetry, and more recently in data warehousing, and artificial intelligence."
real-time data path applications,Synchronous dataflow architectures tune to match the workload presented by real-time data path applications such as wire speed packet forwarding.
two-dimensional functions fed,"A digital image is an image composed of picture elements, also known as pixels, each with finite, discrete quantities of numeric representation for its intensity or gray level that is an output from its two-dimensional functions fed as input by its spatial coordinates denoted with x, y on the x-axis and y-axis, respectively."
multi-agent methods inspired,Artificial ants stand for multi-agent methods inspired by the behavior of real ants.
real-time garbage collectors address,"Incremental, concurrent, and real-time garbage collectors address these problems, with varying trade-offs."
varying trade-offs,"Incremental, concurrent, and real-time garbage collectors address these problems, with varying trade-offs."
non-letter symbols,"Like HTML (<b>bold</b>), some languages use named elements that share a common format for start and end tags (e. g. BBCode [b]bold[/b]), whereas proper lightweight markup languages are restricted to ASCII-only punctuation marks and other non-letter symbols for tags, but some also mix both styles (e. g. Textile bq. )"
spatial-domain algorithms,"Unlike many spatial-domain algorithms, the phase correlation method is resilient to noise, occlusions, and other defects typical of medical or satellite images."
low-bandwidth links,"The Remote Imaging Protocol and its associated Remote Imaging Protocol Script language, RIPscrip, is a graphics language that provides a system for sending vector graphics over low-bandwidth links, notably modems."
general weighted low-rank approximation problem,"The general weighted low-rank approximation problem does not admit an analytic solution in terms of the singular value decomposition and is solved by local optimization methods, which provide no guarantee that a globally optimal solution is found."
general weighted low-rank,"The general weighted low-rank approximation problem does not admit an analytic solution in terms of the singular value decomposition and is solved by local optimization methods, which provide no guarantee that a globally optimal solution is found."
weighted low-rank,The resulting optimization algorithm (called alternating projections) is globally convergent with a linear convergence rate to a locally optimal solution of the weighted low-rank approximation problem.
several loosely-coupled interchangeable components,"The hexagonal architecture divides a system into several loosely-coupled interchangeable components, such as the application core, the database, the user interface, test scripts and interfaces with other systems."
several loosely-coupled,"The hexagonal architecture divides a system into several loosely-coupled interchangeable components, such as the application core, the database, the user interface, test scripts and interfaces with other systems."
loosely-coupled interchangeable components,"The hexagonal architecture divides a system into several loosely-coupled interchangeable components, such as the application core, the database, the user interface, test scripts and interfaces with other systems."
computational-complexity standpoint,"From a computational-complexity standpoint, priority queues are congruent to sorting algorithms."
semi-convergent splitting,"A regular splitting of a non-singular matrix A results in a convergent matrix T. A semi-convergent splitting of a matrix A results in a semi-convergent matrix T. A general iterative method converges for every initial vector if T is convergent, and under certain conditions if T is semi-convergent."
untyped lambda-terms,"Typed lambda calculi are weaker than the untyped lambda calculus, which is the primary subject of this article, in the sense that typed lambda calculi can express less than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate."
every simply typed lambda-term,"Typed lambda calculi are weaker than the untyped lambda calculus, which is the primary subject of this article, in the sense that typed lambda calculi can express less than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate."
lambda-terms need,"Typed lambda calculi are weaker than the untyped lambda calculus, which is the primary subject of this article, in the sense that typed lambda calculi can express less than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate."
untyped lambda-term,"Typed lambda calculi are weaker than the untyped lambda calculus, which is the primary subject of this article, in the sense that typed lambda calculi can express less than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate."
untyped lambda-terms need,"Typed lambda calculi are weaker than the untyped lambda calculus, which is the primary subject of this article, in the sense that typed lambda calculi can express less than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate."
"every simply typed lambda-term,","Typed lambda calculi are weaker than the untyped lambda calculus, which is the primary subject of this article, in the sense that typed lambda calculi can express less than the untyped calculus can, but on the other hand typed lambda calculi allow more things to be proven; in the simply typed lambda calculus it is, for example, a theorem that every evaluation strategy terminates for every simply typed lambda-term, whereas evaluation of untyped lambda-terms need not terminate."
non-number objects,"However, in the untyped lambda calculus, there is no way to prevent a function from being applied to truth values, strings, or other non-number objects."
non-linear association,"In statistics, the maximal information coefficient (MIC) is a measure of the strength of the linear or non-linear association between two variables X and Y."
real-world processes,"Markov chains have many applications as statistical models of real-world processes, such as studying cruise control systems in motor vehicles, queues or lines of customers arriving at an airport, currency exchange rates and animal population dynamics."
grammar-like rules,"In theoretical computer science, a Markov algorithm is a string rewriting system that uses grammar-like rules to operate on strings of symbols."
uses grammar-like,"In theoretical computer science, a Markov algorithm is a string rewriting system that uses grammar-like rules to operate on strings of symbols."
uses grammar-like rules,"In theoretical computer science, a Markov algorithm is a string rewriting system that uses grammar-like rules to operate on strings of symbols."
multi-level caches,"Cache hierarchy, or multi-level caches, refers to a memory architecture that uses a hierarchy of memory stores based on varying access speeds to cache data."
upper-level cache,"Under an exclusive policy, all the cache hierarchy components are completely exclusive, so that any element in the upper-level cache will not be present in any of the lower cache components."
use standards-compliant,"A relational data stream management system (RDSMS) is a distributed, in-memory data stream management system (DSMS) that is designed to use standards-compliant SQL queries to process unstructured and structured data streams in real-time."
improving end-to-end,"In routers and switches, active queue management (AQM) is the policy of dropping packets inside a buffer associated with a network interface controller (NIC) before that buffer becomes full, often with the goal of reducing network congestion or improving end-to-end latency."
ns-2 simulation code,An active queue management and denial-of-Service (AQM&DoS) simulation platform is established based on the NS-2 simulation code of the RRED algorithm.
(twisted-pair wire,"These pathways, called communication channels, use two types of media: cable (twisted-pair wire, cable, and fiber-optic cable) and broadcast (microwave, satellite, radio, and infrared)."
twisted-pair wire,"These pathways, called communication channels, use two types of media: cable (twisted-pair wire, cable, and fiber-optic cable) and broadcast (microwave, satellite, radio, and infrared)."
fiber-optic cable,"These pathways, called communication channels, use two types of media: cable (twisted-pair wire, cable, and fiber-optic cable) and broadcast (microwave, satellite, radio, and infrared)."
discrete-alphabet setting,Communication channels are also studied in a discrete-alphabet setting.
including real-time,"The descriptions provided by Townsend in his foreword and by Foth in his preface to the Handbook of Research on Urban Informatics emphasize two key aspects: (1) the new possibilities (including real-time data) for both citizens and city administrations afforded by ubiquitous computing, and (2) the convergence of physical and digital aspects of the city."
including real-time data,"The descriptions provided by Townsend in his foreword and by Foth in his preface to the Handbook of Research on Urban Informatics emphasize two key aspects: (1) the new possibilities (including real-time data) for both citizens and city administrations afforded by ubiquitous computing, and (2) the convergence of physical and digital aspects of the city."
large-scale ontologies,"In philosophy, the term formal ontology is used to refer to an ontology defined by axioms in a formal language with the goal to provide an unbiased (domain- and application-independent) view on reality, which can help the modeler of domain- or application-specific ontologies (information science) to avoid possibly erroneous ontological assumptions encountered in modeling large-scale ontologies."
modeling large-scale ontologies,"In philosophy, the term formal ontology is used to refer to an ontology defined by axioms in a formal language with the goal to provide an unbiased (domain- and application-independent) view on reality, which can help the modeler of domain- or application-specific ontologies (information science) to avoid possibly erroneous ontological assumptions encountered in modeling large-scale ontologies."
application-specific ontologies,"In philosophy, the term formal ontology is used to refer to an ontology defined by axioms in a formal language with the goal to provide an unbiased (domain- and application-independent) view on reality, which can help the modeler of domain- or application-specific ontologies (information science) to avoid possibly erroneous ontological assumptions encountered in modeling large-scale ontologies."
modeling large-scale,"In philosophy, the term formal ontology is used to refer to an ontology defined by axioms in a formal language with the goal to provide an unbiased (domain- and application-independent) view on reality, which can help the modeler of domain- or application-specific ontologies (information science) to avoid possibly erroneous ontological assumptions encountered in modeling large-scale ontologies."
comparing several common-sense alternatives,"Thus query optimization typically tries to approximate the optimum by comparing several common-sense alternatives to provide in a reasonable time a ""good enough"" plan which typically does not deviate much from the best possible result."
comparing several common-sense,"Thus query optimization typically tries to approximate the optimum by comparing several common-sense alternatives to provide in a reasonable time a ""good enough"" plan which typically does not deviate much from the best possible result."
common-sense alternatives,"Thus query optimization typically tries to approximate the optimum by comparing several common-sense alternatives to provide in a reasonable time a ""good enough"" plan which typically does not deviate much from the best possible result."
many-valued logic,Fuzzy logic is a form of many-valued logic in which the truth value of variables may be any real number between 0 and 1.
infinite-valued logicnotably,"Fuzzy logic had, however, been studied since the 1920s, as infinite-valued logicnotably by ukasiewicz and Tarski."
non-numerical information,Fuzzy logic is based on the observation that people make decisions based on imprecise and non-numerical information.
perform sub-quadratic,"Polynomial interpolation is also essential to perform sub-quadratic multiplication and squaring such as Karatsuba multiplication and ToomCook multiplication, where an interpolation through points on a polynomial which defines the product yields the product itself."
perform sub-quadratic multiplication,"Polynomial interpolation is also essential to perform sub-quadratic multiplication and squaring such as Karatsuba multiplication and ToomCook multiplication, where an interpolation through points on a polynomial which defines the product yields the product itself."
sub-quadratic multiplication,"Polynomial interpolation is also essential to perform sub-quadratic multiplication and squaring such as Karatsuba multiplication and ToomCook multiplication, where an interpolation through points on a polynomial which defines the product yields the product itself."
network-based application firewalls operate,"Network-based application firewalls operate at the application layer of a TCP/IP stack and can understand certain applications and protocols such as File Transfer Protocol (FTP), Domain Name System (DNS), or Hypertext Transfer Protocol (HTTP)."
whose elements satisfy pre-determined stability conditions,"The stability radius of an object (system, function, matrix, parameter) at a given nominal point is the radius of the largest ball, centered at the nominal point, all of whose elements satisfy pre-determined stability conditions."
whose elements satisfy pre-determined,"The stability radius of an object (system, function, matrix, parameter) at a given nominal point is the radius of the largest ball, centered at the nominal point, all of whose elements satisfy pre-determined stability conditions."
pre-determined stability conditions,"The stability radius of an object (system, function, matrix, parameter) at a given nominal point is the radius of the largest ball, centered at the nominal point, all of whose elements satisfy pre-determined stability conditions."
connection-oriented transfer mode,"For example, the Transmission Control Protocol (TCP) implements a connection-oriented transfer mode, and the PDU of this protocol is called a segment, while the User Datagram Protocol (UDP) uses datagrams as protocol data units for connectionless communication."
code-analysis technique,"In computer science, control-flow analysis (CFA) is a static-code-analysis technique for determining the control flow of a program."
interprocedural control-flow analysis implicitly usually refers,"As a result, interprocedural control-flow analysis implicitly usually refers to a static analysis technique for determining the receiver(s) of function or method calls in computer programs written in a higher-order programming language."
control-flow analysis implicitly usually refers,"As a result, interprocedural control-flow analysis implicitly usually refers to a static analysis technique for determining the receiver(s) of function or method calls in computer programs written in a higher-order programming language."
control-flow analysis must consider,A control-flow analysis must consider where this expression could be invoked and what argument it may receive to determine the possible targets.
correspondingly-fine granularity,Directory services are often central to the security design of an IT system and have a correspondingly-fine granularity of access control.
multi-vendor interoperability,Directory services were part of an Open Systems Interconnection (OSI) initiative for common network standards and multi-vendor interoperability.
inter-carrier electronic messaging,"During the 1980s, the ITU and ISO created a set of standards for directory services, initially to support the requirements of inter-carrier electronic messaging and network-name lookup."
network-name lookup,"During the 1980s, the ITU and ISO created a set of standards for directory services, initially to support the requirements of inter-carrier electronic messaging and network-name lookup."
beta-reduction transformation,"In the context of functional programming languages, inline expansion is usually followed by the beta-reduction transformation."
semi-infinite programming,"Semi-infinite programming: Theory, methods, and applications."
first-class functions,"Anonymous functions are ubiquitous in functional programming languages and other languages with first-class functions, where they fulfil the same role for the function type as literals do for other data types."
errors-in-variables models,"The observed variables are modelled as linear combinations of the potential factors plus ""error"" terms, hence factor analysis can be thought of as a special case of errors-in-variables models."
proof-writing systems use,Most computerized proof-writing systems use a type theory for their foundation.
computerized proof-writing systems use,Most computerized proof-writing systems use a type theory for their foundation.
computerized proof-writing,Most computerized proof-writing systems use a type theory for their foundation.
one-to-one correspondence,"Primitive data types which are native to the processor have a one-to-one correspondence with objects in the computer's memory, and operations on these types are often the fastest possible in most cases."
stochastic spin-glass,"A Boltzmann machine (also called SherringtonKirkpatrick model with external field or stochastic Ising-Lenz-Little model) is a stochastic spin-glass model with an external field, i. e. , a SherringtonKirkpatrick model, that is a stochastic Ising Model."
stochastic spin-glass model,"A Boltzmann machine (also called SherringtonKirkpatrick model with external field or stochastic Ising-Lenz-Little model) is a stochastic spin-glass model with an external field, i. e. , a SherringtonKirkpatrick model, that is a stochastic Ising Model."
single-linkage clustering page,A simple agglomerative clustering algorithm is described in the single-linkage clustering page; it can easily be adapted to different types of linkage (see below).
universal first-order quantifiers,"In mathematical logic, a formula of first-order logic is in Skolem normal form if it is in prenex normal form with only universal first-order quantifiers."
universal first-order,"In mathematical logic, a formula of first-order logic is in Skolem normal form if it is in prenex normal form with only universal first-order quantifiers."
first-order formula may,Every first-order formula may be converted into Skolem normal form while not changing its satisfiability via a process called Skolemization (sometimes spelled Skolemnization).
knowledge-based system,Knowledge acquisition is the process used to define the rules and ontologies required for a knowledge-based system.
re-use based approach,A more recent approach to knowledge acquisition is a re-use based approach.
object-oriented programming language capabilities,Object-oriented database management systems (OODBMSs) also called ODBMS (Object Database Management System) combine database capabilities with object-oriented programming language capabilities.
graph-structured objects,Object database management systems grew out of research during the early to mid-1970s into having intrinsic database management support for graph-structured objects.
heuristic-based iterative methods,"A mathematically rigorous convergence analysis of an iterative method is usually performed; however, heuristic-based iterative methods are also common."
non-invasive way,"Implicit data collection is used in humancomputer interaction to gather data about the user in an implicit, non-invasive way."
support object-oriented,"are multi-paradigm and they support object-oriented programming to a greater or lesser degree, typically in combination with imperative, procedural programming."
support object-oriented programming,"are multi-paradigm and they support object-oriented programming to a greater or lesser degree, typically in combination with imperative, procedural programming."
object-oriented programming made,"Terminology invoking ""objects"" and ""oriented"" in the modern sense of object-oriented programming made its first appearance at MIT in the late 1950s and early 1960s."
meta-object protocol,"Experimentation with various extensions to Lisp (such as LOOPS and Flavors introducing multiple inheritance and mixins) eventually led to the Common Lisp Object System, which integrates functional programming and object-oriented programming and allows extension via a Meta-object protocol."
byte-oriented communications protocol devised,Digital Data Communications Message Protocol (DDCMP) is a byte-oriented communications protocol devised by Digital Equipment Corporation in 1974 to allow communication over point-to-point network links for the company's DECnet Phase I network protocol suite.
point-to-point network links,Digital Data Communications Message Protocol (DDCMP) is a byte-oriented communications protocol devised by Digital Equipment Corporation in 1974 to allow communication over point-to-point network links for the company's DECnet Phase I network protocol suite.
onboard non-volatile,"A serial connection to a personal computer allows the programmer to download software to the BASIC Stamp, which is stored in the onboard non-volatile memory device: it remains programmed until it is erased or reprogrammed, even when the power of the stamp is removed."
onboard non-volatile memory device,"A serial connection to a personal computer allows the programmer to download software to the BASIC Stamp, which is stored in the onboard non-volatile memory device: it remains programmed until it is erased or reprogrammed, even when the power of the stamp is removed."
analyzing high-dimensional datasets,Parallel coordinates are a common way of visualizing and analyzing high-dimensional datasets.
analyzing high-dimensional,Parallel coordinates are a common way of visualizing and analyzing high-dimensional datasets.
physics-related problems,"In physics-related problems, Monte Carlo methods are useful for simulating systems with many coupled degrees of freedom, such as fluids, disordered materials, strongly coupled solids, and cellular structures (see cellular Potts model, interacting particle systems, McKeanVlasov processes, kinetic models of gases)."
stand-alone data dictionary,"The software package for a stand-alone data dictionary or data repository may interact with the software modules of the DBMS, but it is mainly used by the designers, users and administrators of a computer system for information resource management."
improve human decision-making,"In general, the term cognitive computing has been used to refer to new hardware and/or software that mimics the functioning of the human brain (2004) and helps to improve human decision-making."
computing-branded technology platforms typically specialize,"Cognitive computing-branded technology platforms typically specialize in the processing and analysis of large, unstructured datasets."
high-quality content,Content intelligence is often viewed as an asset for creating and maintaining high-quality content for targeted audiences.
maintaining high-quality,Content intelligence is often viewed as an asset for creating and maintaining high-quality content for targeted audiences.
maintaining high-quality content,Content intelligence is often viewed as an asset for creating and maintaining high-quality content for targeted audiences.
correct yes-or-no,"In computability theory and computational complexity theory, an undecidable problem is a decision problem for which it is proved to be impossible to construct an algorithm that always leads to a correct yes-or-no answer."
non-key attributes,"As this table structure consists of a compound primary key, it doesn't contain any non-key attributes and it's already in BCNF (and therefore also satisfies all the previous normal forms)."
axis-aligned rectangles,"Some well-studied sets of ranges, and the names of the respective problems are axis-aligned rectangles (orthogonal range searching), simplices, halfspaces, and spheres/circles."
well-studied sets,"Some well-studied sets of ranges, and the names of the respective problems are axis-aligned rectangles (orthogonal range searching), simplices, halfspaces, and spheres/circles."
end-user subscriber certificate,"The chain of trust of a certificate chain is an ordered list of certificates, containing an end-user subscriber certificate and intermediate certificates (that represents the intermediate CA), that enables the receiver to verify that the sender and all intermediate certificates are trustworthy."
packet-switched telecommunication networks,"In the field of computer networking and other packet-switched telecommunication networks, quality of service refers to traffic prioritization and resource reservation control mechanisms rather than the achieved service quality."
self-standing mathematical objects,"Finite differences were introduced by Brook Taylor in 1715 and have also been studied as abstract self-standing mathematical objects in works by George Boole (1860), L. M. Milne-Thomson (1933), and Kroly Jordan (1939)."
abstract self-standing,"Finite differences were introduced by Brook Taylor in 1715 and have also been studied as abstract self-standing mathematical objects in works by George Boole (1860), L. M. Milne-Thomson (1933), and Kroly Jordan (1939)."
abstract self-standing mathematical objects,"Finite differences were introduced by Brook Taylor in 1715 and have also been studied as abstract self-standing mathematical objects in works by George Boole (1860), L. M. Milne-Thomson (1933), and Kroly Jordan (1939)."
correct bit-insertions,"A few forward error correction codes are designed to correct bit-insertions and bit-deletions, such as Marker Codes and Watermark Codes."
describing many-body,Coupled cluster (CC) is a numerical technique used for describing many-body systems.
describing many-body systems,Coupled cluster (CC) is a numerical technique used for describing many-body systems.
constructs multi-electron,Coupled cluster essentially takes the basic HartreeFock molecular orbital method and constructs multi-electron wavefunctions using the exponential cluster operator to account for electron correlation.
multi-electron wavefunctions using,Coupled cluster essentially takes the basic HartreeFock molecular orbital method and constructs multi-electron wavefunctions using the exponential cluster operator to account for electron correlation.
constructs multi-electron wavefunctions using,Coupled cluster essentially takes the basic HartreeFock molecular orbital method and constructs multi-electron wavefunctions using the exponential cluster operator to account for electron correlation.
valence-universal multi,"Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
coupled-cluster theory,"Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
multi-reference coupled cluster approaches,"Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
"universal multi-reference,","Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
universal multi-reference coupled cluster approaches,"Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
state-universal multi,"Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
universal multi-reference,"Coupled-cluster theory can also be used to obtain solutions for excited states using, for example, linear-response, equation-of-motion, state-universal multi-reference, or valence-universal multi-reference coupled cluster approaches."
potential-energy surface,"This is easily seen, for example, in the single bond breaking of F2 when using a restricted HartreeFock (RHF) reference, which is not size-consistent, at the CCSDT (coupled cluster single-double-triple) level of theory, which provides an almost exact, full-CI-quality, potential-energy surface and does not dissociate the molecule into F and F+ ions, like the RHF wave function, but rather into two neutral F atoms."
coupled cluster single-double,"This is easily seen, for example, in the single bond breaking of F2 when using a restricted HartreeFock (RHF) reference, which is not size-consistent, at the CCSDT (coupled cluster single-double-triple) level of theory, which provides an almost exact, full-CI-quality, potential-energy surface and does not dissociate the molecule into F and F+ ions, like the RHF wave function, but rather into two neutral F atoms."
coupled cluster single-double-triple),"This is easily seen, for example, in the single bond breaking of F2 when using a restricted HartreeFock (RHF) reference, which is not size-consistent, at the CCSDT (coupled cluster single-double-triple) level of theory, which provides an almost exact, full-CI-quality, potential-energy surface and does not dissociate the molecule into F and F+ ions, like the RHF wave function, but rather into two neutral F atoms."
partial concurrent think-aloud,"Partial concurrent thinking aloud (or partial concurrent think-aloud, or PCTA) is a method used to gather data in usability testing with screen reader users."
"partial concurrent think-aloud,","Partial concurrent thinking aloud (or partial concurrent think-aloud, or PCTA) is a method used to gather data in usability testing with screen reader users."
context-free grammars generate,The language equality question (do two given context-free grammars generate the same language)
two given context-free,The language equality question (do two given context-free grammars generate the same language)
two given context-free grammars generate,The language equality question (do two given context-free grammars generate the same language)
context-free grammars arise,"Context-free grammars arise in linguistics where they are used to describe the structure of sentences and words in a natural language, and they were in fact invented by the linguist Noam Chomsky for this purpose."
whereby phrase-structure,"In linguistics, some authors use the term phrase structure grammar to refer to context-free grammars, whereby phrase-structure grammars are distinct from dependency grammars."
phrase-structure grammars,"In linguistics, some authors use the term phrase structure grammar to refer to context-free grammars, whereby phrase-structure grammars are distinct from dependency grammars."
whereby phrase-structure grammars,"In linguistics, some authors use the term phrase structure grammar to refer to context-free grammars, whereby phrase-structure grammars are distinct from dependency grammars."
connectivity-based clustering,"Connectivity-based clustering, also known as hierarchical clustering, is based on the core idea of objects being more related to nearby objects than to objects farther away. !! Connectivity-based clustering is a whole family of methods that differ by the way distances are computed."
large-scale structure,"The Bolshoi simulation, a computer model of the universe run in 2010 on the Pleiades supercomputer at the NASA Ames Research Center, was the most accurate cosmological simulation to that date of the evolution of the large-scale structure of the universe."
term one-class,"The term one-class classification (OCC) was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection."
term one-class classification,"The term one-class classification (OCC) was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection."
solve one-class,Several approaches have been proposed to solve one-class classification (OCC).
solve one-class classification,Several approaches have been proposed to solve one-class classification (OCC).
considered one-class,"When the SVM algorithm is modified to only use positive examples, the process is considered one-class classification."
considered one-class classification,"When the SVM algorithm is modified to only use positive examples, the process is considered one-class classification."
greater cross-browser compatibility,Subsequent releases of JavaScript and JScript would implement the ECMAScript standard for greater cross-browser compatibility.
greater cross-browser,Subsequent releases of JavaScript and JScript would implement the ECMAScript standard for greater cross-browser compatibility.
particular diagram-based approach,"The term ""path coefficient"" derives from Wright (1921), where a particular diagram-based approach was used to consider the relations between variables in a multivariate system."
particular diagram-based,"The term ""path coefficient"" derives from Wright (1921), where a particular diagram-based approach was used to consider the relations between variables in a multivariate system."
diagram-based approach,"The term ""path coefficient"" derives from Wright (1921), where a particular diagram-based approach was used to consider the relations between variables in a multivariate system."
agent-based distributed data mining,"The very early work on agent mining focused on agent-based knowledge discovery, agent-based distributed data mining, and agent-based distributed machine learning, and using data mining to enhance agent intelligence."
breadth-first search differs,The output of lexicographic breadth-first search differs from a standard breadth-first search in having a consistent rule for breaking such ties.
lexicographic breadth-first search differs,The output of lexicographic breadth-first search differs from a standard breadth-first search in having a consistent rule for breaking such ties.
standard breadth-first,"The output of lexicographic breadth-first search differs from a standard breadth-first search in having a consistent rule for breaking such ties. !! Instead, the lexicographic breadth-first search uses a set partitioning data structure in order to produce the same ordering more efficiently, just as a standard breadth-first search uses a queue data structure to produce its ordering efficiently. !! The lexicographic breadth-first search algorithm replaces the queue of vertices of a standard breadth-first search with an ordered sequence of sets of vertices."
standard breadth-first search,The output of lexicographic breadth-first search differs from a standard breadth-first search in having a consistent rule for breaking such ties. !! The lexicographic breadth-first search algorithm replaces the queue of vertices of a standard breadth-first search with an ordered sequence of sets of vertices.
lexicographic breadth-first search uses,"Instead, the lexicographic breadth-first search uses a set partitioning data structure in order to produce the same ordering more efficiently, just as a standard breadth-first search uses a queue data structure to produce its ordering efficiently."
standard breadth-first search uses,"Instead, the lexicographic breadth-first search uses a set partitioning data structure in order to produce the same ordering more efficiently, just as a standard breadth-first search uses a queue data structure to produce its ordering efficiently."
breadth-first search uses,"Instead, the lexicographic breadth-first search uses a set partitioning data structure in order to produce the same ordering more efficiently, just as a standard breadth-first search uses a queue data structure to produce its ordering efficiently."
lexicographic breadth-first search algorithm replaces,The lexicographic breadth-first search algorithm replaces the queue of vertices of a standard breadth-first search with an ordered sequence of sets of vertices.
breadth-first search algorithm replaces,The lexicographic breadth-first search algorithm replaces the queue of vertices of a standard breadth-first search with an ordered sequence of sets of vertices.
end-user development,End-user development (EUD) or end-user programming (EUP) refers to activities and tools that allow end-users people who are not professional software developers to program computers.
end-users people,End-user development (EUD) or end-user programming (EUP) refers to activities and tools that allow end-users people who are not professional software developers to program computers.
allow end-users,End-user development (EUD) or end-user programming (EUP) refers to activities and tools that allow end-users people who are not professional software developers to program computers.
allow end-users people,End-user development (EUD) or end-user programming (EUP) refers to activities and tools that allow end-users people who are not professional software developers to program computers.
end-user programming,End-user development (EUD) or end-user programming (EUP) refers to activities and tools that allow end-users people who are not professional software developers to program computers.
support end-user,One evolution in this area has considered the use of mobile devices to support end-user development activities.
support end-use,One evolution in this area has considered the use of mobile devices to support end-user development activities.
support end-user development activities,One evolution in this area has considered the use of mobile devices to support end-user development activities.
end-user development activities,"Many end-user development activities are collaborative in nature, including collaboration between professional developers and end-user developers and collaboration among end-user developers. !! One evolution in this area has considered the use of mobile devices to support end-user development activities."
non-professional software developers,"End-User Development can be defined as a set of methods, techniques, and tools that allow users of software systems, who are acting as non-professional software developers, at some point to create, modify or extend a software artifact."
end-user development may also refer,"Other artifacts of end-user development may also refer to the creation of user-generated content such as annotations, which may be or not computationally interpretable (i. e. can be processed by associated automated functions)."
user-generated content,"Other artifacts of end-user development may also refer to the creation of user-generated content such as annotations, which may be or not computationally interpretable (i. e. can be processed by associated automated functions)."
end-user developers,"Many end-user development activities are collaborative in nature, including collaboration between professional developers and end-user developers and collaboration among end-user developers."
collaboration among end-user,"Many end-user development activities are collaborative in nature, including collaboration between professional developers and end-user developers and collaboration among end-user developers."
collaboration among end-user developers,"Many end-user development activities are collaborative in nature, including collaboration between professional developers and end-user developers and collaboration among end-user developers."
model-based reasoning refers,"In artificial intelligence, model-based reasoning refers to an inference method used in expert systems based on a model of the physical world."
model-based reasoning system knowledge,In a model-based reasoning system knowledge can be represented using causal rules.
"appear human-made,","A ""synthetic intelligence"" would therefore be or appear human-made, but not a simulation."
appear human-made,"A ""synthetic intelligence"" would therefore be or appear human-made, but not a simulation."
many information-security,"a small change to a message should change the hash value so extensively that a new hash value appears uncorrelated with the old hash value (avalanche effect)Cryptographic hash functions have many information-security applications, notably in digital signatures, message authentication codes (MACs), and other forms of authentication."
many information-security applications,"a small change to a message should change the hash value so extensively that a new hash value appears uncorrelated with the old hash value (avalanche effect)Cryptographic hash functions have many information-security applications, notably in digital signatures, message authentication codes (MACs), and other forms of authentication."
length-extension attacks,"Currently, popular cryptographic hash functions are vulnerable to length-extension attacks: given hash(m) and len(m) but not m, by choosing a suitable m an attacker can calculate hash(m m), where denotes concatenation."
well-defined matter throughout,Value Sensitive Design takes human values into account in a well-defined matter throughout the whole process.
near-zero total correlation indicates,"A near-zero total correlation indicates that the variables in the group are essentially statistically independent; they are completely unrelated, in the sense that knowing the value of one variable does not provide any clue as to the values of the other variables."
computer-mediated communication,Semiotic Engineering views HCI as computer-mediated communication between designers and users at interaction time.
multi-relational data mining engine,Safarii: a Data Mining environment for analysing large relational databases based on a multi-relational data mining engine.
e-based machine learning methods,"Learning classifier systems, or LCS, are a paradigm of rule-based machine learning methods that combine a discovery component (e. g. typically a genetic algorithm) with a learning component (performing either supervised learning, reinforcement learning, or unsupervised learning)."
context-dependent rules,"Learning classifier systems seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions (e. g. behavior modeling, classification, data mining, regression, function approximation, or game strategy)."
using rule-based agents,"The founding concepts behind learning classifier systems came from attempts to model complex adaptive systems, using rule-based agents to form an artificial cognitive system (i. e. artificial intelligence)."
e-based agents,"The founding concepts behind learning classifier systems came from attempts to model complex adaptive systems, using rule-based agents to form an artificial cognitive system (i. e. artificial intelligence)."
using rule-based,"The founding concepts behind learning classifier systems came from attempts to model complex adaptive systems, using rule-based agents to form an artificial cognitive system (i. e. artificial intelligence)."
using non-bayesian,"Savage argued that using non-Bayesian methods such as minimax, the loss function should be based on the idea of regret, i. e. , the loss associated with a decision should be the difference between the consequences of the best decision that could have been made had the underlying circumstances been known and the decision that was in fact taken before they were known."
change-of-basis matrix,amounts to multiplying the Vandermonde matrix by a change-of-basis matrix M (from the right).
tree problems,"In computer science, parallel tree contraction is a broadly applicable technique for the parallel solution of a large number of tree problems, and is used as an algorithm design technique for the design of a large number of parallel graph algorithms."
sparc machines,Performance Analyzer is a commercial utility software for software performance analysis for x86 or SPARC machines.
commercial utility software,Performance Analyzer is a commercial utility software for software performance analysis for x86 or SPARC machines.
physical security,"In the fields of physical security and information security, access control (AC) is the selective restriction of access to a place or other resource, while access management describes the process. !! DMA attacks can be prevented by physical security against potentially malicious devices."
login credentials,Locks and login credentials are two analogous mechanisms of access control.
binary point,"The term floating point refers to the fact that a number's radix point (decimal point, or, more commonly in computers, binary point) can ""float""; that is, it can be placed anywhere relative to the significant digits of the number."
floating point,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats. !! The value distribution is similar to floating point, but the value-to-representation curve (i. e. , the graph of the logarithm function) is smooth (except at 0). !! The term floating point refers to the fact that a number's radix point (decimal point, or, more commonly in computers, binary point) can ""float""; that is, it can be placed anywhere relative to the significant digits of the number. !! The hardware to manipulate these representations is less costly than floating point, and it can be used to perform normal integer operations, too. !! Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536. !! Some simple rational numbers (e. g. , 1/3 and 1/10) cannot be represented exactly in binary floating point, no matter what the precision is."
balanced ternary floating point,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
rigidity theory,"Pseudoforests are exactly the (1,0)-sparse graphs, and the Laman graphs arising in rigidity theory are exactly the (2,3)-tight graphs."
degree structures,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
noncomputable functions,"How can noncomputable functions be classified into a hierarchy based on their level of noncomputabilityAlthough there is considerable overlap in terms of knowledge and methods, mathematical computability theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of subrecursive hierarchies, formal methods, and formal languages."
rot13 system,"The encryption step performed by a Caesar cipher is often incorporated as part of more complex schemes, such as the Vigenre cipher, and still has modern application in the ROT13 system."
npj computational materials,"Those dedicated to the field include Computational Materials Science, Modelling and Simulation in Materials Science and Engineering, and npj Computational Materials."
engineered artifact,"The aim of the theory of artificial consciousness is to ""Define that which would have to be synthesized were consciousness to be found in an engineered artifact"" (Aleksander 1995)."
cerebral function monitoring,"Amplitude integrated electroencephalography (aEEG) or cerebral function monitoring (CFM) is a technique for monitoring brain function in intensive care settings over longer periods of time than the traditional electroencephalogram (EEG), typically hours to days."
class prototype creation,"Since lazy inheritance called only once at the moment of first object instance creation, it seems logical to combine process of class prototype creation with resolving necessary dependencies of that class."
random field,"In other words, a random field is said to be a Markov random field if it satisfies Markov properties."
prototypical markov random field,"The prototypical Markov random field is the Ising model; indeed, the Markov random field was introduced as the general setting for the Ising model."
executed control flow,"Buffer overflowsRuntime error detection tools can only detect errors in the executed control flow of the application. !! The instruction path length of an assembly language program is generally vastly different than the number of source lines of code for that program, because the instruction path length includes only code in the executed control flow for the given input and does not include code that is not relevant for the particular input, or unreachable code."
detect errors,Buffer overflowsRuntime error detection tools can only detect errors in the executed control flow of the application.
frontal solver,"A frontal solver builds a LU or Cholesky decomposition of a sparse matrix given as the assembly of element matrices by assembling the matrix and eliminating equations only on a subset of elements at a time. !! A frontal solver, conceived by Bruce Irons, is an approach to solving sparse linear systems which is used extensively in finite element analysis. !! A multifrontal solver of Duff and Reid is an improvement of the frontal solver that uses several independent fronts at the same time."
frontal solver builds,A frontal solver builds a LU or Cholesky decomposition of a sparse matrix given as the assembly of element matrices by assembling the matrix and eliminating equations only on a subset of elements at a time.
mean geometry,The point distribution model is a model for representing the mean geometry of a shape and some statistical modes of geometric variation inferred from a training set of shapes.
biconjugate gradient method,"The biconjugate gradient method is numerically unstable (compare to the biconjugate gradient stabilized method), but very important from a theoretical point of view."
lean graphical notation technique,C4 model is a lean graphical notation technique for modelling the architecture of software systems.
c4 model documents,"C4 model documents the architecture of a software system, by showing multiple points of view that explain the decomposition of a system into containers and components, the relationship between these elements, and, where appropriate, the relation with its users."
memory references passed,"A memory management unit (MMU), sometimes called paged memory management unit (PMMU), is a computer hardware unit having all memory references passed through itself, primarily performing the translation of virtual memory addresses to physical addresses."
multiple processes running,"It includes the original Sun 1 memory management unit that provides address translation, memory protection, memory sharing and memory allocation for multiple processes running on the CPU."
normalisation by evaluation,"In programming language semantics, normalisation by evaluation (NBE) is a style of obtaining the normal form of terms in the -calculus by appealing to their denotational semantics."
product design,"Systems design is the process of defining the architecture, product design, modules, interfaces, and data for a system to satisfy specified requirements."
machine code output,"A programming language is any set of rules that converts strings, or graphical program elements in the case of visual programming languages, to various kinds of machine code output."
symmetric hash join,The symmetric hash join is a special type of hash join designed for data streams.
visual image,"The human processor model uses the cognitive, perceptual, and motor processors along with the visual image, working memory, and long term memory storages. !! Effective music visualization aims to attain a high degree of visual correlation between a musical track's spectral characteristics such as frequency and amplitude and the objects or components of the visual image being rendered and displayed."
spectral characteristics,Effective music visualization aims to attain a high degree of visual correlation between a musical track's spectral characteristics such as frequency and amplitude and the objects or components of the visual image being rendered and displayed.
machine morality,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents."
shape optimization,"Shape optimization is an infinite-dimensional optimization problem. !! Shape optimization is part of the field of optimal control theory. !! Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them. !! Shape optimization problems are usually solved numerically, by using iterative methods. !! Topological optimization techniques can then help work around the limitations of pure shape optimization. !! Topology optimization is different from shape optimization and sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations. !! Wing-shape optimization is by nature an iterative process. !! Wing-shape optimization is a software implementation of shape optimization primarily used for aircraft design."
polynomial function f,"If R is commutative, then one can associate with every polynomial P in R[x] a polynomial function f with domain and range equal to R. (More generally, one can take domain and range to be any same unital associative algebra over R. ) One obtains the value f(r) by substitution of the value r for the symbol x in P. One reason to distinguish between polynomials and polynomial functions is that, over some rings, different polynomials may give rise to the same polynomial function (see Fermat's little theorem for an example where R is the integers modulo p)."
proof theory,"In these areas, computability theory overlaps with proof theory and effective descriptive set theory."
routing vehicles,"Ant colony optimization algorithms have been applied to many combinatorial optimization problems, ranging from quadratic assignment to protein folding or routing vehicles and a lot of derived methods have been adapted to dynamic problems in real variables, stochastic problems, multi-targets and parallel implementations."
conceptual model,The system engineering community uses an architecture description language as a language and/or a conceptual model to describe and represent system architectures.
discrete global grid,"A triangulated irregular network (TIN) is a representation of a continuous surface consisting entirely of triangular facets (a triangle mesh), used mainly as Discrete Global Grid in primary elevation modeling."
respective terminology,"Though experts use the term ""synthetic media,"" individual methods such as deepfakes and text synthesis are sometimes not referred to as such by the media but instead by their respective terminology (and often use ""deepfakes"" as a euphemism, e. g. ""deepfakes for text"" for natural-language generation; ""deepfakes for voices"" for neural voice cloning, etc. )"
user intervention,"Error messages are used when user intervention is required, to indicate that a desired operation has failed, or to relay important warnings (such as warning a computer user that they are almost out of hard disk space)."
low usage,"In computing, lightweight software also called lite program and lightweight application, is a computer program that is designed to have a small memory footprint (RAM usage) and low CPU usage, overall a low usage of system resources."
implement sets,"Weight-balanced trees are popular in the functional programming community and are used to implement sets and maps in MIT Scheme, SLIB and implementations of Haskell."
balanced trees,"Weight-balanced trees are popular in the functional programming community and are used to implement sets and maps in MIT Scheme, SLIB and implementations of Haskell. !! With the new operations, the implementation of weight-balanced trees can be more efficient and highly-parallelizable. !! Several set operations have been defined on weight-balanced trees: union, intersection and set difference."
learning processes,Meta learning is a branch of metacognition concerned with learning about one's own learning and learning processes.
graph associates,An adjacency list representation for a graph associates each vertex in the graph with the collection of its neighbouring vertices or edges.
deterministic variability,Robust optimization is a field of optimization theory that deals with optimization problems in which a certain measure of robustness is sought against uncertainty that can be represented as deterministic variability in the value of the parameters of the problem itself and/or its solution.
software engineering discipline,Software construction is a software engineering discipline.
categorical description,"Therefore, a subobject classifier is also known as a ""truth value object"" and the concept is widely used in the categorical description of logic."
parallel manipulator systems,"Serial and parallel manipulator systems are generally designed to position an end-effector with six degrees of freedom, consisting of three in translation and three in orientation."
considers goal-directed,"Leading AI textbooks define ""artificial intelligence"" as the ""study and design of intelligent agents"", a definition that considers goal-directed behavior to be the essence of intelligence."
goal-directed behavior,"Leading AI textbooks define ""artificial intelligence"" as the ""study and design of intelligent agents"", a definition that considers goal-directed behavior to be the essence of intelligence."
considers goal-directed behavior,"Leading AI textbooks define ""artificial intelligence"" as the ""study and design of intelligent agents"", a definition that considers goal-directed behavior to be the essence of intelligence."
many interdisciplinary socio-cognitive modeling,"Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations."
many interdisciplinary socio-cognitive,"Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations."
socio-cognitive modeling,"Intelligent agents in artificial intelligence are closely related to agents in economics, and versions of the intelligent agent paradigm are studied in cognitive science, ethics, the philosophy of practical reason, as well as in many interdisciplinary socio-cognitive modeling and computer social simulations."
solvent-accessible surface area,The accessible surface area (ASA) or solvent-accessible surface area (SASA) is the surface area of a biomolecule that is accessible to a solvent.
non-polar solvent,Accessible surface area is often used when calculating the transfer free energy required to move a biomolecule from aqueous solvent to a non-polar solvent such as a lipid environment.
end-users may see,"End-users may see a stack trace displayed as part of an error message, which the user can then report to a programmer."
e-invariant eigenvalues,"Analogous scale-invariant decompositions can be derived from other matrix decompositions, e. g. , to obtain scale-invariant eigenvalues."
scale-invariant eigenvalues,"Analogous scale-invariant decompositions can be derived from other matrix decompositions, e. g. , to obtain scale-invariant eigenvalues."
e-invariant decompositions,"Analogous scale-invariant decompositions can be derived from other matrix decompositions, e. g. , to obtain scale-invariant eigenvalues."
scale-invariant decompositions,"Analogous scale-invariant decompositions can be derived from other matrix decompositions, e. g. , to obtain scale-invariant eigenvalues."
obtain scale-invariant,"Analogous scale-invariant decompositions can be derived from other matrix decompositions, e. g. , to obtain scale-invariant eigenvalues."
obtain scale-invariant eigenvalues,"Analogous scale-invariant decompositions can be derived from other matrix decompositions, e. g. , to obtain scale-invariant eigenvalues."
graphically represent finite-state,State diagrams can be used to graphically represent finite-state machines (also called finite automata).
graphically represent finite-state machines,State diagrams can be used to graphically represent finite-state machines (also called finite automata).
also support-vector networks,"In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis."
also support-vector,"In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis."
support-vector machine constructs,"More formally, a support-vector machine constructs a hyperplane or set of hyperplanes in a high- or infinite-dimensional space, which can be used for classification, regression, or other tasks like outliers detection."
support-vector machine weights,Support-vector machine weights have also been used to interpret SVM models in the past.
support-vector machine models,Posthoc interpretation of support-vector machine models in order to identify features used by the model to make predictions is a relatively new area of research with special significance in the biological sciences.
higher-dimensional feature space increases,"It is noteworthy that working in a higher-dimensional feature space increases the generalization error of support-vector machines, although given enough samples the algorithm still performs well."
log-polar bins used,(c) is the diagram of the log-polar bins used to compute the shape context.
information-theoretic security,"Important sub-fields of information theory include source coding, algorithmic complexity theory, algorithmic information theory and information-theoretic security."
evidence-based conclusions,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
reach evidence-based conclusions,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
reach evidence-based,"While there is great interest in using video game rehabilitation with children with cerebral palsy, it is difficult to compare outcomes between studies, and therefore to reach evidence-based conclusions on its effectiveness."
uni-temporal database,"A uni-temporal database has one axis of time, either the validity range or the system time range."
greedily generated error-correcting codes,Lexicographic codes or lexicodes are greedily generated error-correcting codes with remarkably good properties.
greedily generated error-correcting,Lexicographic codes or lexicodes are greedily generated error-correcting codes with remarkably good properties.
initiative human-computer,"Human-centered computing (HCC) studies the design, development, and deployment of mixed-initiative human-computer systems."
human-computer systems,"Human-centered computing (HCC) studies the design, development, and deployment of mixed-initiative human-computer systems."
initiative human-computer systems,"Human-centered computing (HCC) studies the design, development, and deployment of mixed-initiative human-computer systems."
mixed-initiative human,"Human-centered computing (HCC) studies the design, development, and deployment of mixed-initiative human-computer systems."
human-centered computing researchers,"Human-centered computing researchers and practitioners usually come from one or more of disciplines such as computer science, human factors, sociology, psychology, cognitive science, anthropology, communication studies, graphic design and industrial design."
human-centered systems,Human-centered systems (HCS) are systems designed for human-centered computing.
state machine-based,"Finite-state machine-based programming is generally the same, but, formally speaking, does not cover all possible variants, as FSM stands for finite-state machine, and automata-based programming does not necessarily employ FSMs in the strict sense."
machine-based programming,"Finite-state machine-based programming is generally the same, but, formally speaking, does not cover all possible variants, as FSM stands for finite-state machine, and automata-based programming does not necessarily employ FSMs in the strict sense."
state machine-based programming,"Finite-state machine-based programming is generally the same, but, formally speaking, does not cover all possible variants, as FSM stands for finite-state machine, and automata-based programming does not necessarily employ FSMs in the strict sense."
automata-based programming indeed closely matches,Automata-based programming indeed closely matches the programming needs found in the field of automation.
non-commercial item,"User experience evaluation (UXE) or user experience assessment (UXA) refers to a collection of methods, skills and tools utilized to uncover how a person perceives a system (product, service, non-commercial item, or a combination of them) before, during and after interacting with it."
user-centered design practices,"User experience evaluation has become common practice in web design, especially within organizations implementing user-centered design practices."
especially within organizations implementing user-centered,"User experience evaluation has become common practice in web design, especially within organizations implementing user-centered design practices."
especially within organizations implementing user-centered design practices,"User experience evaluation has become common practice in web design, especially within organizations implementing user-centered design practices."
so-called possible worlds,"In application of modal logic to computer science, the so-called possible worlds can be understood as representing possible states and the accessibility relation can be understood as a program."
using specialized data structures like min-max heap,"Double-ended priority queues can be built from balanced binary search trees (where the minimum and maximum elements are the leftmost and rightmost leaves, respectively), or using specialized data structures like min-max heap and pairing heap."
create low-cost,One such example is using mobile virtualization to create low-cost Android smartphones without a separate baseband processor by running the applications and the baseband processor code in separate virtual machines on a single processor.
using table-valued,"SQL-92 does not support creating or using table-valued columns, which means that using only the ""traditional relational database features"" (excluding extensions even if they were later standardized) most relational databases will be in first normal form by necessity."
using table-valued columns,"SQL-92 does not support creating or using table-valued columns, which means that using only the ""traditional relational database features"" (excluding extensions even if they were later standardized) most relational databases will be in first normal form by necessity."
table-valued columns,"SQL-92 does not support creating or using table-valued columns, which means that using only the ""traditional relational database features"" (excluding extensions even if they were later standardized) most relational databases will be in first normal form by necessity."
fixed-point arithmetic,The terms binary angular measurement (BAM) and binary angular measurement system (BAMS) refer to certain methodologies for representing and manipulating angles using binary (base 2) fixed-point arithmetic.
non-monotonic logic,Logic programming languages that include this extension have the knowledge representation capabilities of a non-monotonic logic.
known problem-solving behaviour,"In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs."
problem-solving behaviour,"In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs."
known problem-solving,"In the Prolog family of logic programming languages, the programmer can also use the known problem-solving behaviour of the execution mechanism to improve the efficiency of programs."
optimize human well-being,"Cognitive ergonomics studies cognition in work and operational settings, in order to optimize human well-being and system performance."
deterministic context-free,"In formal grammar theory, the deterministic context-free grammars (DCFGs) are a proper subset of the context-free grammars. !! In formal language theory, deterministic context-free languages (DCFL) are a proper subset of context-free languages. !! On the other hand, deterministic context-free languages can be accepted in O(n) time by an LR(k) parser."
pool-based sampling,"Pool-Based Sampling: In this scenario, instances are drawn from the entire data pool and assigned a confidence score, a measurement of how well the learner understands the data."
first-order theory,"In mathematical logic, Skolem arithmetic is the first-order theory of the natural numbers with multiplication, named in honor of Thoralf Skolem."
zeroth-order logic,"It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes zeroth-order logic."
sometimes zeroth-order logic,"It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes zeroth-order logic."
sometimes zeroth-order,"It is also called propositional logic, statement logic, sentential calculus, sentential logic, or sometimes zeroth-order logic."
non-logical objects,"Unlike first-order logic, propositional logic does not deal with non-logical objects, predicates about them, or quantifiers. !! First-order logic uses quantified variables over non-logical objects, and allows the use of sentences that contain variables, so that rather than propositions such as ""Socrates is a man"", one can have expressions in the form ""there exists x such that x is Socrates and x is a man"", where ""there exists"" is a quantifier, while x is a variable."
higher-order logics,"However, all the machinery of propositional logic is included in first-order logic and higher-order logics."
source ad-free,"UserLAnd Technologies is a free and open-source ad-free compatibility layer mobile app that allows Linux distributions, computer programs, computer games and numerical computing programs to run on mobile devices without requiring a root account."
source ad-free compatibility layer mobile app,"UserLAnd Technologies is a free and open-source ad-free compatibility layer mobile app that allows Linux distributions, computer programs, computer games and numerical computing programs to run on mobile devices without requiring a root account."
open-source ad,"UserLAnd Technologies is a free and open-source ad-free compatibility layer mobile app that allows Linux distributions, computer programs, computer games and numerical computing programs to run on mobile devices without requiring a root account."
ad-free compatibility layer mobile app,"UserLAnd Technologies is a free and open-source ad-free compatibility layer mobile app that allows Linux distributions, computer programs, computer games and numerical computing programs to run on mobile devices without requiring a root account."
two-operand instructions,Most bitwise operations are presented as two-operand instructions where the result replaces one of the input operands.
low-cost processors,"On simple low-cost processors, typically, bitwise operations are substantially faster than division, several times faster than multiplication, and sometimes significantly faster than addition."
simple low-cost processors,"On simple low-cost processors, typically, bitwise operations are substantially faster than division, several times faster than multiplication, and sometimes significantly faster than addition."
simple low-cost,"On simple low-cost processors, typically, bitwise operations are substantially faster than division, several times faster than multiplication, and sometimes significantly faster than addition."
first-order iterative optimization algorithm,In mathematics gradient descent (also often called steepest descent) is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.
full-sized 1919 board,"Deep reinforcement learning reached another milestone in 2015 when AlphaGo, a computer program trained with deep RL to play Go, became the first computer Go program to beat a human professional Go player without handicap on a full-sized 1919 board."
free-form languages descend,"Most free-form languages descend from ALGOL, including C, Pascal, and Perl."
real-time process control,"Distributed algorithms are used in different application areas of distributed computing, such as telecommunications, scientific computing, distributed information processing, and real-time process control."
peer-reviewed scientific journal published,ACM Transactions on Computer Systems is a quarterly peer-reviewed scientific journal published by the Association for Computing Machinery.
quarterly peer-reviewed,ACM Transactions on Computer Systems is a quarterly peer-reviewed scientific journal published by the Association for Computing Machinery.
quarterly peer-reviewed scientific journal published,ACM Transactions on Computer Systems is a quarterly peer-reviewed scientific journal published by the Association for Computing Machinery.
discrete-time signal,"In signal processing, a digital filter is a system that performs mathematical operations on a sampled, discrete-time signal to reduce or enhance certain aspects of that signal."
very-high-dimensional vector space model implementations,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
high-dimensional model,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
high-dimensional vector space model implementations,"Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e. g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately."
general-purpose commercial telegraph code known,Acme Commodity and Phrase Code is a codebook providing the general-purpose commercial telegraph code known as the Acme Code.
non-biological sequences,"Sequence alignments are also used for non-biological sequences, such as calculating the distance cost between strings in a natural language or in financial data."
produce high-quality sequence alignments,"Instead, human knowledge is applied in constructing algorithms to produce high-quality sequence alignments, and occasionally in adjusting the final results to reflect patterns that are difficult to represent algorithmically (especially in the case of nucleotide sequences)."
produce high-quality,"Instead, human knowledge is applied in constructing algorithms to produce high-quality sequence alignments, and occasionally in adjusting the final results to reflect patterns that are difficult to represent algorithmically (especially in the case of nucleotide sequences)."
high-quality sequence alignments,"Instead, human knowledge is applied in constructing algorithms to produce high-quality sequence alignments, and occasionally in adjusting the final results to reflect patterns that are difficult to represent algorithmically (especially in the case of nucleotide sequences)."
building-blueprint counterpart,"Therefore, a true software blueprint should share a number of key properties with its building-blueprint counterpart."
single-aspect focus,The single-aspect focus of a software blueprint means that an optimal description medium can be selected.
non-formalized systems investigated,The non-formalized systems investigated during this early stage go under the name of naive set theory.
n-ary rather,"The everyday division of documents into chapters, sections, paragraphs, and so on is an analogous example with n-ary rather than binary trees."
general-purpose language,"A general-purpose language is a computer language that is broadly applicable across application domains, and lacks specialized features for a particular domain."
non-universal quantum computation introduced,"Boson sampling is a restricted model of non-universal quantum computation introduced by Scott Aaronson and Alex Arkhipov after the original work of L. Troyansky and Naftali Tishby, that explored possible usage of boson scattering to evaluate expectation values of permanents of matrices."
non-universal approach,"Although the problem is well defined for any bosonic particles, its photonic version is currently considered as the most promising platform for a scalable implementation of a boson sampling device, which makes it a non-universal approach to linear optical quantum computing."
full linear-optical,"Moreover, while not universal, the boson sampling scheme is strongly believed to implement computing tasks which are hard to implement with classical computers by using far fewer physical resources than a full linear-optical quantum computing setup."
full linear-optical quantum computing setup,"Moreover, while not universal, the boson sampling scheme is strongly believed to implement computing tasks which are hard to implement with classical computers by using far fewer physical resources than a full linear-optical quantum computing setup."
linear-optical quantum computing setup,"Moreover, while not universal, the boson sampling scheme is strongly believed to implement computing tasks which are hard to implement with classical computers by using far fewer physical resources than a full linear-optical quantum computing setup."
single-photon measurements,"Then, the photonic implementation of the boson sampling task consists of generating a sample from the probability distribution of single-photon measurements at the output of the circuit."
semi-structured model,"The semi-structured model is a database model where there is no separation between the data and the schema, and the amount of structure used depends on the purpose."
variable-cardinality set,"Syntactic pattern recognition or structural pattern recognition is a form of pattern recognition, in which each object can be represented by a variable-cardinality set of symbolic, nominal features."
least-squares versions,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
least-squares support-vector machine,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
squares support-vector machines,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
least-squares support,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
squares support-vector,"Least-squares support-vector machines (LS-SVM) for statistics and in statistical modeling, are least-squares versions of support-vector machines (SVM), which are a set of related supervised learning methods that analyze data and recognize patterns, and which are used for classification and regression analysis."
two-dimensional array would,An Access Control Matrix should be thought of only as an abstract model of permissions at a given point in time; a literal implementation of it as a two-dimensional array would have excessive memory requirements.
simply row-based,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
column-based implementations,"Although these two mechanisms have sometimes been presented (for example in Butler Lampson's Protection paper) as simply row-based and column-based implementations of the Access Control Matrix, this view has been criticized as drawing a misleading equivalence between systems that does not take into account dynamic behaviour."
real-valued feature vectors,"Using string kernels with kernelized learning algorithms such as support vector machines allow such algorithms to work with strings, without having to translate these to fixed-length, real-valued feature vectors."
max-flow min,Max-flow min-cut theorem.
min-cut theorem states,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink. !! In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
flow min-cut theorem states,"In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink. !! In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
flow min-cut,"Max-flow min-cut theorem. !! In computer science and optimization theory, the max-flow min-cut theorem states that in a flow network, the maximum amount of flow passing from the source to the sink is equal to the total weight of the edges in a minimum cut, i. e. , the smallest total weight of the edges which if removed would disconnect the source from the sink. !! In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense. !! The other half of the max-flow min-cut theorem refers to a different aspect of a network: the collection of cuts. !! The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
min-cut theorem refers,The other half of the max-flow min-cut theorem refers to a different aspect of a network: the collection of cuts.
flow min-cut theorem refers,The other half of the max-flow min-cut theorem refers to a different aspect of a network: the collection of cuts.
flow min-cut theorem,Max-flow min-cut theorem.
flow min-cut theorem follows,"The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
min-cut theorem follows,"The equality in the max-flow min-cut theorem follows from the strong duality theorem in linear programming, which states that if the primal program has an optimal solution, x*, then the dual program also has an optimal solution, y*, such that the optimal values formed by the two solutions are equal."
generalized max-flow,"In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
generalized max-flow min,"In this new definition, the generalized max-flow min-cut theorem states that the maximum value of an s-t flow is equal to the minimum capacity of an s-t cut in the new sense."
monadic second-order,"Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2. !! In the study of graph algorithms, Courcelle's theorem is the statement that every graph property definable in the monadic second-order logic of graphs can be decided in linear time on graphs of bounded treewidth."
monadic second-order logic known,Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2.
second-order logic known,Courcelle's theorem may also be used with a stronger variation of monadic second-order logic known as MSO2.
bearer-independent call control,The Bearer-Independent Call Control (BICC) is a signaling protocol based on N-ISUP that is used for supporting narrowband Integrated Services Digital Network (ISDN) service over a broadband backbone network.
perform data-flow,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
control-flow graph,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
data-flow equations,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
perform data-flow analysis,"A simple way to perform data-flow analysis of programs is to set up data-flow equations for each node of the control-flow graph and solve them by repeatedly calculating the output from the input locally at each node until the whole system stabilizes, i. e. , it reaches a fixpoint."
multi-objective optimization problems involving two,"Minimizing cost while maximizing comfort while buying a car, and maximizing performance whilst minimizing fuel consumption and emission of pollutants of a vehicle are examples of multi-objective optimization problems involving two and three objectives, respectively."
nontrivial multi-objective,"For a nontrivial multi-objective optimization problem, no single solution exists that simultaneously optimizes each objective."
direct term-by-term,"Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
term-by-term summation,"Binary splitting requires more memory than direct term-by-term summation, but is asymptotically faster since the sizes of all occurring subproducts are reduced."
full-precision division,"Additionally, whereas the most naive evaluation scheme for a rational series uses a full-precision division for each term in the series, binary splitting requires only one final division at the target precision; this is not only faster, but conveniently eliminates rounding errors."
cost-benefit analysis,"In network science, the optimization mechanism is a network growth algorithm, which randomly places new nodes in the system, and connects them to the existing nodes based on a cost-benefit analysis."
self-assembly processes,"The theory formed the basis for such fields of study as complex dynamical systems, edge of chaos theory, and self-assembly processes."
q-pel motion,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
264 decoders always support quarter-pixel,H. 264 decoders always support quarter-pixel motion.
264 decoders always support quarter-pixel motion,H. 264 decoders always support quarter-pixel motion.
"much like half-pixel,","Quarter-pixel motion compensation, much like half-pixel, is achieved through interpolation."
much like half-pixel,"Quarter-pixel motion compensation, much like half-pixel, is achieved through interpolation."
self-evaluation functions,"The various funds, programmes, and agencies of the United Nations has a mix of independent, semi-independent and self-evaluation functions, which have organized themselves as a system-wide UN Evaluation Group (UNEG), that works together to strengthen the function, and to establish UN norms and standards for evaluation."
"several object-oriented,","Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
several object-oriented,"Resource acquisition is initialization (RAII) is a programming idiom used in several object-oriented, statically-typed programming languages to describe a particular language behavior."
third normal form-compliant data model,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
form-compliant data model,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
third normal form-compliant,"The negative outcome of such a design is that a doctor's number will be duplicated in the database if they have multiple patients, thus increasing both the chance of input error and the cost and risk of updating that number should it change (compared to a third normal form-compliant data model that only stores a doctor's number once on a doctor table)."
real large-scale,"For this reason, ranking-based similarity learning is easier to apply in real large-scale applications."
real large-scale applications,"For this reason, ranking-based similarity learning is easier to apply in real large-scale applications."
chemometrics non-negative,"In chemometrics non-negative matrix factorization has a long history under the name ""self modeling curve resolution""."
parts-based decomposition,In Learning the parts of objects by non-negative matrix factorization Lee and Seung proposed NMF mainly for parts-based decomposition of images.
pre-arranged listing,A dictionary attack is based on trying all the strings in a pre-arranged listing.
real-valued matrices,"If A and B are each real-valued matrices, the Frobenius inner product is the sum of the entries of the Hadamard product."
finite-dimensional real,Tensor product of Hilbert spaces the Frobenius inner product is the special case where the vector spaces are finite-dimensional real or complex vector spaces with the usual Euclidean inner product
divide-and-conquer recurrences provides,"In the analysis of algorithms, the master theorem for divide-and-conquer recurrences provides an asymptotic analysis (using Big O notation) for recurrence relations of types that occur in the analysis of many divide and conquer algorithms."
if-then-else structure,SKI combinator calculus can also implement Boolean logic in the form of an if-then-else structure.
adaptive decision-making,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
adaptive decision-making unit situated,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
decision-making unit situated,A learning automaton is an adaptive decision-making unit situated in a random environment that learns the optimal action through repeated interactions with its environment.
data-driven tagged,"Notable examples of American tagged architectures were the Lisp machines, which had tagged pointer support at the hardware and opcode level, the Burroughs large systems, which had a data-driven tagged and descriptor-based architecture, and the non-commercial Rice Computer."
dense-matrix structures,Operations using standard dense-matrix structures and algorithms are slow and inefficient when applied to large sparse matrices as processing and memory are wasted on the zeros.
manipulate using standard dense-matrix algorithms,Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.
manipulate using standard dense-matrix,Some very large sparse matrices are infeasible to manipulate using standard dense-matrix algorithms.
non-financial business reporting,"Value network analysis offers a taxonomy for non-financial business reporting, which is becoming increasingly important in SEC Filings."
non-financial value,Value network analysis addresses both financial and non-financial value.
example input-output,Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.
example input-output pairs,Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.
input-output pairs,Supervised learning (SL) is the machine learning task of learning a function that maps an input to an output based on example input-output pairs.
narrowband analog-to-digital,Adaptive predictive coding (APC) is a narrowband analog-to-digital conversion that uses a one-level or multilevel sampling system in which the value of the signal at each sampling instant is predicted according to a linear function of the past values of the quantized signals.
real-time genetic algorithms within,The use of real-time genetic algorithms within the network to compose network services is also enabled by active networking.
time-sharing operating systems schedule tasks,"Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources."
real-time systems,"Other specialized classes of operating systems (special-purpose operating systems), such as embedded and real-time systems, exist for many applications."
security-focused operating systems also exist,Security-focused operating systems also exist.
non-intersection condition,"Some authors define a weaker version of the definition of ""graph embedding"" by omitting the non-intersection condition for edges."
standard low-level details,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
low-level details,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
standard low-level,"The designers of software frameworks aim to facilitate software developments by allowing designers and programmers to devote their time to meeting software requirements rather than dealing with the more standard low-level details of providing a working system, thereby reducing overall development time."
variable-size list data structure,"In computer science, a dynamic array, growable array, resizable array, dynamic table, mutable array, or array list is a random access, variable-size list data structure that allows elements to be added or removed."
fixed-size array,"A dynamic array is not the same thing as a dynamically allocated array, which is an array whose size is fixed when the array is allocated, although a dynamic array may use such a fixed-size array as a back end."
metric k-center,"In graph theory, the metric k-center or metric facility location problem is a combinatorial optimization problem studied in theoretical computer science."
julia-based implementation,"jl: an efficient Julia-based implementation of various types of echo state networks, and (iv) pyESN: simple echo state networks in Python."
order depth-first search,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
order depth-first,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
post-order depth,"Note that some algorithms (such as post-order depth-first search) begin at the root, but first visit leaf nodes (access the value of leaf nodes), only to visit the root last (i. e. , they first access the children of the root, but only access the value of the root last)."
non-leaf node,"Similarly, (L+) (>H) assigns each non-leaf node with finitely many children its last child node. !! of the latter case form the relation (L) (<H) which is a partial map that assigns each non-leaf node its first child node."
long-term memory,He included more aspects of his research on long-term memory and thinking processes into this research and eventually designed a cognitive architecture he eventually called ACT.
desired input-output relations,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
desired input-output,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
input-output relations,"Quantum neural networks can be applied to algorithmic design: given qubits with tunable mutual interactions, one can attempt to learn interactions following the classical backpropagation rule from a training set of desired input-output relations, taken to be the desired output algorithm's behavior."
high-level controllers,High-level controllers such as model predictive control (MPC) or real-time optimization (RTO) employ mathematical optimization.
extremely well-studied formulation,An extremely well-studied formulation in stochastic control is that of linear quadratic Gaussian control.
well-studied formulation,An extremely well-studied formulation in stochastic control is that of linear quadratic Gaussian control.
extremely well-studied,An extremely well-studied formulation in stochastic control is that of linear quadratic Gaussian control.
grid-like topology,"Furthermore, convolutional neural networks are ideal for data with a grid-like topology (such as images) as spatial relations between separate features are taken into account during convolution and/or pooling."
automatically analyzing time-varying,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
automatically analyzing time-varying signals,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
time-varying signals,"Convolutional neural networks were presented at the Neural Information Processing Workshop in 1987, automatically analyzing time-varying signals by replacing learned multiplication with convolution in time, and demonstrated for speech recognition."
wake-sleep algorithm,"Helmholtz machines are usually trained using an unsupervised learning algorithm, such as the wake-sleep algorithm."
position-invariant recognition,"Helmholtz machines may also be used in applications requiring a supervised learning algorithm (e. g. character recognition, or position-invariant recognition of an object within a field)."
carry-select adder generally consists,The carry-select adder generally consists of ripple-carry adders and a multiplexer.
therefore two ripple-carry,"Adding two n-bit numbers with a carry-select adder is done with two adders (therefore two ripple-carry adders), in order to perform the calculation twice, one time with the assumption of the carry-in being zero and the other assuming it will be one."
bit carry-select adder,A 16-bit carry-select adder with variable size can be similarly created. !! A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
bit ripple-carry,A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
bit carry-select,A 16-bit carry-select adder with variable size can be similarly created. !! A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
16-bit carry,A 16-bit carry-select adder with variable size can be similarly created. !! A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
4-bit ripple,A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
bit ripple-carry adder,A 16-bit carry-select adder with a uniform block size of 4 can be created with three of these blocks and a 4-bit ripple-carry adder.
in-situ matrix transposition,"In-place matrix transposition, also called in-situ matrix transposition, is the problem of transposing an NM matrix in-place in computer memory, ideally with O(1) (bounded) additional storage, or at most with additional storage much less than NM."
i-th entry,"Instead of the truth table, traditionally used to represent Boolean functions, one may use a more compact representation for an n-variable symmetric Boolean function: the (n + 1)-vector, whose i-th entry (i = 0, ."
n-ary versions,"Parity function: their value is 1 if the input vector has odd number of onesThe n-ary versions of AND, OR, XOR, NAND, NOR and XNOR are also symmetric Boolean functions."
n - variable ordinary boolean function acting,"Effectively, an n-variable symmetric Boolean function corresponds to a log(n)-variable ordinary Boolean function acting on the base-2 representation of the input weight."
real-time text,"The term ""streaming media"" can apply to media other than video and audio, such as live closed captioning, ticker tape, and real-time text, which are all considered ""streaming text""."
subject-oriented programming advocates,"Subject-oriented programming advocates the organization of the classes that describe objects into ""subjects"", which may be composed to form larger subjects."
well-designed frameworks,"In the presentation of subject-oriented programming, the join-points were deliberately restricted to field access and method call on the grounds that those were the points at which well-designed frameworks were designed to admit functional extension."
sometimes called memory-based learning,"In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory."
sometimes called memory-based,"In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compare new problem instances with instances seen in training, which have been stored in memory."
support regular expression-like,Path expressions have been extended to support regular expression-like flexibility.
support regular expression-like flexibility,Path expressions have been extended to support regular expression-like flexibility.
expression-like flexibility,Path expressions have been extended to support regular expression-like flexibility.
near-real-time system animation,Reactive programming has been proposed as a way to simplify the creation of interactive user interfaces and near-real-time system animation.
real-time system animation,Reactive programming has been proposed as a way to simplify the creation of interactive user interfaces and near-real-time system animation.
next-node link,"With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link. !! In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence."
memory-saving manner,"Using the proxy pattern, the code of the ProxyImage avoids multiple loading of the image, accessing it from the other system in a memory-saving manner."
rule-based machine learning systems inspired,"In artificial intelligence, artificial immune systems (AIS) are a class of computationally intelligent, rule-based machine learning systems inspired by the principles and processes of the vertebrate immune system."
linear context-free rewriting systems,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
linear context-free,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
context-free rewriting systems,"For example, cross-serial dependencies can be expressed in linear context-free rewriting systems (LCFRS); one can write a LCFRS grammar for {anbncndn | n 1} for example."
self-driving cars combine,"Self-driving cars combine a variety of sensors to perceive their surroundings, such as thermographic cameras, radar, lidar, sonar, GPS, odometry and inertial measurement units."
self-driving cars available,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
fully self-driving,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
self-driving commercial car,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
fully self-driving commercial car,"Several projects to develop a fully self-driving commercial car are in various stages of development, but there are no self-driving cars available for everyday consumers."
off-line map,"Modern self-driving cars generally use Bayesian simultaneous localization and mapping (SLAM) algorithms, which fuse data from multiple sensors and an off-line map into current location estimates and map updates."
allows self-driving,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
allows self-driving cars,"Researchers at their Computer Science and Artificial Intelligence Laboratory (CSAIL) have developed a new system, called MapLite, which allows self-driving cars to drive on roads that they have never been on before, without using 3D maps."
distribution-based clustering,Distribution-based clustering produces complex models for clusters that can capture correlation and dependence between attributes.
distribution-based clustering produces complex models,Distribution-based clustering produces complex models for clusters that can capture correlation and dependence between attributes.
quantum many-body,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
many-body systems,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy. !! Coupled cluster (CC) is a numerical technique used for describing many-body systems.
quantum many-body systems,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
low-energy physics,The density matrix renormalization group (DMRG) is a numerical variational technique devised to obtain the low-energy physics of quantum many-body systems with high accuracy.
two-dimensional complexity theory,"In this way, parameterized complexity can be seen as two-dimensional complexity theory."
non-computing examples,"This section illustrates abstract interpretation by means of real-world, non-computing examples."
two weight-balanced,"Join: The function Join is on two weight-balanced trees t1 and t2 and a key k and will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2."
two weight-balanced trees t1,"Join: The function Join is on two weight-balanced trees t1 and t2 and a key k and will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2."
weight-balanced trees t1,"Join: The function Join is on two weight-balanced trees t1 and t2 and a key k and will return a tree containing all elements in t1, t2 as well as k. It requires k to be greater than all keys in t1 and smaller than all keys in t2."
"rectangular sub-regions,","Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value."
rectangular sub-regions,"Pooling: In a CNN's pooling layers, feature maps are divided into rectangular sub-regions, and the features in each rectangle are independently down-sampled to a single value, commonly by taking their average or maximum value."
word-like strings,"Linguistic notations which are distinguished in particular by the use of word-like strings of text to represent complex software constructions, and the combination of such word-like strings into patterns that have a sentence-like syntax."
sentence-like syntax,"Linguistic notations which are distinguished in particular by the use of word-like strings of text to represent complex software constructions, and the combination of such word-like strings into patterns that have a sentence-like syntax."
real-world entities,A data model (or datamodel) is an abstract model that organizes elements of data and standardizes how they relate to one another and to the properties of real-world entities.
computer-generated perceptual information,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory."
real-world environment,"Augmented reality (AR) is an interactive experience of a real-world environment where the objects that reside in the real world are enhanced by computer-generated perceptual information, sometimes across multiple sensory modalities, including visual, auditory, haptic, somatosensory and olfactory. !! In this way, augmented reality alters one's ongoing perception of a real-world environment, whereas virtual reality completely replaces the user's real-world environment with a simulated one."
creating object-oriented,Portable Distributed Objects (PDO) is an application programming interface (API) for creating object-oriented code that can be executed remotely on a network of computers.
creating object-oriented code,Portable Distributed Objects (PDO) is an application programming interface (API) for creating object-oriented code that can be executed remotely on a network of computers.
term delay-tolerant,"In 2002, Kevin Fall started to adapt some of the ideas in the IPN design to terrestrial networks and coined the term delay-tolerant networking and the DTN acronym."
term delay-tolerant networking,"In 2002, Kevin Fall started to adapt some of the ideas in the IPN design to terrestrial networks and coined the term delay-tolerant networking and the DTN acronym."
mixed-field samples,Biodiversity informatics may also have to cope with managing information from unnamed taxa such as that produced by environmental sampling and sequencing of mixed-field samples.
3-connected components,"Tree contraction has been used in designing many efficient parallel algorithms, including expression evaluation, finding lowest common ancestors, tree isomorphism, graph isomorphism, maximal subtree isomorphism, common subexpression elimination, computing the 3-connected components of a graph, and finding an explicit planar embedding of a planar graphBased on the research and work on parallel tree contraction, various algorithms have been proposed targeting to improve the efficiency or simplicity of this topic."
linear frequency-domain method,Eigenmode expansion is a linear frequency-domain method.
linear frequency-domain,Eigenmode expansion is a linear frequency-domain method.
frequency-domain method,Eigenmode expansion is a linear frequency-domain method.
"unlimited fan-out,","Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
real op-amps,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
non-ideal physical device,"Depending on the context, the term may refer to an ideal logic gate, one that has for instance zero rise time and unlimited fan-out, or it may refer to a non-ideal physical device (see Ideal and real op-amps for comparison)."
domain-specific ontology consisting,"A reference modelin systems, enterprise, and software engineeringis an abstract framework or domain-specific ontology consisting of an interlinked set of clearly defined concepts produced by an expert or body of experts to encourage clear communication."
representing floating-point,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
representing floating-point numbers,"Historically, several number bases have been used for representing floating-point numbers, with base two (binary) being the most common, followed by base ten (decimal floating point), and other less common varieties, such as base sixteen (hexadecimal floating point), base eight (octal floating point), base four (quaternary floating point), base three (balanced ternary floating point) and even base 256 and base 65,536."
value-to-representation curve,"The value distribution is similar to floating point, but the value-to-representation curve (i. e. , the graph of the logarithm function) is smooth (except at 0)."
discrete-parameter systems,"Automata theory was initially considered a branch of mathematical systems theory, studying the behavior of discrete-parameter systems."
rapidly draw three-dimensional scenes composed,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
rapidly draw three-dimensional,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
three-dimensional scenes composed,Binary space partitioning arose from the computer graphics need to rapidly draw three-dimensional scenes composed of polygons.
time-stretch analog,"A Time-stretch analog-to-digital converter (TS-ADC) digitizes a very wide bandwidth analog signal, that cannot be digitized by a conventional electronic ADC, by time-stretching the signal prior to digitization."
stretch analog-to-digital,"A Time-stretch analog-to-digital converter (TS-ADC) digitizes a very wide bandwidth analog signal, that cannot be digitized by a conventional electronic ADC, by time-stretching the signal prior to digitization."
digital audio workstation-based sound recording,Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
digital audio workstation-based,Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
workstation-based sound recording,Analog-to-digital converters are integral to 2000s era music reproduction technology and digital audio workstation-based sound recording.
therefore need analog-to-digital,People often produce music on computers using an analog recording and therefore need analog-to-digital converters to create the pulse-code modulation (PCM) data streams that go onto compact discs and digital music files.
machine-like environment,"Some memory debuggers (e. g. Valgrind) work by running the executable in a virtual machine-like environment, monitoring memory access, allocation and deallocation so that no recompilation with special memory allocation libraries is required."
virtual machine-like environment,"Some memory debuggers (e. g. Valgrind) work by running the executable in a virtual machine-like environment, monitoring memory access, allocation and deallocation so that no recompilation with special memory allocation libraries is required."
e-like environment,"Some memory debuggers (e. g. Valgrind) work by running the executable in a virtual machine-like environment, monitoring memory access, allocation and deallocation so that no recompilation with special memory allocation libraries is required."
virtual machine-like,"Some memory debuggers (e. g. Valgrind) work by running the executable in a virtual machine-like environment, monitoring memory access, allocation and deallocation so that no recompilation with special memory allocation libraries is required."
one sub-discipline,"Computational materials science is one sub-discipline of both computational science and computational engineering, containing significant overlap with computational chemistry and computational physics."
implements short-circuit evaluation,"In any programming language that implements short-circuit evaluation, the expression x and y is equivalent to the conditional expression if x then y else x, and the expression x or y is equivalent to if x then x else y."
implements short-circuit,"In any programming language that implements short-circuit evaluation, the expression x and y is equivalent to the conditional expression if x then y else x, and the expression x or y is equivalent to if x then x else y."
use short-circuit evaluation,10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE.
use short-circuit,10 The norm IEC 61131-3 doesn't actually define if AND and OR use short-circuit evaluation and it doesn't define the operators AND_THEN and OR_ELSE.
short-circuit evaluation guarantees,"In this example, short-circuit evaluation guarantees that myfunc(b) is never called."
average-case lower bound,"A comparison sort must have an average-case lower bound of (n log n) comparison operations, which is known as linearithmic time."
non-comparison sorts,"Non-comparison sorts (such as the examples discussed below) can achieve O(n) performance by using operations other than comparisons, allowing them to sidestep this lower bound (assuming elements are constant-sized)."
n-comparison sorts,"Non-comparison sorts (such as the examples discussed below) can achieve O(n) performance by using operations other than comparisons, allowing them to sidestep this lower bound (assuming elements are constant-sized)."
"drawn left-to-right,","Conversely, given an ordered tree, and conventionally drawing the root at the top, then the child vertices in an ordered tree can be drawn left-to-right, yielding an essentially unique planar embedding."
motor-actuated joints,Serial manipulators are the most common industrial robots and they are designed as a series of links connected by motor-actuated joints that extend from a base to an end-effector.
low-density regions,"In the case of semi-supervised learning, the smoothness assumption additionally yields a preference for decision boundaries in low-density regions, so few points are close to each other but in different classes."
bio-inspired computing,"Bio-inspired computing, short for biologically inspired computing, is a field of study which seeks to solve computer science problems using models of biology. !! Bio-inspired computing is a major subset of natural computation."
bio-inspired computing relates,"Within computer science, bio-inspired computing relates to artificial intelligence and machine learning."
bio-inspired computing uses,"Bio-inspired computing uses an evolutionary approach, while traditional A. I. uses a 'creationist' approach."
arbitrary n-bit central processing unit,"Bit slicing is a technique for constructing a processor from modules of processors of smaller bit width, for the purpose of increasing the word length; in theory to make an arbitrary n-bit central processing unit (CPU)."
large-scale integrated circuits,"Bit slicing, although not called that at the time, was also used in computers before large-scale integrated circuits (LSI, the predecessor to today's VLSI, or very-large-scale integration circuits)."
single-instruction multiple,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
perform single-instruction multiple,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
perform single-instruction,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
instruction multiple-data,"In more recent times, the term bit slicing was reused by Matthew Kwan to refer to the technique of using a general-purpose CPU to implement multiple parallel simple virtual machines using general logic instructions to perform single-instruction multiple-data (SIMD) operations."
model various low-,"In the domain of artificial intelligence, a Markov random field is used to model various low- to mid-level tasks in image processing and computer vision."
mid-level tasks,"In the domain of artificial intelligence, a Markov random field is used to model various low- to mid-level tasks in image processing and computer vision."
general-purpose meaning,"While, in principle, any general-purpose lossless compression algorithm (general-purpose meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress."
(general-purpose meaning,"While, in principle, any general-purpose lossless compression algorithm (general-purpose meaning that they can accept any bitstring) can be used on any type of data, many are unable to achieve significant compression on data that are not of the form for which they were designed to compress."
address complex real-world problems,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
real-world problems,"Although the idea of trajectory optimization has been around for hundreds of years (calculus of variations, brachystochrone problem), it only became practical for real-world problems with the advent of the computer. !! Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
address complex real-world,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
nature-inspired computational methodologies,"Generally, computational intelligence is a set of nature-inspired computational methodologies and approaches to address complex real-world problems to which mathematical or traditional modelling can be useless for a few reasons: the processes might be too complex for mathematical reasoning, it might contain some uncertainties during the process, or the process might simply be stochastic in nature."
type-2 fuzzy ontology,Diet assessment based on type-2 fuzzy ontology and fuzzy markup language.
guaranteed worst-case,The performance of a binary search tree is dependent on the order of insertion of the nodes into the tree; several variations of the binary search tree can be built with guaranteed worst-case performance.
guaranteed worst-case performance,The performance of a binary search tree is dependent on the order of insertion of the nodes into the tree; several variations of the binary search tree can be built with guaranteed worst-case performance.
first-order complete,"Many important complexity classes are closed under first-order reductions, and many of the traditional complete problems are first-order complete as well (Immerman 1999 p. 49-50)."
previous existing pre-generated music plus visualization combinations,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
previous existing pre-generated,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
real-time generated,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
pre-generated music plus visualization combinations,"""Music visualization"" can be defined, in contrast to previous existing pre-generated music plus visualization combinations (as for example music videos), by its characteristic as being real-time generated."
man-made machines,"Machine ethics (or machine morality, computational morality, or computational ethics) is a part of the ethics of artificial intelligence concerned with adding or ensuring moral behaviors of man-made machines that use artificial intelligence, otherwise known as artificial intelligent agents."
zero-temperature phase,"In physics, topological order is a kind of order in the zero-temperature phase of matter (also known as quantum matter)."
quantized non-abelian,"Macroscopically, topological order is defined and described by robust ground state degeneracy and quantized non-Abelian geometric phases of degenerate ground states."
long-range quantum entanglement,"Microscopically, topological orders correspond to patterns of long-range quantum entanglement."
non-abelian statistics,"Various topologically ordered states have interesting properties, such as (1) topological degeneracy and fractional statistics or non-abelian statistics that can be used to realize a topological quantum computer; (2) perfect conducting edge states that may have important device applications; (3) emergent gauge field and Fermi statistics that suggest a quantum information origin of elementary particles; (4) topological entanglement entropy that reveals the entanglement origin of topological order, etc."
means clustering minimizes within-cluster,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
k-means clustering minimizes within,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
means clustering minimizes within-cluster variances,"k-means clustering minimizes within-cluster variances (squared Euclidean distances), but not regular Euclidean distances, which would be the more difficult Weber problem: the mean optimizes squared errors, whereas only the geometric median minimizes Euclidean distances."
k-means clustering tends,"They both use cluster centers to model the data; however, k-means clustering tends to find clusters of comparable spatial extent, while the Gaussian mixture model allows clusters to have different shapes."
k-means clustering aims,", xn), where each observation is a d-dimensional real vector, k-means clustering aims to partition the n observations into k ( n) sets S = {S1, S2, ."
ligand-protein binding,"Ensemble properties of molecular motion (e. g. , probability of folding (PFold), escape time in ligand-protein binding) is computed efficiently and accurately with stochastic roadmap simulation."
two-square cipher uses two 5x5 matrices,"The two-square cipher uses two 5x5 matrices and comes in two varieties, horizontal and vertical."
infinite-dimensional optimization problem,Shape optimization is an infinite-dimensional optimization problem.
high-dimensional theories,"Emerging high-dimensional theories of shape are central to many studies in computational anatomy, as are questions emerging from the fledgling field of shape statistics."
computer-assisted research,"The Alliance of Digital Humanities Organizations is an umbrella organisation whose goals are to promote and support digital research and teaching across arts and humanities disciplines, drawing together humanists engaged in digital and computer-assisted research, teaching, creation, dissemination, and beyond, in all areas reflected by its diverse membership."
reversible-jump variant,"But the reversible-jump variant is useful when doing Markov chain Monte Carlo or Gibbs sampling over nonparametric Bayesian models such as those involving the Dirichlet process or Chinese restaurant process, where the number of mixing components/clusters/etc."
out-of-order execution microprocessors,"Memory disambiguation is a set of techniques employed by high-performance out-of-order execution microprocessors that execute memory access instructions (loads and stores) out of program order. !! Memory dependence prediction is a technique, employed by high-performance out-of-order execution microprocessors that execute memory access operations (loads and stores) out of program order, to predict true dependencies between loads and stores at instruction execution time."
special-purpose model transformation languages,"However, special-purpose model transformation languages can offer advantages, such as syntax that makes it easy to refer to model elements."
well-known recursive algorithms generate,Many well-known recursive algorithms generate an entirely new piece of data from the given data and recur on it.
non-singleton set,The only non-singleton set with this property is the empty set.
pre-recorded verbal warning,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
emitting high-volume,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
vehicle-mounted siren,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
high-volume sound,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
emitting high-volume sound,"Car alarms work by emitting high-volume sound (often a vehicle-mounted siren, klaxon, pre-recorded verbal warning, the vehicle's own horn, or a combination of these) when the conditions necessary for triggering it are met."
high-level constructs,Quantum programming languages help express quantum algorithms using high-level constructs.
"several quantum hardware back-ends,","A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
several quantum hardware back-ends,"A quantum programming environment and optimizing compiler developed by Cambridge Quantum Computing that targets simulators and several quantum hardware back-ends, released in December 2018."
require bit manipulation include low-level,"Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization."
require bit manipulation include low-level device control,"Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization."
low-level device control,"Computer programming tasks that require bit manipulation include low-level device control, error detection and correction algorithms, data compression, encryption algorithms, and optimization."
many-fold speed ups,"Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel."
give many-fold,"Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel."
give many-fold speed ups,"Bit manipulation, in some cases, can obviate or reduce the need to loop over a data structure and can give many-fold speed ups, as bit manipulations are processed in parallel."
challenging low-level,"Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
non-obvious ways,"Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
challenging low-level device control data manipulation tasks,"Bit twiddling and bit bashing are often used interchangeably with bit manipulation, but sometimes exclusively refer to clever or non-obvious ways or uses of bit manipulation, or tedious or challenging low-level device control data manipulation tasks."
also called 2-tuples,"Ordered pairs are also called 2-tuples, or sequences (sometimes, lists in a computer science context) of length 2."
"also called 2-tuples,","Ordered pairs are also called 2-tuples, or sequences (sometimes, lists in a computer science context) of length 2."
sometimes called 2-dimensional vectors,Ordered pairs of scalars are sometimes called 2-dimensional vectors.
sometimes called 2-dimensional,Ordered pairs of scalars are sometimes called 2-dimensional vectors.
many-one reductions,"The most frequently used of these are the many-one reductions, and in some cases the phrase ""polynomial-time reduction"" may be used to mean a polynomial-time many-one reduction. !! Just as many-one reductions are important for proving NP-completeness, parsimonious reductions are important for proving completeness for counting complexity classes such as P. !! The three most common types of polynomial-time reduction, from the most to the least restrictive, are polynomial-time many-one reductions, truth-table reductions, and Turing reductions."
stimulus-response mechanism,"A Functional Presence Engines is, subsequently, a stimulus-response mechanism that allows for a higher variability of inputs to elicit response patterns with a high likelihood of correctness, even from incomplete training."
addresses story-based,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
addresses story-based media within,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
story-based media within,Alex McDowell coined the phrase 'immersive design' in 2007 in order to frame a discussion around a design discipline that addresses story-based media within the context of digital and virtual technologies.
fixed-size computation,"Amdahl's law does represent the law of diminishing returns if on considering what sort of return one gets by adding more processors to a machine, if one is running a fixed-size computation that will use all available processors to their capacity."
table-based format,"The most popular example of a database model is the relational model, which uses a table-based format."
human-usable data,"To provide more human-usable data, these programs often perform a reverse lookup before writing the log, thus writing a name rather than the IP address."
time-symmetric interpretations,Time-symmetric interpretations of quantum mechanics were first suggested by Walter Schottky in 1921.
openly criticized non-orthodox interpretations,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
openly criticized non-orthodox,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
non-orthodox interpretations,"Others, like Nico van Kampen and Willis Lamb, have openly criticized non-orthodox interpretations of quantum mechanics."
pseudo-randomly changing systems,"In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems."
model pseudo-randomly changing systems,"In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems."
model pseudo-randomly,"In probability theory, a Markov model is a stochastic model used to model pseudo-randomly changing systems."
well-known algorithms,Several well-known algorithms for hidden Markov models exist.
most-likely corresponding sequence,"For example, given a sequence of observations, the Viterbi algorithm will compute the most-likely corresponding sequence of states, the forward algorithm will compute the probability of the sequence of observations, and the BaumWelch algorithm will estimate the starting probabilities, the transition function, and the observation function of a hidden Markov model."
knowledge-based systems,"Knowledge engineering (KE) refers to all technical, scientific and social aspects involved in building, maintaining and using knowledge-based systems. !! Reasoning systems play an important role in the implementation of artificial intelligence and knowledge-based systems."
non-speech frames,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
important role since non-speech,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
important role since non-speech frames,"In speech processing applications, voice activity detection plays an important role since non-speech frames are often discarded."
multi-qubit state,"In quantum computing, a graph state is a special type of multi-qubit state that can be represented by a graph."
quantum error-correcting,"Graph states are useful in quantum error-correcting codes, entanglement measurement and purification and for characterization of computational resources in measurement based quantum computing models."
semi-supervised learning falls,Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data).
semi-supervised learning combines,Semi-supervised learning combines this information to surpass the classification performance that can be obtained either by discarding the unlabeled data and doing supervised learning or by discarding the labels and doing unsupervised learning.
instruction-level parallelism since,Software pipelining has been known to assembly language programmers of machines with instruction-level parallelism since such architectures existed.
high-level symbolic,"In artificial intelligence, symbolic artificial intelligence is the term for the collection of all methods in artificial intelligence research that are based on high-level symbolic (human-readable) representations of problems, logic and search."
computer-generated records,"In computer log management and intelligence, log analysis (or system and network log analysis) is an art and science seeking to make sense out of computer-generated records (also called log or audit trail records)."
real-world compressors,"To determine the similarity of objects such as genomes, languages, music, internet attacks and worms, software programs, and so on, information distance is normalized and the Kolmogorov complexity terms approximated by real-world compressors (the Kolmogorov complexity is a lower bound to the length in bits of a compressed version of the object)."
semi-structured data sets,Structure mining or structured data mining is the process of finding and extracting useful information from semi-structured data sets.
technology-based system,"For the full development of a 3D User Interaction system, is required to have access to a few basic parameters, all this technology-based system should know, or at least partially, as the relative position of the user, the absolute position, angular velocity, rotation data, orientation or height."
-2 define generic models,"ISO/IEC 29192-6 Lightweight cryptography - Message authentication codesISO/IEC 9797-1 and -2 define generic models and algorithms that can be used with any block cipher or hash function, and a variety of different parameters."
cross-site cooking,"Cross-site cooking can be used to perform session fixation attacks, as a malicious site can fixate the session identifier cookie of another site. !! Cross-site cooking is a type of browser exploit which allows a site attacker to set a cookie for a browser into the cookie domain of another site server. !! Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc."
cross-site cooking could,"But if this security vulnerability requires e. g. an administrator password which attacker does not know, cross-site cooking could be used to fool innocent users to unintentionally perform the attack."
cross-zone scripting etc,"Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc."
cross-site tracing,"Cross-site cooking is similar in concept to cross-site scripting, cross-site request forgery, cross-site tracing, cross-zone scripting etc."
using knowledge-based,"Knowledge engineering (KE) refers to all technical, scientific and social aspects involved in building, maintaining and using knowledge-based systems."
using knowledge-based systems,"Knowledge engineering (KE) refers to all technical, scientific and social aspects involved in building, maintaining and using knowledge-based systems."
minimal geometrical-topological value,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
minimal geometrical-topological,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
geometrical-topological value,"Thus, the quantum LC circuit is the minimal geometrical-topological value of the quantum waveguide, in which there are no electric or magnetic charges, but electromagnetic waves only."
counter-intuitively easy,Alignments of random points in a plane can be demonstrated by statistics to be counter-intuitively easy to find when a large number of random points are marked on a bounded flat surface.
electro-acoustical devices,An audio analyzer is a test and measurement instrument used to objectively quantify the audio performance of electronic and electro-acoustical devices.
re-usable form,A design pattern is the re-usable form of a solution to a design problem.
observer-independent state,The assumption rejected by relational quantum mechanics is the existence of an observer-independent state of a system.
same-origin policy,A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy.
cross-site scripting vulnerability may,A cross-site scripting vulnerability may be used by attackers to bypass access controls such as the same-origin policy.
cross-site scripting carried,Cross-site scripting carried out on websites accounted for roughly 84% of all security vulnerabilities documented by Symantec up until 2007.
timing-dependent plasticity,"The modifications can themselves depend on spike timing patterns (temporal coding), i. e. , can be a special case of spike-timing-dependent plasticity."
inherently thread-safe,Immutable objects are also useful because they are inherently thread-safe.
makes high-level,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
high-level design choices,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
makes high-level design choices,"A software architect is a software development expert who makes high-level design choices and tries to enforce technical standards, including software coding standards, tools, and platforms."
complex-math functions,The C99 standard of the C programming language includes complex data types and complex-math functions in the standard library header <complex.
proposed standard supported bi-directional,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication.
proposed standard supported bi-directional communication,The working group was renamed as the Human Interface Device class at the suggestion of Tom Schmidt of DEC because the proposed standard supported bi-directional communication.
over-the-top video streaming service owned,"Peacock is an American over-the-top video streaming service owned and operated by the Television and Streaming division of NBCUniversal, a subsidiary of Comcast."
over-the-top streaming service,"This included the launch of an over-the-top streaming service, named ""Peacock"" and made available in April 2020."
called two-party,"This abstract problem with two parties (called two-party communication complexity), and its general form with more than two parties, is relevant in many contexts."
sentiment analysis like-,"There are various other types of sentiment analysis like- Aspect Based sentiment analysis, Grading sentiment analysis (positive, negative, neutral), Multilingual sentiment analysis and detection of emotions."
real-world measurements,"Numerical analysis continues this long tradition: rather than giving exact symbolic answers translated into digits and applicable only to real-world measurements, approximate solutions within specified error bounds are used."
latent variables organized layer-wise,"Most modern deep learning models are based on artificial neural networks, specifically convolutional neural networks (CNN)s, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines."
include object prototype-based,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
prototype-based approaches,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
include object prototype-based approaches,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
class-based subset,"What follows is a description of the class-based subset of object-oriented design, which does not include object prototype-based approaches where objects are not typically obtained by instantiating classes but by cloning other (prototype) objects."
object-oriented decomposition,Object-oriented design is a method of design encompassing the process of object-oriented decomposition and a notation for depicting both logical and physical as well as state and dynamic models of the system under design.
established best-practices employed,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
best-practices employed,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
established best-practices,"Many of these techniques are based on established best-practices employed to efficiently route traffic at the network layer including redundancy and load balancing In theory, an Application Delivery Network (ADN) is closely related to a content delivery network."
constant-factor approximations,"In mathematical optimization, greedy algorithms optimally solve combinatorial problems having the properties of matroids and give constant-factor approximations to optimization problems with the submodular structure."
give constant-factor,"In mathematical optimization, greedy algorithms optimally solve combinatorial problems having the properties of matroids and give constant-factor approximations to optimization problems with the submodular structure."
give constant-factor approximations,"In mathematical optimization, greedy algorithms optimally solve combinatorial problems having the properties of matroids and give constant-factor approximations to optimization problems with the submodular structure."
low-level routines,"Basic Linear Algebra Subprograms (BLAS) is a specification that prescribes a set of low-level routines for performing common linear algebra operations such as vector addition, scalar multiplication, dot products, linear combinations, and matrix multiplication."
compile-time term,"A concise rule for determining whether phase distinction is preserved in a language or not has been proposed by Luca Cardelli - If A is a compile-time term and B is a subterm of A, then B must also be a compile-time term."
mathematics higher-order,In mathematics higher-order functions are also termed operators or functionals.
higher-order function twice takes,"In the following examples, the higher-order function twice takes a function, and applies the function to some value twice."
higher-order function or_else,"In this Erlang example, the higher-order function or_else/2 takes a list of functions (Fs) and argument (X)."
non-parametric statistic measuring,Transfer entropy is a non-parametric statistic measuring the amount of directed (time-asymmetric) transfer of information between two random processes.
vector auto-regressive,Transfer entropy reduces to Granger causality for vector auto-regressive processes.
auto-regressive processes,Transfer entropy reduces to Granger causality for vector auto-regressive processes.
"creating evidence-based,","User experience design (UX design, UXD, UED, or XD) is the process of creating evidence-based, interaction designs between human users and products or websites."
creating evidence-based,"User experience design (UX design, UXD, UED, or XD) is the process of creating evidence-based, interaction designs between human users and products or websites."
design approaches like human-computer,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
design approaches like human-computer interaction,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others."
user-centered design,"User experience design draws from design approaches like human-computer interaction and user-centered design, and includes elements from similar disciplines like interaction design, visual design, information architecture, user research, and others. !! Thus hands-on computing is a component of user-centered design, focusing on how users physically respond to virtual environments."
pre-defined presentation semantics,"Some markup languages, such as the widely used HTML, have pre-defined presentation semantics, meaning that their specification prescribes some aspects of how to present the structured data on particular media."
type-based program analysis polymorphic recursion,In type-based program analysis polymorphic recursion is often essential in gaining high precision of the analysis.
region-based memory management system,"Notable examples of systems employing polymorphic recursion include Dussart, Henglein and Mossin's binding-time analysis and the TofteTalpin region-based memory management system."
binding-time analysis,"Notable examples of systems employing polymorphic recursion include Dussart, Henglein and Mossin's binding-time analysis and the TofteTalpin region-based memory management system."
classical point-set topology,"Topos theory is, in some sense, a generalization of classical point-set topology."
classical point-set,"Topos theory is, in some sense, a generalization of classical point-set topology."
general problem-solving,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! Brute-force attacks are an application of brute-force search, the general problem-solving technique of enumerating all candidates and checking each one."
general problem-solving technique,"In computer science, brute-force search or exhaustive search, also known as generate and test, is a very general problem-solving technique and algorithmic paradigm that consists of systematically enumerating all possible candidates for the solution and checking whether each candidate satisfies the problem's statement. !! Brute-force attacks are an application of brute-force search, the general problem-solving technique of enumerating all candidates and checking each one."
8-bit sound samples compress better,"Unfortunately, not even all 8-bit sound samples compress better when delta encoded, and the usability of delta encoding is even smaller for 16-bit and better samples."
first-order predicate calculusis,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science."
first-order logicalso known,"First-order logicalso known as predicate logic, quantificational logic, and first-order predicate calculusis a collection of formal systems used in mathematics, philosophy, linguistics, and computer science."
non-strict evaluation,"In programming language theory, lazy evaluation, or call-by-need, is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing)."
(non-strict evaluation,"In programming language theory, lazy evaluation, or call-by-need, is an evaluation strategy which delays the evaluation of an expression until its value is needed (non-strict evaluation) and which also avoids repeated evaluations (sharing)."
capability-limited address space,"Lazy evaluation was introduced for lambda calculus by Christopher Wadsworth and employed by the Plessey System 250 as a critical part of a Lambda-Calculus Meta-Machine, reducing the resolution overhead for access to objects in a capability-limited address space."
displaying data-flow diagrams,There are several notations for displaying data-flow diagrams.
displaying data-flow,There are several notations for displaying data-flow diagrams.
another data-flow diagram,"The refined representation of a process can be done in another data-flow diagram, which subdivides this process into sub-processes."
another data-flow,"The refined representation of a process can be done in another data-flow diagram, which subdivides this process into sub-processes."
traditional rule-based system,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
traditional rule-based,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
often hand-crafted,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
traditional rule-based systems,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
rule-based decision makers,"While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
"often hand-crafted,","While rule-based machine learning is conceptually a type of rule-based system, it is distinct from traditional rule-based systems, which are often hand-crafted, and other rule-based decision makers."
rule-based machine learning applies,"This is because rule-based machine learning applies some form of learning algorithm to automatically identify useful rules, rather than a human needing to apply prior domain knowledge to manually construct rules and curate a rule set."
near-human performance,"Some researchers have achieved ""near-human performance"" on the MNIST database, using a committee of neural networks; in the same paper, the authors achieve performance double that of humans on other recognition tasks."
"""near-human performance","Some researchers have achieved ""near-human performance"" on the MNIST database, using a committee of neural networks; in the same paper, the authors achieve performance double that of humans on other recognition tasks."
general-purpose computer algebra systems aim,General-purpose computer algebra systems aim to be useful to a user working in any scientific field that requires manipulation of mathematical expressions.
general-purpose computer algebra systems,This large amount of required computer capabilities explains the small number of general-purpose computer algebra systems.
space-division multiplexing,"Spatial multiplexing or space-division multiplexing (often abbreviated SM, SDM or SMX) is a multiplexing technique in MIMO wireless communication, fibre-optic communication and other communications technologies used to transmit independent channels separated in space."
non-contact acoustic wave generation,Electromagnetic acoustic transducer (EMAT) is a transducer for non-contact acoustic wave generation and reception in conducting materials.
in-car information,"Remote Touch is a vehicle interface system present in some Lexus cars for use in conjunction with in-car information, configuration, and entertainment systems."
on-screen cursor,"The Remote Touch controller, which is similar to a computer mouse or joystick, allows the driver to operate an on-screen cursor on the vehicle's GPS navigation system screen. !! Remote Touch utilizes haptic feedback, where the controller provides reaction force, and force feedback, where the on-screen cursor can move to nearby buttons automatically."
energy-efficient motors,"The US Environmental Protection Agency has investigated fuzzy control for energy-efficient motors, and NASA has studied fuzzy control for automated space docking: simulations show that a fuzzy control system can greatly reduce fuel consumption."
different use-cases,The Stability Model has been seen and used in an array of different use-cases.
see worst-case complexity,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
see worst-case,"Randomized algorithms are particularly useful when faced with a malicious ""adversary"" or attacker who deliberately tries to feed a bad input to the algorithm (see worst-case complexity and competitive analysis (online algorithm)) such as in the Prisoner's dilemma."
normal floating-point formats,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
normal floating-point,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
fixed-length entries found,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
variable-sized entries,"In computing, tapered floating point (TFP) is a format similar to floating point, but with variable-sized entries for the significand and exponent instead of the fixed-length entries found in normal floating-point formats."
non-linear behavior,"Advanced structural analysis may examine dynamic response, stability and non-linear behavior."
input piece-by-piece,"In computer science, an online algorithm is one that can process its input piece-by-piece in a serial fashion, i. e. , in the order that the input is fed to the algorithm, without having the entire input available from the start."
operator-valued measure,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
semi-definite operators,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
positive semi-definite operators,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
positive-operator-valued measure,"In functional analysis and quantum measurement theory, a positive-operator-valued measure (POVM) is a measure whose values are positive semi-definite operators on a Hilbert space."
projection-valued measures,"POVMs are a generalisation of projection-valued measures (PVMs) and, correspondingly, quantum measurements described by POVMs are a generalisation of quantum measurement described by PVMs."
digital-to-analog converters,"Similar digital-to-analog converters can be found in digital speakers such as USB speakers, and in sound cards."
high-speed expansion ports,"A DMA attack is a type of side channel attack in computer security, in which an attacker can penetrate a computer or other device, by exploiting the presence of high-speed expansion ports that permit direct memory access (DMA)."
current allocation-level,"Gap analysis identifies gaps between the optimized allocation and integration of the inputs (resources), and the current allocation-level."
self-adjusting form,A skew heap is a self-adjusting form of a leftist heap which attempts to maintain balance by unconditionally swapping all nodes in the merge path when merging two heaps.
information-theoretic minimum,"When the data are compressible, as is often the case in practice for natural language text, the compressed data structure can occupy space very close to the information-theoretic minimum, and significantly less space than most compression schemes."
risc-like instruction set architecture designed,The Clipper architecture is a 32-bit RISC-like instruction set architecture designed by Fairchild Semiconductor.
nonlinear neuron-like,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
neuron-like nodes used,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
nonlinear neuron-like nodes used,"Alex Nugent describes a physical neural network as one or more nonlinear neuron-like nodes used to sum signals and nanoconnections formed from nanoparticles, nanowires, or nanotubes which determine the signal strength input to the nodes."
computations-intensive tasks,"However, since transferring information between the processor and the outside world does still dissipate energy, superconducting computing was seen as well-suited for computations-intensive tasks where the data largely stays in the cryogenic environment, rather than big data applications where large amounts of information are streamed from outside the processor."
wire-photo standards conversion,"Many of the techniques of digital image processing, or digital picture processing as it often was called, were developed in the 1960s, at Bell Laboratories, the Jet Propulsion Laboratory, Massachusetts Institute of Technology, University of Maryland, and a few other research facilities, with application to satellite imagery, wire-photo standards conversion, medical imaging, videophone, character recognition, and photograph enhancement."
using support-vector,"Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements."
using support-vector machines,"Multiclass SVM aims to assign labels to instances by using support-vector machines, where the labels are drawn from a finite set of several elements."
look-ahead adders,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
carry look-ahead,A lookahead carry unit (LCU) is a logical unit in digital circuit design used to decrease calculation time in adder units and used in conjunction with carry look-ahead adders (CLAs).
non-symmetric linear programming problems,"The minimum degree algorithm is derived from a method first proposed by Markowitz in 1959 for non-symmetric linear programming problems, which is loosely described as follows."
single-label problem,"Multi-label classification is a generalization of multiclass classification, which is the single-label problem of categorizing instances into precisely one of more than two classes; in the multi-label problem there is no constraint on how many of the classes the instance can be assigned to."
e-type tasks,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
perform concierge-type,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
data-handling tasks based,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
perform concierge-type tasks,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
concierge-type tasks,"There are two types of automated personal assistants: intelligent automated assistants (for example, Apples Siri and Trontons Cluzee), which perform concierge-type tasks (e. g. , making dinner reservations, purchasing event tickets, making travel arrangements) or provide information based on voice input or commands; and smart personal agents, which automatically perform management or data-handling tasks based on online information and events often without user initiation or interaction."
allows multiple high-level,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
allows multiple high-level languages,The Common Language Infrastructure (CLI) is an open specification and technical standard originally developed by Microsoft and standardized by ISO (ISO/IEC 23271) and Ecma International (ECMA 335) that describes executable code and a runtime environment that allows multiple high-level languages to be used on different computer platforms without being rewritten for specific architectures.
context-free composition functions,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
adding potentially non-context,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
adding potentially non-context-free,Generalized context-free grammar (GCFG) is a grammar formalism that expands on context-free grammars by adding potentially non-context-free composition functions to rewrite rules.
64-bit versions,The early MIPS architectures were 32-bit; 64-bit versions were developed later.
many new 32-bit,"During the mid-1990s, many new 32-bit MIPS processors for embedded systems were MIPS II implementations because the introduction of the 64-bit MIPS III architecture in 1991 left MIPS II as the newest 32-bit MIPS architecture until MIPS32 was introduced in 1999. :19MIPS Computer Systems' R4000 microprocessor (1991) was the first MIPS III implementation."
feature-space mathematical analysis technique,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
parametric feature-space,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
called mode-seeking algorithm,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
so-called mode,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
mode-seeking algorithm,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
parametric feature-space mathematical analysis technique,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
non-parametric feature,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
called mode-seeking,"Mean shift is a non-parametric feature-space mathematical analysis technique for locating the maxima of a density function, a so-called mode-seeking algorithm."
infinite-dimensional generalization,Gaussian processes can be seen as an infinite-dimensional generalization of multivariate normal distributions.
integer-valued functions,Number theory (or arithmetic or higher arithmetic in older usage) is a branch of pure mathematics devoted primarily to the study of the integers and integer-valued functions.
well-known examples,"Well-known examples of disk encryption software include: BitLocker for Windows; FileVault for Apple OS/X; LUKS a standard free software mainly for Linux and TrueCrypt, a non-commercial freeware application, for Windows, OS/X and Linux."
cross-linguistic challenges,Different theories have been proposed by linguists to further refine this theory in order to account for cross-linguistic challenges to the Lexical Integrity Hypothesis.
syntactic operations cannot access word-internal,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures."
word-internal structures,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures."
syntactic operations cannot access word-internal structures,"The Lexical Integrity Hypothesis is a subset of the Lexicalist hypothesis, which states that morphology and syntax do not interact, with the result (among others) that some syntactic operations cannot access word-internal structures."
two-group problems,"Early work on statistical classification was undertaken by Fisher, in the context of two-group problems, leading to Fisher's linear discriminant function as the rule for assigning a group to a new observation."
fuzzy-multi layer perceptron,"Connectionist expert systems are artificial neural network (ANN) based expert systems where the ANN generates inferencing rules e. g. , fuzzy-multi layer perceptron where linguistic and natural form of inputs are used."
under-foot pressure patterns,Development of a connectionist expert system to identify foot problems based on under-foot pressure patterns.
information-theoretic method,Minimum message length (MML) is a Bayesian information-theoretic method for statistical model comparison and selection.
non-incident edges,"There are more refined algorithms to cope with some of these issues, for example iterated snap rounding guarantees a ""large"" separation between points and non-incident edges."
semi-automatic creation,"Ontology learning (ontology extraction, ontology generation, or ontology acquisition) is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text, and encoding them with an ontology language for easy retrieval."
user-visible side effects,"Some programming languages allow a program to operate differently or even have a different control flow than the source code, as long as it exhibits the same user-visible side effects, if undefined behavior never happens during program execution."
non-hole entries,"in which the ith term counts the number of partial permutations with support of size i, that is, the number of partial permutations with i non-hole entries."
known-item search,"Exploratory search is distinguished from known-item search, for which the searcher has a particular target in mind."
two-dimensional analog signals,"In electrical engineering and computer science, analog image processing is any image processing task conducted on two-dimensional analog signals by analog means (as opposed to digital image processing)."
high-quality solutions,"Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection."
generate high-quality solutions,"Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection."
generate high-quality,"Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on biologically inspired operators such as mutation, crossover and selection."
low-density subset sum problems,Solving low-density subset sum problems.
heap-ordered trees,"In computer science, a Fibonacci heap is a data structure for priority queue operations, consisting of a collection of heap-ordered trees."
find-minimum operation takes constant,"For the Fibonacci heap, the find-minimum operation takes constant (O(1)) amortized time."
non-constant factor,A Fibonacci heap is thus better than a binary or binomial heap when b is smaller than a by a non-constant factor.
case-based reasoning,"Textual case-based reasoning (TCBR) is a subtopic of case-based reasoning, in short CBR, a popular area in artificial intelligence."
context-aware smart home technologies,"Ubiquitous computing touches on distributed computing, mobile computing, location computing, mobile networking, sensor networks, humancomputer interaction, context-aware smart home technologies, and artificial intelligence."
head-to-head benchmarks,Lossless compression algorithms and their implementations are routinely tested in head-to-head benchmarks.
information-theoretically secure solution,The best known example of quantum cryptography is quantum key distribution which offers an information-theoretically secure solution to the key exchange problem.
non-symmetric matrices,The biconjugate gradient method provides a generalization to non-symmetric matrices.
dht-based routing protocol,"Augmented tree-based routing (ATR) protocol, first proposed in 2007, is a multi-path DHT-based routing protocol for scalable networks."
continuous self-map,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
continuous self-map f,"A topological dynamical system consists of a Hausdorff topological space X (usually assumed to be compact) and a continuous self-map f. Its topological entropy is a nonnegative extended real number that can be defined in various ways, which are known to be equivalent."
may possess human-like qualities,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
may possess human-like,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
human-robot interaction environments,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
human-like qualities,"Software agents interacting with people (e. g. chatbots, human-robot interaction environments) may possess human-like qualities such as natural language understanding and speech, personality or embody humanoid form (see Asimo)."
still computer-generated,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
still computer-generated images,"Thus, ray tracing was first deployed in applications where taking a relatively long time to render could be tolerated, such as in still computer-generated images, and film and television visual effects (VFX), but was less suited to real-time applications such as video games, where speed is critical in rendering each frame."
rasterization-based rendering,"Since 2018, however, hardware acceleration for real-time ray tracing has become standard on new commercial graphics cards, and graphics APIs have followed suit, allowing developers to use hybrid ray tracing and rasterization-based rendering in games and other real-time applications with a lesser hit to frame render times."
c-gap problem,"In computational complexity theory, a gap reduction is a reduction to a particular type of decision problem, known as a c-gap problem."
hardware-maintained structure,"In computing, cache algorithms (also frequently called cache replacement algorithms or cache replacement policies) are optimizing instructions, or algorithms, that a computer program or a hardware-maintained structure can utilize in order to manage a cache of information stored on the computer."
off-diagonal entries,"In mathematics, particularly matrix theory, a Stieltjes matrix, named after Thomas Joannes Stieltjes, is a real symmetric positive definite matrix with nonpositive off-diagonal entries."
z-matrix whose eigenvalues,"From the above definition, a Stieltjes matrix is a symmetric invertible Z-matrix whose eigenvalues have positive real parts."
inter-connected switches,"Further, any computer connected to the same set of inter-connected switches/repeaters is a member of the same broadcast domain."
higher-layer devices form boundaries,Routers and other higher-layer devices form boundaries between broadcast domains.
quarter-pixel motion,Quarter-pixel motion (also known as Q-pel motion or Qpel motion) refers to using a quarter of the distance between pixels (or luma sample positions) as the motion vector precision for motion estimation and motion compensation in video compression schemes.
nist hash function competition,"The SANDstorm hash was accepted into the first round of the NIST hash function competition, but was not accepted into the second round."
engineering applications,Large sparse matrices often appear in scientific or engineering applications when solving partial differential equations.
ibm db2,"In computer science, Algorithms for Recovery and Isolation Exploiting Semantics, or ARIES is a recovery algorithm designed to work with a no-force, steal database approach; it is used by IBM DB2, Microsoft SQL Server and many other database systems."
dtn acronym,"In 2002, Kevin Fall started to adapt some of the ideas in the IPN design to terrestrial networks and coined the term delay-tolerant networking and the DTN acronym."
operating system-level virtualization technology,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
operating system-level,"Solaris Containers (including Solaris Zones) is an implementation of operating system-level virtualization technology for x86 and SPARC systems, first released publicly in February 2004 in build 51 beta of Solaris 10, and subsequently in the first full release of Solaris 10, 2005."
dependence analysis produces execution-order,"In compiler theory, dependence analysis produces execution-order constraints between statements/instructions."
"best-first search""","""Some authors have used ""best-first search"" to refer specifically to a search with a heuristic that attempts to predict how close the end of a path is to a solution (or, goal), so that paths which are judged to be closer to a solution (or, goal) are extended first."
e-mail addresses,"Callback verification, also known as callout verification or Sender Address Verification, is a technique used by SMTP software in order to validate e-mail addresses."
validate e-mail addresses,"Callback verification, also known as callout verification or Sender Address Verification, is a technique used by SMTP software in order to validate e-mail addresses."
e-mail address,"This is commonly done in order to prevent directory harvest attacks and will, by design, give no information about whether an e-mail address is valid and thus prevent callback verification from working."
